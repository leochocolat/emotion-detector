/******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });
/******/ 		}
/******/ 	};
/******/
/******/ 	// define __esModule on exports
/******/ 	__webpack_require__.r = function(exports) {
/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 		}
/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
/******/ 	};
/******/
/******/ 	// create a fake namespace object
/******/ 	// mode & 1: value is a module id, require it
/******/ 	// mode & 2: merge all properties of value into the ns
/******/ 	// mode & 4: return value when already ns object
/******/ 	// mode & 8|1: behave like require
/******/ 	__webpack_require__.t = function(value, mode) {
/******/ 		if(mode & 1) value = __webpack_require__(value);
/******/ 		if(mode & 8) return value;
/******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;
/******/ 		var ns = Object.create(null);
/******/ 		__webpack_require__.r(ns);
/******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });
/******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
/******/ 		return ns;
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = "";
/******/
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = "./src/javascript/index.js");
/******/ })
/************************************************************************/
/******/ ({

/***/ "./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js":
/*!****************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js ***!
  \****************************************************************/
/*! exports provided: AdadeltaOptimizer, AdagradOptimizer, AdamOptimizer, AdamaxOptimizer, DataStorage, ENV, Environment, KernelBackend, MomentumOptimizer, Optimizer, RMSPropOptimizer, Rank, Reduction, SGDOptimizer, Tensor, TensorBuffer, Variable, abs, acos, acosh, add, addN, addStrict, all, any, argMax, argMin, asin, asinh, atan, atan2, atanh, avgPool, avgPool3d, backend, backend_util, basicLSTMCell, batchNorm, batchNorm2d, batchNorm3d, batchNorm4d, batchNormalization, batchNormalization2d, batchNormalization3d, batchNormalization4d, batchToSpaceND, booleanMaskAsync, browser, buffer, cast, ceil, clipByValue, clone, complex, concat, concat1d, concat2d, concat3d, concat4d, conv1d, conv2d, conv2dDerFilter, conv2dDerInput, conv2dTranspose, conv3d, conv3dTranspose, cos, cosh, cumsum, customGrad, deprecationWarn, depthToSpace, depthwiseConv2d, diag, disableDeprecationWarnings, dispose, disposeVariables, div, divStrict, dot, dropout, elu, enableDebugMode, enableProdMode, environment, equal, equalStrict, erf, exp, expandDims, expm1, eye, fft, fill, findBackend, findBackendFactory, floor, floorDiv, frame, fused, gather, gatherND, getBackend, grad, grads, greater, greaterEqual, greaterEqualStrict, greaterStrict, hammingWindow, hannWindow, ifft, imag, image, inTopKAsync, io, irfft, isFinite, isInf, isNaN, keep, leakyRelu, less, lessEqual, lessEqualStrict, lessStrict, linalg, linspace, localResponseNormalization, log, log1p, logSigmoid, logSoftmax, logSumExp, logicalAnd, logicalNot, logicalOr, logicalXor, losses, matMul, math, max, maxPool, maxPool3d, maximum, maximumStrict, mean, memory, min, minimum, minimumStrict, mod, modStrict, moments, movingAverage, mul, mulStrict, multiRNNCell, multinomial, neg, nextFrame, norm, notEqual, notEqualStrict, oneHot, ones, onesLike, op, outerProduct, pad, pad1d, pad2d, pad3d, pad4d, pool, pow, powStrict, prelu, print, prod, profile, rand, randomGamma, randomNormal, randomUniform, range, ready, real, reciprocal, registerBackend, relu, removeBackend, reshape, reverse, reverse1d, reverse2d, reverse3d, reverse4d, rfft, round, rsqrt, scalar, scatterND, selu, separableConv2d, serialization, setBackend, setPlatform, setdiff1dAsync, sigmoid, sign, signal, sin, sinh, slice, slice1d, slice2d, slice3d, slice4d, softmax, softplus, spaceToBatchND, sparseToDense, spectral, split, sqrt, square, squaredDifference, squaredDifferenceStrict, squeeze, stack, step, stft, stridedSlice, sub, subStrict, sum, tan, tanh, tensor, tensor1d, tensor2d, tensor3d, tensor4d, tensor5d, tensor6d, tensor_util, test_util, tidy, tile, time, topk, train, transpose, truncatedNormal, unsortedSegmentSum, unstack, util, valueAndGrad, valueAndGrads, variable, variableGrads, version_core, webgl, where, whereAsync, zeros, zerosLike */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* WEBPACK VAR INJECTION */(function(global, process, Buffer, setImmediate) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AdadeltaOptimizer\", function() { return xp; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AdagradOptimizer\", function() { return bp; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AdamOptimizer\", function() { return wp; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AdamaxOptimizer\", function() { return Cp; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DataStorage\", function() { return Jr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ENV\", function() { return i; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Environment\", function() { return o; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"KernelBackend\", function() { return Zr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"MomentumOptimizer\", function() { return Rp; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Optimizer\", function() { return yp; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"RMSPropOptimizer\", function() { return Ip; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Rank\", function() { return pt; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Reduction\", function() { return Sc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SGDOptimizer\", function() { return Ep; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Tensor\", function() { return ct; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TensorBuffer\", function() { return it; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Variable\", function() { return ht; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"abs\", function() { return Es; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"acos\", function() { return Rs; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"acosh\", function() { return Is; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"add\", function() { return Ru; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"addN\", function() { return Iu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"addStrict\", function() { return ku; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"all\", function() { return zl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"any\", function() { return Gl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"argMax\", function() { return Hl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"argMin\", function() { return ql; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"asin\", function() { return ks; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"asinh\", function() { return Ns; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"atan\", function() { return Ss; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"atan2\", function() { return Nu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"atanh\", function() { return As; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"avgPool\", function() { return _l; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"avgPool3d\", function() { return Ml; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"backend\", function() { return Qe; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"backend_util\", function() { return xo; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"basicLSTMCell\", function() { return sc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"batchNorm\", function() { return du; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"batchNorm2d\", function() { return vu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"batchNorm3d\", function() { return mu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"batchNorm4d\", function() { return gu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"batchNormalization\", function() { return fu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"batchNormalization2d\", function() { return cu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"batchNormalization3d\", function() { return hu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"batchNormalization4d\", function() { return pu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"batchToSpaceND\", function() { return er; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"booleanMaskAsync\", function() { return sl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"browser\", function() { return ap; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"buffer\", function() { return Zn; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"cast\", function() { return nr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ceil\", function() { return Ts; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"clipByValue\", function() { return Ds; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"clone\", function() { return rr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"complex\", function() { return mn; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"concat\", function() { return Mn; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"concat1d\", function() { return Bn; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"concat2d\", function() { return Pn; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"concat3d\", function() { return Ln; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"concat4d\", function() { return Wn; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"conv1d\", function() { return pl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"conv2d\", function() { return fl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"conv2dDerFilter\", function() { return vl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"conv2dDerInput\", function() { return ml; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"conv2dTranspose\", function() { return xl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"conv3d\", function() { return dl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"conv3dTranspose\", function() { return bl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"cos\", function() { return _s; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"cosh\", function() { return Os; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"cumsum\", function() { return or; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"customGrad\", function() { return jr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"deprecationWarn\", function() { return Be; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"depthToSpace\", function() { return ar; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"depthwiseConv2d\", function() { return gl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"diag\", function() { return bc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"disableDeprecationWarnings\", function() { return Me; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"dispose\", function() { return Ve; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"disposeVariables\", function() { return Pe; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"div\", function() { return Su; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"divStrict\", function() { return Au; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"dot\", function() { return Cl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"dropout\", function() { return wc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"elu\", function() { return Zl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"enableDebugMode\", function() { return Fe; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"enableProdMode\", function() { return Oe; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"environment\", function() { return u; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"equal\", function() { return qu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"equalStrict\", function() { return $u; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"erf\", function() { return Fs; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"exp\", function() { return Ms; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"expandDims\", function() { return ir; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"expm1\", function() { return Bs; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"eye\", function() { return sr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"fft\", function() { return fc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"fill\", function() { return Tn; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"findBackend\", function() { return je; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"findBackendFactory\", function() { return Xe; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"floor\", function() { return Ps; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"floorDiv\", function() { return Tu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"frame\", function() { return Ic; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"fused\", function() { return Zc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"gather\", function() { return al; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"gatherND\", function() { return xc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getBackend\", function() { return $e; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"grad\", function() { return Gr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"grads\", function() { return Hr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"greater\", function() { return Ku; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"greaterEqual\", function() { return ju; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"greaterEqualStrict\", function() { return Xu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"greaterStrict\", function() { return Yu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"hammingWindow\", function() { return Rc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"hannWindow\", function() { return Ec; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ifft\", function() { return dc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"imag\", function() { return yn; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"image\", function() { return Yc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"inTopKAsync\", function() { return Ac; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"io\", function() { return ep; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"irfft\", function() { return mc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isFinite\", function() { return Xs; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isInf\", function() { return js; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isNaN\", function() { return Ks; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"keep\", function() { return ze; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"leakyRelu\", function() { return tc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"less\", function() { return Qu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"lessEqual\", function() { return Ju; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"lessEqualStrict\", function() { return Zu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"lessStrict\", function() { return tl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"linalg\", function() { return Gc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"linspace\", function() { return Dn; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"localResponseNormalization\", function() { return ac; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"log\", function() { return Ls; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"log1p\", function() { return Ws; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"logSigmoid\", function() { return Us; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"logSoftmax\", function() { return Qr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"logSumExp\", function() { return $l; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"logicalAnd\", function() { return yu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"logicalNot\", function() { return xu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"logicalOr\", function() { return bu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"logicalXor\", function() { return wu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"losses\", function() { return Wc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"matMul\", function() { return wl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"math\", function() { return rp; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"max\", function() { return Kl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"maxPool\", function() { return Dl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"maxPool3d\", function() { return Fl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"maximum\", function() { return Du; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"maximumStrict\", function() { return _u; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"mean\", function() { return jl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"memory\", function() { return Le; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"min\", function() { return Xl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"minimum\", function() { return Ou; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"minimumStrict\", function() { return Fu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"mod\", function() { return Mu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"modStrict\", function() { return Bu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"moments\", function() { return Yl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"movingAverage\", function() { return lc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"mul\", function() { return Pu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"mulStrict\", function() { return Lu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"multiRNNCell\", function() { return uc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"multinomial\", function() { return ur; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"neg\", function() { return Vs; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"nextFrame\", function() { return Ap; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"norm\", function() { return ic; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"notEqual\", function() { return el; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"notEqualStrict\", function() { return nl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"oneHot\", function() { return lr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ones\", function() { return Sn; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"onesLike\", function() { return On; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"op\", function() { return vn; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"outerProduct\", function() { return El; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"pad\", function() { return cr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"pad1d\", function() { return hr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"pad2d\", function() { return pr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"pad3d\", function() { return fr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"pad4d\", function() { return dr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"pool\", function() { return Ol; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"pow\", function() { return Wu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"powStrict\", function() { return Uu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"prelu\", function() { return ec; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"print\", function() { return tr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"prod\", function() { return Jl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"profile\", function() { return We; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"rand\", function() { return vr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"randomGamma\", function() { return gr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"randomNormal\", function() { return mr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"randomUniform\", function() { return yr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"range\", function() { return _n; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ready\", function() { return qe; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"real\", function() { return gn; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"reciprocal\", function() { return zs; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"registerBackend\", function() { return Ye; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"relu\", function() { return nc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"removeBackend\", function() { return Ke; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"reshape\", function() { return xr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"reverse\", function() { return Rl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"reverse1d\", function() { return Il; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"reverse2d\", function() { return kl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"reverse3d\", function() { return Nl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"reverse4d\", function() { return Sl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"rfft\", function() { return vc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"round\", function() { return Gs; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"rsqrt\", function() { return Hs; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"scalar\", function() { return wn; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"scatterND\", function() { return pc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"selu\", function() { return rc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"separableConv2d\", function() { return yl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"serialization\", function() { return lp; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"setBackend\", function() { return He; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"setPlatform\", function() { return Je; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"setdiff1dAsync\", function() { return kr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"sigmoid\", function() { return qs; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"sign\", function() { return $s; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"signal\", function() { return Nc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"sin\", function() { return Ys; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"sinh\", function() { return Qs; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"slice\", function() { return Bl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"slice1d\", function() { return Pl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"slice2d\", function() { return Ll; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"slice3d\", function() { return Wl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"slice4d\", function() { return Ul; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"softmax\", function() { return Yr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"softplus\", function() { return Js; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"spaceToBatchND\", function() { return br; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"sparseToDense\", function() { return yc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"spectral\", function() { return gc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"split\", function() { return Un; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"sqrt\", function() { return Zs; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"square\", function() { return tu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"squaredDifference\", function() { return Vu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"squaredDifferenceStrict\", function() { return zu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"squeeze\", function() { return wr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"stack\", function() { return Cr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"step\", function() { return eu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"stft\", function() { return kc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"stridedSlice\", function() { return cc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"sub\", function() { return Gu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"subStrict\", function() { return Hu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"sum\", function() { return Ql; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"tan\", function() { return nu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"tanh\", function() { return ru; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"tensor\", function() { return xn; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"tensor1d\", function() { return Cn; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"tensor2d\", function() { return En; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"tensor3d\", function() { return Rn; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"tensor4d\", function() { return In; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"tensor5d\", function() { return kn; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"tensor6d\", function() { return Nn; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"tensor_util\", function() { return It; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"test_util\", function() { return vp; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"tidy\", function() { return Ue; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"tile\", function() { return Er; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"time\", function() { return Ge; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"topk\", function() { return hc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"train\", function() { return Np; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"transpose\", function() { return oc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"truncatedNormal\", function() { return Rr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"unsortedSegmentSum\", function() { return il; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"unstack\", function() { return Ir; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"util\", function() { return Y; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"valueAndGrad\", function() { return qr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"valueAndGrads\", function() { return $r; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"variable\", function() { return gt; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"variableGrads\", function() { return Kr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"version_core\", function() { return mp; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"webgl\", function() { return gp; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"where\", function() { return Cu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"whereAsync\", function() { return Eu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"zeros\", function() { return An; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"zerosLike\", function() { return Fn; });\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar t=function(e,n){return(t=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(t,e){t.__proto__=e}||function(t,e){for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n])})(e,n)};function e(e,n){function r(){this.constructor=e}t(e,n),e.prototype=null===n?Object.create(n):(r.prototype=n.prototype,new r)}function n(t,e,n,r){return new(n||(n=Promise))(function(o,a){function i(t){try{u(r.next(t))}catch(t){a(t)}}function s(t){try{u(r.throw(t))}catch(t){a(t)}}function u(t){t.done?o(t.value):new n(function(e){e(t.value)}).then(i,s)}u((r=r.apply(t,e||[])).next())})}function r(t,e){var n,r,o,a,i={label:0,sent:function(){if(1&o[0])throw o[1];return o[1]},trys:[],ops:[]};return a={next:s(0),throw:s(1),return:s(2)},\"function\"==typeof Symbol&&(a[Symbol.iterator]=function(){return this}),a;function s(a){return function(s){return function(a){if(n)throw new TypeError(\"Generator is already executing.\");for(;i;)try{if(n=1,r&&(o=2&a[0]?r.return:a[0]?r.throw||((o=r.return)&&o.call(r),0):r.next)&&!(o=o.call(r,a[1])).done)return o;switch(r=0,o&&(a=[2&a[0],o.value]),a[0]){case 0:case 1:o=a;break;case 4:return i.label++,{value:a[1],done:!1};case 5:i.label++,r=a[1],a=[0];continue;case 7:a=i.ops.pop(),i.trys.pop();continue;default:if(!(o=(o=i.trys).length>0&&o[o.length-1])&&(6===a[0]||2===a[0])){i=0;continue}if(3===a[0]&&(!o||a[1]>o[0]&&a[1]<o[3])){i.label=a[1];break}if(6===a[0]&&i.label<o[1]){i.label=o[1],o=a;break}if(o&&i.label<o[2]){i.label=o[2],i.ops.push(a);break}o[2]&&i.ops.pop(),i.trys.pop();continue}a=e.call(t,i)}catch(t){a=[6,t],r=0}finally{n=o=0}if(5&a[0])throw a[1];return{value:a[0]?a[1]:void 0,done:!0}}([a,s])}}}var o=function(){function t(t){this.global=t,this.flags={},this.flagRegistry={},this.urlFlags={},this.populateURLFlags()}return t.prototype.setPlatform=function(t,e){null!=this.platform&&console.warn(\"Platform \"+this.platformName+\" has already been set. Overwriting the platform with \"+e+\".\"),this.platformName=t,this.platform=e},t.prototype.registerFlag=function(t,e,n){if(this.flagRegistry[t]={evaluationFn:e,setHook:n},null!=this.urlFlags[t]){var r=this.urlFlags[t];console.warn(\"Setting feature override from URL \"+t+\": \"+r+\".\"),this.set(t,r)}},t.prototype.get=function(t){return t in this.flags?this.flags[t]:(this.flags[t]=this.evaluateFlag(t),this.flags[t])},t.prototype.getNumber=function(t){return this.get(t)},t.prototype.getBool=function(t){return this.get(t)},t.prototype.getFlags=function(){return this.flags},Object.defineProperty(t.prototype,\"features\",{get:function(){return this.flags},enumerable:!0,configurable:!0}),t.prototype.set=function(t,e){if(null==this.flagRegistry[t])throw new Error(\"Cannot set flag \"+t+\" as it has not been registered.\");this.flags[t]=e,null!=this.flagRegistry[t].setHook&&this.flagRegistry[t].setHook(e)},t.prototype.evaluateFlag=function(t){if(null==this.flagRegistry[t])throw new Error(\"Cannot evaluate flag '\"+t+\"': no evaluation function found.\");return this.flagRegistry[t].evaluationFn()},t.prototype.setFlags=function(t){this.flags=Object.assign({},t)},t.prototype.reset=function(){this.flags={},this.urlFlags={},this.populateURLFlags()},t.prototype.populateURLFlags=function(){var t=this;if(void 0!==this.global&&void 0!==this.global.location&&void 0!==this.global.location.search){var e=a(this.global.location.search);if(\"tfjsflags\"in e)e.tfjsflags.split(\",\").forEach(function(e){var n=e.split(\":\"),r=n[0],o=n[1];t.urlFlags[r]=function(t,e){if(\"true\"===(e=e.toLowerCase())||\"false\"===e)return\"true\"===e;if(\"\"+ +e===e)return+e;throw new Error(\"Could not parse value flag value \"+e+\" for flag \"+t+\".\")}(r,o)})}},t}();function a(t){var e={};return t.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g,function(t){for(var n=[],r=1;r<arguments.length;r++)n[r-1]=arguments[r];return function(t,e,n){t[decodeURIComponent(e)]=decodeURIComponent(n||\"\")}(e,n[0],n[1]),n.join(\"=\")}),e}var i=null;function s(t){i=t}var u=Object.freeze({Environment:o,getQueryParams:a,get ENV(){return i},setEnvironmentGlobal:s});function l(t){for(var e=t.length,n=0,r=0;e>0;)r=Math.random()*e|0,n=t[--e],t[e]=t[r],t[r]=n}function c(t,e,n){return Math.max(t,Math.min(e,n))}function h(t){return t%2==0?t:t+1}function p(t){for(var e=0,n=0;n<t.length;n++)e+=t[n];return e}function f(t,e){if(!t)throw new Error(\"string\"==typeof e?e:e())}function d(t,e,n){void 0===n&&(n=\"\"),f(y(t,e),function(){return n+\" Shapes \"+t+\" and \"+e+\" must match\"})}function v(t){f(null!=t,function(){return\"The input to the tensor constructor must be a non-null value.\"})}function m(t,e,n){if(void 0===e&&(e=[]),void 0===n&&(n=!1),null==e&&(e=[]),Array.isArray(t)||_(t)&&!n)for(var r=0;r<t.length;++r)m(t[r],e,n);else e.push(t);return e}function g(t){if(0===t.length)return 1;for(var e=t[0],n=1;n<t.length;n++)e*=t[n];return e}function y(t,e){if(t===e)return!0;if(null==t||null==e)return!1;if(t.length!==e.length)return!1;for(var n=0;n<t.length;n++)if(t[n]!==e[n])return!1;return!0}function x(t){return t%1==0}function b(t){if(null!=Math.tanh)return Math.tanh(t);if(t===1/0)return 1;if(t===-1/0)return-1;var e=Math.exp(2*t);return(e-1)/(e+1)}function w(t){var e=Math.ceil(Math.sqrt(t));return[e,Math.ceil(t/e)]}function C(t,e){return e<=t.length?t:t+\" \".repeat(e-t.length)}function E(t,e,n){return void 0===e&&(e=function(t){return 0}),new Promise(function(r,o){var a=0,i=function(){if(t())r();else{var s=e(++a);null!=n&&a>=n?o():setTimeout(i,s)}};i()})}function R(t,e){for(var n=1,r=-1,o=0;o<t.length;++o)if(t[o]>=0)n*=t[o];else if(-1===t[o]){if(-1!==r)throw Error(\"Shapes can only have 1 implicit size. Found -1 at dim \"+r+\" and dim \"+o);r=o}else if(t[o]<0)throw Error(\"Shapes can not be < 0. Found \"+t[o]+\" at dim \"+o);if(-1===r){if(e>0&&e!==n)throw Error(\"Size(\"+e+\") must match the product of shape \"+t);return t}if(0===n)throw Error(\"Cannot infer the missing size in [\"+t+\"] when there are 0 elements\");if(e%n!=0)throw Error(\"The implicit shape can't be a fractional number. Got \"+e+\" / \"+n);var a=t.slice();return a[r]=e/n,a}function I(t,e){var n=e.length;return f((t=null==t?e.map(function(t,e){return e}):[].concat(t)).every(function(t){return t>=-n&&t<n}),function(){return\"All values in axis param must be in range [-\"+n+\", \"+n+\") but got axis \"+t}),f(t.every(function(t){return x(t)}),function(){return\"All values in axis param must be integers but got axis \"+t}),t.map(function(t){return t<0?n+t:t})}function k(t,e){for(var n=[],r=[],o=null!=e&&Array.isArray(e)&&0===e.length,a=null==e||o?null:I(e,t).sort(),i=0,s=0;s<t.length;++s){if(null!=a){if(a[i]===s&&1!==t[s])throw new Error(\"Can't squeeze axis \"+s+\" since its dim '\"+t[s]+\"' is not 1\");(null==a[i]||a[i]>s)&&1===t[s]&&(n.push(t[s]),r.push(s)),a[i]<=s&&i++}1!==t[s]&&(n.push(t[s]),r.push(s))}return{newShape:n,keptDims:r}}function N(t,e){var n=null;if(null==t||\"float32\"===t)n=new Float32Array(e);else if(\"int32\"===t)n=new Int32Array(e);else{if(\"bool\"!==t)throw new Error(\"Unknown data type \"+t);n=new Uint8Array(e)}return n}function S(t,e){var n=null;if(null==t||\"float32\"===t)n=new Float32Array(e);else if(\"int32\"===t)n=new Int32Array(e);else if(\"bool\"===t)n=new Uint8Array(e);else{if(\"string\"!==t)throw new Error(\"Unknown data type \"+t);n=new Array(e)}return n}function A(t,e){for(var n=0;n<t.length;n++){var r=t[n];if(isNaN(r)||!isFinite(r))throw Error(\"A tensor of type \"+e+\" being uploaded contains \"+r+\".\")}}function T(t){return\"bool\"===t||\"complex64\"===t||\"float32\"===t||\"int32\"===t||\"string\"===t}function D(t,e){return\"complex64\"!==e&&((\"float32\"!==e||\"complex64\"===t)&&((\"int32\"!==e||\"float32\"===t||\"complex64\"===t)&&(\"bool\"!==e||\"bool\"!==t)))}function _(t){return t instanceof Float32Array||t instanceof Int32Array||t instanceof Uint8Array}function O(t){if(\"float32\"===t||\"int32\"===t)return 4;if(\"complex64\"===t)return 8;if(\"bool\"===t)return 1;throw new Error(\"Unknown dtype \"+t)}function F(t){if(null==t)return 0;var e=0;return t.forEach(function(t){return e+=t.length}),e}function M(t){return\"string\"==typeof t||t instanceof String}function B(t){return\"boolean\"==typeof t}function P(t){return\"number\"==typeof t}function L(t){return Array.isArray(t)?L(t[0]):t instanceof Float32Array?\"float32\":t instanceof Int32Array||t instanceof Uint8Array?\"int32\":P(t)?\"float32\":M(t)?\"string\":B(t)?\"bool\":\"float32\"}function W(t){return!!(t&&t.constructor&&t.call&&t.apply)}function U(t,e){for(var n=e;n<t;++n)if(t%n==0)return n;return t}function V(t){var e=t.length;if(e<2)return[];var n=new Array(e-1);n[e-2]=t[e-1];for(var r=e-3;r>=0;--r)n[r]=n[r+1]*t[r+1];return n}function z(t,e,n){if(\"string\"===e)throw new Error(\"Cannot convert a string[] to a TypedArray\");if(Array.isArray(t)&&(t=m(t)),n&&A(t,e),function(t,e){return t instanceof Float32Array&&\"float32\"===e||t instanceof Int32Array&&\"int32\"===e||t instanceof Uint8Array&&\"bool\"===e}(t,e))return t;if(null==e||\"float32\"===e||\"complex64\"===e)return new Float32Array(t);if(\"int32\"===e)return new Int32Array(t);if(\"bool\"===e){for(var r=new Uint8Array(t.length),o=0;o<r.length;++o)0!==Math.round(t[o])&&(r[o]=1);return r}throw new Error(\"Unknown data type \"+e)}function G(t,e){if(0===t.length)return e[0];var n=t.reduce(function(t,e){return t*e});if(0===n)return[];if(n!==e.length)throw new Error(\"[\"+t+\"] does not match the input size.\");return function t(e,n,r){var o=new Array;if(1===n.length)for(var a=n[0],i=0;i<a;i++)o[i]=r[e+i];else{a=n[0];var s=n.slice(1),u=s.reduce(function(t,e){return t*e});for(i=0;i<a;i++)o[i]=t(e+i*u,s,r)}return o}(0,t,e)}function H(t,e){for(var n=q(t,e),r=0;r<n.length;r++)n[r]=1;return n}function q(t,e){if(null==e||\"float32\"===e||\"complex64\"===e)return new Float32Array(t);if(\"int32\"===e)return new Int32Array(t);if(\"bool\"===e)return new Uint8Array(t);throw new Error(\"Unknown data type \"+e)}function $(){return i.platform.now()}function K(t){t.forEach(function(e){f(Number.isInteger(e)&&e>=0,function(){return\"Tensor must have a shape comprised of positive integers but got shape [\"+t+\"].\"})})}function j(t,e){return void 0===e&&(e=\"utf-8\"),e=e||\"utf-8\",i.platform.encode(t,e)}function X(t,e){return void 0===e&&(e=\"utf-8\"),e=e||\"utf-8\",i.platform.decode(t,e)}var Y=Object.freeze({shuffle:l,clamp:c,nearestLargerEven:h,sum:p,randUniform:function(t,e){var n=Math.random();return e*n+(1-n)*t},distSquared:function(t,e){for(var n=0,r=0;r<t.length;r++){var o=Number(t[r])-Number(e[r]);n+=o*o}return n},assert:f,assertShapesMatch:d,assertNonNull:v,flatten:m,sizeFromShape:g,isScalarShape:function(t){return 0===t.length},arraysEqual:y,isInt:x,tanh:b,sizeToSquarishShape:w,createShuffledIndices:function(t){for(var e=new Uint32Array(t),n=0;n<t;++n)e[n]=n;return l(e),e},rightPad:C,repeatedTry:E,inferFromImplicitShape:R,parseAxisParam:I,squeezeShape:k,getTypedArrayFromDType:N,getArrayFromDType:S,checkConversionForErrors:A,isValidDtype:T,hasEncodingLoss:D,isTypedArray:_,bytesPerElement:O,bytesFromStringArray:F,isString:M,isBoolean:B,isNumber:P,inferDtype:L,isFunction:W,nearestDivisor:U,computeStrides:V,toTypedArray:z,toNestedArray:G,makeOnesTypedArray:H,makeZerosTypedArray:q,now:$,assertNonNegativeIntegerDimensions:K,fetch:function(t,e){return i.platform.fetch(t,e)},encodeString:j,decodeString:X}),Q=function(){function t(t,e){this.backendTimer=t,this.logger=e,null==e&&(this.logger=new J)}return t.prototype.profileKernel=function(t,e,n){var r,o=this,a=this.backendTimer.time(function(){r=n()});return(Array.isArray(r)?r:[r]).forEach(function(n){n.data().then(function(r){!function(t,e,n){if(\"float32\"!==e)return!1;for(var r=0;r<t.length;r++){var o=t[r];if(isNaN(o)||!isFinite(o))return console.warn(\"Found \"+o+\" in the result of '\"+n+\"'\"),!0}}(r,n.dtype,t),a.then(function(a){var i=\"\";null!=a.getExtraProfileInfo&&(i=a.getExtraProfileInfo()),o.logger.logKernelProfile(t,n,r,a.kernelMs,e,i)})})}),r},t}();var J=function(){function t(){}return t.prototype.logKernelProfile=function(t,e,n,r,o,a){var i=C(r+\"ms\",9),s=C(t,25),u=e.rank,l=e.size,c=C(e.shape.toString(),14),h=\"\";for(var p in o){var f=o[p].shape,d=f.length;h+=p+\": \"+d+\"D \"+(d>0?f:\"\")+\" \"}console.log(\"%c\"+s+\"\\t%c\"+i+\"\\t%c\"+u+\"D \"+c+\"\\t%c\"+l+\"\\t%c\"+h+\"\\t%c\"+a,\"font-weight:bold\",\"color:red\",\"color:blue\",\"color: orange\",\"color: green\",\"color: steelblue\")},t}(),Z=20,tt=3,et=7;function nt(t,e,n,r){var o=V(e),a=function(t,e,n,r){var o=g(e),a=r[r.length-1],i=new Array(a).fill(0),s=e.length,u=\"complex64\"===n?at(t):t;if(s>1)for(var l=0;l<o/a;l++)for(var c=l*a,h=0;h<a;h++)i[h]=Math.max(i[h],rt(u[c+h],0,n).length);return i}(t,e,n,o),i=e.length,s=function t(e,n,r,o,a,i){void 0===i&&(i=!0);var s=\"complex64\"===r?2:1;var u=n[0];var l=n.length;if(0===l){if(\"complex64\"===r){var c=at(e);return[rt(c[0],0,r)]}return\"bool\"===r?[ot(e[0])]:[e[0].toString()]}if(1===l){if(u>Z){var h=tt*s,p=Array.from(e.slice(0,h)),f=Array.from(e.slice(u-tt*s,u));return\"complex64\"===r&&(p=at(p),f=at(f)),[\"[\"+p.map(function(t,e){return rt(t,a[e],r)}).join(\", \")+\", ..., \"+f.map(function(t,e){return rt(t,a[u-tt+e],r)}).join(\", \")+\"]\"]}var d=\"complex64\"===r?at(e):Array.from(e);return[\"[\"+d.map(function(t,e){return rt(t,a[e],r)}).join(\", \")+\"]\"]}var v=n.slice(1);var m=o.slice(1);var g=o[0]*s;var y=[];if(u>Z){for(var x=0;x<tt;x++){var b=x*g,w=b+g;y.push.apply(y,t(e.slice(b,w),v,r,m,a,!1))}y.push(\"...\");for(var x=u-tt;x<u;x++){var b=x*g,w=b+g;y.push.apply(y,t(e.slice(b,w),v,r,m,a,x===u-1))}}else for(var x=0;x<u;x++){var b=x*g,w=b+g;y.push.apply(y,t(e.slice(b,w),v,r,m,a,x===u-1))}var C=2===l?\",\":\"\";y[0]=\"[\"+y[0]+C;for(var x=1;x<y.length-1;x++)y[x]=\" \"+y[x]+C;var E=\",\\n\";for(var x=2;x<l;x++)E+=\"\\n\";y[y.length-1]=\" \"+y[y.length-1]+\"]\"+(i?\"\":E);return y}(t,e,n,o,a),u=[\"Tensor\"];return r&&(u.push(\"  dtype: \"+n),u.push(\"  rank: \"+i),u.push(\"  shape: [\"+e+\"]\"),u.push(\"  values:\")),u.push(s.map(function(t){return\"    \"+t}).join(\"\\n\")),u.join(\"\\n\")}function rt(t,e,n){return C(Array.isArray(t)?parseFloat(t[0].toFixed(et))+\" + \"+parseFloat(t[1].toFixed(et))+\"j\":M(t)?\"'\"+t+\"'\":\"bool\"===n?ot(t):parseFloat(t.toFixed(et)).toString(),e)}function ot(t){return 0===t?\"false\":\"true\"}function at(t){for(var e=[],n=0;n<t.length;n+=2)e.push([t[n],t[n+1]]);return e}var it=function(){function t(t,e,n){var r=this;if(this.dtype=e,this.shape=t.slice(),this.size=g(t),null!=n){var o=n.length;f(o===this.size,function(){return\"Length of values '\"+o+\"' does not match the size inferred by the shape '\"+r.size+\"'.\"})}if(\"complex64\"===e)throw new Error(\"complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).\");this.values=n||S(e,this.size),this.strides=V(t)}return t.prototype.set=function(t){for(var e=this,n=[],r=1;r<arguments.length;r++)n[r-1]=arguments[r];0===n.length&&(n=[0]),f(n.length===this.rank,function(){return\"The number of provided coordinates (\"+n.length+\") must match the rank (\"+e.rank+\")\"});var o=this.locToIndex(n);this.values[o]=t},t.prototype.get=function(){for(var t=[],e=0;e<arguments.length;e++)t[e]=arguments[e];0===t.length&&(t=[0]);for(var n=0,r=0,o=t;r<o.length;r++){var a=o[r];if(a<0||a>=this.shape[n]){var i=\"Requested out of range element at \"+t+\".   Buffer shape=\"+this.shape;throw new Error(i)}n++}for(var s=t[t.length-1],u=0;u<t.length-1;++u)s+=this.strides[u]*t[u];return this.values[s]},t.prototype.locToIndex=function(t){if(0===this.rank)return 0;if(1===this.rank)return t[0];for(var e=t[t.length-1],n=0;n<t.length-1;++n)e+=this.strides[n]*t[n];return e},t.prototype.indexToLoc=function(t){if(0===this.rank)return[];if(1===this.rank)return[t];for(var e=new Array(this.shape.length),n=0;n<e.length-1;++n)e[n]=Math.floor(t/this.strides[n]),t-=e[n]*this.strides[n];return e[e.length-1]=t,e},Object.defineProperty(t.prototype,\"rank\",{get:function(){return this.shape.length},enumerable:!0,configurable:!0}),t.prototype.toTensor=function(){return ct.make(this.shape,{values:this.values},this.dtype)},t}(),st=null,ut=null,lt=null;var ct=function(){function t(t,e,n,r,o){this.kept=!1,this.isDisposedInternal=!1,this.shape=t.slice(),this.dtype=e||\"float32\",this.size=g(t),this.strides=V(t),this.dataId=null!=r?r:{},this.id=st().nextTensorId(),this.rankType=this.rank<5?this.rank.toString():\"higher\",st().registerTensor(this,o),null!=n&&st().write(o,this.dataId,n)}return t.make=function(e,n,r,o){var a=n.values;return null!=n.values&&\"string\"===r&&M(n.values[0])&&(a=n.values.map(function(t){return j(t)})),new t(e,r,a,n.dataId,o)},t.prototype.flatten=function(){return this.throwIfDisposed(),this.as1D()},t.prototype.asScalar=function(){return this.throwIfDisposed(),f(1===this.size,function(){return\"The array must have only 1 element.\"}),this.reshape([])},t.prototype.as1D=function(){return this.throwIfDisposed(),this.reshape([this.size])},t.prototype.as2D=function(t,e){return this.throwIfDisposed(),this.reshape([t,e])},t.prototype.as3D=function(t,e,n){return this.throwIfDisposed(),this.reshape([t,e,n])},t.prototype.as4D=function(t,e,n,r){return this.throwIfDisposed(),this.reshape([t,e,n,r])},t.prototype.as5D=function(t,e,n,r,o){return this.throwIfDisposed(),this.reshape([t,e,n,r,o])},t.prototype.asType=function(t){return this.throwIfDisposed(),ut.cast(this,t)},Object.defineProperty(t.prototype,\"rank\",{get:function(){return this.shape.length},enumerable:!0,configurable:!0}),t.prototype.buffer=function(){return n(this,void 0,void 0,function(){var t;return r(this,function(e){switch(e.label){case 0:return[4,this.data()];case 1:return t=e.sent(),[2,ut.buffer(this.shape,this.dtype,t)]}})})},t.prototype.bufferSync=function(){return ut.buffer(this.shape,this.dtype,this.dataSync())},t.prototype.array=function(){return n(this,void 0,void 0,function(){var t;return r(this,function(e){switch(e.label){case 0:return[4,this.data()];case 1:return t=e.sent(),[2,G(this.shape,t)]}})})},t.prototype.arraySync=function(){return G(this.shape,this.dataSync())},t.prototype.data=function(){return n(this,void 0,void 0,function(){var t,e;return r(this,function(n){switch(n.label){case 0:return this.throwIfDisposed(),t=st().read(this.dataId),\"string\"!==this.dtype?[3,2]:[4,t];case 1:e=n.sent();try{return[2,e.map(function(t){return X(t)})]}catch(t){throw new Error(\"Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().\")}n.label=2;case 2:return[2,t]}})})},t.prototype.dataSync=function(){this.throwIfDisposed();var t=st().readSync(this.dataId);if(\"string\"===this.dtype)try{return t.map(function(t){return X(t)})}catch(t){throw new Error(\"Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().\")}return t},t.prototype.bytes=function(){return n(this,void 0,void 0,function(){var t;return r(this,function(e){switch(e.label){case 0:return this.throwIfDisposed(),[4,st().read(this.dataId)];case 1:return t=e.sent(),\"string\"===this.dtype?[2,t]:[2,new Uint8Array(t.buffer)]}})})},t.prototype.dispose=function(){this.isDisposed||(st().disposeTensor(this),this.isDisposedInternal=!0)},Object.defineProperty(t.prototype,\"isDisposed\",{get:function(){return this.isDisposedInternal},enumerable:!0,configurable:!0}),t.prototype.throwIfDisposed=function(){if(this.isDisposed)throw new Error(\"Tensor is disposed.\")},t.prototype.toFloat=function(){return this.asType(\"float32\")},t.prototype.toInt=function(){return this.asType(\"int32\")},t.prototype.toBool=function(){return this.asType(\"bool\")},t.prototype.print=function(t){return void 0===t&&(t=!1),ut.print(this,t)},t.prototype.reshape=function(t){return this.throwIfDisposed(),ut.reshape(this,t)},t.prototype.reshapeAs=function(t){return this.throwIfDisposed(),this.reshape(t.shape)},t.prototype.expandDims=function(t){return void 0===t&&(t=0),ut.expandDims(this,t)},t.prototype.cumsum=function(t,e,n){return void 0===t&&(t=0),void 0===e&&(e=!1),void 0===n&&(n=!1),ut.cumsum(this,t,e,n)},t.prototype.squeeze=function(t){return this.throwIfDisposed(),ut.squeeze(this,t)},t.prototype.clone=function(){return this.throwIfDisposed(),ut.clone(this)},t.prototype.oneHot=function(t,e,n){return this.throwIfDisposed(),ut.oneHot(this,t,e,n)},t.prototype.toString=function(t){return void 0===t&&(t=!1),nt(this.dataSync(),this.shape,this.dtype,t)},t.prototype.tile=function(t){return this.throwIfDisposed(),ut.tile(this,t)},t.prototype.gather=function(t,e){return void 0===e&&(e=0),this.throwIfDisposed(),ut.gather(this,t,e)},t.prototype.matMul=function(t,e,n){return void 0===e&&(e=!1),void 0===n&&(n=!1),this.throwIfDisposed(),ut.matMul(this,t,e,n)},t.prototype.dot=function(t){return this.throwIfDisposed(),ut.dot(this,t)},t.prototype.norm=function(t,e,n){return void 0===t&&(t=\"euclidean\"),void 0===e&&(e=null),void 0===n&&(n=!1),this.throwIfDisposed(),ut.norm(this,t,e,n)},t.prototype.slice=function(t,e){return this.throwIfDisposed(),ut.slice(this,t,e)},t.prototype.reverse=function(t){return this.throwIfDisposed(),ut.reverse(this,t)},t.prototype.concat=function(e,n){return void 0===n&&(n=0),this.throwIfDisposed(),e instanceof t&&(e=[e]),ut.concat([this].concat(e),n)},t.prototype.split=function(t,e){return void 0===e&&(e=0),this.throwIfDisposed(),ut.split(this,t,e)},t.prototype.stack=function(t,e){return void 0===e&&(e=0),ut.stack([this,t],e)},t.prototype.unstack=function(t){return void 0===t&&(t=0),ut.unstack(this,t)},t.prototype.pad=function(t,e){return void 0===e&&(e=0),ut.pad(this,t,e)},t.prototype.batchNormalization=function(t,e,n,r,o){return void 0===n&&(n=.001),lt(\"tf.batchNormalization() is going away. Use tf.batchNorm() instead, and note the positional argument change of scale, offset, and varianceEpsilon\"),this.batchNorm(t,e,o,r,n)},t.prototype.batchNorm=function(t,e,n,r,o){return void 0===o&&(o=.001),this.throwIfDisposed(),ut.batchNorm(this,t,e,n,r,o)},t.prototype.all=function(t,e){return void 0===t&&(t=null),void 0===e&&(e=!1),this.throwIfDisposed(),ut.all(this,t,e)},t.prototype.any=function(t,e){return void 0===t&&(t=null),void 0===e&&(e=!1),this.throwIfDisposed(),ut.any(this,t,e)},t.prototype.logSumExp=function(t,e){return void 0===t&&(t=null),void 0===e&&(e=!1),this.throwIfDisposed(),ut.logSumExp(this,t,e)},t.prototype.sum=function(t,e){return void 0===t&&(t=null),void 0===e&&(e=!1),this.throwIfDisposed(),ut.sum(this,t,e)},t.prototype.prod=function(t,e){return void 0===t&&(t=null),void 0===e&&(e=!1),this.throwIfDisposed(),ut.prod(this,t,e)},t.prototype.mean=function(t,e){return void 0===t&&(t=null),void 0===e&&(e=!1),this.throwIfDisposed(),ut.mean(this,t,e)},t.prototype.min=function(t,e){return void 0===t&&(t=null),void 0===e&&(e=!1),this.throwIfDisposed(),ut.min(this,t,e)},t.prototype.max=function(t,e){return void 0===t&&(t=null),void 0===e&&(e=!1),this.throwIfDisposed(),ut.max(this,t,e)},t.prototype.argMin=function(t){return void 0===t&&(t=null),this.throwIfDisposed(),ut.argMin(this,t)},t.prototype.argMax=function(t){return void 0===t&&(t=null),this.throwIfDisposed(),ut.argMax(this,t)},t.prototype.cast=function(t){return this.throwIfDisposed(),ut.cast(this,t)},t.prototype.add=function(t){return this.throwIfDisposed(),ut.add(this,t)},t.prototype.addStrict=function(t){return this.throwIfDisposed(),ut.addStrict(this,t)},t.prototype.atan2=function(t){return this.throwIfDisposed(),ut.atan2(this,t)},t.prototype.sub=function(t){return this.throwIfDisposed(),ut.sub(this,t)},t.prototype.subStrict=function(t){return this.throwIfDisposed(),ut.subStrict(this,t)},t.prototype.pow=function(t){return this.throwIfDisposed(),ut.pow(this,t)},t.prototype.powStrict=function(t){return this.throwIfDisposed(),ut.powStrict(this,t)},t.prototype.mul=function(t){return this.throwIfDisposed(),ut.mul(this,t)},t.prototype.mulStrict=function(t){return this.throwIfDisposed(),ut.mulStrict(this,t)},t.prototype.div=function(t){return this.throwIfDisposed(),ut.div(this,t)},t.prototype.floorDiv=function(t){return this.throwIfDisposed(),ut.floorDiv(this,t)},t.prototype.divStrict=function(t){return this.throwIfDisposed(),ut.divStrict(this,t)},t.prototype.minimum=function(t){return this.throwIfDisposed(),ut.minimum(this,t)},t.prototype.minimumStrict=function(t){return this.throwIfDisposed(),ut.minimumStrict(this,t)},t.prototype.maximum=function(t){return this.throwIfDisposed(),ut.maximum(this,t)},t.prototype.maximumStrict=function(t){return this.throwIfDisposed(),ut.maximumStrict(this,t)},t.prototype.mod=function(t){return this.throwIfDisposed(),ut.mod(this,t)},t.prototype.modStrict=function(t){return this.throwIfDisposed(),ut.modStrict(this,t)},t.prototype.squaredDifference=function(t){return this.throwIfDisposed(),ut.squaredDifference(this,t)},t.prototype.squaredDifferenceStrict=function(t){return this.throwIfDisposed(),ut.squaredDifferenceStrict(this,t)},t.prototype.transpose=function(t){return this.throwIfDisposed(),ut.transpose(this,t)},t.prototype.notEqual=function(t){return this.throwIfDisposed(),ut.notEqual(this,t)},t.prototype.notEqualStrict=function(t){return this.throwIfDisposed(),ut.notEqualStrict(this,t)},t.prototype.less=function(t){return this.throwIfDisposed(),ut.less(this,t)},t.prototype.lessStrict=function(t){return this.throwIfDisposed(),ut.lessStrict(this,t)},t.prototype.equal=function(t){return this.throwIfDisposed(),ut.equal(this,t)},t.prototype.equalStrict=function(t){return this.throwIfDisposed(),ut.equalStrict(this,t)},t.prototype.lessEqual=function(t){return this.throwIfDisposed(),ut.lessEqual(this,t)},t.prototype.lessEqualStrict=function(t){return this.throwIfDisposed(),ut.lessEqualStrict(this,t)},t.prototype.greater=function(t){return this.throwIfDisposed(),ut.greater(this,t)},t.prototype.greaterStrict=function(t){return this.throwIfDisposed(),ut.greaterStrict(this,t)},t.prototype.greaterEqual=function(t){return this.throwIfDisposed(),ut.greaterEqual(this,t)},t.prototype.greaterEqualStrict=function(t){return this.throwIfDisposed(),ut.greaterEqualStrict(this,t)},t.prototype.logicalAnd=function(t){return this.throwIfDisposed(),ut.logicalAnd(this,t)},t.prototype.logicalOr=function(t){return this.throwIfDisposed(),ut.logicalOr(this,t)},t.prototype.logicalNot=function(){return this.throwIfDisposed(),ut.logicalNot(this)},t.prototype.logicalXor=function(t){return this.throwIfDisposed(),ut.logicalXor(this,t)},t.prototype.where=function(t,e){return this.throwIfDisposed(),ut.where(t,this,e)},t.prototype.neg=function(){return this.throwIfDisposed(),ut.neg(this)},t.prototype.ceil=function(){return this.throwIfDisposed(),ut.ceil(this)},t.prototype.floor=function(){return this.throwIfDisposed(),ut.floor(this)},t.prototype.sign=function(){return this.throwIfDisposed(),ut.sign(this)},t.prototype.isNaN=function(){return this.throwIfDisposed(),ut.isNaN(this)},t.prototype.isInf=function(){return this.throwIfDisposed(),ut.isInf(this)},t.prototype.isFinite=function(){return this.throwIfDisposed(),ut.isFinite(this)},t.prototype.exp=function(){return this.throwIfDisposed(),ut.exp(this)},t.prototype.expm1=function(){return this.throwIfDisposed(),ut.expm1(this)},t.prototype.log=function(){return this.throwIfDisposed(),ut.log(this)},t.prototype.log1p=function(){return this.throwIfDisposed(),ut.log1p(this)},t.prototype.sqrt=function(){return this.throwIfDisposed(),ut.sqrt(this)},t.prototype.rsqrt=function(){return this.throwIfDisposed(),ut.rsqrt(this)},t.prototype.square=function(){return this.throwIfDisposed(),ut.square(this)},t.prototype.reciprocal=function(){return this.throwIfDisposed(),ut.reciprocal(this)},t.prototype.abs=function(){return this.throwIfDisposed(),ut.abs(this)},t.prototype.clipByValue=function(t,e){return this.throwIfDisposed(),ut.clipByValue(this,t,e)},t.prototype.relu=function(){return this.throwIfDisposed(),ut.relu(this)},t.prototype.elu=function(){return this.throwIfDisposed(),ut.elu(this)},t.prototype.selu=function(){return this.throwIfDisposed(),ut.selu(this)},t.prototype.leakyRelu=function(t){return void 0===t&&(t=.2),this.throwIfDisposed(),ut.leakyRelu(this,t)},t.prototype.prelu=function(t){return this.throwIfDisposed(),ut.prelu(this,t)},t.prototype.sigmoid=function(){return this.throwIfDisposed(),ut.sigmoid(this)},t.prototype.logSigmoid=function(){return this.throwIfDisposed(),ut.logSigmoid(this)},t.prototype.softplus=function(){return this.throwIfDisposed(),ut.softplus(this)},t.prototype.zerosLike=function(){return this.throwIfDisposed(),ut.zerosLike(this)},t.prototype.onesLike=function(){return this.throwIfDisposed(),ut.onesLike(this)},t.prototype.sin=function(){return this.throwIfDisposed(),ut.sin(this)},t.prototype.cos=function(){return this.throwIfDisposed(),ut.cos(this)},t.prototype.tan=function(){return this.throwIfDisposed(),ut.tan(this)},t.prototype.asin=function(){return this.throwIfDisposed(),ut.asin(this)},t.prototype.acos=function(){return this.throwIfDisposed(),ut.acos(this)},t.prototype.atan=function(){return this.throwIfDisposed(),ut.atan(this)},t.prototype.sinh=function(){return this.throwIfDisposed(),ut.sinh(this)},t.prototype.cosh=function(){return this.throwIfDisposed(),ut.cosh(this)},t.prototype.tanh=function(){return this.throwIfDisposed(),ut.tanh(this)},t.prototype.asinh=function(){return this.throwIfDisposed(),ut.asinh(this)},t.prototype.acosh=function(){return this.throwIfDisposed(),ut.acosh(this)},t.prototype.atanh=function(){return this.throwIfDisposed(),ut.atanh(this)},t.prototype.erf=function(){return this.throwIfDisposed(),ut.erf(this)},t.prototype.round=function(){return this.throwIfDisposed(),ut.round(this)},t.prototype.step=function(t){return void 0===t&&(t=0),this.throwIfDisposed(),ut.step(this,t)},t.prototype.softmax=function(t){return void 0===t&&(t=-1),this.throwIfDisposed(),ut.softmax(this,t)},t.prototype.logSoftmax=function(t){return void 0===t&&(t=-1),this.throwIfDisposed(),ut.logSoftmax(this,t)},t.prototype.resizeBilinear=function(t,e){return void 0===e&&(e=!1),this.throwIfDisposed(),ut.image.resizeBilinear(this,t,e)},t.prototype.resizeNearestNeighbor=function(t,e){return void 0===e&&(e=!1),this.throwIfDisposed(),ut.image.resizeNearestNeighbor(this,t,e)},t.prototype.conv1d=function(t,e,n,r,o,a){return void 0===r&&(r=\"NWC\"),void 0===o&&(o=1),this.throwIfDisposed(),ut.conv1d(this,t,e,n,r,o,a)},t.prototype.conv2d=function(t,e,n,r,o,a){return void 0===r&&(r=\"NHWC\"),void 0===o&&(o=[1,1]),this.throwIfDisposed(),ut.conv2d(this,t,e,n,r,o,a)},t.prototype.conv2dTranspose=function(t,e,n,r,o){return this.throwIfDisposed(),ut.conv2dTranspose(this,t,e,n,r,o)},t.prototype.depthwiseConv2D=function(t,e,n,r,o,a){return void 0===r&&(r=\"NHWC\"),void 0===o&&(o=[1,1]),this.throwIfDisposed(),ut.depthwiseConv2d(this,t,e,n,r,o,a)},t.prototype.separableConv2d=function(t,e,n,r,o,a){return void 0===o&&(o=[1,1]),void 0===a&&(a=\"NHWC\"),this.throwIfDisposed(),ut.separableConv2d(this,t,e,n,r,o,a)},t.prototype.avgPool=function(t,e,n,r){return this.throwIfDisposed(),ut.avgPool(this,t,e,n,r)},t.prototype.maxPool=function(t,e,n,r){return this.throwIfDisposed(),ut.maxPool(this,t,e,n,r)},t.prototype.localResponseNormalization=function(t,e,n,r){return void 0===t&&(t=5),void 0===e&&(e=1),void 0===n&&(n=1),void 0===r&&(r=.5),ut.localResponseNormalization(this,t,e,n,r)},t.prototype.pool=function(t,e,n,r,o){return this.throwIfDisposed(),ut.pool(this,t,e,n,r,o)},t.prototype.variable=function(t,e,n){return void 0===t&&(t=!0),this.throwIfDisposed(),ht.variable(this,t,e,n)},t.prototype.unsortedSegmentSum=function(t,e){return this.throwIfDisposed(),ut.unsortedSegmentSum(this,t,e)},t.prototype.batchToSpaceND=function(t,e){return this.throwIfDisposed(),ut.batchToSpaceND(this,t,e)},t.prototype.spaceToBatchND=function(t,e){return this.throwIfDisposed(),ut.spaceToBatchND(this,t,e)},t.prototype.topk=function(t,e){return void 0===t&&(t=1),void 0===e&&(e=!0),this.throwIfDisposed(),ut.topk(this,t,e)},t.prototype.stridedSlice=function(t,e,n,r,o,a,i,s){return void 0===r&&(r=0),void 0===o&&(o=0),void 0===a&&(a=0),void 0===i&&(i=0),void 0===s&&(s=0),this.throwIfDisposed(),ut.stridedSlice(this,t,e,n,r,o,a,i,s)},t.prototype.depthToSpace=function(t,e){return this.throwIfDisposed(),ut.depthToSpace(this,t,e)},t.prototype.fft=function(){return this.throwIfDisposed(),ut.spectral.fft(this)},t.prototype.ifft=function(){return this.throwIfDisposed(),ut.spectral.ifft(this)},t.prototype.rfft=function(){return this.throwIfDisposed(),ut.spectral.rfft(this)},t.prototype.irfft=function(){return this.throwIfDisposed(),ut.spectral.irfft(this)},t}();Object.defineProperty(ct,Symbol.hasInstance,{value:function(t){return!!t&&null!=t.dataId&&null!=t.shape&&null!=t.dtype}});var ht=function(t){function n(e,n,r){void 0===n&&(n=!0);var o=t.call(this,e.shape,e.dtype,null,e.dataId)||this;o.trainable=n,o.name=r,null==o.name&&(o.name=st().nextVariableId().toString());try{st().registerVariable(o)}catch(t){throw st().disposeTensor(o),t}return o}return e(n,t),n.variable=function(t,e,r,o){return void 0===e&&(e=!0),null!=o&&o!==t.dtype&&(t=t.asType(o)),new n(t,e,r)},n.prototype.assign=function(t){if(t.dtype!==this.dtype)throw new Error(\"dtype of the new value (\"+t.dtype+\") and previous value (\"+this.dtype+\") must match\");if(!y(t.shape,this.shape))throw new Error(\"shape of the new value (\"+t.shape+\") and previous value (\"+this.shape+\") must match\");st().disposeTensor(this),this.dataId=t.dataId,st().registerTensor(this)},n.prototype.dispose=function(){st().disposeVariable(this),this.isDisposedInternal=!0},n}(ct);Object.defineProperty(ht,Symbol.hasInstance,{value:function(t){return t instanceof ct&&null!=t.assign&&t.assign instanceof Function}});var pt,ft,dt,vt,mt,gt=ht.variable;!function(t){t.R0=\"R0\",t.R1=\"R1\",t.R2=\"R2\",t.R3=\"R3\",t.R4=\"R4\",t.R5=\"R5\",t.R6=\"R6\"}(pt||(pt={})),function(t){t.float32=\"float32\",t.int32=\"int32\",t.bool=\"int32\",t.complex64=\"complex64\"}(ft||(ft={})),function(t){t.float32=\"float32\",t.int32=\"int32\",t.bool=\"bool\",t.complex64=\"complex64\"}(dt||(dt={})),function(t){t.float32=\"float32\",t.int32=\"float32\",t.bool=\"float32\",t.complex64=\"complex64\"}(vt||(vt={})),function(t){t.float32=\"complex64\",t.int32=\"complex64\",t.bool=\"complex64\",t.complex64=\"complex64\"}(mt||(mt={}));var yt={float32:vt,int32:ft,bool:dt,complex64:mt};function xt(t,e){if(\"string\"===t||\"string\"===e){if(\"string\"===t&&\"string\"===e)return\"string\";throw new Error(\"Can not upcast \"+t+\" with \"+e)}return yt[t][e]}function bt(t){return xt(t,\"int32\")}function wt(t,e){if(t.dtype===e.dtype)return[t,e];var n=xt(t.dtype,e.dtype);return[t.cast(n),e.cast(n)]}function Ct(t,e){f(t.dtype===e.dtype,function(){return\"The dtypes of the first(\"+t.dtype+\") and second(\"+e.dtype+\") input must match\"})}function Et(t){var e=[];return function t(e,n,r){if(null==e)return;if(e instanceof ct)return void n.push(e);if(o=e,!Array.isArray(o)&&\"object\"!=typeof o)return;var o;var a=e;for(var i in a){var s=a[i];r.has(s)||(r.add(s),t(s,n,r))}}(t,e,new Set),e}var Rt,It=Object.freeze({makeTypesMatch:wt,assertTypesMatch:Ct,isTensorInList:function(t,e){for(var n=0;n<e.length;n++)if(e[n].id===t.id)return!0;return!1},getTensorsInContainer:Et}),kt=function(){function t(){this.registeredVariables={},this.nextTapeNodeId=0,this.numBytes=0,this.numTensors=0,this.numStringTensors=0,this.numDataBuffers=0,this.gradientDepth=0,this.kernelDepth=0,this.scopeStack=[],this.nextScopeId=0,this.tensorInfo=new WeakMap,this.profiling=!1,this.activeProfile={newBytes:0,newTensors:0,peakBytes:0,kernels:[],result:null}}return t.prototype.dispose=function(){for(var t in this.registeredVariables)this.registeredVariables[t].dispose()},t}(),Nt=function(){function t(t){this.ENV=t,this.registry={},this.registryFactory={},this.pendingBackendInitId=0,this.state=new kt}return t.prototype.ready=function(){return n(this,void 0,void 0,function(){var t,e,n;return r(this,function(r){switch(r.label){case 0:if(null!=this.pendingBackendInit)return[2,this.pendingBackendInit.then(function(){})];if(null!=this.backendInstance)return[2];t=this.getSortedBackends(),e=0,r.label=1;case 1:return e<t.length?(n=t[e],[4,this.initializeBackend(n).success]):[3,5];case 2:return r.sent()?[4,this.setBackend(n)]:[3,4];case 3:return r.sent(),[2];case 4:return e++,[3,1];case 5:throw new Error(\"Could not initialize any backends, all backend initializations failed.\")}})})},Object.defineProperty(t.prototype,\"backend\",{get:function(){if(null!=this.pendingBackendInit)throw new Error(\"Backend '\"+this.backendName+\"' has not yet been initialized. Make sure to await tf.ready() before calling other methods\");if(null==this.backendInstance){var t=this.initializeBackendsAndReturnBest(),e=t.name;if(t.asyncInit)throw new Error(\"The highest priority backend '\"+e+\"' has not yet been initialized. Make sure to await tf.ready() before calling other methods\");this.setBackend(e)}return this.backendInstance},enumerable:!0,configurable:!0}),t.prototype.backendNames=function(){return Object.keys(this.registryFactory)},t.prototype.findBackend=function(t){if(!(t in this.registry)){if(!(t in this.registryFactory))return null;if(this.initializeBackend(t).asyncInit)return null}return this.registry[t]},t.prototype.findBackendFactory=function(t){return t in this.registryFactory?this.registryFactory[t].factory:null},t.prototype.registerBackend=function(t,e,n){return void 0===n&&(n=1),t in this.registryFactory?(console.warn(t+\" backend was already registered. Reusing existing backend factory.\"),!1):(this.registryFactory[t]={factory:e,priority:n},!0)},t.prototype.setBackend=function(t){return n(this,void 0,void 0,function(){var e,n,o;return r(this,function(r){switch(r.label){case 0:if(null==this.registryFactory[t])throw new Error(\"Backend name '\"+t+\"' not found in registry\");return this.backendName=t,null!=this.registry[t]?[3,4]:(this.backendInstance=null,e=this.initializeBackend(t),n=e.success,e.asyncInit?[4,n]:[3,2]);case 1:return o=r.sent(),[3,3];case 2:o=n,r.label=3;case 3:if(!o)return[2,!1];r.label=4;case 4:return this.backendInstance=this.registry[t],this.profiler=new Q(this.backendInstance),[2,!0]}})})},t.prototype.initializeBackend=function(t){var e=this,n=this.registryFactory[t];if(null==n)throw new Error(\"Cannot initialize backend \"+t+\", no registration found.\");try{var r=n.factory();if(Promise.resolve(r)===r){var o=++this.pendingBackendInitId,a=r.then(function(n){return!(o<e.pendingBackendInitId)&&(e.registry[t]=n,e.pendingBackendInit=null,!0)}).catch(function(n){return!(o<e.pendingBackendInitId)&&(e.pendingBackendInit=null,console.warn(\"Initialization of backend \"+t+\" failed\"),console.warn(n.stack||n.message),!1)});return this.pendingBackendInit=a,{success:a,asyncInit:!0}}return this.registry[t]=r,{success:!0,asyncInit:!1}}catch(e){return console.warn(\"Initialization of backend \"+t+\" failed\"),console.warn(e.stack||e.message),{success:!1,asyncInit:!1}}},t.prototype.removeBackend=function(t){if(!(t in this.registryFactory))throw new Error(t+\" backend not found in registry\");this.backendName===t&&null!=this.pendingBackendInit&&this.pendingBackendInitId++,t in this.registry&&(this.registry[t].dispose(),delete this.registry[t]),delete this.registryFactory[t],this.backendName===t&&(this.pendingBackendInit=null,this.backendName=null,this.backendInstance=null)},t.prototype.getSortedBackends=function(){var t=this;if(0===Object.keys(this.registryFactory).length)throw new Error(\"No backend found in registry.\");return Object.keys(this.registryFactory).sort(function(e,n){return t.registryFactory[n].priority-t.registryFactory[e].priority})},t.prototype.initializeBackendsAndReturnBest=function(){for(var t=this.getSortedBackends(),e=0;e<t.length;e++){var n=t[e],r=this.initializeBackend(n),o=r.success,a=r.asyncInit;if(a||o)return{name:n,asyncInit:a}}throw new Error(\"Could not initialize any backends, all backend initializations failed.\")},t.prototype.moveData=function(t,e){this.write(t,e,this.readSync(e))},t.prototype.tidy=function(t,e){var n,r=this,o=null;if(null==e){if(\"function\"!=typeof t)throw new Error(\"Please provide a function to tidy()\");e=t}else{if(\"string\"!=typeof t&&!(t instanceof String))throw new Error(\"When calling with two arguments, the first argument to tidy() must be a string\");if(\"function\"!=typeof e)throw new Error(\"When calling with two arguments, the 2nd argument to tidy() must be a function\");o=t}return this.scopedRun(function(){return r.startScope(o)},function(){return r.endScope(n)},function(){return(n=e())instanceof Promise&&console.error(\"Cannot return a Promise inside of tidy.\"),n})},t.prototype.scopedRun=function(t,e,n){t();try{var r=n();return e(),r}catch(t){throw e(),t}},t.prototype.nextTensorId=function(){return t.nextTensorId++},t.prototype.nextVariableId=function(){return t.nextVariableId++},t.prototype.clone=function(t){var e=ct.make(t.shape,{dataId:t.dataId},t.dtype);return this.addTapeNode([t],e,function(t){return[t.toFloat()]}),e},t.prototype.runKernel=function(t,e,n){var r,o=this,a=[],i=this.isTapeOn(),s=null!=this.state.activeScope?this.state.activeScope.name:\"\",u=function(t){i&&(a=t.map(function(t){return o.keep(o.clone(t))}))},l=this.state.numBytes,c=this.state.numTensors;if(this.scopedRun(function(){return o.state.kernelDepth++},function(){return o.state.kernelDepth--},function(){r=o.ENV.getBool(\"DEBUG\")?o.profiler.profileKernel(s,e,function(){return t(o.backend,u)}):t(o.backend,u)}),i){var h={id:this.state.nextTapeNodeId++,name:s,inputs:e,outputs:Array.isArray(r)?r:[r],saved:a};null!=n&&(h.gradient=function(t){return n(t,a)}),this.state.activeTape.push(h)}return this.state.profiling&&this.state.activeProfile.kernels.push({name:s,bytesAdded:this.state.numBytes-l,totalBytesSnapshot:this.state.numBytes,tensorsAdded:this.state.numTensors-c,totalTensorsSnapshot:this.state.numTensors,inputShapes:Object.keys(e).map(function(t){return e[t].shape}),outputShape:Array.isArray(r)?r.map(function(t){return t.shape}):r.shape}),r},t.prototype.registerTensor=function(t,e){var n=this.state.tensorInfo.has(t.dataId)?this.state.tensorInfo.get(t.dataId).refCount:0;if(this.state.numTensors++,\"string\"===t.dtype&&this.state.numStringTensors++,0===n){this.state.numDataBuffers++;var r=0;\"complex64\"!==t.dtype&&\"string\"!==t.dtype&&(r=t.size*O(t.dtype)),this.state.tensorInfo.set(t.dataId,{backend:null!=e?e:this.backend,dtype:t.dtype,shape:t.shape,bytes:r,refCount:0}),this.state.numBytes+=r,null!=e?e.register(t.dataId,t.shape,t.dtype):this.backend.register(t.dataId,t.shape,t.dtype)}this.state.tensorInfo.get(t.dataId).refCount++,t instanceof ht||this.track(t)},t.prototype.registerVariable=function(t){if(null!=this.state.registeredVariables[t.name])throw new Error(\"Variable with name \"+t.name+\" was already registered\");this.state.registeredVariables[t.name]=t},t.prototype.disposeTensor=function(t){if(this.state.tensorInfo.has(t.dataId)){this.state.numTensors--,\"string\"===t.dtype&&this.state.numStringTensors--;var e=this.state.tensorInfo.get(t.dataId);e.refCount<=1?(\"complex64\"!==t.dtype&&(this.state.numBytes-=e.bytes),this.state.numDataBuffers--,e.backend.disposeData(t.dataId),this.state.tensorInfo.delete(t.dataId)):this.state.tensorInfo.get(t.dataId).refCount--}},t.prototype.disposeVariables=function(){for(var t in this.state.registeredVariables){var e=this.state.registeredVariables[t];this.disposeVariable(e)}},t.prototype.disposeVariable=function(t){this.disposeTensor(t),null!=this.state.registeredVariables[t.name]&&delete this.state.registeredVariables[t.name]},t.prototype.memory=function(){var t=this.backend.memory();return t.numTensors=this.state.numTensors,t.numDataBuffers=this.state.numDataBuffers,t.numBytes=this.state.numBytes,this.state.numStringTensors>0&&(t.unreliable=!0,null==t.reasons&&(t.reasons=[]),t.reasons.push(\"Memory usage by string tensors is approximate (2 bytes per character)\")),t},t.prototype.profile=function(t){return n(this,void 0,void 0,function(){var e,n;return r(this,function(r){return this.state.profiling=!0,e=this.state.numBytes,n=this.state.numTensors,this.state.activeProfile.kernels=[],this.state.activeProfile.result=t(),this.state.profiling=!1,this.state.activeProfile.peakBytes=Math.max.apply(Math,this.state.activeProfile.kernels.map(function(t){return t.totalBytesSnapshot})),this.state.activeProfile.newBytes=this.state.numBytes-e,this.state.activeProfile.newTensors=this.state.numTensors-n,[2,this.state.activeProfile]})})},t.prototype.isTapeOn=function(){return this.state.gradientDepth>0&&0===this.state.kernelDepth},t.prototype.addTapeNode=function(t,e,n){var r={};t.forEach(function(t,e){r[e]=t});var o={id:this.state.nextTapeNodeId++,name:this.state.activeScope.name,inputs:r,outputs:[e],gradient:function(t){var e=n(t),r={};return e.forEach(function(t,e){r[e]=function(){return t}}),r}};this.state.activeTape.push(o)},t.prototype.keep=function(t){return t.kept=!0,t},t.prototype.startTape=function(){0===this.state.gradientDepth&&(this.state.activeTape=[]),this.state.gradientDepth++},t.prototype.endTape=function(){this.state.gradientDepth--},t.prototype.startScope=function(t){var e={track:[],name:\"unnamed scope\",id:this.state.nextScopeId++};t&&(e.name=t),this.state.scopeStack.push(e),this.state.activeScope=e},t.prototype.endScope=function(t){for(var e=this,n=Et(t),r=new Set(n.map(function(t){return t.id})),o=0;o<this.state.activeScope.track.length;o++){var a=this.state.activeScope.track[o];a.kept||r.has(a.id)||a.dispose()}var i=this.state.scopeStack.pop();this.state.activeScope=0===this.state.scopeStack.length?null:this.state.scopeStack[this.state.scopeStack.length-1],n.forEach(function(t){t.kept||t.scopeId!==i.id||e.track(t)})},t.prototype.gradients=function(t,e,n,r){var o=this;if(void 0===r&&(r=!1),f(e.length>0,function(){return\"gradients() received an empty list of xs.\"}),null!=n&&\"float32\"!==n.dtype)throw new Error(\"dy must have 'float32' dtype, but has '\"+n.dtype+\"'\");var a=this.scopedRun(function(){return o.startTape()},function(){return o.endTape()},function(){return o.tidy(\"forward\",t)});f(a instanceof ct,function(){return\"The result y returned by f() must be a tensor.\"});var i=function(t,e,n){for(var r={},o={},a=0;a<e.length;a++)r[e[a].id]=!0;for(a=0;a<t.length;a++){var i=(d=t[a]).inputs;for(var s in i){for(var u=i[s],l=!1,c=0;c<e.length;c++)if(r[u.id]){d.outputs.forEach(function(t){return r[t.id]=!0}),l=!0,o[d.id]=!0;break}if(l)break}}var h={};h[n.id]=!0;var p={};for(a=t.length-1;a>=0;a--)for(i=(d=t[a]).inputs,c=0;c<d.outputs.length;c++)if(h[d.outputs[c].id]){for(var s in i)h[i[s].id]=!0,p[d.id]=!0;break}var f=[];for(a=0;a<t.length;a++){var d;if(o[(d=t[a]).id]&&p[d.id]){var v={};for(var s in d.inputs){var m=d.inputs[s];r[m.id]&&(v[s]=m)}var g=Object.assign({},d);g.inputs=v,g.outputs=d.outputs,f.push(g)}}return f}(this.state.activeTape,e,a);if(!r&&0===i.length&&e.length>0)throw new Error(\"Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.\");return this.tidy(\"backward\",function(){var t,r,s={};s[a.id]=null==n?(t=a.shape,r=H(g(t),\"float32\"),ct.make(t,{values:r})):n,function(t,e,n){for(var r=function(r){var o=e[r],a=[];if(o.outputs.forEach(function(e){var n=t[e.id];if(null!=n)a.push(n);else{var r=ct.make(e.shape,{values:q(e.size,e.dtype)},e.dtype);a.push(r)}}),null==o.gradient)throw new Error(\"Cannot compute gradient: gradient function not found for \"+o.name+\".\");var i=o.gradient(1===o.outputs.length?a[0]:a),s=function(e){if(!(e in i))throw new Error(\"Cannot backprop through input \"+e+\". Available gradients found: \"+Object.keys(i)+\".\");var r=n(function(){return i[e]()});if(\"float32\"!==r.dtype)throw new Error(\"Error in gradient for op \"+o.name+\". The gradient of input \"+e+\" must have 'float32' dtype, but has '\"+r.dtype+\"'\");var a=o.inputs[e];if(!y(r.shape,a.shape))throw new Error(\"Error in gradient for op \"+o.name+\". The gradient of input '\"+e+\"' has shape '\"+r.shape+\"', which does not match the shape of the input '\"+a.shape+\"'\");if(null==t[a.id])t[a.id]=r;else{var s=t[a.id];t[a.id]=s.add(r),s.dispose()}};for(var u in o.inputs)s(u)},o=e.length-1;o>=0;o--)r(o)}(s,i,function(t){return o.tidy(t)});var u=e.map(function(t){return s[t.id]});return 0===o.state.gradientDepth&&(o.state.activeTape.forEach(function(t){for(var e in t.saved)t.saved[e].dispose()}),o.state.activeTape=null),{value:a,grads:u}})},t.prototype.customGrad=function(t){var e=this;return f(W(t),function(){return\"The f passed in customGrad(f) must be a function.\"}),function(){for(var n,r=[],o=0;o<arguments.length;o++)r[o]=arguments[o];f(r.every(function(t){return t instanceof ct}),function(){return\"The args passed in customGrad(f)(x1, x2,...) must all be tensors\"});var a={};return r.forEach(function(t,e){a[e]=t}),e.runKernel(function(e,o){return f((n=t.apply(void 0,r.concat([o]))).value instanceof ct,function(){return\"The function f passed in customGrad(f) must return an object where `obj.value` is a tensor\"}),f(W(n.gradFunc),function(){return\"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function.\"}),n.value},a,function(t,e){var o=n.gradFunc(t,e),a=Array.isArray(o)?o:[o];f(a.length===r.length,function(){return\"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...).\"}),f(a.every(function(t){return t instanceof ct}),function(){return\"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors.\"});var i={};return a.forEach(function(t,e){i[e]=function(){return t}}),i})}},t.prototype.write=function(t,e,n){var r=this.state.tensorInfo.get(e),o=r.backend;if(t=t||this.backend,\"string\"===r.dtype){var a=F(n);this.state.numBytes+=a-r.bytes,r.bytes=a}t!==o&&(o.disposeData(e),r.backend=t,t.register(e,r.shape,r.dtype)),t.write(e,n)},t.prototype.readSync=function(t){return this.state.tensorInfo.get(t).backend.readSync(t)},t.prototype.read=function(t){return this.state.tensorInfo.get(t).backend.read(t)},t.prototype.fromPixels=function(t,e){return this.backend.fromPixels(t,e)},t.prototype.time=function(t){return n(this,void 0,void 0,function(){var e,n;return r(this,function(r){switch(r.label){case 0:return e=$(),[4,this.backend.time(t)];case 1:return(n=r.sent()).wallMs=$()-e,[2,n]}})})},t.prototype.track=function(t){return null!=this.state.activeScope&&(t.scopeId=this.state.activeScope.id,this.state.activeScope.track.push(t)),t},Object.defineProperty(t.prototype,\"registeredVariables\",{get:function(){return this.state.registeredVariables},enumerable:!0,configurable:!0}),t.prototype.reset=function(){for(var t in this.pendingBackendInitId++,this.state.dispose(),this.ENV.reset(),this.state=new kt,this.registry)this.registry[t].dispose(),delete this.registry[t];this.backendName=null,this.backendInstance=null,this.pendingBackendInit=null},t.nextTensorId=0,t.nextVariableId=0,t}();var St=function(){var t=function(){if(null==Rt){var t=void 0;if(\"undefined\"!=typeof window)t=window;else if(\"undefined\"!=typeof global)t=global;else if(\"undefined\"!=typeof process)t=process;else{if(\"undefined\"==typeof self)throw new Error(\"Could not find a global object\");t=self}Rt=t}return Rt}();if(null==t._tfengine){var e=new o(t);t._tfengine=new Nt(e)}return s(t._tfengine.ENV),st=function(){return t._tfengine},t._tfengine}();function At(){return\"undefined\"!=typeof window&&null!=window.document||\"undefined\"!=typeof WorkerGlobalScope}i.registerFlag(\"DEBUG\",function(){return!1},function(t){t&&console.warn(\"Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.\")}),i.registerFlag(\"IS_BROWSER\",function(){return At()}),i.registerFlag(\"IS_NODE\",function(){return\"undefined\"!=typeof process&&void 0!==process.versions&&void 0!==process.versions.node}),i.registerFlag(\"IS_CHROME\",function(){return\"undefined\"!=typeof navigator&&null!=navigator&&null!=navigator.userAgent&&/Chrome/.test(navigator.userAgent)&&/Google Inc/.test(navigator.vendor)}),i.registerFlag(\"PROD\",function(){return!1}),i.registerFlag(\"TENSORLIKE_CHECK_SHAPE_CONSISTENCY\",function(){return i.getBool(\"DEBUG\")}),i.registerFlag(\"DEPRECATION_WARNINGS_ENABLED\",function(){return!0}),i.registerFlag(\"IS_TEST\",function(){return!1});var Tt,Dt,_t={},Ot={alpha:!1,antialias:!1,premultipliedAlpha:!1,preserveDrawingBuffer:!1,depth:!1,stencil:!1,failIfMajorPerformanceCaveat:!0};function Ft(t,e){_t[t]=e}function Mt(t){t in _t||(_t[t]=function(t){if(1!==t&&2!==t)throw new Error(\"Cannot get WebGL rendering context, WebGL is disabled.\");var e=Bt(t);if(e.addEventListener(\"webglcontextlost\",function(e){e.preventDefault(),delete _t[t]},!1),1===t)return e.getContext(\"webgl\",Ot)||e.getContext(\"experimental-webgl\",Ot);return e.getContext(\"webgl2\",Ot)}(t));var e=_t[t];return e.isContextLost()?(delete _t[t],Mt(t)):(e.disable(e.DEPTH_TEST),e.disable(e.STENCIL_TEST),e.disable(e.BLEND),e.disable(e.DITHER),e.disable(e.POLYGON_OFFSET_FILL),e.disable(e.SAMPLE_COVERAGE),e.enable(e.SCISSOR_TEST),e.enable(e.CULL_FACE),e.cullFace(e.BACK),_t[t])}function Bt(t){if(\"undefined\"!=typeof OffscreenCanvas&&2===t)return new OffscreenCanvas(300,150);if(\"undefined\"!=typeof document)return document.createElement(\"canvas\");throw new Error(\"Cannot create a canvas in this context\")}function Pt(t,e){return[e,t]}function Lt(t){var e=g(t);return w(Math.ceil(e/4))}function Wt(t,e){return[Math.max(1,Math.ceil(e/2)),Math.max(1,Math.ceil(t/2))]}function Ut(t,e){var n,r,o,a,s,u,l,c,h,p=t;return 2===i.getNumber(\"WEBGL_VERSION\")?(n=p.R32F,r=p.R16F,o=p.RGBA16F,a=p.RGBA32F,s=p.RED,u=4,l=1,c=p.HALF_FLOAT,h=p.FLOAT):(n=t.RGBA,r=t.RGBA,o=t.RGBA,a=p.RGBA,s=t.RGBA,u=4,l=4,c=null!=e?e.HALF_FLOAT_OES:null,h=t.FLOAT),{internalFormatFloat:n,internalFormatHalfFloat:r,internalFormatPackedHalfFloat:o,internalFormatPackedFloat:a,textureFormatFloat:s,downloadTextureFormat:t.RGBA,downloadUnpackNumChannels:u,defaultNumChannels:l,textureTypeHalfFloat:c,textureTypeFloat:h}}function Vt(t,e,n){var r=n();return e&&function(t){var e=t.getError();if(e!==t.NO_ERROR)throw new Error(\"WebGL Error: \"+qt(t,e))}(t),r}!function(t){t[t.RENDER=0]=\"RENDER\",t[t.UPLOAD=1]=\"UPLOAD\",t[t.PIXELS=2]=\"PIXELS\",t[t.DOWNLOAD=3]=\"DOWNLOAD\"}(Tt||(Tt={})),function(t){t[t.UNPACKED_FLOAT16=0]=\"UNPACKED_FLOAT16\",t[t.UNPACKED_FLOAT32=1]=\"UNPACKED_FLOAT32\",t[t.PACKED_4X1_UNSIGNED_BYTE=2]=\"PACKED_4X1_UNSIGNED_BYTE\",t[t.PACKED_2X2_FLOAT32=3]=\"PACKED_2X2_FLOAT32\",t[t.PACKED_2X2_FLOAT16=4]=\"PACKED_2X2_FLOAT16\"}(Dt||(Dt={}));var zt=5.96e-8,Gt=65504;function Ht(t){return!!(i.getBool(\"WEBGL_RENDER_FLOAT32_ENABLED\")||0===t||zt<Math.abs(t)&&Math.abs(t)<Gt)}function qt(t,e){switch(e){case t.NO_ERROR:return\"NO_ERROR\";case t.INVALID_ENUM:return\"INVALID_ENUM\";case t.INVALID_VALUE:return\"INVALID_VALUE\";case t.INVALID_OPERATION:return\"INVALID_OPERATION\";case t.INVALID_FRAMEBUFFER_OPERATION:return\"INVALID_FRAMEBUFFER_OPERATION\";case t.OUT_OF_MEMORY:return\"OUT_OF_MEMORY\";case t.CONTEXT_LOST_WEBGL:return\"CONTEXT_LOST_WEBGL\";default:return\"Unknown error code \"+e}}function $t(t,e,n){return ve(t,e,function(){return t.getExtension(n)},'Extension \"'+n+'\" not supported on this browser.')}function Kt(t,e,n){var r=ve(t,e,function(){return t.createShader(t.VERTEX_SHADER)},\"Unable to create vertex WebGLShader.\");if(Vt(t,e,function(){return t.shaderSource(r,n)}),Vt(t,e,function(){return t.compileShader(r)}),!1===t.getShaderParameter(r,t.COMPILE_STATUS))throw console.log(t.getShaderInfoLog(r)),new Error(\"Failed to compile vertex shader.\");return r}function jt(t,e,n){var r=ve(t,e,function(){return t.createShader(t.FRAGMENT_SHADER)},\"Unable to create fragment WebGLShader.\");if(Vt(t,e,function(){return t.shaderSource(r,n)}),Vt(t,e,function(){return t.compileShader(r)}),!1===t.getShaderParameter(r,t.COMPILE_STATUS))throw function(t,e){var n=Qt.exec(e);if(null==n)return console.log(\"Couldn't parse line number in error: \"+e),void console.log(t);for(var r=+n[1],o=t.split(\"\\n\"),a=o.length.toString().length+2,i=o.map(function(t,e){return C((e+1).toString(),a)+t}),s=0,u=0;u<i.length;u++)s=Math.max(i[u].length,s);var l=i.slice(0,r-1),c=i.slice(r-1,r),h=i.slice(r);console.log(l.join(\"\\n\")),console.log(e.split(\"\\n\")[0]),console.log(\"%c \"+C(c[0],s),\"border:1px solid red; background-color:#e3d2d2; color:#a61717\"),console.log(h.join(\"\\n\"))}(n,t.getShaderInfoLog(r)),new Error(\"Failed to compile fragment shader.\");return r}var Xt,Yt,Qt=/ERROR: [0-9]+:([0-9]+):/g;function Jt(t,e){return ve(t,e,function(){return t.createProgram()},\"Unable to create WebGLProgram.\")}function Zt(t,e,n){if(Vt(t,e,function(){return t.linkProgram(n)}),!1===t.getProgramParameter(n,t.LINK_STATUS))throw console.log(t.getProgramInfoLog(n)),new Error(\"Failed to link vertex and fragment shaders.\")}function te(t,e,n){if(Vt(t,e,function(){return t.validateProgram(n)}),!1===t.getProgramParameter(n,t.VALIDATE_STATUS))throw console.log(t.getProgramInfoLog(n)),new Error(\"Shader program validation failed.\")}function ee(t,e,n){var r=ve(t,e,function(){return t.createBuffer()},\"Unable to create WebGLBuffer\");return Vt(t,e,function(){return t.bindBuffer(t.ARRAY_BUFFER,r)}),Vt(t,e,function(){return t.bufferData(t.ARRAY_BUFFER,n,t.STATIC_DRAW)}),r}function ne(t,e,n){var r=ve(t,e,function(){return t.createBuffer()},\"Unable to create WebGLBuffer\");return Vt(t,e,function(){return t.bindBuffer(t.ELEMENT_ARRAY_BUFFER,r)}),Vt(t,e,function(){return t.bufferData(t.ELEMENT_ARRAY_BUFFER,n,t.STATIC_DRAW)}),r}function re(t,e){return ve(t,e,function(){return t.createTexture()},\"Unable to create WebGLTexture.\")}function oe(t,e){var n=i.getNumber(\"WEBGL_MAX_TEXTURE_SIZE\");if(t<=0||e<=0){var r=\"[\"+t+\"x\"+e+\"]\";throw new Error(\"Requested texture size \"+r+\" is invalid.\")}if(t>n||e>n){r=\"[\"+t+\"x\"+e+\"]\";throw new Error(\"Requested texture size \"+r+\" greater than WebGL maximum on this browser / GPU \"+(\"[\"+n+\"x\"+n+\"]\")+\".\")}}function ae(t,e){return ve(t,e,function(){return t.createFramebuffer()},\"Unable to create WebGLFramebuffer.\")}function ie(t,e,n,r,o,a,i,s){var u=t.getAttribLocation(n,r);return-1!==u&&(Vt(t,e,function(){return t.bindBuffer(t.ARRAY_BUFFER,o)}),Vt(t,e,function(){return t.vertexAttribPointer(u,a,t.FLOAT,!1,i,s)}),Vt(t,e,function(){return t.enableVertexAttribArray(u)}),!0)}function se(t,e,n,r){me(t,r),Vt(t,e,function(){return t.activeTexture(t.TEXTURE0+r)}),Vt(t,e,function(){return t.bindTexture(t.TEXTURE_2D,n)})}function ue(t,e,n,r){return ve(t,e,function(){return t.getUniformLocation(n,r)},'uniform \"'+r+'\" not present in program.')}function le(t,e,n){return t.getUniformLocation(e,n)}function ce(t,e,n,r,o,a){Vt(t,e,function(){return se(t,e,r,a)}),Vt(t,e,function(){return t.uniform1i(o,a)})}function he(t,e,n,r){Vt(t,e,function(){return t.bindFramebuffer(t.FRAMEBUFFER,r)}),Vt(t,e,function(){return t.framebufferTexture2D(t.FRAMEBUFFER,t.COLOR_ATTACHMENT0,t.TEXTURE_2D,n,0)})}function pe(t,e,n){Vt(t,e,function(){return t.bindFramebuffer(t.FRAMEBUFFER,n)}),Vt(t,e,function(){return t.framebufferTexture2D(t.FRAMEBUFFER,t.COLOR_ATTACHMENT0,t.TEXTURE_2D,null,0)})}function fe(t){var e=t.checkFramebufferStatus(t.FRAMEBUFFER);if(e!==t.FRAMEBUFFER_COMPLETE)throw new Error(\"Error binding framebuffer: \"+de(t,e))}function de(t,e){switch(e){case t.FRAMEBUFFER_INCOMPLETE_ATTACHMENT:return\"FRAMEBUFFER_INCOMPLETE_ATTACHMENT\";case t.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:return\"FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT\";case t.FRAMEBUFFER_INCOMPLETE_DIMENSIONS:return\"FRAMEBUFFER_INCOMPLETE_DIMENSIONS\";case t.FRAMEBUFFER_UNSUPPORTED:return\"FRAMEBUFFER_UNSUPPORTED\";default:return\"unknown error \"+e}}function ve(t,e,n,r){var o=Vt(t,e,function(){return n()});if(null==o)throw new Error(r);return o}function me(t,e){var n=t.MAX_COMBINED_TEXTURE_IMAGE_UNITS-1,r=e+t.TEXTURE0;if(r<t.TEXTURE0||r>n)throw new Error(\"textureUnit must be in \"+(\"[gl.TEXTURE0, gl.TEXTURE\"+n+\"]\")+\".\")}function ge(t,e){return void 0===e&&(e=2),g(t.slice(0,t.length-e))}function ye(t){if(0===t.length)throw Error(\"Cannot get rows and columns of an empty shape array.\");return[t.length>1?t[t.length-2]:1,t[t.length-1]]}function xe(t){var e=[1,1,1];return 0===t.length||1===t.length&&1===t[0]||(e=[ge(t)].concat(ye(t))),e}function be(t,e){var n;void 0===e&&(e=!1);var r=i.getNumber(\"WEBGL_MAX_TEXTURE_SIZE\");if(e&&(r*=2,1===(t=t.map(function(e,n){return n>=t.length-2?h(t[n]):t[n]})).length&&(t=[2,t[0]])),2!==t.length){var o=k(t);t=o.newShape}var a=g(t);if(t.length<=1&&a<=r)return[1,a];if(2===t.length&&t[0]<=r&&t[1]<=r)return t;if(3===t.length&&t[0]*t[1]<=r&&t[2]<=r)return[t[0]*t[1],t[2]];if(3===t.length&&t[0]<=r&&t[1]*t[2]<=r)return[t[0],t[1]*t[2]];if(4===t.length&&t[0]*t[1]*t[2]<=r&&t[3]<=r)return[t[0]*t[1]*t[2],t[3]];if(4===t.length&&t[0]<=r&&t[1]*t[2]*t[3]<=r)return[t[0],t[1]*t[2]*t[3]];if(e){var s=ge(t),u=2,l=2;return t.length&&(u=(n=ye(t))[0],l=n[1]),w(a=s*(u/2)*(l/2)).map(function(t){return 2*t})}return w(a)}function we(t){return t%2==0}function Ce(t,e){if(y(t=t.slice(-2),e=e.slice(-2)))return!0;if(!t.length||!e.length)return!0;if(0===t[0]||0===t[1]||0===e[0]||0===e[1])return!0;if(t.length!==e.length){var n=t.slice(-1)[0],r=e.slice(-1)[0];if(n===r)return!0;if(we(n)&&we(r)&&(1===t[0]||1===e[0]))return!0}return t[1]===e[1]&&we(t[0])&&we(e[0])}function Ee(t){if(null==Xt){var e=Mt(t);Xt=e.getParameter(e.MAX_TEXTURE_SIZE)}return Xt}function Re(t){if(null==Yt){var e=Mt(t);Yt=e.getParameter(e.MAX_TEXTURE_IMAGE_UNITS)}return Math.min(16,Yt)}function Ie(t){if(0===t)return 0;var e=Mt(t);return ke(e,\"EXT_disjoint_timer_query_webgl2\")&&2===t?2:ke(e,\"EXT_disjoint_timer_query\")?1:0}function ke(t,e){return null!=t.getExtension(e)}function Ne(t){try{if(null!=Mt(t))return!0}catch(t){return!1}return!1}function Se(t){if(0===t)return!1;var e=Mt(t);if(1===t){if(!ke(e,\"OES_texture_float\"))return!1}else if(!ke(e,\"EXT_color_buffer_float\"))return!1;return Te(e)}function Ae(t){if(0===t)return!1;var e=Mt(t);if(1!==t){if(ke(e,\"EXT_color_buffer_float\"))return Te(e);if(ke(e,\"EXT_color_buffer_half_float\")){var n=e.getExtension(\"EXT_color_buffer_half_float\");return function(t,e){var n=Ut(t,e),r=t.createTexture();t.bindTexture(t.TEXTURE_2D,r);t.texImage2D(t.TEXTURE_2D,0,n.internalFormatHalfFloat,1,1,0,n.textureFormatFloat,n.textureTypeHalfFloat,null);var o=t.createFramebuffer();t.bindFramebuffer(t.FRAMEBUFFER,o),t.framebufferTexture2D(t.FRAMEBUFFER,t.COLOR_ATTACHMENT0,t.TEXTURE_2D,r,0);var a=t.checkFramebufferStatus(t.FRAMEBUFFER)===t.FRAMEBUFFER_COMPLETE;return t.bindTexture(t.TEXTURE_2D,null),t.bindFramebuffer(t.FRAMEBUFFER,null),t.deleteTexture(r),t.deleteFramebuffer(o),a}(e,n)}return!1}return!!ke(e,\"OES_texture_float\")&&(!!ke(e,\"WEBGL_color_buffer_float\")&&Te(e))}function Te(t){var e=Ut(t),n=t.createTexture();t.bindTexture(t.TEXTURE_2D,n);t.texImage2D(t.TEXTURE_2D,0,e.internalFormatFloat,1,1,0,e.textureFormatFloat,e.textureTypeFloat,null);var r=t.createFramebuffer();t.bindFramebuffer(t.FRAMEBUFFER,r),t.framebufferTexture2D(t.FRAMEBUFFER,t.COLOR_ATTACHMENT0,t.TEXTURE_2D,n,0);var o=t.checkFramebufferStatus(t.FRAMEBUFFER)===t.FRAMEBUFFER_COMPLETE;return t.bindTexture(t.TEXTURE_2D,null),t.bindFramebuffer(t.FRAMEBUFFER,null),t.deleteTexture(n),t.deleteFramebuffer(r),o}function De(t){return 2===t&&null!=Mt(t).fenceSync}var _e=Object.freeze({callAndCheck:Vt,canBeRepresented:Ht,getWebGLErrorMessage:qt,getExtensionOrThrow:$t,createVertexShader:Kt,createFragmentShader:jt,createProgram:Jt,linkProgram:Zt,validateProgram:te,createStaticVertexBuffer:ee,createStaticIndexBuffer:ne,getNumChannels:function(){return 2===i.getNumber(\"WEBGL_VERSION\")?1:4},createTexture:re,validateTextureSize:oe,createFramebuffer:ae,bindVertexBufferToProgramAttribute:ie,bindTextureUnit:se,unbindTextureUnit:function(t,e,n){me(t,n),Vt(t,e,function(){return t.activeTexture(t.TEXTURE0+n)}),Vt(t,e,function(){return t.bindTexture(t.TEXTURE_2D,null)})},getProgramUniformLocationOrThrow:ue,getProgramUniformLocation:le,bindTextureToProgramUniformSampler:ce,bindCanvasToFramebuffer:function(t,e){Vt(t,e,function(){return t.bindFramebuffer(t.FRAMEBUFFER,null)}),Vt(t,e,function(){return t.viewport(0,0,t.canvas.width,t.canvas.height)}),Vt(t,e,function(){return t.scissor(0,0,t.canvas.width,t.canvas.height)})},bindColorTextureToFramebuffer:he,unbindColorTextureFromFramebuffer:pe,validateFramebuffer:fe,getFramebufferErrorMessage:de,getBatchDim:ge,getRowsCols:ye,getShapeAs3D:xe,getTextureShapeFromLogicalShape:be,isReshapeFree:Ce,getWebGLMaxTextureSize:Ee,resetMaxTextureSize:function(){Xt=null},resetMaxTexturesInShader:function(){Yt=null},getMaxTexturesInShader:Re,getWebGLDisjointQueryTimerVersion:Ie,hasExtension:ke,isWebGLVersionEnabled:Ne,isCapableOfRenderingToFloatTexture:Se,isDownloadFloatTextureEnabled:Ae,isWebGLFenceEnabled:De});function Oe(){i.set(\"PROD\",!0)}function Fe(){i.set(\"DEBUG\",!0)}function Me(){i.set(\"DEPRECATION_WARNINGS_ENABLED\",!1),console.warn(\"TensorFlow.js deprecation warnings have been disabled.\")}function Be(t){i.getBool(\"DEPRECATION_WARNINGS_ENABLED\")&&console.warn(t+\" You can disable deprecation warnings with tf.disableDeprecationWarnings().\")}function Pe(){St.disposeVariables()}function Le(){return St.memory()}function We(t){return St.profile(t)}function Ue(t,e){return St.tidy(t,e)}function Ve(t){Et(t).forEach(function(t){return t.dispose()})}function ze(t){return St.keep(t)}function Ge(t){return St.time(t)}function He(t){return St.setBackend(t)}function qe(){return St.ready()}function $e(){return St.backendName}function Ke(t){St.removeBackend(t)}function je(t){return St.findBackend(t)}function Xe(t){return St.findBackendFactory(t)}function Ye(t,e,n){return void 0===n&&(n=1),St.registerBackend(t,e,n)}function Qe(){return St.backend}function Je(t,e){i.setPlatform(t,e)}function Ze(){for(var t=[],e=0;e<arguments.length;e++)t[e]=arguments[e];i.getBool(\"IS_TEST\")||console.warn.apply(console,t)}function tn(t,e){var n=t;if(_(t))return\"string\"===e?[]:[t.length];if(!Array.isArray(t))return[];for(var r=[];Array.isArray(n)||_(n)&&\"string\"!==e;)r.push(n.length),n=n[0];return Array.isArray(t)&&i.getBool(\"TENSORLIKE_CHECK_SHAPE_CONSISTENCY\")&&function t(e,n,r){r=r||[];if(!Array.isArray(e)&&!_(e))return void f(0===n.length,function(){return\"Element arr[\"+r.join(\"][\")+\"] is a primitive, but should be an array/TypedArray of \"+n[0]+\" elements\"});f(n.length>0,function(){return\"Element arr[\"+r.join(\"][\")+\"] should be a primitive, but is an array of \"+e.length+\" elements\"});f(e.length===n[0],function(){return\"Element arr[\"+r.join(\"][\")+\"] should have \"+n[0]+\" elements, but has \"+e.length+\" elements\"});var o=n.slice(1);for(var a=0;a<e.length;++a)t(e[a],o,r.concat(a))}(t,r,[]),r}function en(t,e,n,r){if(null!=t&&(\"numeric\"!==t&&t!==e||\"numeric\"===t&&\"string\"===e))throw new Error(\"Argument '\"+n+\"' passed to '\"+r+\"' must be \"+t+\" tensor, but got \"+e+\" tensor\")}function nn(t,e,n,r){if(void 0===r&&(r=\"numeric\"),t instanceof ct)return en(r,t.dtype,e,n),t;var o=L(t);if(\"string\"!==o&&[\"bool\",\"int32\",\"float32\"].indexOf(r)>=0&&(o=r),en(r,o,e,n),null==t||!_(t)&&!Array.isArray(t)&&\"number\"!=typeof t&&\"boolean\"!=typeof t&&\"string\"!=typeof t){var a=null==t?\"null\":t.constructor.name;throw new Error(\"Argument '\"+e+\"' passed to '\"+n+\"' must be a Tensor or TensorLike, but got '\"+a+\"'\")}var s=tn(t,o);_(t)||Array.isArray(t)||(t=[t]);var u=\"string\"!==o?z(t,o,i.getBool(\"DEBUG\")):m(t,[],!0);return ct.make(s,{values:u},o)}function rn(t,e,n,r){if(void 0===r&&(r=\"numeric\"),!Array.isArray(t))throw new Error(\"Argument \"+e+\" passed to \"+n+\" must be a `Tensor[]` or `TensorLike[]`\");return t.map(function(t,r){return nn(t,e+\"[\"+r+\"]\",n)},r)}function on(t,e){for(var n=0;n<t.length;++n)if(t[t.length-n-1]!==e-1-n)return!1;return!0}function an(t,e,n){for(var r=t.length+e.length,o=[],a=0,i=0,s=0;s<r;s++)-1===n.indexOf(s)?o.push(t[a++]):o.push(e[i++]);return o}function sn(t,e){for(var n=[],r=t.length,o=0;o<r;o++)-1===e.indexOf(o)&&n.push(t[o]);return[n,e.map(function(e){return t[e]})]}function un(t,e){return an(t,e.map(function(t){return 1}),e)}function ln(t,e,n){f(on(e,n),function(){return t+\" supports only inner-most axes for now. Got axes \"+e+\" and rank-\"+n+\" input.\"})}function cn(t,e){if(on(t,e))return null;for(var n=[],r=0;r<e;++r)-1===t.indexOf(r)&&n.push(r);return t.forEach(function(t){return n.push(t)}),n}function hn(t){return t.map(function(t,e){return[e,t]}).sort(function(t,e){return t[1]-e[1]}).map(function(t){return t[0]})}function pn(t,e){for(var n=[],r=e-t;r<e;++r)n.push(r);return n}function fn(t,e){var n=t[0].length;t.forEach(function(t,e){f(t.length===n,function(){return\"Error in concat\"+n+\"D: rank of tensors[\"+e+\"] must be the same as the rank of the rest (\"+n+\")\"})}),f(e>=0&&e<n,function(){return\"Error in concat\"+n+\"D: axis must be between 0 and \"+(n-1)+\".\"});var r=t[0];t.forEach(function(t,o){for(var a=0;a<n;a++)f(a===e||t[a]===r[a],function(){return\"Error in concat\"+n+\"D: Shape of tensors[\"+o+\"] (\"+t+\") does not match the shape of the rest (\"+r+\") along the non-concatenated axis \"+o+\".\"})})}function dn(t,e){for(var n=t[0].slice(),r=1;r<t.length;r++)n[e]+=t[r][e];return n}function vn(t){var e=Object.keys(t);if(1!==e.length)throw new Error(\"Please provide an object with a single key (operation name) mapping to a function. Got an object with \"+e.length+\" keys.\");var n=e[0],r=t[n];n.endsWith(\"_\")&&(n=n.substring(0,n.length-1));var o=function(){for(var t=[],e=0;e<arguments.length;e++)t[e]=arguments[e];St.startScope(n);try{var o=r.apply(void 0,t);return o instanceof Promise&&console.error(\"Cannot return a Promise inside of tidy.\"),St.endScope(o),o}catch(t){throw St.endScope(null),t}};return Object.defineProperty(o,\"name\",{value:n,configurable:!0}),o}i.registerFlag(\"HAS_WEBGL\",function(){return i.getNumber(\"WEBGL_VERSION\")>0}),i.registerFlag(\"WEBGL_VERSION\",function(){return Ne(2)?2:Ne(1)?1:0}),i.registerFlag(\"WEBGL_BUFFER_SUPPORTED\",function(){return 2===i.get(\"WEBGL_VERSION\")}),i.registerFlag(\"WEBGL_CPU_FORWARD\",function(){return!0}),i.registerFlag(\"WEBGL_FORCE_F16_TEXTURES\",function(){return!1}),i.registerFlag(\"WEBGL_PACK\",function(){return i.getBool(\"HAS_WEBGL\")}),i.registerFlag(\"WEBGL_PACK_NORMALIZATION\",function(){return i.getBool(\"WEBGL_PACK\")}),i.registerFlag(\"WEBGL_PACK_CLIP\",function(){return i.getBool(\"WEBGL_PACK\")}),i.registerFlag(\"WEBGL_PACK_DEPTHWISECONV\",function(){return!1}),i.registerFlag(\"WEBGL_PACK_BINARY_OPERATIONS\",function(){return i.getBool(\"WEBGL_PACK\")}),i.registerFlag(\"WEBGL_PACK_UNARY_OPERATIONS\",function(){return i.getBool(\"WEBGL_PACK\")}),i.registerFlag(\"WEBGL_PACK_ARRAY_OPERATIONS\",function(){return i.getBool(\"WEBGL_PACK\")}),i.registerFlag(\"WEBGL_PACK_IMAGE_OPERATIONS\",function(){return i.getBool(\"WEBGL_PACK\")}),i.registerFlag(\"WEBGL_PACK_REDUCE\",function(){return i.getBool(\"WEBGL_PACK\")}),i.registerFlag(\"WEBGL_LAZILY_UNPACK\",function(){return i.getBool(\"WEBGL_PACK\")}),i.registerFlag(\"WEBGL_CONV_IM2COL\",function(){return i.getBool(\"WEBGL_PACK\")}),i.registerFlag(\"WEBGL_MAX_TEXTURE_SIZE\",function(){return Ee(i.getNumber(\"WEBGL_VERSION\"))}),i.registerFlag(\"WEBGL_MAX_TEXTURES_IN_SHADER\",function(){return Re(i.getNumber(\"WEBGL_VERSION\"))}),i.registerFlag(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\",function(){var t=i.getNumber(\"WEBGL_VERSION\");return 0===t?0:Ie(t)}),i.registerFlag(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE\",function(){return i.getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\")>0&&(t=navigator.userAgent||navigator.vendor||window.opera,!(/(android|bb\\d+|meego).+mobile|avantgo|bada\\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(t)||/1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\\-(n|u)|c55\\/|capi|ccwa|cdm\\-|cell|chtm|cldc|cmd\\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\\-s|devi|dica|dmob|do(c|p)o|ds(12|\\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\\-|_)|g1 u|g560|gene|gf\\-5|g\\-mo|go(\\.w|od)|gr(ad|un)|haie|hcit|hd\\-(m|p|t)|hei\\-|hi(pt|ta)|hp( i|ip)|hs\\-c|ht(c(\\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\\-(20|go|ma)|i230|iac( |\\-|\\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\\/)|klon|kpt |kwc\\-|kyo(c|k)|le(no|xi)|lg( g|\\/(k|l|u)|50|54|\\-[a-w])|libw|lynx|m1\\-w|m3ga|m50\\/|ma(te|ui|xo)|mc(01|21|ca)|m\\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\\-2|po(ck|rt|se)|prox|psio|pt\\-g|qa\\-a|qc(07|12|21|32|60|\\-[2-7]|i\\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\\-|oo|p\\-)|sdk\\/|se(c(\\-|0|1)|47|mc|nd|ri)|sgh\\-|shar|sie(\\-|m)|sk\\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\\-|v\\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\\-|tdg\\-|tel(i|m)|tim\\-|t\\-mo|to(pl|sh)|ts(70|m\\-|m3|m5)|tx\\-9|up(\\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\\-|your|zeto|zte\\-/i.test(t.substr(0,4))));var t}),i.registerFlag(\"WEBGL_RENDER_FLOAT32_CAPABLE\",function(){return Se(i.getNumber(\"WEBGL_VERSION\"))}),i.registerFlag(\"WEBGL_RENDER_FLOAT32_ENABLED\",function(){return!i.getBool(\"WEBGL_FORCE_F16_TEXTURES\")&&i.getBool(\"WEBGL_RENDER_FLOAT32_CAPABLE\")}),i.registerFlag(\"WEBGL_DOWNLOAD_FLOAT_ENABLED\",function(){return Ae(i.getNumber(\"WEBGL_VERSION\"))}),i.registerFlag(\"WEBGL_FENCE_API_ENABLED\",function(){return De(i.getNumber(\"WEBGL_VERSION\"))}),i.registerFlag(\"WEBGL_SIZE_UPLOAD_UNIFORM\",function(){return i.getBool(\"WEBGL_RENDER_FLOAT32_ENABLED\")?4:0}),lt=Be;var mn=vn({complex_:function(t,e){var n=nn(t,\"real\",\"complex\"),r=nn(e,\"imag\",\"complex\");return d(n.shape,r.shape,\"real and imag shapes, \"+n.shape+\" and \"+r.shape+\", must match in call to tf.complex().\"),St.runKernel(function(t){return t.complex(n,r)},{$real:n,$imag:r})}}),gn=vn({real_:function(t){var e=nn(t,\"input\",\"real\");return St.runKernel(function(t){return t.real(e)},{$input:e})}}),yn=vn({imag_:function(t){var e=nn(t,\"input\",\"imag\");return St.runKernel(function(t){return t.imag(e)},{$input:e})}});function xn(t,e,n){return bn(t,e,tn(t,n),n)}function bn(t,e,n,r){if(null==r&&(r=L(t)),\"complex64\"===r)throw new Error(\"Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).\");if(!_(t)&&!Array.isArray(t)&&\"number\"!=typeof t&&\"boolean\"!=typeof t&&\"string\"!=typeof t)throw new Error(\"values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray\");if(null!=e){K(e);var o=g(e),a=g(n);f(o===a,function(){return\"Based on the provided shape, [\"+e+\"], the tensor should have \"+o+\" values but has \"+a});for(var s=0;s<n.length;++s){var u=n[s],l=s!==n.length-1||u!==g(e.slice(s));f(n[s]===e[s]||!l,function(){return\"Error creating a new Tensor. Inferred shape (\"+n+\") does not match the provided shape (\"+e+\"). \"})}}return _(t)||Array.isArray(t)||(t=[t]),e=e||n,t=\"string\"!==r?z(t,r,i.getBool(\"DEBUG\")):m(t,[],!0),ct.make(e,{values:t},r)}function wn(t,e){if((_(t)&&\"string\"!==e||Array.isArray(t))&&\"complex64\"!==e)throw new Error(\"Error creating a new Scalar: value must be a primitive (number|boolean|string)\");if(\"string\"===e&&_(t)&&!(t instanceof Uint8Array))throw new Error(\"When making a scalar from encoded string, the value must be `Uint8Array`.\");return bn(t,[],[],e)}function Cn(t,e){v(t);var n=tn(t,e);if(1!==n.length)throw new Error(\"tensor1d() requires values to be a flat/TypedArray\");return bn(t,null,n,e)}function En(t,e,n){if(v(t),null!=e&&2!==e.length)throw new Error(\"tensor2d() requires shape to have two numbers\");var r=tn(t,n);if(2!==r.length&&1!==r.length)throw new Error(\"tensor2d() requires values to be number[][] or flat/TypedArray\");if(1===r.length&&null==e)throw new Error(\"tensor2d() requires shape to be provided when `values` are a flat/TypedArray\");return bn(t,e,r,n)}function Rn(t,e,n){if(v(t),null!=e&&3!==e.length)throw new Error(\"tensor3d() requires shape to have three numbers\");var r=tn(t,n);if(3!==r.length&&1!==r.length)throw new Error(\"tensor3d() requires values to be number[][][] or flat/TypedArray\");if(1===r.length&&null==e)throw new Error(\"tensor3d() requires shape to be provided when `values` are a flat array\");return bn(t,e,r,n)}function In(t,e,n){if(v(t),null!=e&&4!==e.length)throw new Error(\"tensor4d() requires shape to have four numbers\");var r=tn(t,n);if(4!==r.length&&1!==r.length)throw new Error(\"tensor4d() requires values to be number[][][][] or flat/TypedArray\");if(1===r.length&&null==e)throw new Error(\"tensor4d() requires shape to be provided when `values` are a flat array\");return bn(t,e,r,n)}function kn(t,e,n){if(v(t),null!=e&&5!==e.length)throw new Error(\"tensor5d() requires shape to have five numbers\");var r=tn(t,n);if(5!==r.length&&1!==r.length)throw new Error(\"tensor5d() requires values to be number[][][][][] or flat/TypedArray\");if(1===r.length&&null==e)throw new Error(\"tensor5d() requires shape to be provided when `values` are a flat array\");return bn(t,e,r,n)}function Nn(t,e,n){if(v(t),null!=e&&6!==e.length)throw new Error(\"tensor6d() requires shape to have six numbers\");var r=tn(t,n);if(6!==r.length&&1!==r.length)throw new Error(\"tensor6d() requires values to be number[][][][][][] or flat/TypedArray\");if(1===r.length&&null==e)throw new Error(\"tensor6d() requires shape to be provided when `values` are a flat array\");return bn(t,e=e||r,r,n)}function Sn(t,e){if(void 0===e&&(e=\"float32\"),\"complex64\"===e){var n=Sn(t,\"float32\"),r=An(t,\"float32\");return mn(n,r)}var o=H(g(t),e);return ct.make(t,{values:o},e)}function An(t,e){if(void 0===e&&(e=\"float32\"),\"complex64\"===e){var n=An(t,\"float32\"),r=An(t,\"float32\");return mn(n,r)}var o=q(g(t),e);return ct.make(t,{values:o},e)}function Tn(t,e,n){return St.runKernel(function(r){return r.fill(t,e,n)},{})}function Dn(t,e,n){if(n<=0)throw new Error(\"The number of values should be positive.\");return St.runKernel(function(r){return r.linspace(t,e,n)},{})}function _n(t,e,n,r){if(void 0===n&&(n=1),void 0===r&&(r=\"float32\"),0===n)throw new Error(\"Cannot have a step of zero\");if(t===e||t<e&&n<0||e<t&&n>1)return An([0],r);var o=q(Math.abs(Math.ceil((e-t)/n)),r);e<t&&1===n&&(n=-1),o[0]=t;for(var a=1;a<o.length;a++)o[a]=o[a-1]+n;return Cn(o,r)}var On=vn({onesLike_:function(t){var e=nn(t,\"x\",\"onesLike\");if(\"complex64\"===e.dtype){var n=On(gn(e)),r=Fn(yn(e));return mn(n,r)}return St.runKernel(function(t){return t.onesLike(e)},{$x:e},function(t,e){return{$x:function(){return Fn(t)}}})}}),Fn=vn({zerosLike_:function(t){var e=nn(t,\"x\",\"zerosLike\");return St.runKernel(function(t){return t.zerosLike(e)},{$x:e},function(t,e){return{$x:function(){return Fn(t)}}})}});var Mn=vn({concat_:function(t,e){void 0===e&&(e=0),f(t.length>=1,function(){return\"Pass at least one tensor to concat\"});var n=rn(t,\"tensors\",\"concat\");\"complex64\"===n[0].dtype&&n.forEach(function(t){if(\"complex64\"!==t.dtype)throw new Error(\"Cannot concatenate complex64 tensors with a tensor\\n          with dtype \"+t.dtype+\". \")}),e=I(e,n[0].shape)[0];var r=dn(n.map(function(t){return t.shape}),e);if(0===g(r))return xn([],r);if(1===(n=n.filter(function(t){return t.size>0})).length)return n[0];var o=n.map(function(t){return t.shape});fn(o,e);var a=n;return St.runKernel(function(t){return t.concat(n,e)},a,function(t){var n=o.map(function(t){return t[e]});return Un(t,n,e).map(function(t){return function(){return t}})})}}),Bn=vn({concat1d_:function(t){return Mn(t,0)}}),Pn=vn({concat2d_:function(t,e){return Mn(t,e)}}),Ln=vn({concat3d_:function(t,e){return Mn(t,e)}}),Wn=vn({concat4d_:function(t,e){return Mn(t,e)}}),Un=vn({split_:function(t,e,n){void 0===n&&(n=0);var r,o=nn(t,\"x\",\"split\");return n=I(n,o.shape)[0],\"number\"==typeof e?(f(o.shape[n]%e==0,function(){return\"Number of splits must evenly divide the axis.\"}),r=new Array(e).fill(o.shape[n]/e)):(f(o.shape[n]===e.reduce(function(t,e){return t+e}),function(){return\"The sum of sizes must match the size of the axis dimension.\"}),r=e),St.runKernel(function(t){return t.split(o,r,n)},{$x:o},function(t){return{$x:function(){return Mn(t,n)}}})}});\"undefined\"!=typeof globalThis?globalThis:\"undefined\"!=typeof window?window:\"undefined\"!=typeof global?global:\"undefined\"!=typeof self&&self;function Vn(t,e){return t(e={exports:{}},e.exports),e.exports}var zn=Vn(function(t){!function(t,e,n){function r(t){var e,n=this,r=(e=4022871197,function(t){t=t.toString();for(var n=0;n<t.length;n++){var r=.02519603282416938*(e+=t.charCodeAt(n));r-=e=r>>>0,e=(r*=e)>>>0,e+=4294967296*(r-=e)}return 2.3283064365386963e-10*(e>>>0)});n.next=function(){var t=2091639*n.s0+2.3283064365386963e-10*n.c;return n.s0=n.s1,n.s1=n.s2,n.s2=t-(n.c=0|t)},n.c=1,n.s0=r(\" \"),n.s1=r(\" \"),n.s2=r(\" \"),n.s0-=r(t),n.s0<0&&(n.s0+=1),n.s1-=r(t),n.s1<0&&(n.s1+=1),n.s2-=r(t),n.s2<0&&(n.s2+=1),r=null}function o(t,e){return e.c=t.c,e.s0=t.s0,e.s1=t.s1,e.s2=t.s2,e}function a(t,e){var n=new r(t),a=e&&e.state,i=n.next;return i.int32=function(){return 4294967296*n.next()|0},i.double=function(){return i()+1.1102230246251565e-16*(2097152*i()|0)},i.quick=i,a&&(\"object\"==typeof a&&o(a,n),i.state=function(){return o(n,{})}),i}e&&e.exports?e.exports=a:n&&n.amd?n(function(){return a}):this.alea=a}(0,t,!1)}),Gn=Vn(function(t){!function(t,e,n){function r(t){var e=this,n=\"\";e.x=0,e.y=0,e.z=0,e.w=0,e.next=function(){var t=e.x^e.x<<11;return e.x=e.y,e.y=e.z,e.z=e.w,e.w^=e.w>>>19^t^t>>>8},t===(0|t)?e.x=t:n+=t;for(var r=0;r<n.length+64;r++)e.x^=0|n.charCodeAt(r),e.next()}function o(t,e){return e.x=t.x,e.y=t.y,e.z=t.z,e.w=t.w,e}function a(t,e){var n=new r(t),a=e&&e.state,i=function(){return(n.next()>>>0)/4294967296};return i.double=function(){do{var t=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===t);return t},i.int32=n.next,i.quick=i,a&&(\"object\"==typeof a&&o(a,n),i.state=function(){return o(n,{})}),i}e&&e.exports?e.exports=a:n&&n.amd?n(function(){return a}):this.xor128=a}(0,t,!1)}),Hn=Vn(function(t){!function(t,e,n){function r(t){var e=this,n=\"\";e.next=function(){var t=e.x^e.x>>>2;return e.x=e.y,e.y=e.z,e.z=e.w,e.w=e.v,(e.d=e.d+362437|0)+(e.v=e.v^e.v<<4^t^t<<1)|0},e.x=0,e.y=0,e.z=0,e.w=0,e.v=0,t===(0|t)?e.x=t:n+=t;for(var r=0;r<n.length+64;r++)e.x^=0|n.charCodeAt(r),r==n.length&&(e.d=e.x<<10^e.x>>>4),e.next()}function o(t,e){return e.x=t.x,e.y=t.y,e.z=t.z,e.w=t.w,e.v=t.v,e.d=t.d,e}function a(t,e){var n=new r(t),a=e&&e.state,i=function(){return(n.next()>>>0)/4294967296};return i.double=function(){do{var t=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===t);return t},i.int32=n.next,i.quick=i,a&&(\"object\"==typeof a&&o(a,n),i.state=function(){return o(n,{})}),i}e&&e.exports?e.exports=a:n&&n.amd?n(function(){return a}):this.xorwow=a}(0,t,!1)}),qn=Vn(function(t){!function(t,e,n){function r(t){var e=this;e.next=function(){var t,n,r=e.x,o=e.i;return t=r[o],n=(t^=t>>>7)^t<<24,n^=(t=r[o+1&7])^t>>>10,n^=(t=r[o+3&7])^t>>>3,n^=(t=r[o+4&7])^t<<7,t=r[o+7&7],n^=(t^=t<<13)^t<<9,r[o]=n,e.i=o+1&7,n},function(t,e){var n,r=[];if(e===(0|e))r[0]=e;else for(e=\"\"+e,n=0;n<e.length;++n)r[7&n]=r[7&n]<<15^e.charCodeAt(n)+r[n+1&7]<<13;for(;r.length<8;)r.push(0);for(n=0;n<8&&0===r[n];++n);for(8==n?r[7]=-1:r[n],t.x=r,t.i=0,n=256;n>0;--n)t.next()}(e,t)}function o(t,e){return e.x=t.x.slice(),e.i=t.i,e}function a(t,e){null==t&&(t=+new Date);var n=new r(t),a=e&&e.state,i=function(){return(n.next()>>>0)/4294967296};return i.double=function(){do{var t=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===t);return t},i.int32=n.next,i.quick=i,a&&(a.x&&o(a,n),i.state=function(){return o(n,{})}),i}e&&e.exports?e.exports=a:n&&n.amd?n(function(){return a}):this.xorshift7=a}(0,t,!1)}),$n=Vn(function(t){!function(t,e,n){function r(t){var e=this;e.next=function(){var t,n,r=e.w,o=e.X,a=e.i;return e.w=r=r+1640531527|0,n=o[a+34&127],t=o[a=a+1&127],n^=n<<13,t^=t<<17,n^=n>>>15,t^=t>>>12,n=o[a]=n^t,e.i=a,n+(r^r>>>16)|0},function(t,e){var n,r,o,a,i,s=[],u=128;for(e===(0|e)?(r=e,e=null):(e+=\"\\0\",r=0,u=Math.max(u,e.length)),o=0,a=-32;a<u;++a)e&&(r^=e.charCodeAt((a+32)%e.length)),0===a&&(i=r),r^=r<<10,r^=r>>>15,r^=r<<4,r^=r>>>13,a>=0&&(i=i+1640531527|0,o=0==(n=s[127&a]^=r+i)?o+1:0);for(o>=128&&(s[127&(e&&e.length||0)]=-1),o=127,a=512;a>0;--a)r=s[o+34&127],n=s[o=o+1&127],r^=r<<13,n^=n<<17,r^=r>>>15,n^=n>>>12,s[o]=r^n;t.w=i,t.X=s,t.i=o}(e,t)}function o(t,e){return e.i=t.i,e.w=t.w,e.X=t.X.slice(),e}function a(t,e){null==t&&(t=+new Date);var n=new r(t),a=e&&e.state,i=function(){return(n.next()>>>0)/4294967296};return i.double=function(){do{var t=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===t);return t},i.int32=n.next,i.quick=i,a&&(a.X&&o(a,n),i.state=function(){return o(n,{})}),i}e&&e.exports?e.exports=a:n&&n.amd?n(function(){return a}):this.xor4096=a}(0,t,!1)}),Kn=Vn(function(t){!function(t,e,n){function r(t){var e=this,n=\"\";e.next=function(){var t=e.b,n=e.c,r=e.d,o=e.a;return t=t<<25^t>>>7^n,n=n-r|0,r=r<<24^r>>>8^o,o=o-t|0,e.b=t=t<<20^t>>>12^n,e.c=n=n-r|0,e.d=r<<16^n>>>16^o,e.a=o-t|0},e.a=0,e.b=0,e.c=-1640531527,e.d=1367130551,t===Math.floor(t)?(e.a=t/4294967296|0,e.b=0|t):n+=t;for(var r=0;r<n.length+20;r++)e.b^=0|n.charCodeAt(r),e.next()}function o(t,e){return e.a=t.a,e.b=t.b,e.c=t.c,e.d=t.d,e}function a(t,e){var n=new r(t),a=e&&e.state,i=function(){return(n.next()>>>0)/4294967296};return i.double=function(){do{var t=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===t);return t},i.int32=n.next,i.quick=i,a&&(\"object\"==typeof a&&o(a,n),i.state=function(){return o(n,{})}),i}e&&e.exports?e.exports=a:n&&n.amd?n(function(){return a}):this.tychei=a}(0,t,!1)}),jn=Vn(function(t){!function(e,n){var r,o=this,a=256,i=6,s=\"random\",u=n.pow(a,i),l=n.pow(2,52),c=2*l,h=a-1;function p(t,h,p){var g=[],y=v(function t(e,n){var r,o=[],a=typeof e;if(n&&\"object\"==a)for(r in e)try{o.push(t(e[r],n-1))}catch(t){}return o.length?o:\"string\"==a?e:e+\"\\0\"}((h=1==h?{entropy:!0}:h||{}).entropy?[t,m(e)]:null==t?function(){try{var t;return r&&(t=r.randomBytes)?t=t(a):(t=new Uint8Array(a),(o.crypto||o.msCrypto).getRandomValues(t)),m(t)}catch(t){var n=o.navigator,i=n&&n.plugins;return[+new Date,o,i,o.screen,m(e)]}}():t,3),g),x=new f(g),b=function(){for(var t=x.g(i),e=u,n=0;t<l;)t=(t+n)*a,e*=a,n=x.g(1);for(;t>=c;)t/=2,e/=2,n>>>=1;return(t+n)/e};return b.int32=function(){return 0|x.g(4)},b.quick=function(){return x.g(4)/4294967296},b.double=b,v(m(x.S),e),(h.pass||p||function(t,e,r,o){return o&&(o.S&&d(o,x),t.state=function(){return d(x,{})}),r?(n[s]=t,e):t})(b,y,\"global\"in h?h.global:this==n,h.state)}function f(t){var e,n=t.length,r=this,o=0,i=r.i=r.j=0,s=r.S=[];for(n||(t=[n++]);o<a;)s[o]=o++;for(o=0;o<a;o++)s[o]=s[i=h&i+t[o%n]+(e=s[o])],s[i]=e;(r.g=function(t){for(var e,n=0,o=r.i,i=r.j,s=r.S;t--;)e=s[o=h&o+1],n=n*a+s[h&(s[o]=s[i=h&i+e])+(s[i]=e)];return r.i=o,r.j=i,n})(a)}function d(t,e){return e.i=t.i,e.j=t.j,e.S=t.S.slice(),e}function v(t,e){for(var n,r=t+\"\",o=0;o<r.length;)e[h&o]=h&(n^=19*e[h&o])+r.charCodeAt(o++);return m(e)}function m(t){return String.fromCharCode.apply(0,t)}if(n[\"seed\"+s]=p,v(n.random(),e),t.exports){t.exports=p;try{r=__webpack_require__(/*! crypto */ 0)}catch(t){}}}([],Math)});jn.alea=zn,jn.xor128=Gn,jn.xorwow=Hn,jn.xorshift7=qn,jn.xor4096=$n,jn.tychei=Kn;var Xn=jn.alea,Yn=function(){function t(t,e,n,r,o){this.mean=t,this.stdDev=e,this.dtype=n,this.nextVal=NaN,this.truncated=r,this.truncated&&(this.upper=this.mean+2*this.stdDev,this.lower=this.mean-2*this.stdDev);var a=o||Math.random();this.random=Xn(a.toString())}return t.prototype.nextValue=function(){if(!isNaN(this.nextVal)){var t=this.nextVal;return this.nextVal=NaN,t}for(var e,n,r=!1;!r;){var o=void 0,a=void 0,i=void 0;do{i=(o=2*this.random()-1)*o+(a=2*this.random()-1)*a}while(i>=1||0===i);var s=Math.sqrt(-2*Math.log(i)/i);e=this.mean+this.stdDev*o*s,n=this.mean+this.stdDev*a*s,this.truncated&&!this.isValidTruncated(e)||(r=!0)}return this.truncated&&!this.isValidTruncated(n)||(this.nextVal=this.convertValue(n)),this.convertValue(e)},t.prototype.convertValue=function(t){return null==this.dtype||\"float32\"===this.dtype?t:Math.round(t)},t.prototype.isValidTruncated=function(t){return t<=this.upper&&t>=this.lower},t}(),Qn=function(){function t(t,e,n,r){this.alpha=t,this.beta=1/e,this.dtype=n;var o=r||Math.random();this.randu=Xn(o.toString()),this.randn=new Yn(0,1,n,!1,this.randu()),this.d=t<1?t+2/3:t-1/3,this.c=1/Math.sqrt(9*this.d)}return t.prototype.nextValue=function(){for(var t,e,n,r,o,a;;){do{r=this.randn.nextValue(),a=1+this.c*r}while(a<=0);if(a*=a*a,e=1-.331*(t=r*r)*t,n=.5*t+this.d*(1-a+Math.log(a)),(o=this.randu())<e||Math.log(o)<n)break}return a=1/this.beta*this.d*a,this.alpha<1&&(a*=Math.pow(this.randu(),1/this.alpha)),this.convertValue(a)},t.prototype.convertValue=function(t){return\"float32\"===this.dtype?t:Math.round(t)},t}(),Jn=function(){function t(t,e,n,r){var o=this;if(void 0===t&&(t=0),void 0===e&&(e=1),this.canReturnFloat=function(){return null==o.dtype||\"float32\"===o.dtype},this.min=t,this.range=e-t,this.dtype=n,null==r&&(r=Math.random()),\"number\"==typeof r&&(r=r.toString()),!this.canReturnFloat()&&this.range<=1)throw new Error(\"The difference between \"+t+\" - \"+e+\" <= 1 and dtype is not float\");this.random=Xn(r)}return t.prototype.convertValue=function(t){return this.canReturnFloat()?t:Math.round(t)},t.prototype.nextValue=function(){return this.convertValue(this.min+this.range*this.random())},t}();function Zn(t,e,n){return void 0===e&&(e=\"float32\"),e=e||\"float32\",K(t),new it(t,e,n)}function tr(t,e){void 0===e&&(e=!1),console.log(t.toString(e))}var er=vn({batchToSpaceND_:function(t,e,n){var r=nn(t,\"x\",\"batchToSpaceND\"),o=e.reduce(function(t,e){return t*e});return f(r.rank>=1+e.length,function(){return\"input rank is \"+r.rank+\" but should be > than blockShape.length \"+e.length}),f(n.length===e.length,function(){return\"crops.length is \"+n.length+\" but should be equal to blockShape.length  \"+e.length}),f(r.shape[0]%o==0,function(){return\"input tensor batch is \"+r.shape[0]+\" but is not divisible by the product of the elements of blockShape \"+e.join(\" * \")+\" === \"+o}),St.runKernel(function(t){return t.batchToSpaceND(r,e,n)},{$x:r},function(t){return{$x:function(){return t.spaceToBatchND(e,n)}}})}}),nr=vn({cast_:function(t,e){var n=nn(t,\"x\",\"cast\");if(!T(e))throw new Error(\"Failed to cast to unknown dtype \"+e);if(\"string\"===e&&\"string\"!==n.dtype||\"string\"!==e&&\"string\"===n.dtype)throw new Error(\"Only strings can be casted to strings\");return St.runKernel(function(t){return t.cast(n,e)},{$x:n},function(t){return{$x:function(){return t.clone()}}})}}),rr=vn({clone_:function(t){var e=nn(t,\"x\",\"clone\",null);return St.runKernel(function(t){return ct.make(e.shape,{dataId:e.dataId},e.dtype)},{$x:e},function(t){return{$x:function(){return t.toFloat()}}})}}),or=vn({cumsum_:function(t,e,n,r){void 0===e&&(e=0),void 0===n&&(n=!1),void 0===r&&(r=!1);var o=nn(t,\"x\",\"cumsum\"),a=cn([e|=0],o.rank),i=o;null!=a&&(i=o.transpose(a));var s=pn(1,o.rank)[0],u=St.runKernel(function(t){return t.cumsum(i,s,n,r)},{permutedX:i},function(t){return{permutedX:function(){return t.cumsum(e,n,!r)}}});return null!=a&&(u=u.transpose(a)),u}}),ar=vn({depthToSpace_:function(t,e,n){void 0===n&&(n=\"NHWC\");var r=nn(t,\"x\",\"depthToSpace\"),o=\"NHWC\"===n?r.shape[1]:r.shape[2],a=\"NHWC\"===n?r.shape[2]:r.shape[3],i=\"NHWC\"===n?r.shape[3]:r.shape[1];return f(o*e>=0,function(){return\"Negative dimension size caused by overflow when multiplying\\n      \"+o+\" and \"+e+\"  for depthToSpace with input shape\\n      \"+r.shape}),f(a*e>=0,function(){return\"Negative dimension size caused by overflow when multiplying\\n      \"+a+\" and \"+e+\" for depthToSpace with input shape\\n          \"+r.shape}),f(i%(e*e)==0,function(){return\"Dimension size must be evenly divisible by \"+e*e+\" but is \"+i+\" for depthToSpace with input shape \"+r.shape}),St.runKernel(function(t){return t.depthToSpace(r,e,n)},{$x:r})}}),ir=vn({expandDims_:function(t,e){void 0===e&&(e=0);var n=nn(t,\"x\",\"expandDims\",null);f(e<=n.rank,function(){return\"Axis must be <= rank of the tensor\"});var r=n.shape.slice();return e<0&&(f(-(n.rank+1)<=e,function(){return\"Axis must be in the interval [\"+-(n.rank+1)+\", \"+n.rank+\"]\"}),e=n.rank+e+1),r.splice(e,0,1),xr(n,r)}}),sr=vn({eye_:function(t,e,n,r){void 0===r&&(r=\"float32\"),null==e&&(e=t);for(var o=Zn([t,e],r),a=t<=e?t:e,i=0;i<a;++i)o.set(1,i,i);var s=o.toTensor().as2D(t,e);if(null==n)return s;if(1===n.length)return Er(ir(s,0),[n[0],1,1]);if(2===n.length)return Er(ir(ir(s,0),0),[n[0],n[1],1,1]);if(3===n.length)return Er(ir(ir(ir(s,0),0),0),[n[0],n[1],n[2],1,1]);throw new Error(\"eye() currently supports only 1D and 2D batchShapes, but received \"+n.length+\"D.\")}}),ur=vn({multinomial_:function(t,e,n,r){void 0===r&&(r=!1);var o=nn(t,\"logits\",\"multinomial\"),a=o.size,i=o.rank;if(a<2)throw new Error(\"Error in multinomial: you need at least 2 outcomes, but got \"+a+\".\");if(i>2)throw new Error(\"Rank of probabilities must be 1 or 2, but is \"+i);n=n||Math.random();var s=1===i?o.as2D(1,-1):o,u=St.runKernel(function(t){return t.multinomial(s,r,e,n)},{logits2D:s});return 1===i?u.as1D():u}}),lr=vn({oneHot_:function(t,e,n,r){if(void 0===n&&(n=1),void 0===r&&(r=0),e<2)throw new Error(\"Error in oneHot: depth must be >=2, but it is \"+e);var o=nn(t,\"indices\",\"oneHot\",\"int32\"),a=o.shape.concat([e]);return o=o.flatten(),St.runKernel(function(t){return t.oneHot(o,e,n,r)},{$indices:o},function(t){return{$indices:function(){return An(o.shape,\"float32\")}}}).reshape(a)}}),cr=vn({pad_:function(t,e,n){void 0===n&&(n=0);var r=nn(t,\"x\",\"pad\");if(0===r.rank)throw new Error(\"pad(scalar) is not defined. Pass non-scalar to pad\");var o=e.map(function(t){return t[0]});return St.runKernel(function(t){return t.pad(r,e,n)},{$x:r},function(t){return{$x:function(){return t.slice(o,r.shape)}}})}}),hr=vn({pad1d_:function(t,e,n){return void 0===n&&(n=0),f(2===e.length,function(){return\"Invalid number of paddings. Must be length of 2.\"}),cr(t,[e],n)}}),pr=vn({pad2d_:function(t,e,n){return void 0===n&&(n=0),f(2===e.length&&2===e[0].length&&2===e[1].length,function(){return\"Invalid number of paddings. Must be length of 2 each.\"}),cr(t,e,n)}}),fr=vn({pad3d_:function(t,e,n){return void 0===n&&(n=0),f(3===e.length&&2===e[0].length&&2===e[1].length&&2===e[2].length,function(){return\"Invalid number of paddings. Must be length of 2 each.\"}),cr(t,e,n)}}),dr=vn({pad4d_:function(t,e,n){return void 0===n&&(n=0),f(4===e.length&&2===e[0].length&&2===e[1].length&&2===e[2].length&&2===e[3].length,function(){return\"Invalid number of paddings. Must be length of 2 each.\"}),cr(t,e,n)}}),vr=vn({rand_:function(t,e,n){var r=g(t),o=null;if(null==n||\"float32\"===n)o=new Float32Array(r);else if(\"int32\"===n)o=new Int32Array(r);else{if(\"bool\"!==n)throw new Error(\"Unknown data type \"+n);o=new Uint8Array(r)}for(var a=0;a<r;a++)o[a]=e();return ct.make(t,{values:o},n)}}),mr=vn({randomNormal_:function(t,e,n,r,o){if(void 0===e&&(e=0),void 0===n&&(n=1),null!=r&&\"bool\"===r)throw new Error(\"Unsupported data type \"+r);for(var a=new Yn(e,n,r,!1,o),i=Zn(t,r),s=0;s<i.values.length;s++)i.values[s]=a.nextValue();return i.toTensor()}}),gr=vn({randomGamma_:function(t,e,n,r,o){if(void 0===n&&(n=1),void 0===r&&(r=\"float32\"),null==n&&(n=1),null==r&&(r=\"float32\"),\"float32\"!==r&&\"int32\"!==r)throw new Error(\"Unsupported data type \"+r);for(var a=new Qn(e,n,r,o),i=Zn(t,r),s=0;s<i.values.length;s++)i.values[s]=a.nextValue();return i.toTensor()}}),yr=vn({randomUniform_:function(t,e,n,r,o){void 0===e&&(e=0),void 0===n&&(n=1),void 0===r&&(r=\"float32\");for(var a=Zn(t,r),i=new Jn(e,n,null,o),s=0;s<a.values.length;s++)a.values[s]=i.nextValue();return a.toTensor()}}),xr=vn({reshape_:function(t,e){var n=nn(t,\"x\",\"reshape\",null);return e=R(e,n.size),f(n.size===g(e),function(){return\"new shape and old shape must have the same number of elements.\"}),St.runKernel(function(t){return t.reshape(n,e)},{$x:n},function(t){return{$x:function(){return t.reshape(n.shape)}}})}}),br=vn({spaceToBatchND_:function(t,e,n){var r=nn(t,\"x\",\"spaceToBatchND\");return f(r.rank>=1+e.length,function(){return\"input rank \"+r.rank+\" should be > than [blockShape] \"+e.length}),f(n.length===e.length,function(){return\"paddings.shape[0] \"+n.length+\" must be equal to [blockShape] \"+e.length}),f(r.shape.reduce(function(t,r,o){return o>0&&o<=e.length?t&&(r+n[o-1][0]+n[o-1][1])%e[o-1]==0:t},!0),function(){return\"input spatial dimensions \"+r.shape.slice(1)+\" with paddings \"+n.toString()+\" must be divisible by blockShapes \"+e.toString()}),St.runKernel(function(t){return t.spaceToBatchND(r,e,n)},{$x:r},function(t){return{$x:function(){return t.batchToSpaceND(e,n)}}})}}),wr=vn({squeeze_:function(t,e){var n=nn(t,\"x\",\"squeeze\");return xr(n,k(n.shape,e).newShape)}}),Cr=vn({stack_:function(t,e){void 0===e&&(e=0);var n=rn(t,\"tensors\",\"stack\");if(f(n.length>=1,function(){return\"Pass at least one tensor to tf.stack\"}),1===n.length)return n[0].expandDims(e);var r=n[0].rank,o=n[0].shape,a=n[0].dtype;f(e<=r,function(){return\"Axis must be <= rank of the tensor\"}),n.forEach(function(t){d(o,t.shape,\"All tensors passed to stack must have matching shapes\")}),n.forEach(function(t){f(a===t.dtype,function(){return\"All tensors passed to stack must have matching dtypes\"})});var i=n.map(function(t){return t.expandDims(e)});return Mn(i,e)}}),Er=vn({tile_:function(t,e){var n=nn(t,\"x\",\"tile\",null);return f(n.rank===e.length,function(){return\"Error in transpose: rank of input \"+n.rank+\" must match length of reps \"+e+\".\"}),St.runKernel(function(t,r){var o=t.tile(n,e);return r([n]),o},{$x:n},function(t,n){var r=n[0];return{$x:function(){var n=Fn(r);if(1===r.rank)for(var o=0;o<e[0];++o)n=n.add(t.slice([o*r.shape[0]],[r.shape[0]]));else if(2===r.rank)for(o=0;o<e[0];++o)for(var a=0;a<e[1];++a)n=n.add(t.slice([o*r.shape[0],a*r.shape[1]],[r.shape[0],r.shape[1]]));else if(3===r.rank)for(o=0;o<e[0];++o)for(a=0;a<e[1];++a)for(var i=0;i<e[2];++i)n=n.add(t.slice([o*r.shape[0],a*r.shape[1],i*r.shape[2]],[r.shape[0],r.shape[1],r.shape[2]]));else{if(4!==r.rank)throw new Error(\"Gradient for tile operation is not implemented for rank-\"+r.rank+\" tensors yet.\");for(o=0;o<e[0];++o)for(a=0;a<e[1];++a)for(i=0;i<e[2];++i)for(var s=0;s<e[3];++s)n=n.add(t.slice([o*r.shape[0],a*r.shape[1],i*r.shape[2],s*r.shape[3]],[r.shape[0],r.shape[1],r.shape[2],r.shape[3]]))}return n}}})}}),Rr=vn({truncatedNormal_:function(t,e,n,r,o){if(void 0===e&&(e=0),void 0===n&&(n=1),null!=r&&\"bool\"===r)throw new Error(\"Unsupported data type \"+r);for(var a=new Yn(e,n,r,!0,o),i=Zn(t,r),s=0;s<i.values.length;s++)i.values[s]=a.nextValue();return i.toTensor()}}),Ir=vn({unstack_:function(t,e){void 0===e&&(e=0),e=e||0;var n=nn(t,\"x\",\"unstack\");return f(e>=-n.shape.length&&e<n.shape.length,function(){return\"Axis = \"+e+\" is not in [-\"+n.shape.length+\", \"+n.shape.length+\")\"}),e<0&&(e+=n.shape.length),St.runKernel(function(t){return t.unstack(n,e)},{$x:n},function(t){return{$x:function(){return Cr(t,e)}}})}}),kr=function(t,e){return n(this,void 0,void 0,function(){var n,o,a,i,s,u,l,c,h,p;return r(this,function(r){switch(r.label){case 0:return n=nn(t,\"x\",\"setdiff1d\"),o=nn(e,\"y\",\"setdiff1d\"),f(n.dtype===o.dtype,function(){return\"x and y should have the same dtype, but got x (\"+n.dtype+\") and y (\"+o.dtype+\").\"}),f(1===n.rank,function(){return\"x should be 1D tensor, but got x (\"+n.shape+\").\"}),f(1===o.rank,function(){return\"y should be 1D tensor, but got y (\"+o.shape+\").\"}),[4,n.data()];case 1:return a=r.sent(),[4,o.data()];case 2:for(i=r.sent(),s=new Set(i),u=0,h=0;h<a.length;h++)s.has(a[h])||u++;for(l=new it([u],n.dtype),c=new it([u],\"int32\"),h=0,p=0;h<a.length;h++)s.has(a[h])||(l.values[p]=a[h],c.values[p]=h,p++);return[2,[l.toTensor(),c.toTensor()]]}})})};function Nr(t,e,n,r){void 0===r&&(r=!0);var o=[];if(r)(o=o.concat(e.slice(0))).push(t[0]/n),o=o.concat(t.slice(1));else{o=o.concat(t[0]);for(var a=e.length,i=0;i<a;++i)o=o.concat([t[i+1]/e[i],e[i]]);o=o.concat(t.slice(a+1))}return o}function Sr(t,e,n){void 0===n&&(n=!0);var r=[];if(n){r.push(e);for(var o=e+1;o<t;++o)o<=2*e?(r.push(o),r.push(o-(e+1))):r.push(o)}else{var a=[],i=[];for(o=1;o<t;++o)o>=2*e+1||o%2==1?i.push(o):a.push(o);r.push.apply(r,a),r.push(0),r.push.apply(r,i)}return r}function Ar(t,e,n,r){void 0===r&&(r=!0);var o=[];r?o.push(t[0]/n):o.push(t[0]*n);for(var a=1;a<t.length;++a)a<=e.length?r?o.push(e[a-1]*t[a]):o.push(t[a]/e[a-1]):o.push(t[a]);return o}function Tr(t,e){for(var n=[0],r=0;r<e;++r)n.push(t[r][0]);return n}function Dr(t,e,n){for(var r=t.slice(0,1),o=0;o<n;++o)r.push(t[o+1]-e[o][0]-e[o][1]);return r}function _r(t,e){if(t.rank<1)throw new Error(\"tf.gatherND() expects the input to be rank 1 or higher, but the rank was \"+t.rank+\".\");if(e.rank<1)throw new Error(\"tf.gatherND() expects the indices to be rank 1 or higher, but the rank was \"+e.rank+\".\");if(\"int32\"!==e.dtype)throw new Error(\"tf.gatherND() expects the indices to be int32 type, but the dtype was \"+e.dtype+\".\");if(e.shape[e.rank-1]>t.rank)throw new Error(\"index innermost dimension length must be <= tensor rank; saw: \"+e.shape[e.rank-1]+\" vs. \"+t.rank);if(0===t.size)throw new Error(\"Requested more than 0 entries, but input is empty. Input shape: \"+t.shape+\".\");for(var n=e.shape,r=n[n.length-1],o=1,a=0;a<n.length-1;++a)o*=n[a];var i=t.shape,s=n.slice();s.pop();var u=1;for(a=r;a<t.rank;++a)u*=i[a],s.push(i[a]);var l=V(t.shape).map(function(t){return t/u}).concat([1]).slice(0,r);return[s,o,u,l]}var Or=30;function Fr(t){return t<=Or?t:U(t,Math.floor(Math.sqrt(t)))}function Mr(t,e,n){if(e.rank<1)throw new Error(\"tf.scatterND() expects the indices to be rank 1 or higher, but the rank was \"+e.rank+\".\");if(t.rank<1)throw new Error(\"tf.scatterND() expects the updates to be rank 1 or higher, but the rank was \"+t.rank+\".\");if(\"int32\"!==e.dtype)throw new Error(\"The dtype of 'indices' should be int32, but got dtype: \"+e.dtype);if(n.length<1)throw new Error(\"Output rank must be greater or equal to 1, but got shape: \"+n);if(0===n.length){if(0===e.size)throw new Error(\"Indices specified for empty output. indices shape: \"+e.shape);if(0===t.size)throw new Error(\"Updates specified for empty output. updates shape: \"+t.shape)}!function(t,e,n){var r=e.rank>1?e.shape[e.rank-1]:1,o=e.rank>1?e.rank-1:1,a=\"Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: \"+n.shape+\", indices.shape: \"+e.shape+\", shape: \"+t+\", sliceDim: \"+r+\", and batchDim: \"+o+\".\";if(n.rank<o)throw new Error(a+\" update.rank < \"+o+\". \");if(t.length<r+(n.rank-o))throw new Error(a+\" Output shape length < \"+(r+(n.rank-o)));if(n.rank!==o+t.length-r)throw new Error(a+\" update.rank != \"+(o+t.length-r));for(var i=0;i<o;++i)if(n.shape[i]!==e.shape[i])throw new Error(a+\" updates.shape[\"+i+\"] (\"+n.shape[i]+\") != indices.shape[\"+i+\"] (\"+e.shape[i]+\").\");for(i=0;i<n.rank-o;++i)if(n.shape[i+o]!==t[i+r])throw new Error(a+\" updates.shape[\"+(i+o)+\"] (\"+n.shape[i+o]+\") != shape[\"+(i+o)+\"] (\"+t[i+o]+\")\")}(n,e,t)}function Br(t,e,n){for(var r=e.rank>1?e.shape[e.rank-1]:1,o=n.length,a=1,i=r;i<o;++i)a*=n[i];var s=r<1?1:r;return{sliceRank:r,numUpdates:e.size/s,sliceSize:a,strides:V(n.slice(0,r)).concat([1]),outputSize:g(n)}}function Pr(t){for(var e=[],n=0;t>0;)1&t&&e.push(n),t/=2,n++;return e}function Lr(t,e,n){for(var r=[],o=0;o<t.length;o++)r[o]=Math.ceil((e[o]-t[o])/n[o]);return r}function Wr(t,e,n,r,o){var a=e[o],i=n[o]||1;(t&1<<o||null==a)&&(a=i>0?Number.MIN_SAFE_INTEGER:Number.MAX_SAFE_INTEGER);var s=r[o];return a<0&&(a+=s),a=c(0,a,s-1)}function Ur(t,e,n,r,o){var a=e[o],i=n[o]||1;(t&1<<o||null==a)&&(a=i>0?Number.MAX_SAFE_INTEGER:Number.MIN_SAFE_INTEGER);var s=r[o];return a<0&&(a+=s),a=i>0?c(0,a,s):c(-1,a,s-1)}function Vr(t,e,n){for(var r=n.length,o=0;o<n.length;o++)if(n[o]>1){r=o;break}for(o=r+1;o<n.length;o++)if(e[o]>0||n[o]!==t[o])return!1;return!0}function zr(t,e){for(var n=t.length>0?t[t.length-1]:1,r=0;r<t.length-1;r++)n+=t[r]*e[r];return n}function Gr(t){return f(W(t),function(){return\"The f passed in grad(f) must be a function\"}),function(e,n){var r=nn(e,\"x\",\"tf.grad\",null),o=null!=n?nn(n,\"dy\",\"tf.grad\"):null;return St.tidy(function(){var e=St.gradients(function(){return t(r)},[r],o),n=e.value,a=e.grads;return null!=o&&d(n.shape,o.shape,\"The shape of dy passed in grad(f)(x, dy) must match the shape returned by f(x)\"),Xr(a),a[0]})}}function Hr(t){return f(W(t),function(){return\"The f passed in grads(f) must be a function\"}),function(e,n){f(Array.isArray(e),function(){return\"The args passed in grads(f)(args) must be an array of `Tensor`s or `TensorLike`s\"});var r=rn(e,\"args\",\"tf.grads\",null),o=null!=n?nn(n,\"dy\",\"tf.grads\"):null;return St.tidy(function(){var e=St.gradients(function(){return t.apply(void 0,r)},r,o),n=e.value,a=e.grads;return null!=o&&d(n.shape,o.shape,\"The shape of dy passed in grads(f)([x1,...], dy) must match the shape returned by f([x1,...])\"),Xr(a),a})}}function qr(t){return f(W(t),function(){return\"The f passed in valueAndGrad(f) must be a function\"}),function(e,n){f(e instanceof ct,function(){return\"The x passed in valueAndGrad(f)(x) must be a tensor\"}),f(null==n||n instanceof ct,function(){return\"The dy passed in valueAndGrad(f)(x, dy) must be a tensor\"});var r=St.gradients(function(){return t(e)},[e],n),o=r.grads,a=r.value;return Xr(o),{grad:o[0],value:a}}}function $r(t){return f(W(t),function(){return\"The f passed in valueAndGrads(f) must be a function\"}),function(e,n){f(Array.isArray(e)&&e.every(function(t){return t instanceof ct}),function(){return\"The args passed in valueAndGrads(f)(args) must be array of tensors\"}),f(null==n||n instanceof ct,function(){return\"The dy passed in valueAndGrads(f)(args, dy) must be a tensor\"});var r=St.gradients(function(){return t.apply(void 0,e)},e,n);return null!=n&&d(r.value.shape,n.shape,\"The shape of dy passed in valueAndGrads(f)([x1,...], dy) must match the shape returned by f([x1,...])\"),Xr(r.grads),r}}function Kr(t,e){f(W(t),function(){return\"The f passed in variableGrads(f) must be a function\"}),f(null==e||Array.isArray(e)&&e.every(function(t){return t instanceof ht}),function(){return\"The varList passed in variableGrads(f, varList) must be an array of variables\"});var n=null!=e;if(!n)for(var r in e=[],St.registeredVariables)e.push(St.registeredVariables[r]);var o=n?e.filter(function(t){return!t.trainable}):null,a=e.length;f((e=e.filter(function(t){return t.trainable})).length>0,function(){return\"variableGrads() expects at least one of the input variables to be trainable, but none of the \"+a+\" variables is trainable.\"});var i=St.gradients(t,e,null,!0),s=i.value,u=i.grads;f(u.some(function(t){return null!=t}),function(){return\"Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize().\"}),f(0===s.rank,function(){return\"The f passed in variableGrads(f) must return a scalar, but it returned a rank-\"+s.rank+\" tensor\"});var l={};return e.forEach(function(t,e){null!=u[e]&&(l[t.name]=u[e])}),null!=o&&o.forEach(function(t){return l[t.name]=null}),{value:s,grads:l}}function jr(t){return St.customGrad(t)}function Xr(t){if(t.filter(function(t){return null==t}).length>0)throw new Error(\"Cannot compute gradient of y=f(x) with respect to x. Make sure that\\n    the f you passed encloses all operations that lead from x to y.\")}var Yr=vn({softmax_:function(t,e){void 0===e&&(e=-1);var n=nn(t,\"logits\",\"softmax\");if(-1===e&&(e=n.rank-1),e!==n.rank-1)throw Error(\"Softmax along a non-last dimension is not yet supported. Logits was rank \"+n.rank+\" and dim was \"+e);return jr(function(t,n){var r=t.logSumExp([e],!0),o=t.toFloat().sub(r).exp();return n([o]),{value:o,gradFunc:function(t,n){var r=n[0],o=t.mul(r);return o.sub(o.sum([e],!0).mul(r))}}})(n)}}),Qr=vn({logSoftmax_:function(t,e){void 0===e&&(e=-1);var n=nn(t,\"logits\",\"logSoftmax\");if(-1===e&&(e=n.rank-1),e!==n.rank-1)throw Error(\"Log Softmax along a non-last dimension is not yet supported. Logits was rank \"+n.rank+\" and axis was \"+e);return jr(function(t,n){var r=t.max(e,!0),o=t.sub(r),a=o.toFloat().sub(o.exp().sum(e,!0).log());return n([a]),{value:a,gradFunc:function(t,n){var r=n[0].exp();return t.sub(t.sum(e,!0).mul(r))}}})(n)}}),Jr=function(){function t(t,e){this.backend=t,this.dataMover=e,this.data=new WeakMap}return t.prototype.get=function(t){return this.data.has(t)||this.dataMover.moveData(this.backend,t),this.data.get(t)},t.prototype.set=function(t,e){this.data.set(t,e)},t.prototype.has=function(t){return this.data.has(t)},t.prototype.delete=function(t){return this.data.delete(t)},t}(),Zr=function(){function t(){}return t.prototype.time=function(t){throw new Error(\"Not yet implemented.\")},t.prototype.read=function(t){throw new Error(\"Not yet implemented.\")},t.prototype.readSync=function(t){throw new Error(\"Not yet implemented.\")},t.prototype.disposeData=function(t){throw new Error(\"Not yet implemented.\")},t.prototype.write=function(t,e){throw new Error(\"Not yet implemented.\")},t.prototype.fromPixels=function(t,e){throw new Error(\"Not yet implemented.\")},t.prototype.register=function(t,e,n){throw new Error(\"Not yet implemented.\")},t.prototype.memory=function(){throw new Error(\"Not yet implemented.\")},t.prototype.floatPrecision=function(){throw new Error(\"Not yet implemented\")},t.prototype.epsilon=function(){return 32===this.floatPrecision()?1e-7:1e-4},t.prototype.batchMatMul=function(t,e,n,r){throw new Error(\"Not yet implemented\")},t.prototype.fusedBatchMatMul=function(t){t.a,t.b,t.transposeA,t.transposeB,t.bias,t.activation,t.preluActivationWeights;throw new Error(\"Not yet implemented\")},t.prototype.slice=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.stridedSlice=function(t,e,n,r){throw new Error(\"Not yet implemented\")},t.prototype.unstack=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.reverse=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.concat=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.neg=function(t){throw new Error(\"Not yet implemented\")},t.prototype.add=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.addN=function(t){throw new Error(\"Not yet implemented\")},t.prototype.subtract=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.multiply=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.realDivide=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.floorDiv=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.sum=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.prod=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.unsortedSegmentSum=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.argMin=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.argMax=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.equal=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.notEqual=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.less=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.lessEqual=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.greater=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.greaterEqual=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.logicalNot=function(t){throw new Error(\"Not yet implemented\")},t.prototype.logicalAnd=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.logicalOr=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.where=function(t){throw new Error(\"Not yet implemented\")},t.prototype.select=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.topk=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.min=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.minimum=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.mod=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.max=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.maximum=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.all=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.any=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.squaredDifference=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.ceil=function(t){throw new Error(\"Not yet implemented\")},t.prototype.floor=function(t){throw new Error(\"Not yet implemented\")},t.prototype.round=function(t){throw new Error(\"Not yet implemented\")},t.prototype.sign=function(t){throw new Error(\"Not yet implemented\")},t.prototype.isNaN=function(t){throw new Error(\"Not yet implemented\")},t.prototype.isInf=function(t){throw new Error(\"Not yet implemented\")},t.prototype.isFinite=function(t){throw new Error(\"Not yet implemented\")},t.prototype.pow=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.exp=function(t){throw new Error(\"Not yet implemented\")},t.prototype.expm1=function(t){throw new Error(\"Not yet implemented\")},t.prototype.log=function(t){throw new Error(\"Not yet implemented\")},t.prototype.log1p=function(t){throw new Error(\"Not yet implemented\")},t.prototype.sqrt=function(t){throw new Error(\"Not yet implemented\")},t.prototype.rsqrt=function(t){throw new Error(\"Not yet implemented\")},t.prototype.square=function(t){throw new Error(\"Not yet implemented\")},t.prototype.reciprocal=function(t){throw new Error(\"Not yet implemented\")},t.prototype.relu=function(t){throw new Error(\"Not yet implemented\")},t.prototype.prelu=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.elu=function(t){throw new Error(\"Not yet implemented\")},t.prototype.eluDer=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.selu=function(t){throw new Error(\"Not yet implemented\")},t.prototype.int=function(t){throw new Error(\"Not yet implemented\")},t.prototype.clip=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.abs=function(t){throw new Error(\"Not yet implemented\")},t.prototype.complexAbs=function(t){throw new Error(\"Not yet implemented\")},t.prototype.sigmoid=function(t){throw new Error(\"Not yet implemented\")},t.prototype.softplus=function(t){throw new Error(\"Not yet implemented\")},t.prototype.sin=function(t){throw new Error(\"Not yet implemented\")},t.prototype.cos=function(t){throw new Error(\"Not yet implemented\")},t.prototype.tan=function(t){throw new Error(\"Not yet implemented\")},t.prototype.asin=function(t){throw new Error(\"Not yet implemented\")},t.prototype.acos=function(t){throw new Error(\"Not yet implemented\")},t.prototype.atan=function(t){throw new Error(\"Not yet implemented\")},t.prototype.atan2=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.sinh=function(t){throw new Error(\"Not yet implemented\")},t.prototype.cosh=function(t){throw new Error(\"Not yet implemented\")},t.prototype.tanh=function(t){throw new Error(\"Not yet implemented\")},t.prototype.asinh=function(t){throw new Error(\"Not yet implemented\")},t.prototype.acosh=function(t){throw new Error(\"Not yet implemented\")},t.prototype.atanh=function(t){throw new Error(\"Not yet implemented\")},t.prototype.erf=function(t){throw new Error(\"Not yet implemented\")},t.prototype.step=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.fusedConv2d=function(t,e,n,r,o,a){throw new Error(\"Not yet implemented\")},t.prototype.conv2d=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.conv2dDerInput=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.conv2dDerFilter=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.depthwiseConv2D=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.depthwiseConv2DDerInput=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.depthwiseConv2DDerFilter=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.conv3d=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.conv3dDerInput=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.conv3dDerFilter=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.maxPool=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.maxPoolBackprop=function(t,e,n,r){throw new Error(\"Not yet implemented\")},t.prototype.avgPool=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.avgPoolBackprop=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.avgPool3d=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.avgPool3dBackprop=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.maxPool3d=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.maxPool3dBackprop=function(t,e,n,r){throw new Error(\"Not yet implemented\")},t.prototype.reshape=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.cast=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.tile=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.pad=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.transpose=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.gather=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.gatherND=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.scatterND=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.batchToSpaceND=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.spaceToBatchND=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.resizeBilinear=function(t,e,n,r){throw new Error(\"Not yet implemented\")},t.prototype.resizeBilinearBackprop=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.resizeNearestNeighbor=function(t,e,n,r){throw new Error(\"Not yet implemented\")},t.prototype.resizeNearestNeighborBackprop=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.batchNormalization=function(t,e,n,r,o,a){throw new Error(\"Not yet implemented\")},t.prototype.localResponseNormalization4D=function(t,e,n,r,o){throw new Error(\"Not yet implemented\")},t.prototype.LRNGrad=function(t,e,n,r,o,a,i){throw new Error(\"Not yet implemented\")},t.prototype.multinomial=function(t,e,n,r){throw new Error(\"Not yet implemented\")},t.prototype.oneHot=function(t,e,n,r){throw new Error(\"Not yet implemented\")},t.prototype.cumsum=function(t,e,n,r){throw new Error(\"Not yet implemented\")},t.prototype.nonMaxSuppression=function(t,e,n,r,o){throw new Error(\"Not yet implemented\")},t.prototype.fft=function(t){throw new Error(\"Not yet implemented\")},t.prototype.ifft=function(t){throw new Error(\"Not yet implemented\")},t.prototype.complex=function(t,e){throw new Error(\"Not yet implemented\")},t.prototype.real=function(t){throw new Error(\"Not yet implemented\")},t.prototype.imag=function(t){throw new Error(\"Not yet implemented\")},t.prototype.cropAndResize=function(t,e,n,r,o,a){throw new Error(\"Not yet implemented\")},t.prototype.depthToSpace=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.split=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.sparseToDense=function(t,e,n,r){throw new Error(\"Not yet implemented\")},t.prototype.diag=function(t){throw new Error(\"Not yet implemented\")},t.prototype.fill=function(t,e,n){throw new Error(\"Not yet implemented.\")},t.prototype.onesLike=function(t){throw new Error(\"Not yet implemented\")},t.prototype.zerosLike=function(t){throw new Error(\"Not yet implemented\")},t.prototype.linspace=function(t,e,n){throw new Error(\"Not yet implemented\")},t.prototype.dispose=function(){throw new Error(\"Not yet implemented\")},t}();function to(t,e){for(var n=t.length,r=[],o=0;o<n;o++){var a=n-1-o,i=t[a]||1;(e[e.length-1-o]||1)>1&&1===i&&r.unshift(a)}return r}function eo(t,e){for(var n=[],r=0;r<e.length;r++){var o=t[t.length-r-1],a=e.length-r-1,i=e[a];(null==o||1===o&&i>1)&&n.unshift(a)}return n}function no(t,e){for(var n=[],r=Math.max(t.length,e.length),o=0;o<r;o++){var a=t[t.length-o-1];null==a&&(a=1);var i=e[e.length-o-1];if(null==i&&(i=1),1===a)n.unshift(i);else if(1===i)n.unshift(a);else{if(a!==i)throw Error(\"Operands could not be broadcast together with shapes \"+t+\" and \"+e+\".\");n.unshift(a)}}return n}function ro(t,e,n,r,o,a,i){void 0===i&&(i=\"channelsLast\");var s,u=uo(e),l=u[0],c=u[1];if(\"channelsLast\"===i)s=[l,c,t[3],t[3]];else{if(\"channelsFirst\"!==i)throw new Error(\"Unknown dataFormat \"+i);s=[l,c,t[1],t[1]]}return ao(t,s,n,r,o,a,!1,i)}function oo(t,e,n,r,o,a,i){void 0===i&&(i=\"NDHWC\");var s,u,l=lo(e),c=l[0],h=l[1],p=l[2];if(\"NDHWC\"===i)u=\"channelsLast\",s=[c,h,p,t[4],t[4]];else{if(\"NCDHW\"!==i)throw new Error(\"Unknown dataFormat \"+i);u=\"channelsFirst\",s=[c,h,p,t[1],t[1]]}return io(t,s,n,r,o,!1,u,a)}function ao(t,e,n,r,o,a,i,s){void 0===i&&(i=!1),void 0===s&&(s=\"channelsLast\");var u=[-1,-1,-1,-1],l=u[0],c=u[1],h=u[2],p=u[3];if(\"channelsLast\"===s)l=t[0],c=t[1],h=t[2],p=t[3];else{if(\"channelsFirst\"!==s)throw new Error(\"Unknown dataFormat \"+s);l=t[0],p=t[1],c=t[2],h=t[3]}var d,v=e[0],m=e[1],g=e[3],y=uo(n),b=y[0],w=y[1],C=uo(r),E=C[0],R=C[1],I=co(v,E),k=co(m,R),N=function(t,e,n,r,o,a,i,s){var u,l,c;if(\"number\"==typeof t){var h=0===t?\"VALID\":\"NUMBER\";u={top:t,bottom:t,left:t,right:t,type:h};var p=function(t,e,n,r,o){null==r&&(r=so(t,e,n));var a=t[0],i=t[1],s=ho((a-e+2*r)/n+1,o);f(x(s),function(){return\"The output # of rows (\"+s+\") must be an integer. Change the stride and/or zero pad parameters\"});var u=ho((i-e+2*r)/n+1,o);return f(x(u),function(){return\"The output # of columns (\"+u+\") must be an integer. Change the stride and/or zero pad parameters\"}),[s,u]}([e,n],a,r,t,s);l=p[0],c=p[1]}else if(\"same\"===t){l=Math.ceil(e/r),c=Math.ceil(n/o);var d=Math.max(0,(l-1)*r+a-e),v=Math.max(0,(c-1)*o+i-n),m=Math.floor(d/2),g=d-m,y=Math.floor(v/2),b=v-y;u={top:m,bottom:g,left:y,right:b,type:\"SAME\"}}else{if(\"valid\"!==t)throw Error(\"Unknown padding parameter: \"+t);u={top:0,bottom:0,left:0,right:0,type:\"VALID\"},l=Math.ceil((e-a+1)/r),c=Math.ceil((n-i+1)/o)}return{padInfo:u,outHeight:l,outWidth:c}}(o,c,h,b,w,I,k,a),S=N.padInfo,A=N.outHeight,T=N.outWidth,D=i?g*p:g;return\"channelsFirst\"===s?d=[l,D,A,T]:\"channelsLast\"===s&&(d=[l,A,T,D]),{batchSize:l,dataFormat:s,inHeight:c,inWidth:h,inChannels:p,outHeight:A,outWidth:T,outChannels:D,padInfo:S,strideHeight:b,strideWidth:w,filterHeight:v,filterWidth:m,effectiveFilterHeight:I,effectiveFilterWidth:k,dilationHeight:E,dilationWidth:R,inShape:t,outShape:d,filterShape:e}}function io(t,e,n,r,o,a,i,s){void 0===a&&(a=!1),void 0===i&&(i=\"channelsLast\");var u=[-1,-1,-1,-1,-1],l=u[0],c=u[1],h=u[2],p=u[3],d=u[4];if(\"channelsLast\"===i)l=t[0],c=t[1],h=t[2],p=t[3],d=t[4];else{if(\"channelsFirst\"!==i)throw new Error(\"Unknown dataFormat \"+i);l=t[0],d=t[1],c=t[2],h=t[3],p=t[4]}var v,m=e[0],g=e[1],y=e[2],b=e[4],w=lo(n),C=w[0],E=w[1],R=w[2],I=lo(r),k=I[0],N=I[1],S=I[2],A=co(m,k),T=co(g,N),D=co(y,S),_=function(t,e,n,r,o,a,i,s,u,l,c){var h,p,d,v;if(\"number\"==typeof t){var m=0===t?\"VALID\":\"NUMBER\";h={top:t,bottom:t,left:t,right:t,front:t,back:t,type:m};var g=function(t,e,n,r,o,a){null==o&&(o=so(t,e,r));var i=t[0],s=t[1],u=t[2],l=ho((i-e+2*o)/r+1,a);f(x(l),function(){return\"The output # of depths (\"+l+\") must be an integer. Change the stride and/or zero pad parameters\"});var c=ho((s-e+2*o)/r+1,a);f(x(c),function(){return\"The output # of rows (\"+c+\") must be an integer. Change the stride and/or zero pad parameters\"});var h=ho((u-e+2*o)/r+1,a);return f(x(h),function(){return\"The output # of columns (\"+h+\") must be an integer. Change the stride and/or zero pad parameters\"}),[l,c,h,n]}([e,n,r,1],s,1,o,t,c);p=g[0],d=g[1],v=g[2]}else if(\"same\"===t){p=Math.ceil(e/o),d=Math.ceil(n/a),v=Math.ceil(r/i);var y=(p-1)*o+s-e,b=(d-1)*a+u-n,w=(v-1)*i+l-r,C=Math.floor(y/2),E=y-C,R=Math.floor(b/2),I=b-R,k=Math.floor(w/2),N=w-k;h={top:R,bottom:I,left:k,right:N,front:C,back:E,type:\"SAME\"}}else{if(\"valid\"!==t)throw Error(\"Unknown padding parameter: \"+t);h={top:0,bottom:0,left:0,right:0,front:0,back:0,type:\"VALID\"},p=Math.ceil((e-s+1)/o),d=Math.ceil((n-u+1)/a),v=Math.ceil((r-l+1)/i)}return{padInfo:h,outDepth:p,outHeight:d,outWidth:v}}(o,c,h,p,C,E,R,A,T,D,s),O=_.padInfo,F=_.outDepth,M=_.outHeight,B=_.outWidth,P=a?b*d:b;return\"channelsFirst\"===i?v=[l,P,F,M,B]:\"channelsLast\"===i&&(v=[l,F,M,B,P]),{batchSize:l,dataFormat:i,inDepth:c,inHeight:h,inWidth:p,inChannels:d,outDepth:F,outHeight:M,outWidth:B,outChannels:P,padInfo:O,strideDepth:C,strideHeight:E,strideWidth:R,filterDepth:m,filterHeight:g,filterWidth:y,effectiveFilterDepth:A,effectiveFilterHeight:T,effectiveFilterWidth:D,dilationDepth:k,dilationHeight:N,dilationWidth:S,inShape:t,outShape:v,filterShape:e}}function so(t,e,n,r){void 0===r&&(r=1);var o=co(e,r);return Math.floor((t[0]*(n-1)-n+o)/2)}function uo(t){return\"number\"==typeof t?[t,t,t]:2===t.length?[t[0],t[1],1]:t}function lo(t){return\"number\"==typeof t?[t,t,t]:t}function co(t,e){return e<=1?t:t+(t-1)*(e-1)}function ho(t,e){if(!e)return t;switch(e){case\"round\":return Math.round(t);case\"ceil\":return Math.ceil(t);case\"floor\":return Math.floor(t);default:throw new Error(\"Unknown roundingMode \"+e)}}function po(t){var e=uo(t),n=e[0],r=e[1],o=e[2];return 1===n&&1===r&&1===o}function fo(t,e){return po(t)||po(e)}function vo(t){if(\"NHWC\"===t)return\"channelsLast\";if(\"NCHW\"===t)return\"channelsFirst\";throw new Error(\"Unknown dataFormat \"+t)}function mo(t,e,n){if(\"complex64\"===e){if(\"complex64\"===t.dtype)return t.clone();var r=An(t.shape),o=t.toFloat(),a=n.complex(o,r);return r.dispose(),o.dispose(),a}if(!D(t.dtype,e))return ct.make(t.shape,{dataId:t.dataId},e);if(\"complex64\"===t.dtype){var i=n.real(t);a=i.cast(e);return i.dispose(),a}if(\"int32\"===e)return n.int(t);if(\"bool\"===e){var s=wn(0,t.dtype);a=n.notEqual(t,s);return s.dispose(),a}throw new Error(\"Error in Cast: failed to cast \"+t.dtype+\" to \"+e)}function go(t,e){return ct.make(e,{dataId:t.dataId},t.dtype)}function yo(t,e,n){var r=(e-t)/(n-1),o=q(n,\"float32\");o[0]=t;for(var a=1;a<o.length;a++)o[a]=o[a-1]+r;return Cn(o,\"float32\")}var xo=Object.freeze({castTensor:mo,reshapeTensor:go,linspaceImpl:yo,upcastType:xt,axesAreInnerMostDims:on,combineLocations:an,computeOutAndReduceShapes:sn,expandShapeToKeepDim:un,assertAxesAreInnerMostDims:ln,getAxesPermutation:cn,getUndoAxesPermutation:hn,getInnerMostAxes:pn,getBroadcastDims:to,getReductionAxes:eo,assertAndGetBroadcastShape:no,assertParamsConsistent:fn,computeOutShape:dn,computePool2DInfo:ro,computePool3DInfo:oo,computeConv2DInfo:ao,computeConv3DInfo:io,computeDefaultPad:so,tupleValuesAreOne:po,eitherStridesOrDilationsAreOne:fo,convertConv2DDataFormat:vo});function bo(t,e){if(t.length!==e.length)throw new Error(\"Cannot merge real and imag arrays of different lengths. real:\"+t.length+\", imag: \"+e.length+\".\");for(var n=new Float32Array(2*t.length),r=0;r<n.length;r+=2)n[r]=t[r/2],n[r+1]=e[r/2];return n}function wo(t,e){return{real:t[2*e],imag:t[2*e+1]}}function Co(t,e,n,r){t[2*r]=e,t[2*r+1]=n}function Eo(t,e,n){var r=(n?2:-2)*Math.PI*(t/e);return{real:Math.cos(r),imag:Math.sin(r)}}function Ro(t,e,n,r,o){for(var a=Array.from(e).map(function(t,e){return{score:t,boxIndex:e}}).filter(function(t){return t.score>o}).sort(function(t,e){return e.score-t.score}),i=[],s=0;s<a.length;s++){var u=a[s],l=u.score,c=u.boxIndex;if(l<o)break;for(var h=!1,p=i.length-1;p>=0;--p){if(Io(t,c,i[p])>=r){h=!0;break}}if(!h&&(i.push(c),i.length>=n))break}return Cn(i,\"int32\")}function Io(t,e,n){var r=t.subarray(4*e,4*e+4),o=t.subarray(4*n,4*n+4),a=Math.min(r[0],r[2]),i=Math.min(r[1],r[3]),s=Math.max(r[0],r[2]),u=Math.max(r[1],r[3]),l=Math.min(o[0],o[2]),c=Math.min(o[1],o[3]),h=Math.max(o[0],o[2]),p=Math.max(o[1],o[3]),f=(s-a)*(u-i),d=(h-l)*(p-c);if(f<=0||d<=0)return 0;var v=Math.max(a,l),m=Math.max(i,c),g=Math.min(s,h),y=Math.min(u,p),x=Math.max(g-v,0)*Math.max(y-m,0);return x/(f+d-x)}function ko(t,e,n){var r=new Array(t.rank).fill(0),o=t.shape.slice();return e.map(function(e){o[n]=e;var a=t.slice(r,o);return r[n]+=e,a})}function No(t,e){for(var n=new Array(t.rank),r=0;r<n.length;r++)n[r]=t.shape[r]*e[r];var o=Zn(n,t.dtype);for(r=0;r<o.values.length;++r){for(var a=o.indexToLoc(r),i=new Array(t.rank),s=0;s<i.length;s++)i[s]=a[s]%t.shape[s];var u=t.locToIndex(i);o.values[r]=t.values[u]}return o.toTensor()}function So(t,e,n,r,o){for(var a=e[e.length-1],i=[t.length/a,a],s=i[0],u=i[1],l=N(n,s*r),c=N(\"int32\",s*r),h=0;h<s;h++){for(var p=h*u,f=t.subarray(p,p+u),d=[],v=0;v<f.length;v++)d.push({value:f[v],index:v});d.sort(function(t,e){return e.value-t.value});var m=h*r,g=l.subarray(m,m+r),y=c.subarray(m,m+r);for(v=0;v<r;v++)g[v]=d[v].value,y[v]=d[v].index}var x=e.slice();return x[x.length-1]=r,[xn(l,x,n),xn(c,x,\"int32\")]}function Ao(t,e){for(var n=[],r=0;r<e.length;r++)e[r]&&n.push(r);var o=Zn(t,\"int32\"),a=Zn([n.length,t.length],\"int32\");for(r=0;r<n.length;r++){var i=o.indexToLoc(n[r]),s=r*t.length;a.values.set(i,s)}return a.toTensor()}var To=function(){return function(t,e){this.outputShape=[],this.outputShape=t,this.variableNames=e.map(function(t,e){return\"T\"+e});var n=[];this.variableNames.forEach(function(t){n.push(\"float v\"+t+\" = get\"+t+\"AtOutCoords();\")});var r=this.variableNames.map(function(t){return\"v\"+t}).join(\" + \");this.userCode=\"\\n      void main() {\\n        \"+n.join(\"\\n        \")+\"\\n\\n        float result = \"+r+\";\\n        setOutput(result);\\n      }\\n    \"}}(),Do=function(){return function(t,e){this.outputShape=[],this.usesPackedTextures=!0,this.outputShape=t,this.variableNames=e.map(function(t,e){return\"T\"+e});var n=[];this.variableNames.forEach(function(t){n.push(\"vec4 v\"+t+\" = get\"+t+\"AtOutCoords();\")});var r=this.variableNames.map(function(t){return\"v\"+t}).join(\" + \");this.userCode=\"\\n      void main() {\\n        \"+n.join(\"\\n        \")+\"\\n\\n        vec4 result = \"+r+\";\\n        setOutput(result);\\n      }\\n    \"}}(),_o=function(){return function(t,e,n){this.variableNames=[\"A\"];var r=t.windowSize,o=t.batchSize,a=t.inSize,i=Math.ceil(a/r);n||this.variableNames.push(\"bestIndicesA\"),this.outputShape=[o,i];var s=\"max\"===e?\">\":\"<\",u=n?\"inOffset + i;\":\"round(getBestIndicesA(batch, inOffset + i));\";this.userCode=\"\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int outIdx = coords[1];\\n        int inOffset = outIdx * \"+r+\";\\n\\n        int bestIndex = inOffset;\\n        float bestValue = getA(batch, bestIndex);\\n\\n        for (int i = 0; i < \"+r+\"; i++) {\\n          int inIdx = \"+u+\";\\n          float candidate = getA(batch, inIdx);\\n          if (candidate \"+s+\" bestValue) {\\n            bestValue = candidate;\\n            bestIndex = inIdx;\\n          }\\n        }\\n        setOutput(float(bestIndex));\\n      }\\n    \"}}();function Oo(t,e){return[\"x\",\"y\",\"z\",\"w\",\"u\",\"v\"].slice(0,e).map(function(e){return t+\".\"+e})}function Fo(t,e){return 1===e?[t]:Oo(t,e)}function Mo(){var t,e,n,r,o,a,s,u,l,c;return 2===i.getNumber(\"WEBGL_VERSION\")?(t=\"#version 300 es\",e=\"in\",n=\"out\",r=\"in\",o=\"texture\",a=\"outputColor\",s=\"out vec4 outputColor;\",u=\"\\n      bool isnan_custom(float val) {\\n        return (val > 0. || val < 0. || val == 0.) ? false : true;\\n      }\\n    \",l=\"\",c=\"\\n      #define round(value) newRound(value)\\n      int newRound(float value) {\\n        return int(floor(value + 0.5));\\n      }\\n\\n      ivec4 newRound(vec4 value) {\\n        return ivec4(floor(value + vec4(0.5)));\\n      }\\n    \"):(t=\"\",e=\"attribute\",n=\"varying\",r=\"varying\",o=\"texture2D\",a=\"gl_FragColor\",s=\"\",u=\"\\n      bool isnan_custom(float val) {\\n        return (val > 0. || val < 1. || val == 0.) ? false : true;\\n      }\\n    \",l=\"\\n      uniform float INFINITY;\\n\\n      bool isinf(float val) {\\n        return abs(val) == INFINITY;\\n      }\\n      bvec4 isinf(vec4 val) {\\n        return equal(abs(val), vec4(INFINITY));\\n      }\\n    \",c=\"\\n      int round(float value) {\\n        return int(floor(value + 0.5));\\n      }\\n\\n      ivec4 round(vec4 value) {\\n        return ivec4(floor(value + vec4(0.5)));\\n      }\\n    \"),{version:t,attribute:e,varyingVs:n,varyingFs:r,texture2D:o,output:a,defineOutput:s,defineSpecialNaN:u,defineSpecialInf:l,defineRound:c}}function Bo(t,e,n){void 0===n&&(n=\"index\");var r=V(e);return r.map(function(e,o){return\"int \"+t[o]+\" = \"+n+\" / \"+e+\"; \"+(o===r.length-1?\"int \"+t[o+1]+\" = \"+n+\" - \"+t[o]+\" * \"+e:\"index -= \"+t[o]+\" * \"+e)+\";\"}).join(\"\")}function Po(t){var e=V(t).map(function(t){return t.toString()});return\"\\n  int getFlatIndex(ivec3 coords) {\\n    return coords.x * \"+e[0]+\" + coords.y * \"+e[1]+\" + coords.z;\\n  }\\n\"}var Lo=\"\\n  const float FLOAT_MAX = 1.70141184e38;\\n  const float FLOAT_MIN = 1.17549435e-38;\\n\\n  lowp vec4 encode_float(highp float v) {\\n    if (isnan(v)) {\\n      return vec4(255, 255, 255, 255);\\n    }\\n\\n    highp float av = abs(v);\\n\\n    if(av < FLOAT_MIN) {\\n      return vec4(0.0, 0.0, 0.0, 0.0);\\n    } else if(v > FLOAT_MAX) {\\n      return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;\\n    } else if(v < -FLOAT_MAX) {\\n      return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;\\n    }\\n\\n    highp vec4 c = vec4(0,0,0,0);\\n\\n    highp float e = floor(log2(av));\\n    highp float m = exp2(fract(log2(av))) - 1.0;\\n\\n    c[2] = floor(128.0 * m);\\n    m -= c[2] / 128.0;\\n    c[1] = floor(32768.0 * m);\\n    m -= c[1] / 32768.0;\\n    c[0] = floor(8388608.0 * m);\\n\\n    highp float ebias = e + 127.0;\\n    c[3] = floor(ebias / 2.0);\\n    ebias -= c[3] * 2.0;\\n    c[2] += floor(ebias) * 128.0;\\n\\n    c[3] += 128.0 * step(0.0, -v);\\n\\n    return c / 255.0;\\n  }\\n\";function Wo(t,e,n,r){var o=[];t.forEach(function(t){var e=g(t.shapeInfo.logicalShape);t.shapeInfo.isUniform?o.push(\"uniform float \"+t.name+(e>1?\"[\"+e+\"]\":\"\")+\";\"):(o.push(\"uniform sampler2D \"+t.name+\";\"),o.push(\"uniform int offset\"+t.name+\";\"))});var a,i,s=o.join(\"\\n\"),u=t.map(function(t){return function(t,e,n){void 0===n&&(n=!1);var r=\"\";r+=n?Vo(t):Uo(t);var o=t.shapeInfo.logicalShape,a=e.logicalShape;o.length<=a.length&&(r+=n?function(t,e){var n,r=t.name,o=r.charAt(0).toUpperCase()+r.slice(1),a=\"get\"+o+\"AtOutCoords\",i=t.shapeInfo.logicalShape.length,s=e.logicalShape.length,u=to(t.shapeInfo.logicalShape,e.logicalShape),l=jo(s),c=s-i,h=[\"x\",\"y\",\"z\",\"w\",\"u\",\"v\"];n=0===i?\"\":s<2&&u.length>=1?\"coords = 0;\":u.map(function(t){return\"coords.\"+h[t+c]+\" = 0;\"}).join(\"\\n\");var p=\"\";p=s<2&&i>0?\"coords\":t.shapeInfo.logicalShape.map(function(t,e){return\"coords.\"+h[e+c]}).join(\", \");var f=\"return outputValue;\",d=1===g(t.shapeInfo.logicalShape),v=1===g(e.logicalShape);if(1!==i||d||v){if(d&&!v)f=1===s?\"\\n        return vec4(outputValue.x, outputValue.x, 0., 0.);\\n      \":\"\\n        return vec4(outputValue.x);\\n      \";else if(u.length){var m=i-2,y=i-1;u.indexOf(m)>-1&&u.indexOf(y)>-1?f=\"return vec4(outputValue.x);\":u.indexOf(m)>-1?f=\"return vec4(outputValue.x, outputValue.y, outputValue.x, outputValue.y);\":u.indexOf(y)>-1&&(f=\"return vec4(outputValue.xx, outputValue.zz);\")}}else f=\"\\n      return vec4(outputValue.xy, outputValue.xy);\\n    \";return\"\\n    vec4 \"+a+\"() {\\n      \"+l+\" coords = getOutputCoords();\\n      \"+n+\"\\n      vec4 outputValue = get\"+o+\"(\"+p+\");\\n      \"+f+\"\\n    }\\n  \"}(t,e):function(t,e){var n=t.name,r=n.charAt(0).toUpperCase()+n.slice(1),o=\"get\"+r+\"AtOutCoords\",a=e.texShape,i=t.shapeInfo.texShape,s=t.shapeInfo.logicalShape.length,u=e.logicalShape.length;if(!t.shapeInfo.isUniform&&s===u&&null==t.shapeInfo.flatOffset&&y(i,a))return\"\\n      float \"+o+\"() {\\n        return sampleTexture(\"+n+\", resultUV);\\n      }\\n    \";var l,c=jo(u),h=to(t.shapeInfo.logicalShape,e.logicalShape),p=u-s,f=[\"x\",\"y\",\"z\",\"w\",\"u\",\"v\"];l=0===s?\"\":u<2&&h.length>=1?\"coords = 0;\":h.map(function(t){return\"coords.\"+f[t+p]+\" = 0;\"}).join(\"\\n\");var d=\"\";d=u<2&&s>0?\"coords\":t.shapeInfo.logicalShape.map(function(t,e){return\"coords.\"+f[e+p]}).join(\", \");return\"\\n    float \"+o+\"() {\\n      \"+c+\" coords = getOutputCoords();\\n      \"+l+\"\\n      return get\"+r+\"(\"+d+\");\\n    }\\n  \"}(t,e));return r}(t,e,r)}).join(\"\\n\"),l=e.texShape,c=Mo(),h=function(t){return\"\\n    float sampleTexture(sampler2D textureSampler, vec2 uv) {\\n      return \"+t.texture2D+\"(textureSampler, uv).r;\\n    }\\n  \"}(c),p=function(t){return t.version+\"\\n    precision highp float;\\n    precision highp int;\\n    precision highp sampler2D;\\n    \"+t.varyingFs+\" vec2 resultUV;\\n    \"+t.defineOutput+\"\\n    const vec2 halfCR = vec2(0.5, 0.5);\\n\\n    struct ivec5\\n    {\\n      int x;\\n      int y;\\n      int z;\\n      int w;\\n      int u;\\n    };\\n\\n    struct ivec6\\n    {\\n      int x;\\n      int y;\\n      int z;\\n      int w;\\n      int u;\\n      int v;\\n    };\\n\\n    uniform float NAN;\\n    #define isnan(value) isnan_custom(value)\\n    \"+t.defineSpecialNaN+\"\\n    bvec4 isnan_custom(vec4 val) {\\n      return bvec4(isnan(val.x), isnan(val.y), isnan(val.z), isnan(val.w));\\n    }\\n\\n    \"+t.defineSpecialInf+\"\\n    \"+t.defineRound+\"\\n\\n    int imod(int x, int y) {\\n      return x - y * (x / y);\\n    }\\n\\n    int idiv(int a, int b, float sign) {\\n      int res = a / b;\\n      int mod = imod(a, b);\\n      if (sign < 0. && mod != 0) {\\n        res -= 1;\\n      }\\n      return res;\\n    }\\n\\n    //Based on the work of Dave Hoskins\\n    //https://www.shadertoy.com/view/4djSRW\\n    #define HASHSCALE1 443.8975\\n    float random(float seed){\\n      vec2 p = resultUV * seed;\\n      vec3 p3  = fract(vec3(p.xyx) * HASHSCALE1);\\n      p3 += dot(p3, p3.yzx + 19.19);\\n      return fract((p3.x + p3.y) * p3.z);\\n    }\\n\\n    \"+zo+\"\\n    \"+Go+\"\\n    \"+Ho+\"\\n  \"}(c);return e.isPacked?(a=function(t,e){switch(t.length){case 0:return\"\\n    int getOutputCoords() {\\n      return 0;\\n    }\\n  \";case 1:return function(t,e){var n=[Math.ceil(e[0]/2),Math.ceil(e[1]/2)];if(1===n[0])return\"\\n      int getOutputCoords() {\\n        return 2 * int(resultUV.x * \"+n[1]+\".0);\\n      }\\n    \";if(1===n[1])return\"\\n      int getOutputCoords() {\\n        return 2 * int(resultUV.y * \"+n[0]+\".0);\\n      }\\n    \";return\"\\n    int getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\"+n[0]+\", \"+n[1]+\"));\\n      return 2 * (resTexRC.x * \"+n[1]+\" + resTexRC.y);\\n    }\\n  \"}(0,e);case 2:return function(t,e){var n=[Math.ceil(e[0]/2),Math.ceil(e[1]/2)];if(y(t,e))return\"\\n      ivec2 getOutputCoords() {\\n        return 2 * ivec2(resultUV.yx * vec2(\"+n[0]+\", \"+n[1]+\"));\\n      }\\n    \";var r=Math.ceil(t[1]/2);return\"\\n    ivec2 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\"+n[0]+\", \"+n[1]+\"));\\n\\n      int index = resTexRC.x * \"+n[1]+\" + resTexRC.y;\\n      int r = 2 * (index / \"+r+\");\\n      int c = imod(index, \"+r+\") * 2;\\n\\n      return ivec2(r, c);\\n    }\\n  \"}(t,e);case 3:return n=t,r=e,o=[Math.ceil(r[0]/2),Math.ceil(r[1]/2)],a=Math.ceil(n[2]/2),i=a*Math.ceil(n[1]/2),\"\\n    ivec3 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\"+o[0]+\", \"+o[1]+\"));\\n      int index = resTexRC.x * \"+o[1]+\" + resTexRC.y;\\n\\n      int b = index / \"+i+\";\\n      index -= b * \"+i+\";\\n\\n      int r = 2 * (index / \"+a+\");\\n      int c = imod(index, \"+a+\") * 2;\\n\\n      return ivec3(b, r, c);\\n    }\\n  \";default:return function(t,e){for(var n=[Math.ceil(e[0]/2),Math.ceil(e[1]/2)],r=Math.ceil(t[t.length-1]/2),o=r*Math.ceil(t[t.length-2]/2),a=o,i=\"\",s=\"b, r, c\",u=2;u<t.length-1;u++)a*=t[t.length-u-1],i=\"\\n      int b\"+u+\" = index / \"+a+\";\\n      index -= b\"+u+\" * \"+a+\";\\n    \"+i,s=\"b\"+u+\", \"+s;return\"\\n    ivec\"+t.length+\" getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\"+n[0]+\", \"+n[1]+\"));\\n      int index = resTexRC.x * \"+n[1]+\" + resTexRC.y;\\n\\n      \"+i+\"\\n\\n      int b = index / \"+o+\";\\n      index -= b * \"+o+\";\\n\\n      int r = 2 * (index / \"+r+\");\\n      int c = imod(index, \"+r+\") * 2;\\n\\n      return ivec\"+t.length+\"(\"+s+\");\\n    }\\n  \"}(t,e)}var n,r,o,a,i}(e.logicalShape,l),i=function(t){return\"\\n    void setOutput(vec4 val) {\\n      \"+t.output+\" = val;\\n    }\\n  \"}(c)):(a=function(t,e){switch(t.length){case 0:return\"\\n    int getOutputCoords() {\\n      return 0;\\n    }\\n  \";case 1:return function(t,e){if(1===e[0])return\"\\n      int getOutputCoords() {\\n        return int(resultUV.x * \"+e[1]+\".0);\\n      }\\n    \";if(1===e[1])return\"\\n      int getOutputCoords() {\\n        return int(resultUV.y * \"+e[0]+\".0);\\n      }\\n    \";return\"\\n    int getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\"+e[0]+\", \"+e[1]+\"));\\n      return resTexRC.x * \"+e[1]+\" + resTexRC.y;\\n    }\\n  \"}(0,e);case 2:return function(t,e){if(y(t,e))return\"\\n      ivec2 getOutputCoords() {\\n        return ivec2(resultUV.yx * vec2(\"+e[0]+\", \"+e[1]+\"));\\n      }\\n    \";if(1===t[1])return\"\\n      ivec2 getOutputCoords() {\\n        ivec2 resTexRC = ivec2(resultUV.yx *\\n                               vec2(\"+e[0]+\", \"+e[1]+\"));\\n        int index = resTexRC.x * \"+e[1]+\" + resTexRC.y;\\n        return ivec2(index, 0);\\n      }\\n    \";if(1===t[0])return\"\\n      ivec2 getOutputCoords() {\\n        ivec2 resTexRC = ivec2(resultUV.yx *\\n                               vec2(\"+e[0]+\", \"+e[1]+\"));\\n        int index = resTexRC.x * \"+e[1]+\" + resTexRC.y;\\n        return ivec2(0, index);\\n      }\\n    \";return\"\\n    ivec2 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\"+e[0]+\", \"+e[1]+\"));\\n      int index = resTexRC.x * \"+e[1]+\" + resTexRC.y;\\n      int r = index / \"+t[1]+\";\\n      int c = index - r * \"+t[1]+\";\\n      return ivec2(r, c);\\n    }\\n  \"}(t,e);case 3:return n=e,r=Bo([\"r\",\"c\",\"d\"],t),\"\\n    ivec3 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\"+n[0]+\", \"+n[1]+\"));\\n      int index = resTexRC.x * \"+n[1]+\" + resTexRC.y;\\n      \"+r+\"\\n      return ivec3(r, c, d);\\n    }\\n  \";case 4:return function(t,e){var n=Bo([\"r\",\"c\",\"d\",\"d2\"],t);return\"\\n    ivec4 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n        vec2(\"+e[0]+\", \"+e[1]+\"));\\n      int index = resTexRC.x * \"+e[1]+\" + resTexRC.y;\\n      \"+n+\"\\n      return ivec4(r, c, d, d2);\\n    }\\n  \"}(t,e);case 5:return function(t,e){var n=Bo([\"r\",\"c\",\"d\",\"d2\",\"d3\"],t);return\"\\n    ivec5 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx * vec2(\"+e[0]+\",\\n                             \"+e[1]+\"));\\n\\n      int index = resTexRC.x * \"+e[1]+\" + resTexRC.y;\\n\\n      \"+n+\"\\n\\n      ivec5 outShape = ivec5(r, c, d, d2, d3);\\n      return outShape;\\n    }\\n  \"}(t,e);case 6:return function(t,e){var n=Bo([\"r\",\"c\",\"d\",\"d2\",\"d3\",\"d4\"],t);return\"\\n    ivec6 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n        vec2(\"+e[0]+\", \"+e[1]+\"));\\n      int index = resTexRC.x * \"+e[1]+\" + resTexRC.y;\\n\\n      \"+n+\"\\n\\n      ivec6 result = ivec6(r, c, d, d2, d3, d4);\\n      return result;\\n    }\\n  \"}(t,e);default:throw new Error(t.length+\"-D output sampling is not yet supported\")}var n,r}(e.logicalShape,l),i=function(t){return\"\\n    void setOutput(float val) {\\n      \"+t.output+\" = vec4(val, 0, 0, 0);\\n    }\\n  \"}(c)),r&&(p+=qo),[p,h,i,s,a,u,n].join(\"\\n\")}function Uo(t){var e=t.shapeInfo.logicalShape;switch(e.length){case 0:return function(t){var e=t.name,n=\"get\"+e.charAt(0).toUpperCase()+e.slice(1);if(t.shapeInfo.isUniform)return\"float \"+n+\"() {return \"+e+\";}\";var r=t.shapeInfo.texShape,o=r[0],a=r[1];if(1===o&&1===a)return\"\\n      float \"+n+\"() {\\n        return sampleTexture(\"+e+\", halfCR);\\n      }\\n    \";var i=t.shapeInfo.texShape,s=i[0],u=i[1],l=$o(e);return\"\\n    float \"+n+\"() {\\n      vec2 uv = uvFromFlat(\"+s+\", \"+u+\", \"+l+\");\\n      return sampleTexture(\"+e+\", uv);\\n    }\\n  \"}(t);case 1:return function(t){var e=t.name,n=\"get\"+e.charAt(0).toUpperCase()+e.slice(1);if(t.shapeInfo.isUniform)return\"\\n      float \"+n+\"(int index) {\\n        \"+Ko(t)+\"\\n      }\\n    \";var r=t.shapeInfo.texShape,o=r[0],a=r[1];if(1===a&&1===o)return\"\\n      float \"+n+\"(int index) {\\n        return sampleTexture(\"+e+\", halfCR);\\n      }\\n    \";var i=$o(e);if(1===a)return\"\\n      float \"+n+\"(int index) {\\n        vec2 uv = vec2(0.5, (float(index + \"+i+\") + 0.5) / \"+o+\".0);\\n        return sampleTexture(\"+e+\", uv);\\n      }\\n    \";if(1===o)return\"\\n      float \"+n+\"(int index) {\\n        vec2 uv = vec2((float(index + \"+i+\") + 0.5) / \"+a+\".0, 0.5);\\n        return sampleTexture(\"+e+\", uv);\\n      }\\n    \";return\"\\n    float \"+n+\"(int index) {\\n      vec2 uv = uvFromFlat(\"+o+\", \"+a+\", index + \"+i+\");\\n      return sampleTexture(\"+e+\", uv);\\n    }\\n  \"}(t);case 2:return function(t){var e=t.shapeInfo.logicalShape,n=t.name,r=\"get\"+n.charAt(0).toUpperCase()+n.slice(1),o=t.shapeInfo.texShape;if(null!=o&&y(e,o)){var a=o[0],i=o[1];return\"\\n    float \"+r+\"(int row, int col) {\\n      vec2 uv = (vec2(col, row) + halfCR) / vec2(\"+i+\".0, \"+a+\".0);\\n      return sampleTexture(\"+n+\", uv);\\n    }\\n  \"}var s=k(e),u=s.newShape,l=s.keptDims,c=u;if(c.length<e.length){var h=Xo(t,c);return\"\\n      \"+Uo(h)+\"\\n      float \"+r+\"(int row, int col) {\\n        return \"+r+\"(\"+Yo([\"row\",\"col\"],l)+\");\\n      }\\n    \"}if(t.shapeInfo.isUniform)return\"\\n      float \"+r+\"(int row, int col) {\\n        int index = round(dot(vec2(row, col), vec2(\"+e[1]+\", 1)));\\n        \"+Ko(t)+\"\\n      }\\n    \";var p=o[0],f=o[1],d=$o(n);if(1===f)return\"\\n    float \"+r+\"(int row, int col) {\\n      float index = dot(vec3(row, col, \"+d+\"), vec3(\"+e[1]+\", 1, 1));\\n      vec2 uv = vec2(0.5, (index + 0.5) / \"+p+\".0);\\n      return sampleTexture(\"+n+\", uv);\\n    }\\n  \";if(1===p)return\"\\n    float \"+r+\"(int row, int col) {\\n      float index = dot(vec3(row, col, \"+d+\"), vec3(\"+e[1]+\", 1, 1));\\n      vec2 uv = vec2((index + 0.5) / \"+f+\".0, 0.5);\\n      return sampleTexture(\"+n+\", uv);\\n    }\\n  \";return\"\\n  float \"+r+\"(int row, int col) {\\n    // Explicitly use integer operations as dot() only works on floats.\\n    int index = row * \"+e[1]+\" + col + \"+d+\";\\n    vec2 uv = uvFromFlat(\"+p+\", \"+f+\", index);\\n    return sampleTexture(\"+n+\", uv);\\n  }\\n\"}(t);case 3:return function(t){var e=t.shapeInfo.logicalShape,n=t.name,r=\"get\"+n.charAt(0).toUpperCase()+n.slice(1),o=e[1]*e[2],a=e[2],i=k(e),s=i.newShape,u=i.keptDims,l=s;if(l.length<e.length){var c=Xo(t,l);return\"\\n        \"+Uo(c)+\"\\n        float \"+r+\"(int row, int col, int depth) {\\n          return \"+r+\"(\"+Yo([\"row\",\"col\",\"depth\"],u)+\");\\n        }\\n      \"}if(t.shapeInfo.isUniform)return\"\\n      float \"+r+\"(int row, int col, int depth) {\\n        int index = round(dot(vec3(row, col, depth),\\n                          vec3(\"+o+\", \"+a+\", 1)));\\n        \"+Ko(t)+\"\\n      }\\n    \";var h=t.shapeInfo.texShape,p=h[0],f=h[1],d=t.shapeInfo.flatOffset;if(f===o&&null==d)return\"\\n        float \"+r+\"(int row, int col, int depth) {\\n          float texR = float(row);\\n          float texC = dot(vec2(col, depth), vec2(\"+a+\", 1));\\n          vec2 uv = (vec2(texC, texR) + halfCR) /\\n                     vec2(\"+f+\".0, \"+p+\".0);\\n          return sampleTexture(\"+n+\", uv);\\n        }\\n      \";if(f===a&&null==d)return\"\\n    float \"+r+\"(int row, int col, int depth) {\\n      float texR = dot(vec2(row, col), vec2(\"+e[1]+\", 1));\\n      float texC = float(depth);\\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(\"+f+\".0, \"+p+\".0);\\n      return sampleTexture(\"+n+\", uv);\\n    }\\n  \";var v=$o(n);return\"\\n      float \"+r+\"(int row, int col, int depth) {\\n        // Explicitly use integer operations as dot() only works on floats.\\n        int index = row * \"+o+\" + col * \"+a+\" + depth + \"+v+\";\\n        vec2 uv = uvFromFlat(\"+p+\", \"+f+\", index);\\n        return sampleTexture(\"+n+\", uv);\\n      }\\n  \"}(t);case 4:return function(t){var e=t.shapeInfo.logicalShape,n=t.name,r=\"get\"+n.charAt(0).toUpperCase()+n.slice(1),o=e[3],a=e[2]*o,i=e[1]*a,s=k(e),u=s.newShape,l=s.keptDims;if(u.length<e.length){var c=Xo(t,u);return\"\\n      \"+Uo(c)+\"\\n      float \"+r+\"(int row, int col, int depth, int depth2) {\\n        return \"+r+\"(\"+Yo([\"row\",\"col\",\"depth\",\"depth2\"],l)+\");\\n      }\\n    \"}if(t.shapeInfo.isUniform)return\"\\n      float \"+r+\"(int row, int col, int depth, int depth2) {\\n        int index = round(dot(vec4(row, col, depth, depth2),\\n                          vec4(\"+i+\", \"+a+\", \"+o+\", 1)));\\n        \"+Ko(t)+\"\\n      }\\n    \";var h=t.shapeInfo.flatOffset,p=t.shapeInfo.texShape,f=p[0],d=p[1];if(d===i&&null==h)return\"\\n      float \"+r+\"(int row, int col, int depth, int depth2) {\\n        float texR = float(row);\\n        float texC =\\n            dot(vec3(col, depth, depth2),\\n                vec3(\"+a+\", \"+o+\", 1));\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                   vec2(\"+d+\".0, \"+f+\".0);\\n        return sampleTexture(\"+n+\", uv);\\n      }\\n    \";if(d===o&&null==h)return\"\\n      float \"+r+\"(int row, int col, int depth, int depth2) {\\n        float texR = dot(vec3(row, col, depth),\\n                         vec3(\"+e[1]*e[2]+\", \"+e[2]+\", 1));\\n        float texC = float(depth2);\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                  vec2(\"+d+\".0, \"+f+\".0);\\n        return sampleTexture(\"+n+\", uv);\\n      }\\n    \";var v=$o(n);return\"\\n    float \"+r+\"(int row, int col, int depth, int depth2) {\\n      // Explicitly use integer operations as dot() only works on floats.\\n      int index = row * \"+i+\" + col * \"+a+\" +\\n          depth * \"+o+\" + depth2;\\n      vec2 uv = uvFromFlat(\"+f+\", \"+d+\", index + \"+v+\");\\n      return sampleTexture(\"+n+\", uv);\\n    }\\n  \"}(t);case 5:return function(t){var e=t.shapeInfo.logicalShape,n=t.name,r=\"get\"+n.charAt(0).toUpperCase()+n.slice(1),o=e[4],a=e[3]*o,i=e[2]*a,s=e[1]*i,u=k(e),l=u.newShape,c=u.keptDims;if(l.length<e.length){var h=Xo(t,l);return\"\\n      \"+Uo(h)+\"\\n      float \"+r+\"(int row, int col, int depth, int depth2, int depth3) {\\n        return \"+r+\"(\"+Yo([\"row\",\"col\",\"depth\",\"depth2\",\"depth3\"],c)+\");\\n      }\\n    \"}if(t.shapeInfo.isUniform)return\"\\n      float \"+r+\"(int row, int col, int depth, int depth2, int depth3) {\\n        float index = dot(\\n          vec4(row, col, depth, depth2),\\n          vec4(\"+s+\", \"+i+\", \"+a+\", \"+o+\")) +\\n          depth3;\\n        \"+Ko(t)+\"\\n      }\\n    \";var p=t.shapeInfo.flatOffset,f=t.shapeInfo.texShape,d=f[0],v=f[1];if(v===s&&null==p)return\"\\n      float \"+r+\"(int row, int col, int depth, int depth2, int depth3) {\\n        int texR = row;\\n        float texC = dot(vec4(col, depth, depth2, depth3),\\n                         vec4(\"+i+\", \"+a+\", \"+o+\", 1));\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                   vec2(\"+v+\".0, \"+d+\".0);\\n        return sampleTexture(\"+n+\", uv);\\n      }\\n    \";if(v===o&&null==p)return\"\\n      float \"+r+\"(int row, int col, int depth, int depth2, int depth3) {\\n        float texR = dot(\\n          vec4(row, col, depth, depth2),\\n          vec4(\"+e[1]*e[2]*e[3]+\",\\n               \"+e[2]*e[3]+\", \"+e[3]+\", 1));\\n        int texC = depth3;\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                  vec2(\"+v+\".0, \"+d+\".0);\\n        return sampleTexture(\"+n+\", uv);\\n      }\\n    \";var m=$o(n);return\"\\n    float \"+r+\"(int row, int col, int depth, int depth2, int depth3) {\\n      // Explicitly use integer operations as dot() only works on floats.\\n      int index = row * \"+s+\" + col * \"+i+\" + depth * \"+a+\" +\\n          depth2 * \"+o+\" + depth3 + \"+m+\";\\n      vec2 uv = uvFromFlat(\"+d+\", \"+v+\", index);\\n      return sampleTexture(\"+n+\", uv);\\n    }\\n  \"}(t);case 6:return function(t){var e=t.shapeInfo.logicalShape,n=t.name,r=\"get\"+n.charAt(0).toUpperCase()+n.slice(1),o=k(e),a=o.newShape,i=o.keptDims;if(a.length<e.length){var s=Xo(t,a);return\"\\n      \"+Uo(s)+\"\\n      float \"+r+\"(int row, int col, int depth,\\n                    int depth2, int depth3, int depth4) {\\n        return \"+r+\"(\"+Yo([\"row\",\"col\",\"depth\",\"depth2\",\"depth3\",\"depth4\"],i)+\");\\n      }\\n    \"}var u=e[5],l=e[4]*u,c=e[3]*l,h=e[2]*c,p=e[1]*h;if(t.shapeInfo.isUniform)return\"\\n      float \"+r+\"(int row, int col, int depth,\\n                  int depth2, int depth3, int depth4) {\\n        int index = round(dot(\\n          vec4(row, col, depth, depth2),\\n          vec4(\"+p+\", \"+h+\", \"+c+\", \"+l+\")) +\\n          dot(\\n            vec2(depth3, depth4),\\n            vec2(\"+u+\", 1)));\\n        \"+Ko(t)+\"\\n      }\\n    \";var f=t.shapeInfo.flatOffset,d=t.shapeInfo.texShape,v=d[0],m=d[1];if(m===p&&null==f)return\"\\n      float \"+r+\"(int row, int col, int depth,\\n                    int depth2, int depth3, int depth4) {\\n        int texR = row;\\n        float texC = dot(vec4(col, depth, depth2, depth3),\\n          vec4(\"+h+\", \"+c+\", \"+l+\", \"+u+\")) +\\n               float(depth4);\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                   vec2(\"+m+\".0, \"+v+\".0);\\n        return sampleTexture(\"+n+\", uv);\\n      }\\n    \";if(m===u&&null==f)return\"\\n      float \"+r+\"(int row, int col, int depth,\\n                    int depth2, int depth3, int depth4) {\\n        float texR = dot(vec4(row, col, depth, depth2),\\n          vec4(\"+e[1]*e[2]*e[3]*e[4]+\",\\n               \"+e[2]*e[3]*e[4]+\",\\n               \"+e[3]*e[4]+\",\\n               \"+e[4]+\")) + float(depth3);\\n        int texC = depth4;\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                  vec2(\"+m+\".0, \"+v+\".0);\\n        return sampleTexture(\"+n+\", uv);\\n      }\\n    \";var g=$o(n);return\"\\n    float \"+r+\"(int row, int col, int depth,\\n                  int depth2, int depth3, int depth4) {\\n      // Explicitly use integer operations as dot() only works on floats.\\n      int index = row * \"+p+\" + col * \"+h+\" + depth * \"+c+\" +\\n          depth2 * \"+l+\" + depth3 * \"+u+\" + depth4 + \"+g+\";\\n      vec2 uv = uvFromFlat(\"+v+\", \"+m+\", index);\\n      return sampleTexture(\"+n+\", uv);\\n    }\\n  \"}(t);default:throw new Error(e.length+\"-D input sampling is not yet supported\")}}function Vo(t){var e,n,r;switch(t.shapeInfo.logicalShape.length){case 0:return e=t.name,n=\"get\"+e.charAt(0).toUpperCase()+e.slice(1),r=Mo(),\"\\n    vec4 \"+n+\"() {\\n      return \"+r.texture2D+\"(\"+e+\", halfCR);\\n    }\\n  \";case 1:return function(t){var e=t.name,n=\"get\"+e.charAt(0).toUpperCase()+e.slice(1),r=t.shapeInfo.texShape,o=[Math.ceil(r[0]/2),Math.ceil(r[1]/2)],a=Mo();return\"\\n    vec4 \"+n+\"(int index) {\\n      vec2 uv = packedUVfrom1D(\\n        \"+o[0]+\", \"+o[1]+\", index);\\n      return \"+a.texture2D+\"(\"+e+\", uv);\\n    }\\n  \"}(t);case 2:return function(t){var e=t.shapeInfo.logicalShape,n=t.name,r=\"get\"+n.charAt(0).toUpperCase()+n.slice(1),o=t.shapeInfo.texShape,a=o[0],i=o[1],s=Mo();if(null!=o&&y(e,o))return\"\\n      vec4 \"+r+\"(int row, int col) {\\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(\"+i+\".0, \"+a+\".0);\\n\\n        return \"+s.texture2D+\"(\"+n+\", uv);\\n      }\\n    \";var u=[Math.ceil(o[0]/2),Math.ceil(o[1]/2)],l=Math.ceil(e[1]/2);return\"\\n    vec4 \"+r+\"(int row, int col) {\\n      vec2 uv = packedUVfrom2D(\"+l+\", \"+u[0]+\", \"+u[1]+\", row, col);\\n      return \"+s.texture2D+\"(\"+n+\", uv);\\n    }\\n  \"}(t);case 3:return function(t){var e=t.shapeInfo.logicalShape,n=t.name,r=\"get\"+n.charAt(0).toUpperCase()+n.slice(1),o=t.shapeInfo.texShape,a=[Math.ceil(o[0]/2),Math.ceil(o[1]/2)];if(1===e[0]){var i=e.slice(1),s=Xo(t,i);return\"\\n        \"+Vo(s)+\"\\n        vec4 \"+r+\"(int b, int row, int col) {\\n          return \"+r+\"(\"+Yo([\"b\",\"row\",\"col\"],[1,2])+\");\\n        }\\n      \"}var u=a[0],l=a[1],c=Math.ceil(e[2]/2),h=c*Math.ceil(e[1]/2),p=Mo();return\"\\n    vec4 \"+r+\"(int b, int row, int col) {\\n      vec2 uv = packedUVfrom3D(\\n        \"+u+\", \"+l+\", \"+h+\", \"+c+\", b, row, col);\\n      return \"+p.texture2D+\"(\"+n+\", uv);\\n    }\\n  \"}(t);default:return function(t){for(var e=t.shapeInfo.logicalShape,n=e.length,r=t.name,o=\"get\"+r.charAt(0).toUpperCase()+r.slice(1),a=t.shapeInfo.texShape,i=[Math.ceil(a[0]/2),Math.ceil(a[1]/2)],s=i[0],u=i[1],l=Math.ceil(e[n-1]/2),c=l*Math.ceil(e[n-2]/2),h=\"int b, int row, int col\",p=\"b * \"+c+\" + (row / 2) * \"+l+\" + (col / 2)\",f=2;f<n-1;f++)h=\"int b\"+f+\", \"+h,c*=e[n-f-1],p=\"b\"+f+\" * \"+c+\" + \"+p;var d=Mo();return\"\\n    vec4 \"+o+\"(\"+h+\") {\\n      int index = \"+p+\";\\n      int texR = index / \"+u+\";\\n      int texC = index - texR * \"+u+\";\\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(\"+u+\", \"+s+\");\\n      return \"+d.texture2D+\"(\"+r+\", uv);\\n    }\\n  \"}(t)}}var zo=\"\\nvec2 uvFromFlat(int texNumR, int texNumC, int index) {\\n  int texR = index / texNumC;\\n  int texC = index - texR * texNumC;\\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\\n}\\nvec2 packedUVfrom1D(int texNumR, int texNumC, int index) {\\n  int texelIndex = index / 2;\\n  int texR = texelIndex / texNumC;\\n  int texC = texelIndex - texR * texNumC;\\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\\n}\\n\",Go=\"\\nvec2 packedUVfrom2D(int texelsInLogicalRow, int texNumR,\\n  int texNumC, int row, int col) {\\n  int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);\\n  int texR = texelIndex / texNumC;\\n  int texC = texelIndex - texR * texNumC;\\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\\n}\\n\",Ho=\"\\nvec2 packedUVfrom3D(int texNumR, int texNumC,\\n    int texelsInBatch, int texelsInLogicalRow, int b,\\n    int row, int col) {\\n  int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);\\n  int texR = index / texNumC;\\n  int texC = index - texR * texNumC;\\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\\n}\\n\",qo=\"\\n  float getChannel(vec4 frag, vec2 innerDims) {\\n    vec2 modCoord = mod(innerDims, 2.);\\n    return modCoord.x == 0. ?\\n      (modCoord.y == 0. ? frag.r : frag.g) :\\n      (modCoord.y == 0. ? frag.b : frag.a);\\n  }\\n  float getChannel(vec4 frag, int dim) {\\n    float modCoord = mod(float(dim), 2.);\\n    return modCoord == 0. ? frag.r : frag.g;\\n  }\\n\";function $o(t){return\"offset\"+t}function Ko(t){var e=t.name,n=g(t.shapeInfo.logicalShape);return n<2?\"return \"+e+\";\":\"\\n    for (int i = 0; i < \"+n+\"; i++) {\\n      if (i == index) {\\n        return \"+e+\"[i];\\n      }\\n    }\\n  \"}function jo(t){if(t<=1)return\"int\";if(2===t)return\"ivec2\";if(3===t)return\"ivec3\";if(4===t)return\"ivec4\";if(5===t)return\"ivec5\";if(6===t)return\"ivec6\";throw Error(\"GPU for rank \"+t+\" is not yet supported\")}function Xo(t,e){var n=JSON.parse(JSON.stringify(t));return n.shapeInfo.logicalShape=e,n}function Yo(t,e){return e.map(function(e){return t[e]}).join(\", \")}var Qo=function(){return function(t,e,n,r){this.variableNames=[\"A\"],this.usesPackedTextures=!0,f(t.length>2,function(){return\"Packed arg\"+(n.charAt(0).toUpperCase()+n.slice(1))+\" supports only inputs with rank above 2.\"});var o=t[t.length-1],a=Math.ceil(o/e);this.outputShape=t.slice(0,-1),a>1&&this.outputShape.push(a),r||this.variableNames.push(\"bestIndicesA\");var i,s,u=this.outputShape,l=u.length,c=jo(l),h=Fo(\"coords\",l);if(1===a){var p=jo(s=l+1);i=\"\\n        \"+p+\" sourceLocR = \"+p+\"(\"+h.join()+\", 0);\\n        ++\"+h[l-1]+\";\\n        \"+p+\" sourceLocG = \"+p+\"(\"+h.join()+\", 0);\\n        ++\"+h[l-2]+\";\\n        \"+p+\" sourceLocA = \"+p+\"(\"+h.join()+\", 0);\\n        --\"+h[l-1]+\";\\n        \"+p+\" sourceLocB = \"+p+\"(\"+h.join()+\", 0);\\n        --\"+h[l-2]+\";\"}else s=l,i=\"\\n        \"+c+\" sourceLocR = coords;\\n        ++\"+h[l-1]+\";\\n        \"+c+\" sourceLocG = coords;\\n        ++\"+h[l-2]+\";\\n        \"+c+\" sourceLocA = coords;\\n        --\"+h[l-1]+\";\\n        \"+c+\" sourceLocB = coords;\\n        --\"+h[l-2]+\";\";var d=[\"x\",\"y\",\"z\",\"w\",\"u\",\"v\"].slice(0,s),v=\".\"+d[s-1],m=d.map(function(t){return\"int \"+t}),g=Fo(\"sourceLocR\",s-1).concat(\"inIdx.r\"),y=Fo(\"sourceLocG\",s-1).concat(\"inIdx.g\"),x=Fo(\"sourceLocB\",s-1).concat(\"inIdx.b\"),b=Fo(\"sourceLocA\",s-1).concat(\"inIdx.a\"),w=\"max\"===n?\"greaterThan\":\"lessThan\",C=r?\"\":\"\\n          inIdx = round(vec4(getBestIndicesAChannel(\"+g.join()+\"),\\n                             getBestIndicesAChannel(\"+y.join()+\"),\\n                             getBestIndicesAChannel(\"+x.join()+\"),\\n                             getBestIndicesAChannel(\"+b.join()+\")));\",E=\"vec4(\\n            getAChannel(\"+g.join()+\"),\\n            hasNextCol ? getAChannel(\"+y.join()+\") : 0.,\\n            hasNextRow ? getAChannel(\"+x.join()+\") : 0.,\\n            hasNextRow && hasNextCol ? getAChannel(\"+b.join()+\") : 0.)\",R=r?\"\":\"\\n      float getBestIndicesAChannel(\"+m.join()+\") {\\n        return getChannel(getBestIndicesA(\"+d.join()+\"),\\n                                          vec2(\"+d.slice(-2).join()+\"));\\n      }\";this.userCode=\"\\n      float getAChannel(\"+m.join()+\") {\\n        return getChannel(getA(\"+d.join()+\"),\\n                               vec2(\"+d.slice(-2).join()+\"));\\n      }\\n      \"+R+\"\\n      void main() {\\n        \"+c+\" coords = getOutputCoords();\\n        bool hasNextCol = \"+h[l-1]+\" < \"+(u[l-1]-1)+\";\\n        bool hasNextRow = \"+h[l-2]+\" < \"+(u[l-2]-1)+\";\\n        \"+i+\"\\n        ivec4 srcIdx = ivec4(sourceLocR\"+v+\", sourceLocG\"+v+\",\\n          sourceLocB\"+v+\", sourceLocA\"+v+\") * \"+e+\";\\n        ivec4 inIdx = srcIdx;\\n        vec4 bestIndex = vec4(inIdx);\\n        vec4 bestValue = \"+E+\";\\n\\n        for (int i = 0; i < \"+e+\"; i++) {\\n          inIdx = srcIdx;\\n          \"+C+\"\\n          vec4 candidate = \"+E+\";\\n          bvec4 nan = isnan(candidate);\\n          bvec4 replace = bvec4(\\n            vec4(\"+w+\"(candidate, bestValue)) * (vec4(1.0) - vec4(nan)));\\n\\n          bestValue = vec4(replace.x  ? candidate.x : bestValue.x,\\n                           replace.y  ? candidate.y : bestValue.y,\\n                           replace.z  ? candidate.z : bestValue.z,\\n                           replace.w  ? candidate.w : bestValue.w);\\n          bestIndex = mix(bestIndex, vec4(inIdx), vec4(replace));\\n          srcIdx++;\\n        }\\n        setOutput(bestIndex);\\n      }\\n    \"}}(),Jo=function(){return function(t){this.variableNames=[\"dy\"],this.outputShape=t.inShape;var e=t.filterHeight,n=t.filterWidth,r=t.strideHeight,o=t.strideWidth,a=t.dilationHeight,i=t.dilationWidth,s=t.effectiveFilterHeight,u=t.effectiveFilterWidth,l=s-1-t.padInfo.top,c=u-1-t.padInfo.left,h=1/(e*n);this.userCode=\"\\n      const ivec2 pads = ivec2(\"+l+\", \"+c+\");\\n      const float avgMultiplier = float(\"+h+\");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n\\n        ivec2 dyRCCorner = coords.yz - pads;\\n        int dyRCorner = dyRCCorner.x;\\n        int dyCCorner = dyRCCorner.y;\\n\\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        for (int wR = 0; wR < \"+s+\";\\n            wR += \"+a+\") {\\n          float dyR = float(dyRCorner + wR) / \"+r+\".0;\\n\\n          if (dyR < 0.0 || dyR >= \"+t.outHeight+\".0 || fract(dyR) > 0.0) {\\n            continue;\\n          }\\n          int idyR = int(dyR);\\n\\n          for (int wC = 0; wC < \"+u+\";\\n            wC+= \"+i+\") {\\n            float dyC = float(dyCCorner + wC) / \"+o+\".0;\\n\\n            if (dyC < 0.0 || dyC >= \"+t.outWidth+\".0 ||\\n                fract(dyC) > 0.0) {\\n              continue;\\n            }\\n            int idyC = int(dyC);\\n\\n            float dyValue = getDy(b, idyR, idyC, d);\\n\\n            dotProd += dyValue * avgMultiplier;\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \"}}(),Zo=function(){return function(t){this.variableNames=[\"dy\"],this.outputShape=t.inShape;var e=t.filterDepth,n=t.filterHeight,r=t.filterWidth,o=t.strideDepth,a=t.strideHeight,i=t.strideWidth,s=t.dilationDepth,u=t.dilationHeight,l=t.dilationWidth,c=t.effectiveFilterDepth,h=t.effectiveFilterHeight,p=t.effectiveFilterWidth,f=c-1-t.padInfo.front,d=h-1-t.padInfo.top,v=p-1-t.padInfo.left,m=1/(e*n*r);this.userCode=\"\\n      const ivec3 pads = ivec3(\"+f+\", \"+d+\", \"+v+\");\\n      const float avgMultiplier = float(\"+m+\");\\n\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int ch = coords.u;\\n\\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\\n        int dyDCorner = dyCorner.x;\\n        int dyRCorner = dyCorner.y;\\n        int dyCCorner = dyCorner.z;\\n\\n        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get\\n        // dx(xD, xR, xC, ch).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n\\n        for (int wD = 0; wD < \"+c+\";\\n            wD += \"+s+\") {\\n          float dyD = float(dyDCorner + wD) / \"+o+\".0;\\n\\n          if (dyD < 0.0 || dyD >= \"+t.outDepth+\".0 || fract(dyD) > 0.0) {\\n            continue;\\n          }\\n          int idyD = int(dyD);\\n\\n          for (int wR = 0; wR < \"+h+\";\\n              wR += \"+u+\") {\\n            float dyR = float(dyRCorner + wR) / \"+a+\".0;\\n\\n            if (dyR < 0.0 || dyR >= \"+t.outHeight+\".0 ||\\n                fract(dyR) > 0.0) {\\n              continue;\\n            }\\n            int idyR = int(dyR);\\n\\n            for (int wC = 0; wC < \"+p+\";\\n                wC += \"+l+\") {\\n              float dyC = float(dyCCorner + wC) / \"+i+\".0;\\n\\n              if (dyC < 0.0 || dyC >= \"+t.outWidth+\".0 ||\\n                  fract(dyC) > 0.0) {\\n                continue;\\n              }\\n              int idyC = int(dyC);\\n\\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\\n\\n              dotProd += dyValue * avgMultiplier;\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \"}}(),ta=function(){return function(t,e,n,r,o,a){this.outputShape=[],this.variableNames=[\"x\",\"mean\",\"variance\"],no(t,e),no(t,n);var i=\"0.0\";null!=r&&(no(t,r),this.variableNames.push(\"offset\"),i=\"getOffsetAtOutCoords()\");var s=\"1.0\";null!=o&&(no(t,o),this.variableNames.push(\"scale\"),s=\"getScaleAtOutCoords()\"),this.outputShape=t,this.userCode=\"\\n      void main() {\\n        float x = getXAtOutCoords();\\n        float mean = getMeanAtOutCoords();\\n        float variance = getVarianceAtOutCoords();\\n        float offset = \"+i+\";\\n        float scale = \"+s+\";\\n        float inv = scale * inversesqrt(variance + float(\"+a+\"));\\n        setOutput(dot(vec3(x, -mean, offset), vec3(inv, inv, 1)));\\n      }\\n    \"}}(),ea=function(){return function(t,e,n,r,o,a){this.usesPackedTextures=!0,this.variableNames=[\"x\",\"mean\",\"variance\"],no(t,e),no(t,n);var i=\"vec4(0.0)\";null!=r&&(no(t,r),this.variableNames.push(\"offset\"),i=\"getOffsetAtOutCoords()\");var s=\"vec4(1.0)\";null!=o&&(no(t,o),this.variableNames.push(\"scale\"),s=\"getScaleAtOutCoords()\"),this.outputShape=t,this.userCode=\"\\n      void main() {\\n        vec4 offset = \"+i+\";\\n        vec4 scale = \"+s+\";\\n\\n        vec4 x = getXAtOutCoords();\\n        vec4 mean = getMeanAtOutCoords();\\n        vec4 variance = getVarianceAtOutCoords();\\n\\n        vec4 inv = scale * inversesqrt(variance + vec4(\"+a+\"));\\n\\n        setOutput((x - mean) * inv + offset);\\n      }\\n    \"}}(),na=\"return areal * breal - aimag * bimag;\",ra=\"return areal * bimag + aimag * breal;\",oa=function(){return function(t,e,n){this.variableNames=[\"AReal\",\"AImag\",\"BReal\",\"BImag\"],this.outputShape=no(e,n),this.userCode=\"\\n      float binaryOpComplex(\\n          float areal, float aimag, float breal, float bimag) {\\n        \"+t+\"\\n      }\\n\\n      void main() {\\n        float areal = getARealAtOutCoords();\\n        float aimag = getAImagAtOutCoords();\\n        float breal = getBRealAtOutCoords();\\n        float bimag = getBImagAtOutCoords();\\n        setOutput(binaryOpComplex(areal, aimag, breal, bimag));\\n      }\\n    \"}}(),aa=\"return a + b;\",ia=\"return a - b;\",sa=\"return a * b;\",ua=\"return (a < 0.) ? b * a : a;\",la=function(){return function(t,e,n){this.variableNames=[\"A\",\"B\"],this.outputShape=no(e,n),this.userCode=\"\\n      float binaryOperation(float a, float b) {\\n        \"+t+\"\\n      }\\n\\n      void main() {\\n        float a = getAAtOutCoords();\\n        float b = getBAtOutCoords();\\n        setOutput(binaryOperation(a, b));\\n      }\\n    \"}}(),ca=\"\\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\\n\",ha=function(){return function(t,e,n,r){void 0===r&&(r=!1),this.variableNames=[\"A\",\"B\"],this.supportsBroadcasting=!0,this.usesPackedTextures=!0,this.outputShape=no(e,n);var o=this.outputShape.length,a=\"\";if(r)if(0===o||1===g(this.outputShape))a=\"\\n          result.y = 0.;\\n          result.z = 0.;\\n          result.w = 0.;\\n        \";else if(a=\"\\n          \"+jo(o)+\" coords = getOutputCoords();\\n        \",1===o)a+=\"\\n            result.y = (coords + 1) >= \"+this.outputShape[0]+\" ? 0. : result.y;\\n            result.z = 0.;\\n            result.w = 0.;\\n          \";else{var i=Fo(\"coords\",o);a+=\"\\n            bool nextRowOutOfBounds =\\n              (\"+i[o-2]+\" + 1) >= \"+this.outputShape[o-2]+\";\\n            bool nextColOutOfBounds =\\n              (\"+i[o-1]+\" + 1) >= \"+this.outputShape[o-1]+\";\\n            result.y = nextColOutOfBounds ? 0. : result.y;\\n            result.z = nextRowOutOfBounds ? 0. : result.z;\\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\\n          \"}this.userCode=\"\\n      vec4 binaryOperation(vec4 a, vec4 b) {\\n        \"+t+\"\\n      }\\n\\n      void main() {\\n        vec4 a = getAAtOutCoords();\\n        vec4 b = getBAtOutCoords();\\n\\n        vec4 result = binaryOperation(a, b);\\n        \"+a+\"\\n\\n        setOutput(result);\\n      }\\n    \"}}(),pa=function(){function t(t){this.variableNames=[\"A\"],this.outputShape=t,this.userCode=\"\\n      uniform float minVal;\\n      uniform float maxVal;\\n\\n      void main() {\\n        float value = getAAtOutCoords();\\n        if (isnan(value)) {\\n          setOutput(value);\\n          return;\\n        }\\n\\n        setOutput(clamp(value, minVal, maxVal));\\n      }\\n    \"}return t.prototype.getCustomSetupFunc=function(t,e){var n=this;return function(r,o){null==n.minLoc&&(n.minLoc=r.getUniformLocationNoThrow(o,\"minVal\"),n.maxLoc=r.getUniformLocationNoThrow(o,\"maxVal\")),r.gl.uniform1f(n.minLoc,t),r.gl.uniform1f(n.maxLoc,e)}},t}(),fa=function(){function t(t){this.variableNames=[\"A\"],this.usesPackedTextures=!0,this.outputShape=t,this.userCode=\"\\n      uniform float minVal;\\n      uniform float maxVal;\\n\\n      void main() {\\n        vec4 value = getAAtOutCoords();\\n\\n        if (any(isnan(value))) {\\n          setOutput(value);\\n          return;\\n        }\\n\\n        setOutput(clamp(value, vec4(minVal), vec4(maxVal)));\\n      }\\n    \"}return t.prototype.getCustomSetupFunc=function(t,e){var n=this;return function(r,o){null==n.minLoc&&(n.minLoc=r.getUniformLocationNoThrow(o,\"minVal\"),n.maxLoc=r.getUniformLocationNoThrow(o,\"maxVal\")),r.gl.uniform1f(n.minLoc,t),r.gl.uniform1f(n.maxLoc,e)}},t}(),da=function(){return function(t){this.variableNames=[\"real\",\"imag\"],this.outputShape=t,this.userCode=\"\\n      void main() {\\n        float re = abs(getRealAtOutCoords());\\n        float im = abs(getImagAtOutCoords());\\n        float mx = max(re, im);\\n\\n        // sadly the length function in glsl is not underflow-safe\\n        // (at least not on Intel GPUs). So the safe solution is\\n        // to ensure underflow-safety in all cases.\\n        setOutput(\\n          mx == 0.0 ? 0.0 : mx * length(vec2(1, min(re, im)/mx))\\n        );\\n      }\\n    \"}}(),va=function(){return function(t){this.outputShape=[],this.outputShape=dn(t,1),this.variableNames=t.map(function(t,e){return\"T\"+e});var e=new Array(t.length-1);e[0]=t[0][1];for(var n=1;n<e.length;n++)e[n]=e[n-1]+t[n][1];var r=[\"if (yC < \"+e[0]+\") setOutput(getT0(yR, yC));\"];for(n=1;n<e.length;n++){var o=e[n-1];r.push(\"else if (yC < \"+e[n]+\") setOutput(getT\"+n+\"(yR, yC-\"+o+\"));\")}var a=e.length,i=e[e.length-1];r.push(\"else setOutput(getT\"+a+\"(yR, yC-\"+i+\"));\"),this.userCode=\"\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int yR = coords.x;\\n        int yC = coords.y;\\n\\n        \"+r.join(\"\\n        \")+\"\\n      }\\n    \"}}(),ma=function(){return function(t,e){this.usesPackedTextures=!0,this.outputShape=[],this.outputShape=dn(t,e);var n=this.outputShape,r=n.length,o=jo(r),a=Fo(\"coords\",r),i=[\"x\",\"y\",\"z\",\"w\",\"u\",\"v\"].slice(0,r);this.variableNames=t.map(function(t,e){return\"T\"+e});var s=new Array(t.length-1);s[0]=t[0][e];for(var u=1;u<s.length;u++)s[u]=s[u-1]+t[u][e];var l=i[e],c=\"vec2(\"+i.slice(-2).join()+\")\",h=i.join(),p=\"if (\"+l+\" < \"+s[0]+\")\\n          return getChannel(getT0(\"+h+\"), \"+c+\");\";for(u=1;u<s.length;u++){var f=s[u-1];p+=\"\\n        else if (\"+l+\" < \"+s[u]+\") {\\n          \"+l+\" -= \"+f+\";\\n          return getChannel(getT\"+u+\"(\"+h+\"), \"+c+\");\\n        }\"}var d=s.length;p+=\"\\n        else {\\n          \"+l+\" -= \"+s[s.length-1]+\";\\n          return getChannel(getT\"+d+\"(\"+h+\"), \"+c+\");\\n        }\",this.userCode=\"\\n      float getValue(\"+i.map(function(t){return\"int \"+t})+\") {\\n        \"+p+\"\\n      }\\n\\n      void main() {\\n        \"+o+\" coords = getOutputCoords();\\n        vec4 result = vec4(getValue(\"+a+\"), 0., 0., 0.);\\n        if (++\"+a[r-1]+\" < \"+n[r-1]+\") {\\n          result.g = getValue(\"+a+\");\\n        }\\n        if (++\"+a[r-2]+\" < \"+n[r-2]+\") {\\n          result.a = getValue(\"+a+\");\\n        }\\n        if (\"+a[r-2]+\" < \"+n[r-2]+\" &&\\n            --\"+a[r-1]+\" < \"+n[r-1]+\") {\\n          result.b = getValue(\"+a+\");\\n        }\\n        setOutput(result);\\n      }\\n    \"}}(),ga=function(){return function(t){this.variableNames=[\"x\",\"dy\"],this.outputShape=t.filterShape;var e=t.strideHeight,n=t.strideWidth,r=t.padInfo.top,o=t.padInfo.left,a=\"channelsLast\"===t.dataFormat;this.userCode=\"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int wR = coords.x;\\n        int wC = coords.y;\\n        int d1 = coords.z;\\n        int d2 = coords.w;\\n\\n        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n\\n        for (int b = 0; b < \"+t.batchSize+\"; b++) {\\n          for (int yR = 0; yR < \"+t.outHeight+\"; yR++) {\\n            int xR = wR + yR * \"+e+\" - \"+r+\";\\n\\n            if (xR < 0 || xR >= \"+t.inHeight+\") {\\n              continue;\\n            }\\n\\n            for (int yC = 0; yC < \"+t.outWidth+\"; yC++) {\\n              int xC = wC + yC * \"+n+\" - \"+o+\";\\n\\n              if (xC < 0 || xC >= \"+t.inWidth+\") {\\n                continue;\\n              }\\n\\n              if (\"+a+\") {\\n                float dyValue = getDy(b, yR, yC, d2);\\n                float xValue = getX(b, xR, xC, d1);\\n                dotProd += (xValue * dyValue);\\n              } else {\\n                float dyValue = getDy(b, d2, yR, yC);\\n                float xValue = getX(b, d1, xR, xC);\\n                dotProd += (xValue * dyValue);\\n              }\\n\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \"}}(),ya=function(){return function(t){this.variableNames=[\"dy\",\"W\"],this.outputShape=t.inShape;var e=t.filterHeight,n=t.filterWidth,r=t.strideHeight,o=t.strideWidth,a=\"channelsLast\"===t.dataFormat,i=e-1-t.padInfo.top,s=n-1-t.padInfo.left,u=a?1:2,l=a?2:3,c=a?3:1;this.userCode=\"\\n      const ivec2 pads = ivec2(\"+i+\", \"+s+\");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int d1 = coords[\"+c+\"];\\n\\n        ivec2 dyCorner = ivec2(coords[\"+u+\"], coords[\"+l+\"]) - pads;\\n        int dyRCorner = dyCorner.x;\\n        int dyCCorner = dyCorner.y;\\n\\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        for (int wR = 0; wR < \"+e+\"; wR++) {\\n          float dyR = float(dyRCorner + wR) / \"+r+\".0;\\n\\n          if (dyR < 0.0 || dyR >= \"+t.outHeight+\".0 || fract(dyR) > 0.0) {\\n            continue;\\n          }\\n          int idyR = int(dyR);\\n\\n          int wRPerm = \"+e+\" - 1 - wR;\\n\\n          for (int wC = 0; wC < \"+n+\"; wC++) {\\n            float dyC = float(dyCCorner + wC) / \"+o+\".0;\\n\\n            if (dyC < 0.0 || dyC >= \"+t.outWidth+\".0 ||\\n                fract(dyC) > 0.0) {\\n              continue;\\n            }\\n            int idyC = int(dyC);\\n\\n            int wCPerm = \"+n+\" - 1 - wC;\\n\\n            for (int d2 = 0; d2 < \"+t.outChannels+\"; d2++) {\\n\\n              if (\"+a+\") {\\n                float xValue = getDy(batch, idyR, idyC, d2);\\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\\n                dotProd += xValue * wValue;\\n              } else {\\n                float xValue = getDy(batch, d2, idyR, idyC);\\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\\n                dotProd += xValue * wValue;\\n              }\\n\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \"}}(),xa=function(){return function(t){this.variableNames=[\"x\",\"dy\"],this.outputShape=t.filterShape;var e=t.strideDepth,n=t.strideHeight,r=t.strideWidth,o=t.padInfo.front,a=t.padInfo.top,i=t.padInfo.left;this.userCode=\"\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int wF = coords.x;\\n        int wR = coords.y;\\n        int wC = coords.z;\\n        int d1 = coords.w;\\n        int d2 = coords.u;\\n\\n        float dotProd = 0.0;\\n\\n        for (int b = 0; b < \"+t.batchSize+\"; b++) {\\n          for (int yF = 0; yF < \"+t.outDepth+\"; yF++) {\\n            int xF = wF + yF * \"+e+\" - \"+o+\";\\n\\n            if (xF < 0 || xF >= \"+t.inDepth+\") {\\n              continue;\\n            }\\n\\n            for (int yR = 0; yR < \"+t.outHeight+\"; yR++) {\\n              int xR = wR + yR * \"+n+\" - \"+a+\";\\n\\n              if (xR < 0 || xR >= \"+t.inHeight+\") {\\n                continue;\\n              }\\n\\n              for (int yC = 0; yC < \"+t.outWidth+\"; yC++) {\\n                int xC = wC + yC * \"+r+\" - \"+i+\";\\n\\n                if (xC < 0 || xC >= \"+t.inWidth+\") {\\n                  continue;\\n                }\\n\\n                float dyValue = getDy(b, yF, yR, yC, d2);\\n                float xValue = getX(b, xF, xR, xC, d1);\\n                dotProd += (xValue * dyValue);\\n              }\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \"}}(),ba=function(){return function(t){this.variableNames=[\"dy\",\"W\"],this.outputShape=t.inShape;var e=t.filterDepth,n=t.filterHeight,r=t.filterWidth,o=t.strideDepth,a=t.strideHeight,i=t.strideWidth,s=e-1-t.padInfo.front,u=n-1-t.padInfo.top,l=r-1-t.padInfo.left;this.userCode=\"\\n      const ivec3 pads = ivec3(\"+s+\", \"+u+\", \"+l+\");\\n\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int d1 = coords.u;\\n\\n\\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\\n        int dyFCorner = dyCorner.x;\\n        int dyRCorner = dyCorner.y;\\n        int dyCCorner = dyCorner.z;\\n\\n        float dotProd = 0.0;\\n        for (int wF = 0; wF < \"+e+\"; wF++) {\\n          float dyF = float(dyFCorner + wF) / \"+o+\".0;\\n\\n          if (dyF < 0.0 || dyF >= \"+t.outDepth+\".0 || fract(dyF) > 0.0) {\\n            continue;\\n          }\\n          int idyF = int(dyF);\\n\\n          int wFPerm = \"+e+\" - 1 - wF;\\n\\n          for (int wR = 0; wR < \"+n+\"; wR++) {\\n            float dyR = float(dyRCorner + wR) / \"+a+\".0;\\n\\n            if (dyR < 0.0 || dyR >= \"+t.outHeight+\".0 ||\\n              fract(dyR) > 0.0) {\\n              continue;\\n            }\\n            int idyR = int(dyR);\\n\\n            int wRPerm = \"+n+\" - 1 - wR;\\n\\n            for (int wC = 0; wC < \"+r+\"; wC++) {\\n              float dyC = float(dyCCorner + wC) / \"+i+\".0;\\n\\n              if (dyC < 0.0 || dyC >= \"+t.outWidth+\".0 ||\\n                  fract(dyC) > 0.0) {\\n                continue;\\n              }\\n              int idyC = int(dyC);\\n\\n              int wCPerm = \"+r+\" - 1 - wC;\\n\\n              for (int d2 = 0; d2 < \"+t.outChannels+\"; d2++) {\\n                float xValue = getDy(batch, idyF, idyR, idyC, d2);\\n                float wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);\\n                dotProd += xValue * wValue;\\n              }\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \"}}(),wa=function(){return function(t){this.variableNames=[\"x\",\"dy\"],this.outputShape=t.filterShape;var e=t.strideHeight,n=t.strideWidth,r=t.padInfo.top,o=t.padInfo.left,a=t.outChannels/t.inChannels;this.userCode=\"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int wR = coords.x;\\n        int wC = coords.y;\\n        int d1 = coords.z;\\n        int dm = coords.w;\\n        int d2 = d1 * \"+a+\" + dm;\\n\\n        float dotProd = 0.0;\\n\\n        // TO DO: Vec4 over the batch size\\n        for (int b = 0; b < \"+t.batchSize+\"; b++) {\\n          for (int yR = 0; yR < \"+t.outHeight+\"; yR++) {\\n            int xR = wR + yR * \"+e+\" - \"+r+\";\\n\\n            if (xR < 0 || xR >= \"+t.inHeight+\") {\\n              continue;\\n            }\\n\\n            for (int yC = 0; yC < \"+t.outWidth+\"; yC++) {\\n              int xC = wC + yC * \"+n+\" - \"+o+\";\\n\\n              if (xC < 0 || xC >= \"+t.inWidth+\") {\\n                continue;\\n              }\\n\\n              float dyValue = getDy(b, yR, yC, d2);\\n              float xValue = getX(b, xR, xC, d1);\\n              dotProd += (xValue * dyValue);\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \"}}(),Ca=function(){return function(t){this.variableNames=[\"dy\",\"W\"],this.outputShape=t.inShape;var e=t.filterHeight,n=t.filterWidth,r=t.strideHeight,o=t.strideWidth,a=e-1-t.padInfo.top,i=n-1-t.padInfo.left,s=t.outChannels/t.inChannels;this.userCode=\"\\n      const ivec2 pads = ivec2(\"+a+\", \"+i+\");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int d1 = coords[3];\\n        ivec2 dyCorner = coords.yz - pads;\\n        int dyRCorner = dyCorner.x;\\n        int dyCCorner = dyCorner.y;\\n\\n        float dotProd = 0.0;\\n\\n        for (int wR = 0; wR < \"+e+\"; wR++) {\\n          float dyR = float(dyRCorner + wR) / \"+r+\".0;\\n\\n          if (dyR < 0.0 || dyR >= \"+t.outHeight+\".0 || fract(dyR) > 0.0) {\\n            continue;\\n          }\\n          int idyR = int(dyR);\\n\\n          int wRPerm = \"+e+\" - 1 - wR;\\n\\n          for (int wC = 0; wC < \"+n+\"; wC++) {\\n            float dyC = float(dyCCorner + wC) / \"+o+\".0;\\n\\n            if (dyC < 0.0 || dyC >= \"+t.outWidth+\".0 ||\\n                fract(dyC) > 0.0) {\\n              continue;\\n            }\\n            int idyC = int(dyC);\\n\\n            int wCPerm = \"+n+\" - 1 - wC;\\n\\n            // TO DO: Vec4 over the channelMul\\n            for (int dm = 0; dm < \"+s+\"; dm++) {\\n              int d2 = d1 * \"+s+\" + dm;\\n              float xValue = getDy(batch, idyR, idyC, d2);\\n              float wValue = getW(wRPerm, wCPerm, d1, dm);\\n              dotProd += xValue * wValue;\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \"}}(),Ea=function(){return function(t,e,n,r){void 0===e&&(e=!1),void 0===n&&(n=null),void 0===r&&(r=!1),this.variableNames=[\"x\",\"W\"],this.outputShape=t.outShape;var o=t.padInfo.top,a=t.padInfo.left,i=t.strideHeight,s=t.strideWidth,u=t.dilationHeight,l=t.dilationWidth,c=t.filterHeight,h=t.filterWidth,p=4*Math.floor(t.inChannels/4),f=t.inChannels%4,d=\"channelsLast\"===t.dataFormat,v=d?1:2,m=d?2:3,g=d?3:1,y=\"\",x=\"\";n&&(y=r?\"float activation(float a) {\\n          float b = getPreluActivationWeightsAtOutCoords();\\n          \"+n+\"\\n        }\":\"\\n          float activation(float x) {\\n            \"+n+\"\\n          }\\n        \",x=\"result = activation(result);\");var b=e?\"result += getBiasAtOutCoords();\":\"\";e&&this.variableNames.push(\"bias\"),r&&this.variableNames.push(\"preluActivationWeights\"),this.userCode=\"\\n      \"+y+\"\\n\\n      const ivec2 strides = ivec2(\"+i+\", \"+s+\");\\n      const ivec2 pads = ivec2(\"+o+\", \"+a+\");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int d2 = coords[\"+g+\"];\\n\\n        ivec2 xRCCorner =\\n            ivec2(coords[\"+v+\"], coords[\"+m+\"]) * strides - pads;\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        // Convolve x(?, ?, d1) with w(:, :, d1, d2) to get y(yR, yC, d2).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        for (int wR = 0; wR < \"+c+\"; wR++) {\\n          int xR = xRCorner + wR * \"+u+\";\\n\\n          if (xR < 0 || xR >= \"+t.inHeight+\") {\\n            continue;\\n          }\\n\\n          for (int wC = 0; wC < \"+h+\"; wC++) {\\n            int xC = xCCorner + wC * \"+l+\";\\n\\n            if (xC < 0 || xC >= \"+t.inWidth+\") {\\n              continue;\\n            }\\n\\n            for (int d1 = 0; d1 < \"+p+\"; d1 += 4) {\\n              vec4 wValues = vec4(\\n                getW(wR, wC, d1, d2),\\n                getW(wR, wC, d1 + 1, d2),\\n                getW(wR, wC, d1 + 2, d2),\\n                getW(wR, wC, d1 + 3, d2)\\n              );\\n\\n              if (\"+d+\") {\\n                vec4 xValues = vec4(\\n                  getX(batch, xR, xC, d1),\\n                  getX(batch, xR, xC, d1 + 1),\\n                  getX(batch, xR, xC, d1 + 2),\\n                  getX(batch, xR, xC, d1 + 3)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              } else {\\n                vec4 xValues = vec4(\\n                  getX(batch, d1, xR, xC),\\n                  getX(batch, d1 + 1, xR, xC),\\n                  getX(batch, d1 + 2, xR, xC),\\n                  getX(batch, d1 + 3, xR, xC)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              }\\n            }\\n\\n            if (\"+(1===f)+\") {\\n\\n              if (\"+d+\") {\\n                dotProd +=\\n                    getX(batch, xR, xC, \"+p+\") *\\n                    getW(wR, wC, \"+p+\", d2);\\n              } else {\\n                dotProd +=\\n                    getX(batch, \"+p+\", xR, xC) *\\n                    getW(wR, wC, \"+p+\", d2);\\n              }\\n\\n            } else if (\"+(2===f)+\") {\\n              vec2 wValues = vec2(\\n                getW(wR, wC, \"+p+\", d2),\\n                getW(wR, wC, \"+p+\" + 1, d2)\\n              );\\n\\n              if (\"+d+\") {\\n                vec2 xValues = vec2(\\n                  getX(batch, xR, xC, \"+p+\"),\\n                  getX(batch, xR, xC, \"+p+\" + 1)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              } else {\\n                vec2 xValues = vec2(\\n                  getX(batch, \"+p+\", xR, xC),\\n                  getX(batch, \"+p+\" + 1, xR, xC)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              }\\n\\n            } else if (\"+(3===f)+\") {\\n              vec3 wValues = vec3(\\n                getW(wR, wC, \"+p+\", d2),\\n                getW(wR, wC, \"+p+\" + 1, d2),\\n                getW(wR, wC, \"+p+\" + 2, d2)\\n              );\\n\\n              if (\"+d+\") {\\n                vec3 xValues = vec3(\\n                  getX(batch, xR, xC, \"+p+\"),\\n                  getX(batch, xR, xC, \"+p+\" + 1),\\n                  getX(batch, xR, xC, \"+p+\" + 2)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              } else {\\n                vec3 xValues = vec3(\\n                  getX(batch, \"+p+\", xR, xC),\\n                  getX(batch, \"+p+\" + 1, xR, xC),\\n                  getX(batch, \"+p+\" + 2, xR, xC)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              }\\n\\n            }\\n          }\\n        }\\n\\n        float result = dotProd;\\n        \"+b+\"\\n        \"+x+\"\\n        setOutput(result);\\n      }\\n    \"}}(),Ra=function(){return function(t){this.variableNames=[\"x\",\"W\"],this.outputShape=t.outShape;var e=t.padInfo.front,n=t.padInfo.top,r=t.padInfo.left,o=t.strideDepth,a=t.strideHeight,i=t.strideWidth,s=t.dilationDepth,u=t.dilationHeight,l=t.dilationWidth,c=t.filterDepth,h=t.filterHeight,p=t.filterWidth,f=4*Math.floor(t.inChannels/4),d=t.inChannels%4;this.userCode=\"\\n      const ivec3 strides = ivec3(\"+o+\", \"+a+\", \"+i+\");\\n      const ivec3 pads = ivec3(\"+e+\", \"+n+\", \"+r+\");\\n\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int d2 = coords.u;\\n\\n        ivec3 xFRCCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\\n        int xFCorner = xFRCCorner.x;\\n        int xRCorner = xFRCCorner.y;\\n        int xCCorner = xFRCCorner.z;\\n\\n        // Convolve x(?, ?, ?, d1) with w(:, :, :, d1, d2) to get\\n        // y(yF, yR, yC, d2). ? = to be determined. : = across all\\n        // values in that axis.\\n        float dotProd = 0.0;\\n        for (int wF = 0; wF < \"+c+\"; wF++) {\\n          int xF = xFCorner + wF * \"+s+\";\\n\\n          if (xF < 0 || xF >= \"+t.inDepth+\") {\\n            continue;\\n          }\\n\\n          for (int wR = 0; wR < \"+h+\"; wR++) {\\n            int xR = xRCorner + wR * \"+u+\";\\n\\n            if (xR < 0 || xR >= \"+t.inHeight+\") {\\n              continue;\\n            }\\n\\n            for (int wC = 0; wC < \"+p+\"; wC++) {\\n              int xC = xCCorner + wC * \"+l+\";\\n\\n              if (xC < 0 || xC >= \"+t.inWidth+\") {\\n                continue;\\n              }\\n\\n              for (int d1 = 0; d1 < \"+f+\"; d1 += 4) {\\n                vec4 xValues = vec4(\\n                  getX(batch, xF, xR, xC, d1),\\n                  getX(batch, xF, xR, xC, d1 + 1),\\n                  getX(batch, xF, xR, xC, d1 + 2),\\n                  getX(batch, xF, xR, xC, d1 + 3)\\n                );\\n                vec4 wValues = vec4(\\n                  getW(wF, wR, wC, d1, d2),\\n                  getW(wF, wR, wC, d1 + 1, d2),\\n                  getW(wF, wR, wC, d1 + 2, d2),\\n                  getW(wF, wR, wC, d1 + 3, d2)\\n                );\\n\\n                dotProd += dot(xValues, wValues);\\n              }\\n\\n              if (\"+(1===d)+\") {\\n                dotProd +=\\n                  getX(batch, xF, xR, xC, \"+f+\") *\\n                  getW(wF, wR, wC, \"+f+\", d2);\\n              } else if (\"+(2===d)+\") {\\n                vec2 xValues = vec2(\\n                  getX(batch, xF, xR, xC, \"+f+\"),\\n                  getX(batch, xF, xR, xC, \"+f+\" + 1)\\n                );\\n                vec2 wValues = vec2(\\n                  getW(wF, wR, wC, \"+f+\", d2),\\n                  getW(wF, wR, wC, \"+f+\" + 1, d2)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              } else if (\"+(3===d)+\") {\\n                vec3 xValues = vec3(\\n                  getX(batch, xF, xR, xC, \"+f+\"),\\n                  getX(batch, xF, xR, xC, \"+f+\" + 1),\\n                  getX(batch, xF, xR, xC, \"+f+\" + 2)\\n                );\\n                vec3 wValues = vec3(\\n                  getW(wF, wR, wC, \"+f+\", d2),\\n                  getW(wF, wR, wC, \"+f+\" + 1, d2),\\n                  getW(wF, wR, wC, \"+f+\" + 2, d2)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              }\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \"}}(),Ia=function(){return function(t){this.variableNames=[\"x\",\"W\"],this.outputShape=t.outShape;var e=t.inHeight,n=t.inWidth,r=t.padInfo.top,o=t.padInfo.left,a=t.strideHeight,i=t.strideWidth,s=t.dilationHeight,u=t.dilationWidth,l=t.filterHeight,c=t.filterWidth,h=t.outChannels/t.inChannels;this.userCode=\"\\n      const ivec2 strides = ivec2(\"+a+\", \"+i+\");\\n      const ivec2 pads = ivec2(\"+r+\", \"+o+\");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords.x;\\n        ivec2 xRCCorner = coords.yz * strides - pads;\\n        int d2 = coords.w;\\n        int d1 = d2 / \"+h+\";\\n        int q = d2 - d1 * \"+h+\";\\n\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        // Convolve x(?, ?, d1) with w(:, :, d1, q) to get y(yR, yC, d2).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        // TO DO(dsmilkov): Flatten the two for loops and vec4 the operations.\\n        for (int wR = 0; wR < \"+l+\"; wR++) {\\n          int xR = xRCorner + wR * \"+s+\";\\n\\n          if (xR < 0 || xR >= \"+e+\") {\\n            continue;\\n          }\\n\\n          for (int wC = 0; wC < \"+c+\"; wC++) {\\n            int xC = xCCorner + wC * \"+u+\";\\n\\n            if (xC < 0 || xC >= \"+n+\") {\\n              continue;\\n            }\\n\\n            float xVal = getX(batch, xR, xC, d1);\\n            float wVal = getW(wR, wC, d1, q);\\n            dotProd += xVal * wVal;\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \"}}(),ka=function(){return function(t){this.variableNames=[\"x\",\"W\"],this.usesPackedTextures=!0,this.outputShape=t.outShape;for(var e=t.inHeight,n=t.inWidth,r=t.padInfo.top,o=t.padInfo.left,a=t.strideHeight,i=t.strideWidth,s=t.dilationHeight,u=t.dilationWidth,l=t.filterHeight,c=t.filterWidth,p=c,f=\"int xR; int xC; int xCOffset;\",d=0;d<l;d++)for(var v=0;v<c;v++)f+=\"\\n          vec4 xTexelR\"+d+\"C\"+2*v+\" = vec4(0.);\\n          vec4 wR\"+d+\"C\"+v+\" = vec4(0.);\\n          vec4 xR\"+d+\"C\"+v+\" = vec4(0.);\";for(d=0;d<l;d++)for(var m=0;m<p;m++){if(f+=\"\\n          xR = xRCorner + \"+d*s+\";\\n          xC = xCCorner + \"+(v=2*m)*u+\";\\n        \",1===i){if(v<c&&(f+=o%2==1?\"\\n                xCOffset = xC + 1;\\n                if(xR >= 0 && xR < \"+e+\" && xCOffset >= 0 && xCOffset < \"+n+\") {\\n                  xTexelR\"+d+\"C\"+v+\" = getX(batch, xR, xCOffset, d1);\\n                } else {\\n                  xTexelR\"+d+\"C\"+v+\" = vec4(0.);\\n                }\\n\\n                xCOffset = xC + 1 - 2;\\n                if(xR >= 0 && xR < \"+e+\" && xCOffset >= 0 && xCOffset < \"+n+\") {\\n                  vec4 previous = getX(batch, xR, xCOffset, d1);\\n                  xR\"+d+\"C\"+v+\" = vec4(previous.zw, xTexelR\"+d+\"C\"+v+\".xy);\\n                } else {\\n                  xR\"+d+\"C\"+v+\" = vec4(0, 0, xTexelR\"+d+\"C\"+v+\".xy);\\n                }\\n              \":\"\\n                if(xR >= 0 && xR < \"+e+\" && xC >= 0 && xC < \"+n+\") {\\n                  xTexelR\"+d+\"C\"+v+\" = getX(batch, xR, xC, d1);\\n                } else {\\n                  xTexelR\"+d+\"C\"+v+\" = vec4(0.);\\n                }\\n\\n                xR\"+d+\"C\"+v+\" = xTexelR\"+d+\"C\"+v+\";\\n              \",v+1<c)){var g=o%2==0?h(u):u;u%2==0&&o%2==1||u%2!=0&&o%2!=1?(f+=\"\\n                  xCOffset = xC + \"+o%2+\" + \"+g+\";\\n\\n                  if(xR >= 0 && xR < \"+e+\" &&\\n                    xCOffset >= 0 && xCOffset < \"+n+\") {\\n                    xTexelR\"+d+\"C\"+(v+2)+\" = getX(batch, xR, xCOffset, d1);\\n                  }\\n                \",u>1&&(f+=\"\\n                    xCOffset -= 2;\\n                    if(xR >= 0 && xR < \"+e+\" &&\\n                      xCOffset >= 0 && xCOffset < \"+n+\") {\\n                      xTexelR\"+d+\"C\"+v+\" = getX(batch, xR, xCOffset, d1);\\n                    } else {\\n                      xTexelR\"+d+\"C\"+v+\" = vec4(0.);\\n                    }\\n                  \"),f+=\"\\n                  xR\"+d+\"C\"+(v+1)+\" = vec4(\\n                    xTexelR\"+d+\"C\"+v+\".zw, xTexelR\"+d+\"C\"+(v+2)+\".xy);\\n                \"):f+=\"\\n                  xCOffset = xC + \"+g+\";\\n\\n                  if(xR >= 0 && xR < \"+e+\" &&\\n                    xCOffset >= 0 && xCOffset < \"+n+\") {\\n                    xTexelR\"+d+\"C\"+(v+2)+\" = getX(batch, xR, xCOffset, d1);\\n                  }\\n\\n                  xR\"+d+\"C\"+(v+1)+\" = xTexelR\"+d+\"C\"+(v+2)+\";\\n                \"}}else v<c&&(f+=\"\\n              if(xR >= 0 && xR < \"+e+\") {\\n            \",o%2==1?(f+=\"\\n                xCOffset = xC + 1 - \"+i+\";\\n                if(xCOffset >= 0 && xCOffset < \"+n+\") {\\n                  xTexelR\"+d+\"C\"+v+\" = getX(batch, xR, xCOffset, d1);\\n                } else {\\n                  xTexelR\"+d+\"C\"+v+\" = vec4(0.);\\n                }\\n\\n                if(xC + 1 >= 0 && xC + 1 < \"+n+\") {\\n                  xTexelR\"+d+\"C\"+(v+2)+\" = getX(batch, xR, xC + 1, d1);\\n                } else {\\n                  xTexelR\"+d+\"C\"+(v+2)+\" = vec4(0.);\\n                }\\n\\n                xR\"+d+\"C\"+v+\" = vec4(\\n                  xTexelR\"+d+\"C\"+v+\".zw, xTexelR\"+d+\"C\"+(v+2)+\".zw);\\n              \",v+1<c&&(f+=\"\\n                  vec4 final = vec4(0.);\\n                  xCOffset = xC + 1 + \"+i+\";\\n                  if(xCOffset >= 0 && xCOffset < \"+n+\") {\\n                    final = getX(batch, xR, xCOffset, d1);\\n                  }\\n                  xR\"+d+\"C\"+(v+1)+\" = vec4(xTexelR\"+d+\"C\"+(v+2)+\".xy, final.xy);\\n                \")):(f+=\"\\n                if(xC >= 0 && xC < \"+n+\") {\\n                  xTexelR\"+d+\"C\"+v+\" = getX(batch, xR, xC, d1);\\n                } else {\\n                  xTexelR\"+d+\"C\"+v+\" = vec4(0.);\\n                }\\n\\n                xCOffset = xC + \"+i+\";\\n                if(xCOffset >= 0 && xCOffset < \"+n+\") {\\n                  xTexelR\"+d+\"C\"+(v+2)+\" = getX(batch, xR, xCOffset, d1);\\n                } else {\\n                  xTexelR\"+d+\"C\"+(v+2)+\" = vec4(0.);\\n                }\\n\\n                xR\"+d+\"C\"+v+\" = vec4(\\n                  xTexelR\"+d+\"C\"+v+\".xy, xTexelR\"+d+\"C\"+(v+2)+\".xy);\\n              \",v+1<c&&(f+=\"\\n                  xR\"+d+\"C\"+(v+1)+\" = vec4(\\n                    xTexelR\"+d+\"C\"+v+\".zw, xTexelR\"+d+\"C\"+(v+2)+\".zw);\\n                \")),f+=\"}\");v<c&&(f+=\"\\n            vec4 wTexelR\"+d+\"C\"+v+\" = getW(\"+d+\", \"+v+\", d1, q);\\n            wR\"+d+\"C\"+v+\" = vec4(wTexelR\"+d+\"C\"+v+\".xz, wTexelR\"+d+\"C\"+v+\".xz);\\n          \",v+1<c&&(f+=\"\\n              vec4 wTexelR\"+d+\"C\"+(v+1)+\" = getW(\"+d+\", \"+(v+1)+\", d1, q);\\n              wR\"+d+\"C\"+(v+1)+\" =\\n                vec4(wTexelR\"+d+\"C\"+(v+1)+\".xz, wTexelR\"+d+\"C\"+(v+1)+\".xz);\"))}for(d=0;d<l;d++)for(v=0;v<c;v++)f+=\"result += xR\"+d+\"C\"+v+\" * wR\"+d+\"C\"+v+\";\";this.userCode=\"\\n      const ivec2 strides = ivec2(\"+a+\", \"+i+\");\\n      const ivec2 pads = ivec2(\"+r+\", \"+o+\");\\n\\n      void main() {\\n\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords.x;\\n        ivec2 xRCCorner = coords.yz * strides - pads;\\n        int d2 = coords.w;\\n        int d1 = d2;\\n        int q = 0;\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        vec4 result = vec4(0.);\\n\\n        \"+f+\"\\n\\n        setOutput(result);\\n      }\\n    \"}}(),Na=function(){return function(t,e,n,r,o){this.variableNames=[\"Image\",\"Boxes\",\"BoxInd\"],this.outputShape=[];var a=t[0],i=t[1],s=t[2],u=t[3],l=e[0],c=n[0],h=n[1];this.outputShape=[l,c,h,u];var p=\"bilinear\"===r?1:0,f=[i-1+\".0\",s-1+\".0\"],d=f[0],v=f[1],m=c>1?[\"\"+(i-1)/(c-1),\"(y2-y1) * height_ratio\",\"y1*\"+d+\" + float(y)*(height_scale)\"]:[\"0.0\",\"0.0\",\"0.5 * (y1+y2) * \"+d],g=m[0],y=m[1],x=m[2],b=h>1?[\"\"+(s-1)/(h-1),\"(x2-x1) * width_ratio\",\"x1*\"+v+\" + float(x)*(width_scale)\"]:[\"0.0\",\"0.0\",\"0.5 * (x1+x2) * \"+v],w=b[0],C=b[1],E=b[2];this.userCode=\"\\n      const float height_ratio = float(\"+g+\");\\n      const float width_ratio = float(\"+w+\");\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int y = coords[1];\\n        int x = coords[2];\\n        int d = coords[3];\\n\\n        // get box vals\\n        float y1 = getBoxes(b,0);\\n        float x1 = getBoxes(b,1);\\n        float y2 = getBoxes(b,2);\\n        float x2 = getBoxes(b,3);\\n\\n        // get image in batch index\\n        int bInd = round(getBoxInd(b));\\n        if(bInd < 0 || bInd >= \"+a+\") {\\n          return;\\n        }\\n\\n        float height_scale = \"+y+\";\\n        float width_scale = \"+C+\";\\n\\n        float in_y = \"+x+\";\\n        if( in_y < 0.0 || in_y > \"+d+\" ) {\\n          setOutput(float(\"+o+\"));\\n          return;\\n        }\\n        float in_x = \"+E+\";\\n        if( in_x < 0.0 || in_x > \"+v+\" ) {\\n          setOutput(float(\"+o+\"));\\n          return;\\n        }\\n\\n        vec2 sourceFracIndexCR = vec2(in_x,in_y);\\n        if(\"+p+\" == 1) {\\n          // Compute the four integer indices.\\n          ivec2 sourceFloorCR = ivec2(sourceFracIndexCR);\\n          ivec2 sourceCeilCR = ivec2(ceil(sourceFracIndexCR));\\n\\n          float topLeft = getImage(b, sourceFloorCR.y, sourceFloorCR.x, d);\\n          float bottomLeft = getImage(b, sourceCeilCR.y, sourceFloorCR.x, d);\\n          float topRight = getImage(b, sourceFloorCR.y, sourceCeilCR.x, d);\\n          float bottomRight = getImage(b, sourceCeilCR.y, sourceCeilCR.x, d);\\n\\n          vec2 fracCR = sourceFracIndexCR - vec2(sourceFloorCR);\\n\\n          float top = topLeft + (topRight - topLeft) * fracCR.x;\\n          float bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;\\n          float newValue = top + (bottom - top) * fracCR.y;\\n          setOutput(newValue);\\n        } else {\\n          // Compute the coordinators of nearest neighbor point.\\n          ivec2 sourceNearestCR = ivec2(floor(\\n            sourceFracIndexCR + vec2(0.5,0.5)));\\n          float newValue = getImage(b, sourceNearestCR.y, sourceNearestCR.x, d);\\n          setOutput(newValue);\\n        }\\n      }\\n    \"}}(),Sa=function(){return function(t,e,n){this.variableNames=[\"x\"],this.outputShape=t;var r=t.length,o=t[t.length-1],a=n?\"<\":\">\";this.userCode=\"\\n      int getIndex(int i) {\\n        \"+(n?\"return \"+o+\" -i - 1;\":\"return i;\")+\"\\n      }\\n\\n      void main() {\\n        \"+jo(r)+\" coords = getOutputCoords();\\n        int end = \"+Aa(r,\"coords\")+\";\\n        float val = 0.0;\\n        for (int i = \"+o+\" - 1; i >= 0; i -= 1) {\\n          int idx = getIndex(i);\\n          if (idx \"+a+\" end) {\\n            continue;\\n          }\\n          if (idx == end && \"+e+\") {\\n            continue;\\n          }\\n          \"+Aa(r,\"coords\")+\" = idx;\\n          val += getX(\"+function(t,e){if(1===t)return\"\"+e;if(2===t)return e+\".x, \"+e+\".y\";if(3===t)return e+\".x, \"+e+\".y, \"+e+\".z\";if(4===t)return e+\".x, \"+e+\".y, \"+e+\".z, \"+e+\".w\";throw Error(\"Cumulative sum for rank \"+t+\" is not yet supported\")}(r,\"coords\")+\");\\n        }\\n        setOutput(val);\\n      }\\n    \"}}();function Aa(t,e){if(1===t)return\"\"+e;if(2===t)return e+\".y\";if(3===t)return e+\".z\";if(4===t)return e+\".w\";throw Error(\"Cumulative sum for rank \"+t+\" is not yet supported\")}var Ta=function(){return function(t,e){this.variableNames=[\"A\"];var n=Mo();this.outputShape=t,this.userCode=\"\\n      ivec3 outCoordsFromFlatIndex(int index) {\\n        \"+Bo([\"r\",\"c\",\"d\"],t)+\"\\n        return ivec3(r, c, d);\\n      }\\n\\n      void main() {\\n        ivec2 resTexRC = ivec2(resultUV.yx *\\n          vec2(\"+e[0]+\", \"+e[1]+\"));\\n        int index = 4 * (resTexRC.x * \"+e[1]+\" + resTexRC.y);\\n\\n        vec4 result = vec4(0.);\\n\\n        for (int i=0; i<4; i++) {\\n          int flatIndex = index + i;\\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\\n          result[i] = getA(rc.x, rc.y, rc.z);\\n        }\\n\\n        \"+n.output+\" = result;\\n      }\\n    \"}}(),Da=function(){return function(t,e){this.variableNames=[\"A\"],this.usesPackedTextures=!0;var n=Mo();this.outputShape=t,this.userCode=\"\\n      ivec3 outCoordsFromFlatIndex(int index) {\\n        \"+Bo([\"r\",\"c\",\"d\"],t)+\"\\n        return ivec3(r, c, d);\\n      }\\n\\n      void main() {\\n        ivec2 resTexRC = ivec2(resultUV.yx *\\n          vec2(\"+e[0]+\", \"+e[1]+\"));\\n        int index = 4 * (resTexRC.x * \"+e[1]+\" + resTexRC.y);\\n\\n        vec4 result = vec4(0.);\\n\\n        for (int i=0; i<4; i++) {\\n          int flatIndex = index + i;\\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\\n          result[i] = getChannel(getA(rc.x, rc.y, rc.z), vec2(rc.y, rc.z));\\n        }\\n\\n        \"+n.output+\" = result;\\n      }\\n    \"}}(),_a=function(){function t(t,e,n){this.variableNames=[\"x\"],this.outputShape=[],this.outputShape=t,this.blockSize=e,this.dataFormat=n,this.userCode=\"\\n    void main() {\\n      ivec4 coords = getOutputCoords();\\n      int b = coords[0];\\n      int h = \"+this.getHeightCoordString()+\";\\n      int w = \"+this.getWidthCoordString()+\";\\n      int d = \"+this.getDepthCoordString()+\";\\n\\n      int in_h = h / \"+e+\";\\n      int offset_h = imod(h, \"+e+\");\\n      int in_w = w / \"+e+\";\\n      int offset_w = imod(w, \"+e+\");\\n      int offset_d = (offset_h * \"+e+\" + offset_w) *\\n        \"+this.getOutputDepthSize()+\";\\n      int in_d = d + offset_d;\\n\\n      float result = \"+this.getInputSamplingString()+\";\\n      setOutput(result);\\n    }\\n  \"}return t.prototype.getHeightCoordString=function(){return\"NHWC\"===this.dataFormat?\"coords[1]\":\"coords[2]\"},t.prototype.getWidthCoordString=function(){return\"NHWC\"===this.dataFormat?\"coords[2]\":\"coords[3]\"},t.prototype.getDepthCoordString=function(){return\"NHWC\"===this.dataFormat?\"coords[3]\":\"coords[1]\"},t.prototype.getOutputDepthSize=function(){return\"NHWC\"===this.dataFormat?this.outputShape[3]:this.outputShape[1]},t.prototype.getInputSamplingString=function(){return\"NHWC\"===this.dataFormat?\"getX(b, in_h, in_w, in_d)\":\"getX(b, in_d, in_h, in_w)\"},t}(),Oa=function(){return function(t){this.variableNames=[\"X\"],this.outputShape=[t,t],this.userCode=\"\\n      void main() {\\n          ivec2 coords = getOutputCoords();\\n          float val = coords[0] == coords[1] ? getX(coords[0]) : 0.0;\\n          setOutput(val);\\n      }\\n    \"}}(),Fa=function(){return function(t){this.variableNames=[\"A\"];var e=Mo();this.outputShape=t,this.userCode=\"\\n      \"+Lo+\"\\n\\n      void main() {\\n        float x = getAAtOutCoords();\\n        \"+e.output+\" = encode_float(x);\\n      }\\n    \"}}(),Ma=function(){return function(t){this.variableNames=[\"A\"],this.usesPackedTextures=!0;var e=Mo();this.outputShape=t,this.userCode=\"\\n      \"+Lo+\"\\n\\n      void main() {\\n        ivec3 coords = getOutputCoords();\\n        float x = getChannel(getAAtOutCoords(), vec2(coords.y, coords.z));\\n        \"+e.output+\" = encode_float(x);\\n      }\\n    \"}}(),Ba=function(){return function(t,e,n){void 0===n&&(n=!1),this.variableNames=[\"A\"];var r=Mo(),o=e[0],a=e[1];this.outputShape=t;var i=\"result\";n&&(i=\"floor(result * 255. + 0.5)\"),this.userCode=\"\\n      \"+Po(t)+\"\\n\\n      void main() {\\n        ivec3 coords = getOutputCoords();\\n\\n        int flatIndex = getFlatIndex(coords);\\n        int offset = imod(flatIndex, 4);\\n\\n        flatIndex = idiv(flatIndex, 4, 1.);\\n        \\n        int r = flatIndex / \"+a+\";\\n        int c = imod(flatIndex, \"+a+\");\\n        vec2 uv = (vec2(c, r) + halfCR) / vec2(\"+a+\".0, \"+o+\".0);\\n        vec4 values = \"+r.texture2D+\"(A, uv);\\n\\n        float result;\\n\\n        if(offset == 0) {\\n          result = values[0];\\n        } else if(offset == 1) {\\n          result = values[1];\\n        } else if(offset == 2) {\\n          result = values[2];\\n        } else {\\n          result = values[3];\\n        }\\n\\n        \"+r.output+\" = vec4(\"+i+\", 0., 0., 0.);\\n      }\\n    \"}}(),Pa=function(){return function(t,e,n){void 0===n&&(n=!1),this.variableNames=[\"A\"];var r=Mo(),o=e[0],a=e[1];this.outputShape=t;var i=\"\",s=\"result\";n&&(s=\"floor(result * 255. + 0.5)\");for(var u=0;u<=1;u++)for(var l=0;l<=1;l++){var c=2*u+l;i+=\"\\n          localCoords = coords;\\n          if(localCoords[2] + \"+l+\" < \"+t[2]+\") {\\n            localCoords[2] += \"+l+\";\\n            if(localCoords[1] + \"+u+\" < \"+t[1]+\") {\\n              localCoords[1] += \"+u+\";\\n\\n              flatIndex = getFlatIndex(localCoords);\\n              offset = imod(flatIndex, 4);\\n    \\n              flatIndex = idiv(flatIndex, 4, 1.);\\n\\n              r = flatIndex / \"+a+\";\\n              c = imod(flatIndex, \"+a+\");\\n              uv = (vec2(c, r) + halfCR) / vec2(\"+a+\".0, \"+o+\".0);\\n              values = \"+r.texture2D+\"(A, uv);\\n\\n              if(offset == 0) {\\n                result[\"+c+\"] = values[0];\\n              } else if(offset == 1) {\\n                result[\"+c+\"] = values[1];\\n              } else if(offset == 2) {\\n                result[\"+c+\"] = values[2];\\n              } else {\\n                result[\"+c+\"] = values[3];\\n              }\\n            }\\n          }\\n        \"}this.userCode=\"\\n      \"+Po(t)+\"\\n\\n      void main() {\\n        ivec3 coords = getOutputCoords();\\n\\n        vec4 result = vec4(0.);\\n        int flatIndex, r, c, offset;\\n        ivec3 localCoords;\\n        vec2 uv;\\n        vec4 values;\\n        \\n        \"+i+\"\\n\\n        \"+r.output+\" = \"+s+\";\\n      }\\n    \"}}(),La=\"return real * expR - imag * expI;\",Wa=\"return real * expI + imag * expR;\",Ua=function(){return function(t,e,n){this.variableNames=[\"real\",\"imag\"];var r=e[1];this.outputShape=e;var o=n?\"2.0 * \"+Math.PI:\"-2.0 * \"+Math.PI,a=n?r+\".0\":\"1.0\";this.userCode=\"\\n      const float exponentMultiplier = \"+o+\";\\n\\n      float unaryOpComplex(float real, float expR, float imag, float expI) {\\n        \"+t+\"\\n      }\\n\\n      float mulMatDFT(int batch, int index) {\\n        float indexRatio = float(index) / float(\"+r+\");\\n        float exponentMultiplierTimesIndexRatio =\\n            exponentMultiplier * indexRatio;\\n\\n        float result = 0.0;\\n\\n        for (int i = 0; i < \"+r+\"; i++) {\\n          // x = (-2|2 * PI / N) * index * i;\\n          float x = exponentMultiplierTimesIndexRatio * float(i);\\n          float expR = cos(x);\\n          float expI = sin(x);\\n          float real = getReal(batch, i);\\n          float imag = getImag(batch, i);\\n\\n          result +=\\n              unaryOpComplex(real, expR, imag, expI) / \"+a+\";\\n        }\\n\\n        return result;\\n      }\\n\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        setOutput(mulMatDFT(coords[0], coords[1]));\\n      }\\n    \"}}(),Va=function(){function t(t,e){this.outputShape=[],this.variableNames=[\"x\"],this.outputShape=t,this.userCode=\"\\n      uniform float value;\\n      void main() {\\n        // Input can be obtained from uniform value.\\n        setOutput(value);\\n      }\\n    \"}return t.prototype.getCustomSetupFunc=function(t){var e=this;return function(n,r){null==e.valueLoc&&(e.valueLoc=n.getUniformLocationNoThrow(r,\"value\")),n.gl.uniform1f(e.valueLoc,t)}},t}(),za=function(){return function(t){this.variableNames=[\"A\"];var e=Mo(),n=t[0],r=t[1];this.outputShape=t,this.userCode=\"\\n      void main() {\\n        ivec3 coords = getOutputCoords();\\n        int texR = coords[0];\\n        int texC = coords[1];\\n        int depth = coords[2];\\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(\"+r+\".0, \"+n+\".0);\\n\\n        vec4 values = \"+e.texture2D+\"(A, uv);\\n        float value;\\n        if (depth == 0) {\\n          value = values.r;\\n        } else if (depth == 1) {\\n          value = values.g;\\n        } else if (depth == 2) {\\n          value = values.b;\\n        } else if (depth == 3) {\\n          value = values.a;\\n        }\\n\\n        setOutput(floor(value * 255.0 + 0.5));\\n      }\\n    \"}}(),Ga=function(){return function(t){this.variableNames=[\"A\"];var e=Mo(),n=t[0],r=t[1];this.outputShape=t,this.userCode=\"\\n      void main() {\\n        ivec3 coords = getOutputCoords();\\n        int texR = coords[0];\\n        int texC = coords[1];\\n        int depth = coords[2];\\n\\n        vec4 result = vec4(0.);\\n\\n        for(int row=0; row<=1; row++) {\\n          for(int col=0; col<=1; col++) {\\n            texC = coords[1] + row;\\n            depth = coords[2] + col;\\n\\n            vec2 uv = (vec2(texC, texR) + halfCR) / vec2(\"+r+\".0, \"+n+\".0);\\n            vec4 values = \"+e.texture2D+\"(A, uv);\\n            float value;\\n            if (depth == 0) {\\n              value = values.r;\\n            } else if (depth == 1) {\\n              value = values.g;\\n            } else if (depth == 2) {\\n              value = values.b;\\n            } else if (depth == 3) {\\n              value = values.a;\\n            }\\n\\n            result[row * 2 + col] = floor(value * 255.0 + 0.5);\\n          }\\n        }\\n\\n        \"+e.output+\" = result;\\n      }\\n    \"}}(),Ha=function(){return function(t,e,n){this.variableNames=[\"A\",\"indices\"];var r=t.slice();r[n]=e,this.outputShape=r,this.rank=r.length;var o=jo(this.rank),a=function(t,e){var n=t.length;if(n>4)throw Error(\"Gather for rank \"+n+\" is not yet supported\");if(1===n)return\"int(getIndices(resRC))\";for(var r=[\"resRC.x\",\"resRC.y\",\"resRC.z\",\"resRC.w\"],o=[],a=0;a<t.length;a++)a===e?o.push(\"int(getIndices(\"+r[a]+\"))\"):o.push(\"\"+r[a]);return o.join()}(t,n);this.userCode=\"\\n      void main() {\\n        \"+o+\" resRC = getOutputCoords();\\n        setOutput(getA(\"+a+\"));\\n      }\\n    \"}}();var qa=function(){return function(t,e,n){this.sliceDim=t,this.strides=e,this.variableNames=[\"x\",\"indices\"],this.outputShape=n;var r=jo(e.length),o=jo(n.length),a=this.sliceDim>1?\"strides[j]\":\"strides\";this.userCode=\"\\n        \"+r+\" strides = \"+r+\"(\"+this.strides+\");\\n         void main() {\\n          \"+o+\" coords = getOutputCoords();\\n          int flattenIndex = 0;\\n          for (int j = 0; j < \"+this.sliceDim+\"; j++) {\\n            int index = round(getIndices(coords[0], j));\\n            flattenIndex += index * \"+a+\";\\n          }\\n          setOutput(getX(flattenIndex, coords[1]));\\n        }\\n      \"}}();function $a(t,e){var n=Mo();return Kt(t,e,n.version+\"\\n    precision highp float;\\n    \"+n.attribute+\" vec3 clipSpacePos;\\n    \"+n.attribute+\" vec2 uv;\\n    \"+n.varyingVs+\" vec2 resultUV;\\n\\n    void main() {\\n      gl_Position = vec4(clipSpacePos, 1);\\n      resultUV = uv;\\n    }\")}function Ka(t,e){return ee(t,e,new Float32Array([-1,1,0,0,1,-1,-1,0,0,0,1,1,0,1,1,1,-1,0,1,0]))}function ja(t,e){return ne(t,e,new Uint16Array([0,1,2,2,1,3]))}function Xa(t,e,n,r,o,a,i){oe(n,r);var s=re(t,e),u=t.TEXTURE_2D;return Vt(t,e,function(){return t.bindTexture(u,s)}),Vt(t,e,function(){return t.texParameteri(u,t.TEXTURE_WRAP_S,t.CLAMP_TO_EDGE)}),Vt(t,e,function(){return t.texParameteri(u,t.TEXTURE_WRAP_T,t.CLAMP_TO_EDGE)}),Vt(t,e,function(){return t.texParameteri(u,t.TEXTURE_MIN_FILTER,t.NEAREST)}),Vt(t,e,function(){return t.texParameteri(u,t.TEXTURE_MAG_FILTER,t.NEAREST)}),Vt(t,e,function(){return t.texImage2D(u,0,o,n,r,0,a,i,null)}),Vt(t,e,function(){return t.bindTexture(t.TEXTURE_2D,null)}),s}function Ya(t,e,n,r,o){var a=Pt(n,r);return Xa(t,e,a[0],a[1],o.internalFormatFloat,o.textureFormatFloat,t.FLOAT)}function Qa(t,e,n,r,o){var a=Pt(n,r);return Xa(t,e,a[0],a[1],o.internalFormatHalfFloat,o.textureFormatFloat,o.textureTypeHalfFloat)}function Ja(t,e,n,r,o){var a=Pt(n,r);return Xa(t,e,a[0],a[1],t.RGBA,t.RGBA,t.UNSIGNED_BYTE)}function Za(t,e,n,r,o){var a=Wt(n,r);return Xa(t,e,a[0],a[1],o.internalFormatPackedFloat,t.RGBA,t.FLOAT)}function ti(t,e,n,r,o){var a=Wt(n,r);return Xa(t,e,a[0],a[1],o.internalFormatPackedHalfFloat,t.RGBA,o.textureTypeHalfFloat)}function ei(t,e,n,r){return Vt(t,e,function(){return t.bindBuffer(t.ARRAY_BUFFER,r)}),ie(t,e,n,\"clipSpacePos\",r,3,20,0)&&ie(t,e,n,\"uv\",r,2,20,12)}function ni(t,e,n,r,o,a,i){var s,u,l;Vt(t,e,function(){return t.bindTexture(t.TEXTURE_2D,n)}),a instanceof Uint8Array?(s=new Uint8Array(r*o*4),u=t.UNSIGNED_BYTE,l=t.RGBA):(s=new Float32Array(r*o*4),u=t.FLOAT,l=i.internalFormatPackedFloat),s.set(a),Vt(t,e,function(){return t.texImage2D(t.TEXTURE_2D,0,l,r,o,0,t.RGBA,u,s)}),Vt(t,e,function(){return t.bindTexture(t.TEXTURE_2D,null)})}function ri(t,e,n,r){Vt(t,e,function(){return t.bindTexture(t.TEXTURE_2D,n)}),r.data instanceof Uint8Array?Vt(t,e,function(){return t.texImage2D(t.TEXTURE_2D,0,t.RGBA,r.width,r.height,0,t.RGBA,t.UNSIGNED_BYTE,r.data)}):Vt(t,e,function(){return t.texImage2D(t.TEXTURE_2D,0,t.RGBA,t.RGBA,t.UNSIGNED_BYTE,r)}),Vt(t,e,function(){return t.bindTexture(t.TEXTURE_2D,null)})}function oi(t,e,n,r,o){var a=t.createBuffer();Vt(t,e,function(){return t.bindBuffer(t.PIXEL_PACK_BUFFER,a)});var i=16*n*r;return Vt(t,e,function(){return t.bufferData(t.PIXEL_PACK_BUFFER,i,t.STREAM_READ)}),Vt(t,e,function(){return t.readPixels(0,0,r,n,t.RGBA,t.FLOAT,0)}),Vt(t,e,function(){return t.bindBuffer(t.PIXEL_PACK_BUFFER,null)}),a}function ai(t,e,n){var r=t,o=new Float32Array(n);return r.bindBuffer(r.PIXEL_PACK_BUFFER,e),r.getBufferSubData(r.PIXEL_PACK_BUFFER,0,o),r.bindBuffer(r.PIXEL_PACK_BUFFER,null),o}function ii(t,e,n,r,o){var a=Pt(n,r),i=a[0],s=a[1],u=new Uint8Array(n*r*4);return Vt(t,e,function(){return t.readPixels(0,0,i,s,o.downloadTextureFormat,t.UNSIGNED_BYTE,u)}),new Float32Array(u.buffer)}function si(t,e,n,r,o,a,i,s){var u=t,l=new Float32Array(function(t,e){var n=Wt(t,e);return n[0]*n[1]*4}(a,i));return u.bindBuffer(u.PIXEL_PACK_BUFFER,e),u.getBufferSubData(u.PIXEL_PACK_BUFFER,0,l),u.bindBuffer(u.PIXEL_PACK_BUFFER,null),l}function ui(t,e,n,r){var o=new Float32Array(n*r*4);return Vt(t,e,function(){return t.readPixels(0,0,r,n,t.RGBA,t.FLOAT,o)}),o}var li=Object.freeze({createVertexShader:$a,createVertexBuffer:Ka,createIndexBuffer:ja,createFloat32MatrixTexture:Ya,createFloat16MatrixTexture:Qa,createUnsignedBytesMatrixTexture:Ja,createPackedMatrixTexture:Za,createFloat16PackedMatrixTexture:ti,bindVertexProgramAttributeStreams:ei,uploadDenseMatrixToTexture:ni,uploadPixelDataToTexture:ri,createBufferFromOutputTexture:oi,downloadFloat32MatrixFromBuffer:ai,downloadByteEncodedFloatMatrixFromOutputTexture:ii,downloadPackedMatrixFromBuffer:si,downloadMatrixFromPackedOutputTexture:ui}),ci=function(){function t(t){this.outputTexture=null,this.program=null,this.disposed=!1,this.vertexAttrsAreBound=!1,this.itemsToPoll=[];var e=i.getNumber(\"WEBGL_VERSION\");if(null!=t?(this.gl=t,Ft(e,t)):this.gl=Mt(e),1===i.getNumber(\"WEBGL_VERSION\"))this.textureFloatExtension=$t(this.gl,this.debug,\"OES_texture_float\"),this.colorBufferFloatExtension=this.gl.getExtension(\"WEBGL_color_buffer_float\"),this.textureHalfFloatExtension=$t(this.gl,this.debug,\"OES_texture_half_float\"),this.colorBufferHalfFloatExtension=this.gl.getExtension(\"EXT_color_buffer_half_float\");else{if(ke(this.gl,\"EXT_color_buffer_float\"))this.colorBufferFloatExtension=this.gl.getExtension(\"EXT_color_buffer_float\");else{if(!ke(this.gl,\"EXT_color_buffer_half_float\"))throw new Error(\"GL context does not support color renderable floats\");this.colorBufferHalfFloatExtension=this.gl.getExtension(\"EXT_color_buffer_half_float\")}}this.vertexBuffer=Ka(this.gl,this.debug),this.indexBuffer=ja(this.gl,this.debug),this.framebuffer=ae(this.gl,this.debug),this.textureConfig=Ut(this.gl,this.textureHalfFloatExtension)}return Object.defineProperty(t.prototype,\"debug\",{get:function(){return i.getBool(\"DEBUG\")},enumerable:!0,configurable:!0}),t.prototype.dispose=function(){var t=this;if(!this.disposed){null!=this.program&&console.warn(\"Disposing a GPGPUContext that still has a bound WebGLProgram. This is probably a resource leak, delete the program with GPGPUContext.deleteProgram before disposing.\"),null!=this.outputTexture&&console.warn(\"Disposing a GPGPUContext that still has a bound output matrix texture.  This is probably a resource leak, delete the output matrix texture with GPGPUContext.deleteMatrixTexture before disposing.\");var e=this.gl;Vt(e,this.debug,function(){return e.finish()}),Vt(e,this.debug,function(){return e.bindFramebuffer(e.FRAMEBUFFER,null)}),Vt(e,this.debug,function(){return e.deleteFramebuffer(t.framebuffer)}),Vt(e,this.debug,function(){return e.bindBuffer(e.ARRAY_BUFFER,null)}),Vt(e,this.debug,function(){return e.bindBuffer(e.ELEMENT_ARRAY_BUFFER,null)}),Vt(e,this.debug,function(){return e.deleteBuffer(t.indexBuffer)}),this.disposed=!0}},t.prototype.createFloat32MatrixTexture=function(t,e){return this.throwIfDisposed(),Ya(this.gl,this.debug,t,e,this.textureConfig)},t.prototype.createFloat16MatrixTexture=function(t,e){return this.throwIfDisposed(),Qa(this.gl,this.debug,t,e,this.textureConfig)},t.prototype.createUnsignedBytesMatrixTexture=function(t,e){return this.throwIfDisposed(),Ja(this.gl,this.debug,t,e,this.textureConfig)},t.prototype.uploadPixelDataToTexture=function(t,e){this.throwIfDisposed(),ri(this.gl,this.debug,t,e)},t.prototype.uploadDenseMatrixToTexture=function(t,e,n,r){this.throwIfDisposed(),ni(this.gl,this.debug,t,e,n,r,this.textureConfig)},t.prototype.createFloat16PackedMatrixTexture=function(t,e){return this.throwIfDisposed(),ti(this.gl,this.debug,t,e,this.textureConfig)},t.prototype.createPackedMatrixTexture=function(t,e){return this.throwIfDisposed(),Za(this.gl,this.debug,t,e,this.textureConfig)},t.prototype.deleteMatrixTexture=function(t){var e=this;this.throwIfDisposed(),this.outputTexture===t&&(pe(this.gl,this.debug,this.framebuffer),this.outputTexture=null),Vt(this.gl,this.debug,function(){return e.gl.deleteTexture(t)})},t.prototype.downloadByteEncodedFloatMatrixFromOutputTexture=function(t,e,n){var r=this;return this.downloadMatrixDriver(t,function(){return ii(r.gl,r.debug,e,n,r.textureConfig)})},t.prototype.downloadPackedMatrixFromBuffer=function(t,e,n,r,o,a){return si(this.gl,t,0,0,0,o,a,this.textureConfig)},t.prototype.downloadFloat32MatrixFromBuffer=function(t,e){return ai(this.gl,t,e)},t.prototype.createBufferFromTexture=function(t,e,n){this.bindTextureToFrameBuffer(t);var r=oi(this.gl,this.debug,e,n,this.textureConfig);return this.unbindTextureToFrameBuffer(),r},t.prototype.createAndWaitForFence=function(){var t=this.createFence(this.gl);return this.pollFence(t)},t.prototype.createFence=function(t){var e,n,r=this;if(i.getBool(\"WEBGL_FENCE_API_ENABLED\")){var o=t,a=o.fenceSync(o.SYNC_GPU_COMMANDS_COMPLETE,0);t.flush(),n=function(){var t=o.clientWaitSync(a,0,0);return t===o.ALREADY_SIGNALED||t===o.CONDITION_SATISFIED},e=a}else i.getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\")>0?(e=this.beginQuery(),this.endQuery(),n=function(){return r.isQueryAvailable(e,i.getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\"))}):n=function(){return!0};return{query:e,isFencePassed:n}},t.prototype.downloadMatrixFromPackedTexture=function(t,e,n){var r=this;return this.downloadMatrixDriver(t,function(){return ui(r.gl,r.debug,e,n)})},t.prototype.createProgram=function(t){this.throwIfDisposed();var e=this.gl,n=jt(e,this.debug,t),r=$a(e,this.debug),o=Jt(e,this.debug);return Vt(e,this.debug,function(){return e.attachShader(o,r)}),Vt(e,this.debug,function(){return e.attachShader(o,n)}),Zt(e,this.debug,o),this.debug&&te(e,this.debug,o),this.vertexAttrsAreBound||(this.setProgram(o),this.vertexAttrsAreBound=ei(e,this.debug,this.program,this.vertexBuffer)),o},t.prototype.deleteProgram=function(t){var e=this;this.throwIfDisposed(),t===this.program&&(this.program=null),null!=t&&Vt(this.gl,this.debug,function(){return e.gl.deleteProgram(t)})},t.prototype.setProgram=function(t){var e=this;this.throwIfDisposed(),this.program=t,null!=this.program&&this.debug&&te(this.gl,this.debug,this.program),Vt(this.gl,this.debug,function(){return e.gl.useProgram(t)})},t.prototype.getUniformLocation=function(t,e,n){return void 0===n&&(n=!0),this.throwIfDisposed(),n?ue(this.gl,this.debug,t,e):le(this.gl,t,e)},t.prototype.getAttributeLocation=function(t,e){var n=this;return this.throwIfDisposed(),Vt(this.gl,this.debug,function(){return n.gl.getAttribLocation(t,e)})},t.prototype.getUniformLocationNoThrow=function(t,e){return this.throwIfDisposed(),this.gl.getUniformLocation(t,e)},t.prototype.setInputMatrixTexture=function(t,e,n){this.throwIfDisposed(),this.throwIfNoProgram(),ce(this.gl,this.debug,this.program,t,e,n)},t.prototype.setOutputMatrixTexture=function(t,e,n){this.setOutputMatrixTextureDriver(t,n,e)},t.prototype.setOutputPackedMatrixTexture=function(t,e,n){this.throwIfDisposed();var r=Wt(e,n),o=r[0],a=r[1];this.setOutputMatrixTextureDriver(t,o,a)},t.prototype.setOutputMatrixWriteRegion=function(t,e,n,r){this.setOutputMatrixWriteRegionDriver(n,t,r,e)},t.prototype.setOutputPackedMatrixWriteRegion=function(t,e,n,r){throw new Error(\"setOutputPackedMatrixWriteRegion not implemented.\")},t.prototype.debugValidate=function(){null!=this.program&&te(this.gl,this.debug,this.program),fe(this.gl)},t.prototype.executeProgram=function(){this.throwIfDisposed(),this.throwIfNoProgram();var t=this.gl;this.debug&&this.debugValidate(),Vt(t,this.debug,function(){return t.drawElements(t.TRIANGLES,6,t.UNSIGNED_SHORT,0)})},t.prototype.blockUntilAllProgramsCompleted=function(){var t=this;this.throwIfDisposed(),Vt(this.gl,this.debug,function(){return t.gl.finish()})},t.prototype.getQueryTimerExtension=function(){return null==this.disjointQueryTimerExtension&&(this.disjointQueryTimerExtension=$t(this.gl,this.debug,2===i.getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\")?\"EXT_disjoint_timer_query_webgl2\":\"EXT_disjoint_timer_query\")),this.disjointQueryTimerExtension},t.prototype.getQueryTimerExtensionWebGL2=function(){return this.getQueryTimerExtension()},t.prototype.getQueryTimerExtensionWebGL1=function(){return this.getQueryTimerExtension()},t.prototype.beginQuery=function(){if(2===i.getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\")){var t=this.gl,e=this.getQueryTimerExtensionWebGL2(),n=t.createQuery();return t.beginQuery(e.TIME_ELAPSED_EXT,n),n}var r=this.getQueryTimerExtensionWebGL1(),o=r.createQueryEXT();return r.beginQueryEXT(r.TIME_ELAPSED_EXT,o),o},t.prototype.endQuery=function(){if(2!==i.getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\")){var t=this.getQueryTimerExtensionWebGL1();t.endQueryEXT(t.TIME_ELAPSED_EXT)}else{var e=this.gl,n=this.getQueryTimerExtensionWebGL2();e.endQuery(n.TIME_ELAPSED_EXT)}},t.prototype.waitForQueryAndGetTime=function(t){return n(this,void 0,void 0,function(){var e=this;return r(this,function(n){switch(n.label){case 0:return[4,E(function(){return e.disposed||e.isQueryAvailable(t,i.getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\"))})];case 1:return n.sent(),[2,this.getQueryTime(t,i.getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\"))]}})})},t.prototype.getQueryTime=function(t,e){if(0===e)return null;if(2===e){var n=this.gl;return n.getQueryParameter(t,n.QUERY_RESULT)/1e6}var r=this.getQueryTimerExtensionWebGL1();return r.getQueryObjectEXT(t,r.QUERY_RESULT_EXT)/1e6},t.prototype.isQueryAvailable=function(t,e){if(0===e)return!0;if(2===e){var n=this.gl,r=this.getQueryTimerExtensionWebGL2(),o=n.getQueryParameter(t,n.QUERY_RESULT_AVAILABLE);return null==this.disjoint&&(this.disjoint=this.gl.getParameter(r.GPU_DISJOINT_EXT)),o&&!this.disjoint}o=(r=this.getQueryTimerExtensionWebGL1()).getQueryObjectEXT(t,r.QUERY_RESULT_AVAILABLE_EXT);return null==this.disjoint&&(this.disjoint=this.gl.getParameter(r.GPU_DISJOINT_EXT)),o&&!this.disjoint},t.prototype.pollFence=function(t){var e=this;return new Promise(function(n){e.addItemToPoll(function(){return t.isFencePassed()},function(){return n()})})},t.prototype.pollItems=function(){for(var t=function(t){for(var e=0;e<t.length;++e){var n=t[e]();if(!n)break}return e-1}(this.itemsToPoll.map(function(t){return t.isDoneFn})),e=0;e<=t;++e){(0,this.itemsToPoll[e].resolveFn)()}this.itemsToPoll=this.itemsToPoll.slice(t+1)},t.prototype.addItemToPoll=function(t,e){var n=this;this.itemsToPoll.push({isDoneFn:t,resolveFn:e}),this.itemsToPoll.length>1||E(function(){return n.pollItems(),0===n.itemsToPoll.length})},t.prototype.bindTextureToFrameBuffer=function(t){this.throwIfDisposed(),he(this.gl,this.debug,t,this.framebuffer),this.debug&&fe(this.gl)},t.prototype.unbindTextureToFrameBuffer=function(){null!=this.outputTexture?(he(this.gl,this.debug,this.outputTexture,this.framebuffer),this.debug&&fe(this.gl)):pe(this.gl,this.debug,this.framebuffer)},t.prototype.downloadMatrixDriver=function(t,e){this.bindTextureToFrameBuffer(t);var n=e();return this.unbindTextureToFrameBuffer(),n},t.prototype.setOutputMatrixTextureDriver=function(t,e,n){this.throwIfDisposed();var r=this.gl;he(r,this.debug,t,this.framebuffer),this.debug&&fe(r),this.outputTexture=t,Vt(r,this.debug,function(){return r.viewport(0,0,e,n)}),Vt(r,this.debug,function(){return r.scissor(0,0,e,n)})},t.prototype.setOutputMatrixWriteRegionDriver=function(t,e,n,r){var o=this;this.throwIfDisposed(),Vt(this.gl,this.debug,function(){return o.gl.scissor(t,e,n,r)})},t.prototype.throwIfDisposed=function(){if(this.disposed)throw new Error(\"Attempted to use disposed GPGPUContext.\")},t.prototype.throwIfNoProgram=function(){if(null==this.program)throw new Error(\"No GPU program is currently set.\")},t}();function hi(t,e){if(t.length!==e.length)throw Error(\"Binary was compiled with \"+t.length+\" inputs, but was executed with \"+e.length+\" inputs\");t.forEach(function(t,n){var r=t.logicalShape,o=e[n],a=o.shape;if(!y(r,a))throw Error(\"Binary was compiled with different shapes than the current args. Shapes \"+r+\" and \"+a+\" must match\");if(!t.isUniform||!o.isUniform){var i=t.texShape,s=o.isUniform?null:o.texData.texShape;if(!y(i,s))throw Error(\"Binary was compiled with different texture shapes than the current args. Shape \"+i+\" and \"+s+\" must match\")}})}var pi=function(){return function(t,e,n){this.variableNames=[\"A\"],this.usesPackedTextures=!0,this.outputShape=t;for(var r=n.filterWidth,o=n.inChannels,a=n.strideWidth,i=n.strideHeight,s=n.padInfo,u=n.outWidth,l=n.dilationWidth,c=n.dilationHeight,h=n.dataFormat,p=s.left,f=s.top,d=o*r,v=Mo(),m=\"channelsLast\"===h,g=m?0:1,y=m?1:2,x=\"\",b=0;b<=1;b++)for(var w=0;w<=1;w++)x+=\"\\n          blockIndex = rc.y + \"+w+\";\\n          pos = rc.x + \"+b+\";\\n\\n          if(blockIndex < \"+t[1]+\" && pos < \"+t[0]+\") {\\n            offsetY = int(blockIndex / (\"+u+\")) * \"+i+\" - \"+f+\";\\n            d0 = offsetY + \"+c+\" * (pos / \"+d+\");\\n\\n            if(d0 < \"+e[g]+\" && d0 >= 0) {\\n\\n              offsetX = int(mod(float(blockIndex), \"+u+\".) * \"+a+\". - \"+p+\".);\\n              d1 = offsetX + \"+l+\" * (int(mod(float(pos), \"+d+\".) / \"+o+\".));\\n\\n              if(d1 < \"+e[y]+\" && d1 >= 0) {\\n\\n                ch = int(mod(float(pos), \"+o+\".));\\n\\n                if (\"+m+\") {\\n                  innerDims = vec2(d1, ch);\\n                  result[\"+(2*b+w)+\"] = getChannel(\\n                    getA(d0, int(innerDims.x),\\n                    int(innerDims.y)), innerDims);\\n                } else {\\n                  innerDims = vec2(d0, d1);\\n                  result[\"+(2*b+w)+\"] = getChannel(\\n                    getA(ch, int(innerDims.x),\\n                    int(innerDims.y)), innerDims);\\n                }\\n              }\\n            }\\n          }\\n        \";this.userCode=\"\\n      void main() {\\n        ivec2 rc = getOutputCoords();\\n\\n        vec4 result = vec4(0);\\n\\n        int blockIndex, pos, offsetY, d0, offsetX, d1, ch;\\n        vec2 innerDims;\\n\\n        \"+x+\"\\n\\n        \"+v.output+\" = result;\\n      }\\n    \"}}(),fi=function(){return function(t,e,n,r,o){this.variableNames=[\"x\"],this.outputShape=[];var a,i=e,s=t[3]-1;this.outputShape=t;var u=\"float(\"+n+\") + float(\"+r+\") * sum\";a=.5===o?\"inversesqrt(\"+u+\")\":1===o?\"1.0/(\"+u+\")\":\"exp(log(\"+u+\") * float(-\"+o+\"));\",this.userCode=\"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int r = coords[1];\\n        int c = coords[2];\\n        int d = coords[3];\\n        float x = getX(b, r, c, d);\\n        float sum = 0.0;\\n        for (int j = -\"+i+\"; j <= \"+i+\"; j++) {\\n          int idx = d + j;\\n          if (idx >= 0 && idx <=  \"+s+\") {\\n            float z = getX(b, r, c, idx);\\n            sum += z * z;\\n          }\\n        }\\n        float val = x * \"+a+\";\\n        setOutput(val);\\n      }\\n    \"}}(),di=function(){return function(t,e,n,r,o){this.variableNames=[\"inputImage\",\"outputImage\",\"dy\"],this.outputShape=[],this.outputShape=t,this.depth=t[3],this.depthRadius=e,this.bias=n,this.alpha=r,this.beta=o,this.userCode=\"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int r = coords[1];\\n        int c = coords[2];\\n\\n        float result = 0.0;\\n        for (int d = 0; d < \"+this.depth+\"; ++d) {\\n          int depthBegin = int(max(0.0, float(d - \"+e+\")));\\n          int depthEnd = int(min(float(\"+this.depth+\"),\\n              float(d + \"+e+\" + 1)));\\n\\n          const int MIN_DEPTH_BEGIN = 0;\\n          const int MAX_DEPTH_END = \"+this.depth+\";\\n\\n          float norm = 0.0;\\n          for (int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k) {\\n            if (k < depthBegin){\\n              continue;\\n            }\\n            else if (k >= depthBegin && k < depthEnd) {\\n              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);\\n            }\\n            else {\\n              break;\\n            }\\n          }\\n\\n          norm = float(\"+r+\") * norm + float(\"+n+\");\\n\\n          for(int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k){\\n            if (k < depthBegin){\\n              continue;\\n            }\\n            else if (k >= depthBegin && k < depthEnd){\\n              float dyi = -2.0 * float(\"+r+\")\\n                * float(\"+o+\")\\n                * getInputImage(b ,r ,c, k) * getOutputImage(b, r, c, d)\\n                / norm;\\n              if (k == d) {\\n                dyi += pow(norm, -1.0 * \"+o+\");\\n              }\\n              if (k == coords[3]) {\\n                dyi *= getDy(b, r, c, d);\\n                result += dyi;\\n              }\\n            }\\n            else {\\n              break;\\n            }\\n          }\\n      }\\n      setOutput(result);\\n      }\\n    \"}}(),vi=function(){return function(t,e,n,r,o){this.variableNames=[\"x\"],this.outputShape=[],this.usesPackedTextures=!0;var a,i=e,s=t[3]-1;this.outputShape=t;var u=\"float(\"+n+\") + float(\"+r+\") * sum\";a=.5===o?\"inversesqrt(\"+u+\")\":1===o?\"1.0/(\"+u+\")\":\"exp(log(\"+u+\") * float(-\"+o+\"));\",this.userCode=\"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords.x;\\n        int r = coords.y;\\n        int c = coords.z;\\n        int d = coords.w;\\n\\n        bool hasNextCol = d < \"+this.outputShape[3]+\";\\n        bool hasNextRow = c < \"+this.outputShape[2]+\";\\n\\n        vec4 sum = vec4(0.);\\n        vec4 xFragAtOutputCoords = getX(b, r, c, d);\\n\\n        vec4 xAtOutputCoords = vec4(\\n          getChannel(xFragAtOutputCoords, vec2(c, d)),\\n          hasNextCol ?\\n            getChannel(xFragAtOutputCoords, vec2(c, d + 1)) : 0.0,\\n          hasNextRow ?\\n            getChannel(xFragAtOutputCoords , vec2(c + 1, d)) : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getChannel(xFragAtOutputCoords, vec2(c + 1, d + 1)) : 0.0\\n        );\\n\\n        int firstChannel = d - \"+i+\";\\n        vec2 cache = vec2(0.);\\n        if(firstChannel >= 0){\\n          vec4 firstChannelFrag = getX(b, r, c, firstChannel);\\n          cache.x = getChannel(firstChannelFrag, vec2(c, firstChannel));\\n            if(hasNextRow){\\n              cache.y = getChannel(firstChannelFrag, vec2(c + 1, firstChannel));\\n            }\\n        }\\n\\n        ivec2 depth = ivec2(d, d + 1);\\n        for (int j = - \"+i+\"; j <= \"+i+\"; j++) {\\n          ivec2 idx = depth + j;\\n          bvec2 aboveLowerBound = greaterThanEqual(idx, ivec2(0));\\n          bvec2 belowUpperBound = lessThanEqual(idx, ivec2(\"+s+\"));\\n\\n          bool depthInRange = aboveLowerBound.x && belowUpperBound.x;\\n          bool depthPlusOneInRange = aboveLowerBound.y && belowUpperBound.y;\\n\\n          if(depthInRange || depthPlusOneInRange){\\n            vec4 z = vec4(0.);\\n            vec4 xFragAtCurrentDepth;\\n            z.xz = cache.xy;\\n            if(depthPlusOneInRange && hasNextCol){\\n              xFragAtCurrentDepth = idx.y != d ?\\n                getX(b, r, c, idx.y) : xFragAtOutputCoords;\\n              z.y = getChannel(xFragAtCurrentDepth, vec2(c, idx.y));\\n              if(hasNextRow){\\n                z.w = getChannel(xFragAtCurrentDepth, vec2(c + 1, idx.y));\\n              }\\n            }\\n            cache.xy = z.yw;\\n            sum += z * z;\\n          }\\n        }\\n        vec4 result = xAtOutputCoords * \"+a+\";\\n        setOutput(result);\\n      }\\n    \"}}(),mi=function(){return function(t){this.variableNames=[\"dy\",\"maxPos\"],this.outputShape=t.inShape;var e=t.strideHeight,n=t.strideWidth,r=t.dilationHeight,o=t.effectiveFilterHeight,a=t.effectiveFilterWidth,i=o-1-t.padInfo.top,s=a-1-t.padInfo.left,u=o*a-1;this.userCode=\"\\n      const ivec2 pads = ivec2(\"+i+\", \"+s+\");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n\\n        ivec2 dyRCCorner = coords.yz - pads;\\n        int dyRCorner = dyRCCorner.x;\\n        int dyCCorner = dyRCCorner.y;\\n\\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        for (int wR = 0; wR < \"+o+\";\\n          wR += \"+r+\") {\\n          float dyR = float(dyRCorner + wR) / \"+e+\".0;\\n\\n          if (dyR < 0.0 || dyR >= \"+t.outHeight+\".0 || fract(dyR) > 0.0) {\\n            continue;\\n          }\\n          int idyR = int(dyR);\\n\\n          for (int wC = 0; wC < \"+a+\"; wC++) {\\n            float dyC = float(dyCCorner + wC) / \"+n+\".0;\\n\\n            if (dyC < 0.0 || dyC >= \"+t.outWidth+\".0 ||\\n                fract(dyC) > 0.0) {\\n              continue;\\n            }\\n            int idyC = int(dyC);\\n\\n            float dyValue = getDy(b, idyR, idyC, d);\\n            int maxPosValue = \"+u+\" - int(getMaxPos(b, idyR, idyC, d));\\n\\n            // Get the current value, check it against the value from the\\n            // position matrix.\\n            int curPosValue = wR * \"+a+\" + wC;\\n            float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\\n\\n            dotProd += dyValue * mask;\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \"}}(),gi=function(){return function(t){this.variableNames=[\"dy\",\"maxPos\"],this.outputShape=t.inShape;var e=t.strideDepth,n=t.strideHeight,r=t.strideWidth,o=t.dilationDepth,a=t.dilationHeight,i=t.dilationWidth,s=t.effectiveFilterDepth,u=t.effectiveFilterHeight,l=t.effectiveFilterWidth,c=s-1-t.padInfo.front,h=u-1-t.padInfo.top,p=l-1-t.padInfo.left,f=s*u*l-1;this.userCode=\"\\n      const ivec3 pads = ivec3(\"+c+\", \"+h+\", \"+p+\");\\n\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int ch = coords.u;\\n\\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\\n        int dyDCorner = dyCorner.x;\\n        int dyRCorner = dyCorner.y;\\n        int dyCCorner = dyCorner.z;\\n\\n        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get\\n        // dx(xD, xR, xC, ch).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n\\n        for (int wD = 0; wD < \"+s+\";\\n           wD += \"+o+\") {\\n          float dyD = float(dyDCorner + wD) / \"+e+\".0;\\n\\n          if (dyD < 0.0 || dyD >= \"+t.outDepth+\".0 || fract(dyD) > 0.0) {\\n            continue;\\n          }\\n          int idyD = int(dyD);\\n\\n          for (int wR = 0; wR < \"+u+\";\\n              wR += \"+a+\") {\\n            float dyR = float(dyRCorner + wR) / \"+n+\".0;\\n\\n            if (dyR < 0.0 || dyR >= \"+t.outHeight+\".0 ||\\n                fract(dyR) > 0.0) {\\n              continue;\\n            }\\n            int idyR = int(dyR);\\n\\n            for (int wC = 0; wC < \"+l+\";\\n                wC += \"+i+\") {\\n              float dyC = float(dyCCorner + wC) / \"+r+\".0;\\n\\n              if (dyC < 0.0 || dyC >= \"+t.outWidth+\".0 ||\\n                  fract(dyC) > 0.0) {\\n                continue;\\n              }\\n              int idyC = int(dyC);\\n\\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\\n              int maxPosValue = \"+f+\" -\\n                  int(getMaxPos(batch, idyD, idyR, idyC, ch));\\n\\n              // Get the current value, check it against the value from the\\n              // position matrix.\\n              int curPosValue =\\n                  wD * \"+u+\" * \"+l+\" +\\n                  wR * \"+l+\" + wC;\\n              float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\\n\\n              dotProd += dyValue * mask;\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \"}}(),yi=function(){return function(t,e,n,r,o,a,i){void 0===n&&(n=!1),void 0===r&&(r=!1),void 0===o&&(o=!1),void 0===a&&(a=null),void 0===i&&(i=!1),this.variableNames=[\"matrixA\",\"matrixB\"],this.usesPackedTextures=!0,this.outputShape=e;var s=n?t[1]:t[2],u=Math.ceil(s/2),l=n?\"i * 2, rc.y\":\"rc.y, i * 2\",c=r?\"rc.z, i * 2\":\"i * 2, rc.z\",h=n?[\"a.xxyy\",\"a.zzww\"]:[\"a.xxzz\",\"a.yyww\"],p=r?[\"b.xzxz\",\"b.ywyw\"]:[\"b.xyxy\",\"b.zwzw\"],f=\"\",d=\"\";a&&(f=i?\"vec4 activation(vec4 a) {\\n          vec4 b = getPreluActivationWeightsAtOutCoords();\\n          \"+a+\"\\n        }\":\"vec4 activation(vec4 x) {\\n          \"+a+\"\\n        }\",d=\"result = activation(result);\");var v=o?\"result += getBiasAtOutCoords();\":\"\";o&&this.variableNames.push(\"bias\"),i&&this.variableNames.push(\"preluActivationWeights\"),this.userCode=\"\\n      \"+f+\"\\n\\n      const float sharedDimension = \"+u+\".0;\\n\\n      vec4 dot2x2ARowBCol(ivec3 rc) {\\n        vec4 result = vec4(0);\\n        for (int i = 0; i < \"+u+\"; i++) {\\n          vec4 a = getMatrixA(rc.x, \"+l+\");\\n          vec4 b = getMatrixB(rc.x, \"+c+\");\\n\\n          // These swizzled products need to be separately added.\\n          // See: https://github.com/tensorflow/tfjs/issues/1735\\n          result += (\"+h[0]+\" * \"+p[0]+\");\\n          result += (\"+h[1]+\" * \"+p[1]+\");\\n        }\\n        return result;\\n      }\\n\\n      void main() {\\n        ivec3 rc = getOutputCoords();\\n        vec4 result = dot2x2ARowBCol(rc);\\n\\n        \"+v+\"\\n\\n        \"+d+\"\\n\\n        setOutput(result);\\n      }\\n    \"}}(),xi=function(){function t(t,e,n){this.variableNames=[\"probs\"],this.outputShape=[t,n],this.userCode=\"\\n      uniform float seed;\\n\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int batch = coords[0];\\n\\n        float r = random(seed);\\n        float cdf = 0.0;\\n\\n        for (int i = 0; i < \"+(e-1)+\"; i++) {\\n          cdf += getProbs(batch, i);\\n\\n          if (r < cdf) {\\n            setOutput(float(i));\\n            return;\\n          }\\n        }\\n\\n        // If no other event happened, last event happened.\\n        setOutput(float(\"+(e-1)+\"));\\n      }\\n    \"}return t.prototype.getCustomSetupFunc=function(t){var e=this;return function(n,r){null==e.seedLoc&&(e.seedLoc=n.getUniformLocation(r,\"seed\")),n.gl.uniform1f(e.seedLoc,t)}},t}(),bi=function(){return function(t,e,n,r){this.variableNames=[\"indices\"],this.outputShape=[t,e],this.userCode=\"\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int index = round(getIndices(coords.x));\\n        setOutput(mix(float(\"+r+\"), float(\"+n+\"),\\n                      float(index == coords.y)));\\n      }\\n    \"}}(),wi=function(){return function(t){this.variableNames=[\"A\"],this.outputShape=t;var e=t.length;if(0===e)this.userCode=\"\\n        void main() {\\n          setOutput(vec4(getA(), 0., 0., 0.));\\n        }\\n      \";else{var n=Fo(\"rc\",e),r=jo(e),o=function(t,e,n){if(1===t)return\"rc > \"+e[0];for(var r=\"\",o=t-2;o<t;o++)r+=n[o]+\" >= \"+e[o],o<t-1&&(r+=\"||\");return r}(e,t,n),a=function(t,e,n,r){if(1===t)return\"\";var o=r.slice(-2);return\"\\n    int r = \"+o[0]+\";\\n    int c = \"+o[1]+\";\\n    int rp1 = r + 1;\\n    int cp1 = c + 1;\\n\\n    bool cEdge = cp1 >= \"+e+\";\\n    bool rEdge = rp1 >= \"+n+\";\\n  \"}(e,t[t.length-1],t[t.length-2],n),i=function(t,e){var n=t.length,r=function(t,e){for(var n=[],r=0;r<=1;r++)for(var o=0;o<=1;o++){for(var a=(0===r?\"r\":\"rp1\")+\", \"+(0===o?\"c\":\"cp1\"),i=2;i<t;i++)a=e[e.length-1-i]+\",\"+a;n.push(a)}return n}(n,e);return 1===n?\"getA(rc),\\n            rc + 1 >= \"+t[0]+\" ? 0. : getA(rc + 1),\\n            0, 0\":\"getA(\"+r[0]+\"),\\n          cEdge ? 0. : getA(\"+r[1]+\"),\\n          rEdge ? 0. : getA(\"+r[2]+\"),\\n          rEdge || cEdge ? 0. : getA(\"+r[3]+\")\"}(t,n);this.userCode=\"\\n        void main() {\\n          \"+r+\" rc = getOutputCoords();\\n\\n          if(\"+o+\") {\\n            setOutput(vec4(0));\\n          } else {\\n            \"+a+\"\\n\\n            setOutput(vec4(\"+i+\"));\\n          }\\n        }\\n      \"}}}();var Ci=function(){return function(t,e,n){this.variableNames=[\"x\"],this.outputShape=e.map(function(e,n){return e[0]+t[n]+e[1]});var r=t.length,o=jo(r),a=e.map(function(t){return t[0]}).join(\",\"),i=e.map(function(e,n){return e[0]+t[n]}).join(\",\"),s=[\"coords[0]\",\"coords[1]\",\"coords[2]\",\"coords[3]\"].slice(0,r);this.userCode=1!==r?\"\\n      \"+o+\" start = \"+o+\"(\"+a+\");\\n      \"+o+\" end = \"+o+\"(\"+i+\");\\n\\n      void main() {\\n        \"+o+\" outC = getOutputCoords();\\n        if (any(lessThan(outC, start)) || any(greaterThanEqual(outC, end))) {\\n          setOutput(float(\"+n+\"));\\n        } else {\\n          \"+o+\" coords = outC - start;\\n          setOutput(getX(\"+s+\"));\\n        }\\n      }\\n    \":\"\\n        int start = \"+a+\";\\n        int end = \"+i+\";\\n\\n        void main() {\\n          int outC = getOutputCoords();\\n          if (outC < start || outC >= end) {\\n            setOutput(float(\"+n+\"));\\n          } else {\\n            setOutput(getX(outC - start));\\n          }\\n        }\\n      \"}}(),Ei=function(){return function(t,e,n){this.variableNames=[\"x\"],this.usesPackedTextures=!0,this.outputShape=e.map(function(e,n){return e[0]+t[n]+e[1]});for(var r=t.length,o=jo(r),a=e.map(function(t){return t[0]}).join(\",\"),i=e.map(function(e,n){return e[0]+t[n]}).join(\",\"),s=Fo(\"rc\",r),u=Fo(\"source\",r),l=s[r-1]+\" < \"+this.outputShape[r-1],c=1===r?\"source\":\"vec2(\"+u.slice(-2).join()+\")\",h=[o+\" rc = outputLoc;\",s[r-1]+\" += 1;\\n       if(\"+l+\") {\\n      \",1===r?\"\":\"}\\n       rc = outputLoc;\\n       \"+s[r-2]+\" += 1;\\n       if(\"+s[r-2]+\" < \"+this.outputShape[r-2]+\") {\",1===r?\"\":\"  \"+s[r-1]+\" += 1;\\n         if(\"+l+\") {\"],p=1===r?\"rc < start || rc >= end\":\"any(lessThan(rc, start)) || any(greaterThanEqual(rc, end))\",f=\"\",d=0,v=1===r?2:4;d<v;d++)f+=\"\\n        \"+h[d]+\"\\n        if (\"+p+\") {\\n          result[\"+d+\"] = float(\"+n+\");\\n        } else {\\n          \"+o+\" source = rc - start;\\n          result[\"+d+\"] = getChannel(getX(\"+u.join()+\"), \"+c+\");\\n        }\\n      \";f+=1===r?\"} \":\"}}\",this.userCode=\"\\n      const \"+o+\" start = \"+o+\"(\"+a+\");\\n      const \"+o+\" end = \"+o+\"(\"+i+\");\\n\\n      void main() {\\n        \"+o+\" outputLoc = getOutputCoords();\\n        vec4 result = vec4(0.);\\n        \"+f+\"\\n        setOutput(result);\\n      }\\n    \"}}(),Ri=function(){return function(t,e,n){if(this.variableNames=[\"x\"],\"avg\"===e&&n)throw new Error(\"Cannot compute positions for average pool.\");var r=t.filterWidth,o=t.strideHeight,a=t.strideWidth,i=t.dilationHeight,s=t.dilationWidth,u=t.effectiveFilterHeight,l=t.effectiveFilterWidth,c=t.padInfo.top,h=t.padInfo.left;this.outputShape=t.outShape;var p=\"avg\"===e,f=\"0.0\";if(p||(f=\"-1.0 / 1e-20\"),n)this.userCode=\"\\n        const ivec2 strides = ivec2(\"+o+\", \"+a+\");\\n        const ivec2 pads = ivec2(\"+c+\", \"+h+\");\\n\\n        void main() {\\n          ivec4 coords = getOutputCoords();\\n          int batch = coords[0];\\n          int d = coords[3];\\n\\n          ivec2 xRCCorner = coords.yz * strides - pads;\\n          int xRCorner = xRCCorner.x;\\n          int xCCorner = xRCCorner.y;\\n\\n          // max/min x(?, ?, d) to get y(yR, yC, d).\\n          // ? = to be determined\\n          float minMaxValue = 0.0;\\n          float minMaxValueFound = 0.0;\\n          int minMaxPosition = 0;\\n          float avgValue = 0.0;\\n\\n          for (int wR = 0; wR < \"+u+\";\\n              wR += \"+i+\") {\\n            int xR = xRCorner + wR;\\n\\n            if (xR < 0 || xR >= \"+t.inHeight+\") {\\n              continue;\\n            }\\n\\n            for (int wC = 0; wC < \"+l+\";\\n                wC += \"+s+\") {\\n              int xC = xCCorner + wC;\\n\\n              if (xC < 0 || xC >= \"+t.inWidth+\") {\\n                continue;\\n              }\\n\\n              float value = getX(batch, xR, xC, d);\\n\\n              // If a min / max value has already been found, use it. If not,\\n              // use the current value.\\n              float currMinMaxValue = mix(\\n                  value, minMaxValue, minMaxValueFound);\\n              if (value >= currMinMaxValue) {\\n                minMaxValue = value;\\n                minMaxValueFound = 1.0;\\n                minMaxPosition = wR * \"+l+\" + wC;\\n              }\\n            }\\n          }\\n          setOutput(float(minMaxPosition));\\n        }\\n      \";else{var d=e+\"(\"+e+\"(\"+e+\"(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])\";\"avg\"===e&&(d=\"avgValue / count\");var v=4*Math.floor(r/4),m=r%4,g=\"\\n      if (\"+p+\") {\\n        avgValue += dot(values, ones);\\n      } else {\\n        minMaxValue = max(values, minMaxValue);\\n      }\\n    \";this.userCode=\"\\n      const ivec2 strides = ivec2(\"+o+\", \"+a+\");\\n      const ivec2 pads = ivec2(\"+c+\", \"+h+\");\\n      const float initializationValue = \"+f+\";\\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\\n\\n      float count = 0.0;\\n\\n      float getValue(int batch, int xR, int xC, int d) {\\n        if (xC < 0 || xC >= \"+t.inWidth+\") {\\n          return initializationValue;\\n        }\\n        count += 1.0;\\n        return getX(batch, xR, xC, d);\\n      }\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int d = coords[3];\\n\\n        ivec2 xRCCorner = coords.yz * strides - pads;\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        // max/min x(?, ?, d) to get y(yR, yC, d).\\n        // ? = to be determined\\n        vec4 minMaxValue = vec4(\"+f+\");\\n        float avgValue = 0.0;\\n        count = 0.0;\\n\\n        for (int wR = 0; wR < \"+u+\";\\n            wR += \"+i+\") {\\n          int xR = xRCorner + wR;\\n\\n          if (xR < 0 || xR >= \"+t.inHeight+\") {\\n            continue;\\n          }\\n\\n          for (int wC = 0; wC < \"+v+\"; wC += 4) {\\n            int xC = xCCorner + wC * \"+s+\";\\n\\n            vec4 values = vec4(\\n              getValue(batch, xR, xC, d),\\n              getValue(batch, xR, xC + \"+s+\", d),\\n              getValue(batch, xR, xC + 2 * \"+s+\", d),\\n              getValue(batch, xR, xC + 3 * \"+s+\", d)\\n            );\\n\\n            \"+g+\"\\n          }\\n\\n          int xC = xCCorner + \"+v+\";\\n          if (\"+(1===m)+\") {\\n            vec4 values = vec4(\\n              getValue(batch, xR, xC, d),\\n              initializationValue,\\n              initializationValue,\\n              initializationValue\\n            );\\n\\n            \"+g+\"\\n          } else if (\"+(2===m)+\") {\\n            vec4 values = vec4(\\n              getValue(batch, xR, xC, d),\\n              getValue(batch, xR, xC + \"+s+\", d),\\n              initializationValue,\\n              initializationValue\\n            );\\n\\n            \"+g+\"\\n          } else if (\"+(3===m)+\") {\\n            vec4 values = vec4(\\n              getValue(batch, xR, xC, d),\\n              getValue(batch, xR, xC + \"+s+\", d),\\n              getValue(batch, xR, xC + 2 * \"+s+\", d),\\n              initializationValue\\n            );\\n\\n            \"+g+\"\\n          }\\n        }\\n        setOutput(\"+d+\");\\n      }\\n    \"}}}(),Ii=function(){return function(t,e,n){if(this.variableNames=[\"x\"],\"avg\"===e&&n)throw new Error(\"Cannot compute positions for average pool.\");var r=t.filterWidth,o=t.strideDepth,a=t.strideHeight,i=t.strideWidth,s=t.dilationDepth,u=t.dilationHeight,l=t.dilationWidth,c=t.effectiveFilterDepth,h=t.effectiveFilterHeight,p=t.effectiveFilterWidth,f=t.padInfo.front,d=t.padInfo.top,v=t.padInfo.left;this.outputShape=t.outShape;var m=\"avg\"===e,g=\"0.0\";if(m||(g=\"-1.0 / 1e-20\"),n)this.userCode=\"\\n        const ivec3 strides =\\n            ivec3(\"+o+\", \"+a+\", \"+i+\");\\n        const ivec3 pads = ivec3(\"+f+\", \"+d+\", \"+v+\");\\n\\n        void main() {\\n          ivec5 coords = getOutputCoords();\\n          int batch = coords.x;\\n          int ch = coords.u;\\n\\n          ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\\n          int xDCorner = xCorner.x;\\n          int xRCorner = xCorner.y;\\n          int xCCorner = xCorner.z;\\n\\n          // max/min x(?, ?, ?, ch) to get y(yD, yR, yC, ch).\\n          // ? = to be determined\\n          float minMaxValue = 0.0;\\n          float minMaxValueFound = 0.0;\\n          int minMaxPosition = 0;\\n\\n          for (int wD = 0; wD < \"+c+\";\\n              wD += \"+s+\") {\\n            int xD = xDCorner + wD;\\n\\n            if (xD < 0 || xD >= \"+t.inDepth+\") {\\n              continue;\\n            }\\n\\n            for (int wR = 0; wR < \"+h+\";\\n                wR += \"+u+\") {\\n              int xR = xRCorner + wR;\\n\\n              if (xR < 0 || xR >= \"+t.inHeight+\") {\\n                continue;\\n              }\\n\\n              for (int wC = 0; wC < \"+p+\";\\n                  wC += \"+l+\") {\\n                int xC = xCCorner + wC;\\n\\n                if (xC < 0 || xC >= \"+t.inWidth+\") {\\n                  continue;\\n                }\\n\\n                float value = getX(batch, xD, xR, xC, ch);\\n\\n                // If a min / max value has already been found, use it. If not,\\n                // use the current value.\\n                float currMinMaxValue = mix(\\n                    value, minMaxValue, minMaxValueFound);\\n                if (value >= currMinMaxValue) {\\n                  minMaxValue = value;\\n                  minMaxValueFound = 1.0;\\n                  minMaxPosition =\\n                      wD * \"+h+\" * \"+p+\" +\\n                      wR * \"+p+\" + wC;;\\n                }\\n              }\\n            }\\n          }\\n          setOutput(float(minMaxPosition));\\n        }\\n      \";else{var y=e+\"(\"+e+\"(\"+e+\"(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])\";\"avg\"===e&&(y=\"avgValue / count\");var x=4*Math.floor(r/4),b=r%4,w=\"\\n      if (\"+m+\") {\\n        avgValue += dot(values, ones);\\n      } else {\\n        minMaxValue = max(values, minMaxValue);\\n      }\\n    \";this.userCode=\"\\n      const ivec3 strides =\\n        ivec3(\"+o+\", \"+a+\", \"+i+\");\\n      const ivec3 pads = ivec3(\"+f+\", \"+d+\", \"+v+\");\\n      const float initializationValue = \"+g+\";\\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\\n\\n      float count = 0.0;\\n\\n      float getValue(int batch, int xD, int xR, int xC, int ch) {\\n        if (xC < 0 || xC >= \"+t.inWidth+\") {\\n          return initializationValue;\\n        }\\n        count += 1.0;\\n        return getX(batch, xD, xR, xC, ch);\\n      }\\n\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int ch = coords.u;\\n\\n        ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\\n        int xDCorner = xCorner.x;\\n        int xRCorner = xCorner.y;\\n        int xCCorner = xCorner.z;\\n\\n        // max/min x(?, ?, ?, d) to get y(yD, yR, yC, ch).\\n        // ? = to be determined\\n        vec4 minMaxValue = vec4(\"+g+\");\\n        float avgValue = 0.0;\\n        count = 0.0;\\n\\n        for (int wD = 0; wD < \"+c+\";\\n            wD += \"+s+\") {\\n          int xD = xDCorner + wD;\\n\\n          if (xD < 0 || xD >= \"+t.inDepth+\") {\\n            continue;\\n          }\\n\\n          for (int wR = 0; wR < \"+h+\";\\n            wR += \"+u+\") {\\n            int xR = xRCorner + wR;\\n\\n            if (xR < 0 || xR >= \"+t.inHeight+\") {\\n              continue;\\n            }\\n\\n            for (int wC = 0; wC < \"+x+\"; wC += 4) {\\n              int xC = xCCorner + wC * \"+l+\";\\n\\n              vec4 values = vec4(\\n                getValue(batch, xD, xR, xC, ch),\\n                getValue(batch, xD, xR, xC + \"+l+\", ch),\\n                getValue(batch, xD, xR, xC + 2 * \"+l+\", ch),\\n                getValue(batch, xD, xR, xC + 3 * \"+l+\", ch)\\n              );\\n\\n              \"+w+\"\\n            }\\n\\n            int xC = xCCorner + \"+x+\";\\n            if (\"+(1===b)+\") {\\n              vec4 values = vec4(\\n                getValue(batch, xD, xR, xC, ch),\\n                initializationValue,\\n                initializationValue,\\n                initializationValue\\n              );\\n\\n              \"+w+\"\\n            } else if (\"+(2===b)+\") {\\n              vec4 values = vec4(\\n                getValue(batch, xD, xR, xC, ch),\\n                getValue(batch, xD, xR, xC + \"+l+\", ch),\\n                initializationValue,\\n                initializationValue\\n              );\\n\\n              \"+w+\"\\n            } else if (\"+(3===b)+\") {\\n              vec4 values = vec4(\\n                getValue(batch, xD, xR, xC, ch),\\n                getValue(batch, xD, xR, xC + \"+l+\", ch),\\n                getValue(batch, xD, xR, xC + 2 * \"+l+\", ch),\\n                initializationValue\\n              );\\n\\n              \"+w+\"\\n            }\\n          }\\n          setOutput(\"+y+\");\\n        }\\n      }\\n    \"}}}(),ki=function(){return function(t,e){this.variableNames=[\"x\"];var n=t.windowSize,r=t.batchSize,o=t.inSize,a=Math.ceil(o/n);this.outputShape=[r,a];var i=\"0.0\",s=\"\";\"prod\"===e?i=\"1.0\":\"min\"===e?(i=\"1.0 / 1e-20\",s=\"min\"):\"max\"===e&&(i=\"-1.0 / 1e-20\",s=\"max\");var u=e+\"(\"+e+\"(\"+e+\"(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])\";\"sum\"===e?u=\"sumValue\":\"prod\"===e?u=\"prodValue\":\"all\"===e?u=\"allValue\":\"any\"===e&&(u=\"anyValue\");var l=4*Math.floor(n/4),c=n%4,h=\"\\n      if (\"+(\"sum\"===e)+\") {\\n        sumValue += dot(values, ones);\\n      } else if (\"+(\"prod\"===e)+\") {\\n        vec2 tmp = vec2(values[0], values[1]) * vec2(values[2], values[3]);\\n        prodValue *= tmp[0] * tmp[1];\\n      } else {\\n        minMaxValue = \"+s+\"(values, minMaxValue);\\n      }\\n    \",p=\"vec4\";\"all\"===e?(i=\"1.0\",h=\"\\n        bool reducedAllValue = all(values);\\n        float floatedReducedAllValue = float(reducedAllValue);\\n        allValue = float(allValue >= 1.0 && floatedReducedAllValue >= 1.0);\\n      \",p=\"bvec4\"):\"any\"===e&&(i=\"0.0\",h=\"\\n        bool reducedAnyValue = any(values);\\n        float floatedReducedAnyValue = float(reducedAnyValue);\\n        anyValue = float(anyValue >= 1.0 || floatedReducedAnyValue >= 1.0);\\n      \",p=\"bvec4\");var f=\"\";o%n>0&&(f=\"\\n        if (inIdx < 0 || inIdx >= \"+o+\") {\\n          return initializationValue;\\n        }\\n      \"),this.userCode=\"\\n      const float initializationValue = \"+i+\";\\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\\n\\n      float getValue(int batch, int inIdx) {\\n        \"+f+\"\\n        return getX(batch, inIdx);\\n      }\\n\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int outIdx = coords[1];\\n        int inOffset = outIdx * \"+n+\";\\n\\n        vec4 minMaxValue = vec4(\"+i+\");\\n        float prodValue = 1.0;\\n        float sumValue = 0.0;\\n        float allValue = 1.0;\\n        float anyValue = 0.0;\\n\\n        for (int i = 0; i < \"+l+\"; i += 4) {\\n          int inIdx = inOffset + i;\\n          \"+p+\" values = \"+p+\"(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2),\\n            getValue(batch, inIdx + 3)\\n          );\\n\\n          \"+h+\"\\n        }\\n\\n        int inIdx = inOffset + \"+l+\";\\n        if (\"+(1===c)+\") {\\n          \"+p+\" values = \"+p+\"(\\n            getValue(batch, inIdx),\\n            initializationValue,\\n            initializationValue,\\n            initializationValue\\n          );\\n\\n          \"+h+\"\\n        } else if (\"+(2===c)+\") {\\n          \"+p+\" values = \"+p+\"(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            initializationValue,\\n            initializationValue\\n          );\\n\\n          \"+h+\"\\n        } else if (\"+(3===c)+\") {\\n          \"+p+\" values = \"+p+\"(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2),\\n            initializationValue\\n          );\\n\\n          \"+h+\"\\n        }\\n        setOutput(\"+u+\");\\n      }\\n    \"}}(),Ni=function(){return function(t,e){this.variableNames=[\"A\"],this.usesPackedTextures=!0,this.outputShape=t;for(var n=\"\",r=0;r<4;r++){var o=\"thisRC = rc;\";r%2==1&&(o+=\"thisRC.z += 1;\"),r>1&&(o+=\"thisRC.y += 1;\"),n+=\"\\n        \"+o+\"\\n        \"+(r>0?\"if(thisRC.y < rows && thisRC.z < cols){\":\"\")+\"\\n          int flatIndex = getFlatIndex(thisRC);\\n\\n          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flatIndex);\\n          vec2 inputRCInnerDims = vec2(float(inputRC.y),float(inputRC.z));\\n\\n          result[\"+r+\"] =\\n            getChannel(getA(inputRC.x, inputRC.y, inputRC.z), inputRCInnerDims);\\n        \"+(r>0?\"}\":\"\")+\"\\n      \"}this.userCode=\"\\n      \\n    ivec3 inputCoordsFromReshapedOutCoords(int index) {\\n      \"+Bo([\"r\",\"c\",\"d\"],e)+\"\\n      return ivec3(r, c, d);\\n    }\\n  \\n      \"+Po(t)+\"\\n\\n      void main() {\\n        ivec3 rc = getOutputCoords();\\n\\n        vec4 result = vec4(0.);\\n\\n        ivec3 thisRC;\\n        int rows = \"+t[1]+\";\\n        int cols = \"+t[2]+\";\\n\\n        \"+n+\"\\n\\n        setOutput(result);\\n      }\\n    \"}}();var Si=function(){return function(t,e,n){this.variableNames=[\"dy\"],this.outputShape=[],this.outputShape=e.shape;var r=e.shape,o=r[1],a=r[2],i=t.shape,s=i[1],u=i[2],l=[n&&s>1?o-1:o,n&&u>1?a-1:a],c=[n&&s>1?s-1:s,n&&u>1?u-1:u],h=l[0]/c[0],p=l[1]/c[1],f=1/h,d=1/p,v=2*Math.ceil(f)+2,m=2*Math.ceil(d)+2;this.userCode=\"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        int r = coords[1];\\n        int c = coords[2];\\n\\n        float accumulator = 0.0;\\n\\n        const float heightScale = float(\"+h+\");\\n        const float widthScale = float(\"+p+\");\\n\\n        const float invHeightScale = float(\"+f+\");\\n        const float invWidthScale = float(\"+d+\");\\n\\n        const int winHeight = int(\"+v+\");\\n        const int winWidth = int(\"+m+\");\\n\\n        // Compute bounds for where in dy we will look\\n        float startRLerp = floor(float(r) * invHeightScale);\\n        int startDyR = int(startRLerp - float(winHeight / 2));\\n\\n        float startCLerp = floor(float(c) * invWidthScale);\\n        int startDyC = int(startCLerp - float(winWidth / 2));\\n\\n        // Loop over dy\\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\\n          int dyR = dyROffset + startDyR;\\n\\n          // Guard against the window exceeding the bounds of dy\\n          if (dyR < 0 || dyR >= \"+s+\") {\\n            continue;\\n          }\\n\\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\\n            int dyC = dyCOffset + startDyC;\\n\\n            // Guard against the window exceeding the bounds of dy\\n            if (dyC < 0 || dyC >= \"+u+\") {\\n              continue;\\n            }\\n\\n            float dxR = float(dyR) * heightScale;\\n            int topDxRIndex = int(floor(dxR));\\n            int bottomDxRIndex = int(min(ceil(dxR), \"+(o-1)+\".0));\\n            float dxRLerp = dxR - float(topDxRIndex);\\n            float inverseDxRLerp = 1.0 - dxRLerp;\\n\\n            float dxC = float(dyC) * widthScale;\\n            int leftDxCIndex = int(floor(dxC));\\n            int rightDxCIndex = int(min(ceil(dxC), \"+(a-1)+\".0));\\n            float dxCLerp = dxC - float(leftDxCIndex);\\n            float inverseDxCLerp = 1.0 - dxCLerp;\\n\\n            if (r == topDxRIndex && c == leftDxCIndex) {\\n              // topLeft\\n              accumulator +=\\n                getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;\\n            }\\n\\n            if (r == topDxRIndex && c == rightDxCIndex) {\\n              // topRight\\n              accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;\\n            }\\n\\n            if (r == bottomDxRIndex && c == leftDxCIndex) {\\n              // bottomLeft\\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;\\n            }\\n\\n            if (r == bottomDxRIndex && c == rightDxCIndex) {\\n              // bottomRight\\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;\\n            }\\n          }\\n        }\\n        // End loop over dy\\n\\n        setOutput(accumulator);\\n      }\\n    \"}}(),Ai=function(){return function(t,e,n,r){this.variableNames=[\"A\"],this.outputShape=[];var o=t[0],a=t[1],i=t[2],s=t[3];this.outputShape=[o,e,n,s];var u=[r&&e>1?a-1:a,r&&n>1?i-1:i],l=[r&&e>1?e-1:e,r&&n>1?n-1:n];this.userCode=\"\\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\\n          \"+u[0]/l[0]+\",\\n          \"+u[1]/l[1]+\");\\n      const vec2 inputShapeRC = vec2(\"+a+\".0, \"+i+\".0);\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        ivec2 yRC = coords.yz;\\n\\n        // Fractional source index.\\n        vec2 sourceFracIndexRC = vec2(yRC) * effectiveInputOverOutputRatioRC;\\n\\n        // Compute the four integer indices.\\n        ivec2 sourceFloorRC = ivec2(sourceFracIndexRC);\\n        ivec2 sourceCeilRC = ivec2(\\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\\n\\n        float topLeft = getA(b, sourceFloorRC.x, sourceFloorRC.y, d);\\n        float bottomLeft = getA(b, sourceCeilRC.x, sourceFloorRC.y, d);\\n        float topRight = getA(b, sourceFloorRC.x, sourceCeilRC.y, d);\\n        float bottomRight = getA(b, sourceCeilRC.x, sourceCeilRC.y, d);\\n\\n        vec2 fracRC = sourceFracIndexRC - vec2(sourceFloorRC);\\n\\n        float top = topLeft + (topRight - topLeft) * fracRC.y;\\n        float bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;\\n        float newValue = top + (bottom - top) * fracRC.x;\\n\\n        setOutput(newValue);\\n      }\\n    \"}}(),Ti=function(){return function(t,e,n,r){this.variableNames=[\"A\"],this.usesPackedTextures=!0,this.outputShape=[];var o=t[0],a=t[1],i=t[2],s=t[3];this.outputShape=[o,e,n,s];var u=[r&&e>1?a-1:a,r&&n>1?i-1:i],l=[r&&e>1?e-1:e,r&&n>1?n-1:n];this.userCode=\"\\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\\n          \"+u[0]/l[0]+\",\\n          \"+u[1]/l[1]+\",\\n          \"+u[1]/l[1]+\");\\n      const vec3 inputShapeRC = vec3(\"+a+\".0, \"+i+\".0,\\n                                     \"+i+\".0);\\n\\n      float getAValue(int b, int r, int c, int d) {\\n        return getChannel(getA(b, r, c, d), vec2(c, d));\\n      }\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        // Calculate values for next column in yRC.z.\\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\\n\\n        // Fractional source index.\\n        vec3 sourceFracIndexRC = vec3(yRC) * effectiveInputOverOutputRatioRC;\\n\\n        // Compute the four integer indices.\\n        ivec3 sourceFloorRC = ivec3(sourceFracIndexRC);\\n        ivec3 sourceCeilRC = ivec3(\\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\\n        \\n        // Should we calculate next column and row elements in 2x2 packed cell.\\n        bool hasNextCol = d < \"+(s-1)+\"; \\n        bool hasNextRow = coords.z < \"+(n-1)+\";\\n\\n        // In parallel, construct four corners for all four components in\\n        // packed 2x2 cell.\\n        vec4 topLeft = vec4(\\n          getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d),\\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d + 1)\\n                     : 0.0,\\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d)\\n                     : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d + 1) : 0.0);\\n\\n        vec4 bottomLeft = vec4(\\n          getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d),\\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d + 1)\\n                     : 0.0,\\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d)\\n                     : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d + 1) : 0.0);\\n\\n        vec4 topRight = vec4(\\n          getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d),\\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d + 1)\\n                     : 0.0,\\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d)\\n                     : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d + 1) : 0.0);\\n\\n        vec4 bottomRight = vec4(\\n          getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d),\\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d + 1)\\n                     : 0.0,\\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d)\\n                     : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d + 1) : 0.0);\\n\\n        vec3 fracRC = sourceFracIndexRC - vec3(sourceFloorRC);\\n\\n        vec4 top = mix(topLeft, topRight, fracRC.yyzz);\\n        vec4 bottom = mix(bottomLeft, bottomRight, fracRC.yyzz);\\n        vec4 newValue = mix(top, bottom, fracRC.x);\\n\\n        setOutput(newValue);\\n      }\\n    \"}}(),Di=function(){return function(t,e,n){this.variableNames=[\"dy\"],this.outputShape=[],this.outputShape=e.shape;var r=e.shape,o=r[1],a=r[2],i=t.shape,s=i[1],u=i[2],l=[n&&s>1?o-1:o,n&&u>1?a-1:a],c=[n&&s>1?s-1:s,n&&u>1?u-1:u],h=l[0]/c[0],p=l[1]/c[1],f=1/h,d=1/p,v=2*Math.ceil(f)+2,m=2*Math.ceil(d)+2;this.userCode=\"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        int r = coords[1];\\n        int c = coords[2];\\n\\n        float accumulator = 0.0;\\n\\n        const float heightScale = float(\"+h+\");\\n        const float widthScale = float(\"+p+\");\\n\\n        const float invHeightScale = float(\"+f+\");\\n        const float invWidthScale = float(\"+d+\");\\n\\n        const int winHeight = int(\"+v+\");\\n        const int winWidth = int(\"+m+\");\\n\\n        // Compute bounds for where in dy we will look\\n        float startRLerp = floor(float(r) * invHeightScale);\\n        int startDyR = int(floor(startRLerp - float(winHeight / 2)));\\n\\n        float startCLerp = floor(float(c) * invWidthScale);\\n        int startDyC = int(floor(startCLerp - float(winWidth / 2)));\\n\\n        // Loop over dy\\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\\n          int dyR = dyROffset + startDyR;\\n\\n          // Guard against the window exceeding the bounds of dy\\n          if (dyR < 0 || dyR >= \"+s+\") {\\n            continue;\\n          }\\n\\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\\n            int dyC = dyCOffset + startDyC;\\n\\n            // Guard against the window exceeding the bounds of dy\\n            if (dyC < 0 || dyC >= \"+u+\") {\\n              continue;\\n            }\\n\\n            float sourceFracRow =\\n              float(\"+l[0]+\") *\\n                (float(dyR) / float(\"+c[0]+\"));\\n\\n            float sourceFracCol =\\n                float(\"+l[1]+\") *\\n                  (float(dyC) / float(\"+c[1]+\"));\\n\\n            int sourceNearestRow = int(min(\\n                float(int(\"+o+\") - 1),\\n                \"+n+\" ? float(round(sourceFracRow)) :\\n                                  float(floor(sourceFracRow))));\\n\\n            int sourceNearestCol = int(min(\\n                float(int(\"+a+\") - 1),\\n                \"+n+\" ? float(round(sourceFracCol)) :\\n                                  float(floor(sourceFracCol))));\\n\\n            if (r == sourceNearestRow && c == sourceNearestCol) {\\n              accumulator += getDy(b, dyR, dyC, d);\\n            }\\n          }\\n        }\\n        // End loop over dy\\n\\n        setOutput(accumulator);\\n      }\\n    \"}}(),_i=function(){return function(t,e,n,r){this.variableNames=[\"A\"],this.outputShape=[];var o=t[0],a=t[1],i=t[2],s=t[3];this.outputShape=[o,e,n,s];var u=[r&&e>1?a-1:a,r&&n>1?i-1:i],l=[r&&e>1?e-1:e,r&&n>1?n-1:n],c=r?\"0.5\":\"0.0\";this.userCode=\"\\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\\n          \"+u[0]/l[0]+\",\\n          \"+u[1]/l[1]+\");\\n      const vec2 inputShapeRC = vec2(\"+a+\".0, \"+i+\".0);\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        ivec2 yRC = coords.yz;\\n\\n        // Fractional source index.\\n        vec2 sourceFracIndexRC = vec2(yRC) * effectiveInputOverOutputRatioRC;\\n\\n        // Compute the coordinators of nearest neighbor point.\\n        ivec2 sourceNearestRC = ivec2(\\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + \"+c+\")));\\n\\n        float newValue = getA(b, sourceNearestRC.x, sourceNearestRC.y, d);\\n\\n        setOutput(newValue);\\n      }\\n    \"}}(),Oi=function(){return function(t,e){this.variableNames=[\"x\"];var n=t.length;if(n>4)throw new Error(\"WebGL backend: Reverse of rank-\"+n+\" tensor is not yet supported\");if(this.outputShape=t,1!==n){var r=t.map(function(n,r){return function(n){return-1!==e.indexOf(n)&&1!==t[n]?t[n]+\" - coords[\"+n+\"] - 1\":\"coords[\"+n+\"]\"}(r)}).join(\",\"),o=jo(n);this.userCode=\"\\n      void main() {\\n        \"+o+\" coords = getOutputCoords();\\n        setOutput(getX(\"+r+\"));\\n      }\\n    \"}else this.userCode=\"\\n        void main() {\\n          int coord = getOutputCoords();\\n          setOutput(getX(\"+t[0]+\" - coord - 1));\\n        }\\n      \"}}(),Fi=function(){return function(t,e){this.variableNames=[\"x\"],this.usesPackedTextures=!0;var n=t.length;if(n>4)throw new Error(\"WebGL backend: Reverse of rank-\"+n+\" tensor is not yet supported\");this.outputShape=t;var r=Fo(\"rc\",n),o=r[n-1]+\" + 1 < \"+this.outputShape[n-1],a=r[n-2]+\" + 1 < \"+this.outputShape[n-2],i=jo(n);function s(n){var r=t.map(function(r,o){return function(n,r){return-1!==e.indexOf(n)&&1!==t[n]?t[n]+\" - \"+r[n]+\" - 1\":\"\"+r[n]}(o,n)});return\"getChannel(getX(\"+r.join(\",\")+\"), vec2(\"+r.slice(-2).join(\",\")+\"))\"}this.userCode=1===n?\"\\n        void main(){\\n          int rc = getOutputCoords();\\n          vec4 result = vec4(0.);\\n          result.r = getChannel(getX(\"+t[0]+\" - rc - 1),\\n            \"+t[0]+\" - rc - 1);\\n          if(\"+o+\"){\\n              result.g = getChannel(getX(\"+t[0]+\" - (rc  + 1) - 1),\\n                \"+t[0]+\" - (rc  + 1) - 1);\\n          }\\n          setOutput(result);\\n        }\\n      \":\"\\n        void main() {\\n          \"+i+\" rc = getOutputCoords();\\n          vec4 result = vec4(0.);\\n          result.r = \"+function(t){return s(t)}(r.slice())+\";\\n          if(\"+o+\"){\\n            result.g = \"+function(t){return t[n-1]=\"(\"+t[n-1]+\" + 1)\",s(t)}(r.slice())+\";\\n          }\\n          if(\"+a+\") {\\n            result.b = \"+function(t){return t[n-2]=\"(\"+t[n-2]+\" + 1)\",s(t)}(r.slice())+\";\\n            if(\"+o+\") {\\n              result.a = \"+function(t){return t[n-1]=\"(\"+t[n-1]+\" + 1)\",t[n-2]=\"(\"+t[n-2]+\" + 1)\",s(t)}(r.slice())+\";\\n            }\\n          }\\n          setOutput(result);\\n        }\\n    \"}}(),Mi=function(){return function(t,e,n,r,o,a,i){void 0===i&&(i=!0),this.variableNames=[\"updates\",\"indices\",\"defaultValue\"],this.outputShape=a;var s=jo(o.length),u=jo(a.length),l=\"\";1===n?l=\"i\":2===n&&(l=\"i, j\");var c=\"getIndices(\"+l+\")\",h=\"\";1===r?h=\"i\":2===r&&(h=\"i, coords[1]\");var p=\"getUpdates(\"+h+\")\",f=e>1?\"strides[j]\":\"strides\";this.userCode=\"\\n        \"+s+\" strides = \"+s+\"(\"+o+\");\\n\\n        void main() {\\n          \"+u+\" coords = getOutputCoords();\\n          float sum = 0.0;\\n          bool found = false;\\n          for (int i = 0; i < \"+t+\"; i++) {\\n            int flattenedIndex = 0;\\n            for (int j = 0; j < \"+e+\"; j++) {\\n              int index = round(\"+c+\");\\n              flattenedIndex += index * \"+f+\";\\n            }\\n            if (flattenedIndex == coords[0]) {\\n              sum += \"+p+\";\\n              found = true;\\n            }\\n          }\\n          setOutput(mix(getDefaultValue(), sum, float(found)));\\n        }\\n      \"}}(),Bi=function(){return function(t,e){this.variableNames=[\"x\",\"segmentIds\"];var n=t.windowSize,r=t.batchSize,o=t.inSize,a=t.numSegments,i=a*Math.ceil(o/n);this.outputShape=[r,i];var s=4*Math.floor(n/4),u=n%4,l=\"\\n        sumValue += dot(values, segFilter);\\n    \",c=\"\";o%n>0&&(c=\"\\n        if (inIdx < 0 || inIdx >= \"+o+\") {\\n          return initializationValue;\\n        }\\n      \");var h=\"\";o%n>0&&(h=\"\\n        if (inIdx < 0 || inIdx >= \"+o+\") {\\n          return -1.0;\\n        }\\n      \"),this.userCode=\"\\n      const float initializationValue = 0.0;\\n\\n      float getValue(int batch, int inIdx) {\\n        \"+c+\"\\n        return getX(batch, inIdx);\\n      }\\n\\n      float getSegmentIdAtIndex(int inIdx) {\\n        \"+h+\"\\n        return getSegmentIds(inIdx);\\n      }\\n\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int outIdx = coords[1];\\n        int inOffset = int(floor(float(outIdx) / float(\\n          \"+a+\")) * float(\"+n+\"));\\n        int currentSeg = int(mod(float(outIdx), float(\"+a+\")));\\n\\n        float sumValue = 0.0;\\n\\n        for (int i = 0; i < \"+s+\"; i += 4) {\\n          int inIdx = inOffset + i;\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2),\\n            getValue(batch, inIdx + 3)\\n          );\\n\\n          vec4 segFilter = vec4(\\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 3)) == currentSeg ? 1 : 0\\n          );\\n\\n          \"+l+\"\\n        }\\n\\n        int inIdx = inOffset + \"+s+\";\\n        if (\"+(1===u)+\") {\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            initializationValue,\\n            initializationValue,\\n            initializationValue\\n          );\\n\\n          int inIdxSeg = int(getSegmentIdAtIndex(inIdx));\\n\\n          vec4 segFilter = vec4(\\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\\n            0,\\n            0,\\n            0\\n          );\\n\\n          \"+l+\"\\n        } else if (\"+(2===u)+\") {\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            initializationValue,\\n            initializationValue\\n          );\\n\\n          vec4 segFilter = vec4(\\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\\n              0,\\n              0\\n          );\\n\\n          \"+l+\"\\n        } else if (\"+(3===u)+\") {\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2),\\n            initializationValue\\n          );\\n\\n          vec4 segFilter = vec4(\\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\\n            0\\n          );\\n\\n          \"+l+\"\\n        }\\n        setOutput(sumValue);\\n      }\\n    \"}}(),Pi=function(){return function(t,e,n){var r,o;if(this.variableNames=[\"c\",\"a\",\"b\"],this.outputShape=e,n>4)throw Error(\"Where for rank \"+n+\" is not yet supported\");if(1===n)o=\"resRC\",r=\"resRC\";else{for(var a=[\"resRC.x\",\"resRC.y\",\"resRC.z\",\"resRC.w\"],i=[],s=[],u=0;u<e.length;u++)s.push(\"\"+a[u]),u<t&&i.push(\"\"+a[u]);r=i.join(),o=s.join()}var l=jo(n);this.userCode=\"\\n      void main() {\\n        \"+l+\" resRC = getOutputCoords();\\n        float cVal = getC(\"+r+\");\\n        if (cVal >= 1.0) {\\n          setOutput(getA(\"+o+\"));\\n        } else {\\n          setOutput(getB(\"+o+\"));\\n        }\\n      }\\n    \"}}(),Li=function(){function t(t){this.variableNames=[\"source\"],this.outputShape=t,this.rank=t.length;var e,n=jo(this.rank),r=\"uniform int start[\"+this.rank+\"];\",o=function(t){if(1===t)return\"sourceLoc\";if(t<=6)return Wi.slice(0,t).map(function(t){return\"sourceLoc.\"+t}).join(\",\");throw Error(\"Slicing for rank \"+t+\" is not yet supported\")}(this.rank);e=\"\\n        \"+n+\" sourceLoc;\\n        \"+n+\" coords = getOutputCoords();\\n        \"+t.map(function(t,e){return\"sourceLoc.\"+Wi[e]+\" = start[\"+e+\"] + coords.\"+Wi[e]+\";\"}).join(\"\\n\")+\"\\n      \",this.userCode=\"\\n      \"+r+\"\\n      void main() {\\n        \"+e+\"\\n        setOutput(getSource(\"+o+\"));\\n      }\\n    \"}return t.prototype.getCustomSetupFunc=function(t){var e=this;if(t.length!==this.rank)throw Error(\"The rank (\"+this.rank+\") of the program must match the length of start (\"+t.length+\")\");return function(n,r){null==e.startLoc&&(e.startLoc=n.getUniformLocationNoThrow(r,\"start\"),null==e.startLoc)||n.gl.uniform1iv(e.startLoc,t)}},t}(),Wi=[\"x\",\"y\",\"z\",\"w\",\"u\",\"v\"];var Ui=function(){function t(t){this.variableNames=[\"source\"],this.usesPackedTextures=!0,this.outputShape=t,this.rank=t.length;var e=jo(this.rank),n=Fo(\"coords\",this.rank),r=Fo(\"sourceLoc\",this.rank),o=1===this.rank?\"sourceLoc\":\"vec2(\"+r.slice(-2).join()+\")\",a=\"getChannel(getSource(\"+r.join()+\"), \"+o+\")\",i=\"\\n      result.x = \"+a+\";\\n      if (++\"+n[this.rank-1]+\" < \"+t[this.rank-1]+\") {\\n        ++\"+r[this.rank-1]+\";\\n        result.y = \"+a+\";\\n        --\"+r[this.rank-1]+\";\\n      }\\n    \",s=1===this.rank?\"\":\"\\n      --\"+n[this.rank-1]+\";\\n      if (++\"+n[this.rank-2]+\" < \"+t[this.rank-2]+\") {\\n        ++\"+r[this.rank-2]+\";\\n        result.z = \"+a+\";\\n        if (++\"+n[this.rank-1]+\" < \"+t[this.rank-1]+\") {\\n          ++\"+r[this.rank-1]+\";\\n          result.w = \"+a+\";\\n        }\\n      }\\n    \",u=this.rank<=4?\"sourceLoc = coords +\\n            \"+e+\"(\"+t.map(function(t,e){return\"start[\"+e+\"]\"}).join()+\");\":t.map(function(t,e){return r[e]+\" = \"+n[e]+\" + start[\"+e+\"];\"}).join(\"\\n\");this.userCode=\"\\n      uniform int start[\"+this.rank+\"];\\n      void main() {\\n        \"+e+\" coords = getOutputCoords();\\n        \"+e+\" sourceLoc;\\n        \"+u+\" \\n        vec4 result = vec4(0.);\\n        \"+i+\"\\n        \"+s+\"\\n        setOutput(result);\\n      }\\n    \"}return t.prototype.getCustomSetupFunc=function(t){var e=this;if(t.length!==this.rank)throw Error(\"The rank (\"+this.rank+\") of the program must match the length of start (\"+t.length+\")\");return function(n,r){null==e.startLoc&&(e.startLoc=n.getUniformLocationNoThrow(r,\"start\"),null==e.startLoc)||n.gl.uniform1iv(e.startLoc,t)}},t}(),Vi=function(){return function(t,e,n){this.variableNames=[\"x\"],this.outputShape=n;var r=n.length,o=jo(n.length),a=jo(n.length),i=\"\";if(1===r)i=\"coords * strides + begin\";else{var s=0;i=n.map(function(t,e){return s++,1===n.length?\"coords * strides[\"+e+\"] + begin[\"+e+\"]\":\"coords[\"+(s-1)+\"] * strides[\"+e+\"] + begin[\"+e+\"]\"}).join(\",\")}this.userCode=\"\\n      \"+o+\" begin = \"+o+\"(\"+t+\");\\n      \"+o+\" strides = \"+o+\"(\"+e+\");\\n\\n      void main() {\\n        \"+a+\" coords = getOutputCoords();\\n        setOutput(getX(\"+i+\"));\\n      }\\n    \"}}(),zi=function(){function t(t){this.gpgpu=t,this.numUsedTextures=0,this.numFreeTextures=0,this.freeTextures={},this.logEnabled=!1,this.usedTextures={}}return t.prototype.acquireTexture=function(t,e,n){var r,o=Gi(e,n),a=Hi(t,o,n);if(a in this.freeTextures||(this.freeTextures[a]=[]),a in this.usedTextures||(this.usedTextures[a]=[]),this.freeTextures[a].length>0){this.numFreeTextures--,this.numUsedTextures++,this.log();var i=this.freeTextures[a].shift();return this.usedTextures[a].push(i),i}return this.numUsedTextures++,this.log(),o===Dt.PACKED_2X2_FLOAT32?r=this.gpgpu.createPackedMatrixTexture(t[0],t[1]):o===Dt.PACKED_2X2_FLOAT16?r=this.gpgpu.createFloat16PackedMatrixTexture(t[0],t[1]):o===Dt.UNPACKED_FLOAT32?r=this.gpgpu.createFloat32MatrixTexture(t[0],t[1]):o===Dt.UNPACKED_FLOAT16?r=this.gpgpu.createFloat16MatrixTexture(t[0],t[1]):o===Dt.PACKED_4X1_UNSIGNED_BYTE&&(r=this.gpgpu.createUnsignedBytesMatrixTexture(t[0],t[1])),this.usedTextures[a].push(r),r},t.prototype.releaseTexture=function(t,e,n,r){if(null!=this.freeTextures){var o=Hi(e,Gi(n,r),r);o in this.freeTextures||(this.freeTextures[o]=[]),this.freeTextures[o].push(t),this.numFreeTextures++,this.numUsedTextures--;var a=this.usedTextures[o],i=a.indexOf(t);if(i<0)throw new Error(\"Cannot release a texture that was never provided by this texture manager\");a.splice(i,1),this.log()}},t.prototype.log=function(){if(this.logEnabled){var t=this.numFreeTextures+this.numUsedTextures;console.log(\"Free/Used\",this.numFreeTextures+\" / \"+this.numUsedTextures,\"(\"+t+\")\")}},t.prototype.getNumUsedTextures=function(){return this.numUsedTextures},t.prototype.getNumFreeTextures=function(){return this.numFreeTextures},t.prototype.dispose=function(){var t=this;if(null!=this.freeTextures){for(var e in this.freeTextures)this.freeTextures[e].forEach(function(e){t.gpgpu.deleteMatrixTexture(e)});for(var e in this.usedTextures)this.usedTextures[e].forEach(function(e){t.gpgpu.deleteMatrixTexture(e)});this.freeTextures=null,this.usedTextures=null,this.numUsedTextures=0,this.numFreeTextures=0}},t}();function Gi(t,e){if(t===Tt.UPLOAD)return Dt.PACKED_2X2_FLOAT32;if(t===Tt.RENDER||null==t)return function(t){return i.getBool(\"WEBGL_RENDER_FLOAT32_ENABLED\")?t?Dt.PACKED_2X2_FLOAT32:Dt.UNPACKED_FLOAT32:t?Dt.PACKED_2X2_FLOAT16:Dt.UNPACKED_FLOAT16}(e);if(t===Tt.DOWNLOAD||t===Tt.PIXELS)return Dt.PACKED_4X1_UNSIGNED_BYTE;throw new Error(\"Unknown logical texture type \"+t)}function Hi(t,e,n){return t[0]+\"_\"+t[1]+\"_\"+e+\"_\"+n}var qi=function(){return function(t,e){this.variableNames=[\"A\"];for(var n=new Array(t.length),r=0;r<n.length;r++)n[r]=t[r]*e[r];this.outputShape=n,this.rank=n.length;var o=jo(this.rank),a=function(t){var e=t.length;if(e>5)throw Error(\"Tile for rank \"+e+\" is not yet supported\");if(1===e)return\"imod(resRC, \"+t[0]+\")\";for(var n=[\"resRC.x\",\"resRC.y\",\"resRC.z\",\"resRC.w\",\"resRC.u\"],r=[],o=0;o<t.length;o++)r.push(\"imod(\"+n[o]+\", \"+t[o]+\")\");return r.join()}(t);this.userCode=\"\\n      void main() {\\n        \"+o+\" resRC = getOutputCoords();\\n        setOutput(getA(\"+a+\"));\\n      }\\n    \"}}();var $i=function(){return function(t,e){this.variableNames=[\"A\"];for(var n=new Array(t.length),r=0;r<n.length;r++)n[r]=t[e[r]];this.outputShape=n,this.rank=n.length;var o=jo(this.rank),a=function(t){var e=t.length;if(e>6)throw Error(\"Transpose for rank \"+e+\" is not yet supported\");for(var n=[\"resRC.x\",\"resRC.y\",\"resRC.z\",\"resRC.w\",\"resRC.u\",\"resRC.v\"],r=new Array(e),o=0;o<t.length;o++)r[t[o]]=n[o];return r.join()}(e);this.userCode=\"\\n    void main() {\\n      \"+o+\" resRC = getOutputCoords();\\n      setOutput(getA(\"+a+\"));\\n    }\\n    \"}}();var Ki=function(){return function(t,e){this.variableNames=[\"A\"],this.usesPackedTextures=!0;for(var n=new Array(t.length),r=0;r<n.length;r++)n[r]=t[e[r]];if(this.outputShape=n,this.rank=n.length,this.rank>6)throw Error(\"Packed transpose for rank \"+this.rank+\" is not yet supported.\");var o=jo(this.rank),a=Oo(\"rc\",this.rank),i=new Array(this.rank);for(r=0;r<e.length;r++)i[e[r]]=a[r];var s=\"vec2(\"+i.slice(-2).join()+\")\",u=\"++\"+a[this.rank-1]+\" < \"+n[this.rank-1],l=\"getChannel(getA(\"+i.join()+\"), \"+s+\")\";this.userCode=\"\\n    void main() {\\n      \"+o+\" rc = getOutputCoords();\\n      vec4 result = vec4(0.);\\n      result[0] = \"+l+\";\\n      if(\"+u+\") {\\n        result[1] = \"+l+\";\\n      }\\n      --\"+a[this.rank-1]+\";\\n      if(++\"+a[this.rank-2]+\" < \"+n[this.rank-2]+\") {\\n        result[2] = \"+l+\";\\n        if(\"+u+\") {\\n          result[3] = \"+l+\";\\n        }\\n      }  \\n      setOutput(result);\\n    }\\n    \"}}(),ji=1.7580993408473768,Xi=1.0507009873554805,Yi=function(){return function(t,e){this.variableNames=[\"A\"],this.outputShape=t,this.userCode=\"\\n      float unaryOperation(float x) {\\n        \"+e+\"\\n      }\\n\\n      void main() {\\n        float x = getAAtOutCoords();\\n        float y = unaryOperation(x);\\n\\n        setOutput(y);\\n      }\\n    \"}}(),Qi=\"if (isnan(x)) return x;\",Ji=\"return x;\",Zi=\"return abs(x);\",ts=Qi+\"\\n  return (x < 0.0) ? 0.0 : x;\\n\",es=\"return (x >= 0.0) ? x : (exp(x) - 1.0);\",ns=\"\\n  // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.\\n  // see: https://arxiv.org/abs/1706.02515\\n  float scaleAlpha = \"+ji+\";\\n  float scale = \"+Xi+\";\\n  return (x >= 0.0) ? scale * x : scaleAlpha * (exp(x) - 1.0);\\n\";var rs=\"return -x;\",os=\"return ceil(x);\",as=\"return floor(x);\",is=\"return exp(x);\",ss=\"return exp(x) - 1.0;\",us=Qi+\"\\n  return sin(x);\\n\",ls=Qi+\"\\n  return cos(x);\\n\",cs=Qi+\"\\n  return atan(x);\\n\",hs=Qi+\"\\n  if (x < 1.0) return NAN;\\n  return log(x + sqrt(x * x - 1.0));\",ps=Qi+\"\\n  if ((x < -1.0) || (x > 1.0)) return NAN;\\n  return (log(1.0 + x) - log(1.0 - x)) / 2.0;\",fs=\"return x;\",ds=\"return x;\",vs=\"\\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\\n  bvec4 isNaN = isnan(x);\\n\\n  result.r = isNaN.r ? x.r : result.r;\\n  result.g = isNaN.g ? x.g : result.g;\\n  result.b = isNaN.b ? x.b : result.b;\\n  result.a = isNaN.a ? x.a : result.a;\\n\\n  return result;\\n\",ms=\"\\n  vec4 result;\\n\\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\\n\\n  return result;\\n\",gs=function(){return function(t,e){this.variableNames=[\"A\"],this.usesPackedTextures=!0,this.outputShape=t,this.userCode=\"\\n      vec4 unaryOperation(vec4 x) {\\n        \"+e+\"\\n      }\\n\\n      void main() {\\n        vec4 x = getAAtOutCoords();\\n        vec4 y = unaryOperation(x);\\n\\n        setOutput(y);\\n      }\\n    \"}}(),ys=function(){return function(t){this.variableNames=[\"A\"],this.usesPackedTextures=!0,this.outputShape=t;var e=t.length,n=Fo(\"rc\",e),r=jo(e),o=function(t,e){if(1===t)return\"rc\";for(var n=\"\",r=0;r<t;r++)n+=e[r],r<t-1&&(n+=\",\");return n}(e,n),a=n.slice(-2),i=e<=1?\"rc\":\"vec2(\"+a.join(\",\")+\")\";this.userCode=\"\\n      void main() {\\n        \"+r+\" rc = getOutputCoords();\\n        vec4 packedInput = getA(\"+o+\");\\n\\n        setOutput(getChannel(packedInput, \"+i+\"));\\n      }\\n    \"}}(),xs={};function bs(t,e){if(void 0===e&&(e=!1),\"linear\"===t)return e?ds:Ji;if(\"relu\"===t)return e?vs:ts;if(\"elu\"===t)return e?ms:es;if(\"prelu\"===t)return e?ca:ua;throw new Error(\"Activation \"+t+\" has not been implemented for the WebGL backend.\")}var ws=600;var Cs=function(){function t(t){if(this.gpgpu=t,this.pendingRead=new WeakMap,this.pendingDisposal=new WeakSet,this.dataRefCount=new WeakMap,this.numBytesInGPU=0,this.uploadWaitMs=0,this.downloadWaitMs=0,this.warnedAboutMemory=!1,this.disposed=!1,!i.getBool(\"HAS_WEBGL\"))throw new Error(\"WebGL is not supported on this device\");if(null==t){var e=Mt(i.getNumber(\"WEBGL_VERSION\"));this.binaryCache=(n=i.getNumber(\"WEBGL_VERSION\"))in xs?xs[n]:(xs[n]={},xs[n]),this.gpgpu=new ci(e),this.canvas=e.canvas,this.gpgpuCreatedLocally=!0}else this.binaryCache={},this.gpgpuCreatedLocally=!1,this.canvas=t.gl.canvas;var n;this.textureManager=new zi(this.gpgpu),this.numMBBeforeWarning=null==i.global.screen?1024:i.global.screen.height*i.global.screen.width*window.devicePixelRatio*ws/1024/1024,this.texData=new Jr(this,St)}return t.prototype.register=function(t,e,n){if(this.texData.has(t))throw new Error(\"Data buffer is already registered\");this.texData.set(t,{shape:e,dtype:n})},t.prototype.fromPixels=function(t,e){if(null==t)throw new Error(\"pixels passed to tf.browser.fromPixels() can not be null\");var n=\"undefined\"!=typeof OffscreenCanvas&&t instanceof OffscreenCanvas||\"undefined\"!=typeof HTMLCanvasElement&&t instanceof HTMLCanvasElement,r=t.data instanceof Uint8Array,o=\"undefined\"!=typeof ImageData&&t instanceof ImageData,a=\"undefined\"!=typeof HTMLVideoElement&&t instanceof HTMLVideoElement,s=\"undefined\"!=typeof HTMLImageElement&&t instanceof HTMLImageElement,u=a?[t.videoWidth,t.videoHeight]:[t.width,t.height],l=u[0],c=u[1],h=[c,l],p=[c,l,e];if(!(n||r||o||a||s))throw new Error(\"pixels passed to tf.browser.fromPixels() must be either an HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData in browser, or OffscreenCanvas, ImageData in webworker or {data: Uint32Array, width: number, height: number}, but was \"+t.constructor.name);(s||a)&&(null==this.fromPixels2DContext&&(this.fromPixels2DContext=Bt(i.getNumber(\"WEBGL_VERSION\")).getContext(\"2d\")),this.fromPixels2DContext.canvas.width=l,this.fromPixels2DContext.canvas.height=c,this.fromPixels2DContext.drawImage(t,0,0,l,c),t=this.fromPixels2DContext.canvas);var f,d,v=this.makeTensorHandle(h,\"int32\");if(this.texData.get(v.dataId).usage=Tt.PIXELS,this.gpgpu.uploadPixelDataToTexture(this.getTexture(v.dataId),t),i.getBool(\"WEBGL_PACK\")){f=new Ga(p);var m=this.makePackedTensor(f.outputShape,v.dtype);d=this.compileAndRun(f,[v],m)}else f=new za(p),d=this.compileAndRun(f,[v]);return this.disposeData(v.dataId),d},t.prototype.makeTensorHandle=function(t,e){var n={};return this.register(n,t,e),{dataId:n,shape:t,dtype:e}},t.prototype.write=function(t,e){if(null==e)throw new Error(\"MathBackendWebGL.write(): values can not be null\");if(i.getBool(\"DEBUG\"))for(var n=0;n<e.length;n++){var r=e[n];if(!Ht(r)){if(i.getBool(\"WEBGL_RENDER_FLOAT32_CAPABLE\"))throw Error(\"The value \"+r+\" cannot be represented with your current settings. Consider enabling float32 rendering: 'tf.ENV.set('WEBGL_RENDER_FLOAT32_ENABLED', true);'\");throw Error(\"The value \"+r+\" cannot be represented on this device.\")}}var o=this.texData.get(t);if(\"complex64\"===o.dtype)throw new Error(\"Cannot write to a complex64 dtype. Please use tf.complex(real, imag).\");this.releaseGPUData(t),o.usage=Tt.UPLOAD,o.values=e},t.prototype.readSync=function(t){var e=this.texData.get(t),n=e.values,r=e.dtype,o=e.complexTensors,a=e.slice,i=e.shape,s=e.isPacked;if(null!=a){var u=void 0;u=s?new gs(i,fs):new Yi(i,fs);var l=this.compileAndRun(u,[{dataId:t,shape:i,dtype:r}]),c=this.readSync(l.dataId);return l.dispose(),c}if(null!=n)return this.convertAndCacheOnCPU(t);if(\"string\"===r)return n;var h,p,f=null!=this.activeTimers;(f&&(h=$()),\"complex64\"===r)?p=bo(o.real.dataSync(),o.imag.dataSync()):p=this.getValuesFromTexture(t);return f&&(this.downloadWaitMs+=$()-h),this.convertAndCacheOnCPU(t,p)},t.prototype.read=function(t){return n(this,void 0,void 0,function(){var e,n,o,a,s,u,l,c,h,p,f,d,v,m,y,x,b,w,C,E,R,I;return r(this,function(r){switch(r.label){case 0:if(this.pendingRead.has(t))return e=this.pendingRead.get(t),[2,new Promise(function(t){return e.push(t)})];if(n=this.texData.get(t),o=n.values,a=n.shape,s=n.slice,u=n.dtype,l=n.complexTensors,c=n.isPacked,null!=s)return h=void 0,h=c?new gs(a,fs):new Yi(a,fs),p=this.compileAndRun(h,[{dataId:t,shape:a,dtype:u}]),f=this.read(p.dataId),p.dispose(),[2,f];if(null!=o)return[2,this.convertAndCacheOnCPU(t)];if(!i.getBool(\"WEBGL_DOWNLOAD_FLOAT_ENABLED\")&&2===i.getNumber(\"WEBGL_VERSION\"))throw new Error(\"tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and WEBGL_VERSION=2 not yet supported.\");return d=null,\"complex64\"!==u&&i.get(\"WEBGL_BUFFER_SUPPORTED\")&&(v=this.decode(t),m=this.texData.get(v.dataId),d=(I=this.gpgpu).createBufferFromTexture.apply(I,[m.texture].concat(Lt(a)))),this.pendingRead.set(t,[]),\"complex64\"===u?[3,2]:[4,this.gpgpu.createAndWaitForFence()];case 1:r.sent(),r.label=2;case 2:return\"complex64\"!==u?[3,4]:[4,Promise.all([l.real.data(),l.imag.data()])];case 3:return x=r.sent(),b=x[0],w=x[1],y=bo(b,w),[3,5];case 4:null==d?y=this.getValuesFromTexture(t):(C=g(a),y=this.gpgpu.downloadFloat32MatrixFromBuffer(d,C)),r.label=5;case 5:return null!=v&&this.disposeData(v.dataId),E=this.convertAndCacheOnCPU(t,y),R=this.pendingRead.get(t),this.pendingRead.delete(t),R.forEach(function(t){return t(E)}),this.pendingDisposal.has(t)&&(this.pendingDisposal.delete(t),this.disposeData(t)),[2,E]}})})},t.prototype.getValuesFromTexture=function(t){var e,n=this,r=this.texData.get(t),o=r.shape,a=r.dtype,s=r.isPacked,u=g(o);if(i.getBool(\"WEBGL_DOWNLOAD_FLOAT_ENABLED\")){var l=this.decode(t),c=this.texData.get(l.dataId),h=(e=this.gpgpu).downloadMatrixFromPackedTexture.apply(e,[c.texture].concat(Lt(o))).subarray(0,u);return this.disposeData(l.dataId),h}var p=i.getBool(\"WEBGL_PACK\")&&!0===s,f=p?xe(o):o,d=this.makeTensorHandle(f,\"float32\");d.size=g(o),this.texData.get(d.dataId).usage=Tt.DOWNLOAD;var v=Ue(function(){var e=p?new Ma(f):new Fa(f);return n.compileAndRun(e,[{shape:f,dtype:a,dataId:t}],d,null)}),m=this.texData.get(v.dataId),y=this.gpgpu.downloadByteEncodedFloatMatrixFromOutputTexture(m.texture,m.texShape[0],m.texShape[1]).subarray(0,u);return this.disposeData(d.dataId),y},t.prototype.time=function(t){return n(this,void 0,void 0,function(){var e,n,o,a,i,s,u;return r(this,function(r){switch(r.label){case 0:return e=this.activeTimers,n=[],o=!1,null==this.programTimersStack?(this.programTimersStack=n,o=!0):this.activeTimers.push(n),this.activeTimers=n,t(),a=m(this.activeTimers.map(function(t){return t.query})).filter(function(t){return null!=t}),i=m(this.activeTimers.map(function(t){return t.name})).filter(function(t){return null!=t}),this.activeTimers=e,o&&(this.programTimersStack=null),[4,Promise.all(a)];case 1:return s=r.sent(),u={uploadWaitMs:this.uploadWaitMs,downloadWaitMs:this.downloadWaitMs,kernelMs:p(s),getExtraProfileInfo:function(){return s.map(function(t,e){return{name:i[e],ms:t}}).map(function(t){return t.name+\": \"+t.ms}).join(\", \")},wallMs:null},this.uploadWaitMs=0,this.downloadWaitMs=0,[2,u]}})})},t.prototype.memory=function(){return{unreliable:!1,numBytesInGPU:this.numBytesInGPU}},t.prototype.startTimer=function(){return i.getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\")>0?this.gpgpu.beginQuery():{startMs:$(),endMs:null}},t.prototype.endTimer=function(t){return i.getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\")>0?(this.gpgpu.endQuery(),t):(t.endMs=$(),t)},t.prototype.getQueryTime=function(t){return n(this,void 0,void 0,function(){var e;return r(this,function(n){return i.getNumber(\"WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION\")>0?[2,this.gpgpu.waitForQueryAndGetTime(t)]:[2,(e=t).endMs-e.startMs]})})},t.prototype.disposeData=function(t){if(!this.pendingDisposal.has(t))if(this.pendingRead.has(t))this.pendingDisposal.add(t);else if(this.texData.has(t)){this.releaseGPUData(t);var e=this.texData.get(t).complexTensors;null!=e&&(e.real.dispose(),e.imag.dispose()),this.texData.delete(t)}},t.prototype.releaseGPUData=function(t){var e=this.texData.get(t),n=e.texture,r=e.dtype,o=e.texShape,a=e.usage,i=e.isPacked,s=e.slice,u=s&&s.origDataId||t,l=this.dataRefCount.get(u);l>1?this.dataRefCount.set(u,l-1):(this.dataRefCount.delete(u),null!=n&&(this.numBytesInGPU-=this.computeBytes(o,r),this.textureManager.releaseTexture(n,o,a,i)));var c=this.texData.get(t);c.texture=null,c.texShape=null,c.isPacked=!1,c.slice=null},t.prototype.getTexture=function(t){return this.uploadToGPU(t),this.texData.get(t).texture},t.prototype.getDataInfo=function(t){return this.texData.get(t)},t.prototype.getCPUBackend=function(){return i.getBool(\"WEBGL_CPU_FORWARD\")?(null==this.cpuBackend&&(this.cpuBackend=St.findBackend(\"cpu\")),this.cpuBackend):null},t.prototype.shouldExecuteOnCPU=function(t,e){var n=this;return void 0===e&&(e=128),null!=this.getCPUBackend()&&t.every(function(t){return null==n.texData.get(t.dataId).texture&&t.size<e})},t.prototype.getGPGPUContext=function(){return this.gpgpu},t.prototype.complex=function(t,e){var n=this.makeOutputArray(t.shape,\"complex64\");return this.texData.get(n.dataId).complexTensors={real:St.keep(t.clone()),imag:St.keep(e.clone())},n},t.prototype.real=function(t){return this.texData.get(t.dataId).complexTensors.real.clone()},t.prototype.imag=function(t){return this.texData.get(t.dataId).complexTensors.imag.clone()},t.prototype.slice=function(t,e,n){if(this.shouldExecuteOnCPU([t]))return this.cpuBackend.slice(t,e,n);if(0===g(n))return xn([],n,t.dtype);var r=this.texData.get(t.dataId).isPacked,o=Vr(t.shape,e,n);if(r||!o){var a=i.getBool(\"WEBGL_PACK_ARRAY_OPERATIONS\")?new Ui(n):new Li(n),s=a.getCustomSetupFunc(e);return this.compileAndRun(a,[t],null,s)}return this.uploadToGPU(t.dataId),this.shallowSlice(t,e,n)},t.prototype.shallowSlice=function(t,e,n){var r=this.texData.get(t.dataId),o=ct.make(n,{},t.dtype,this),a=this.texData.get(o.dataId);Object.assign(a,r),a.shape=n,a.dtype=t.dtype;var i=zr(e,t.strides);r.slice&&(i+=r.slice.flatOffset),a.slice={flatOffset:i,origDataId:r.slice&&r.slice.origDataId||t.dataId};var s=this.dataRefCount.get(a.slice.origDataId)||1;return this.dataRefCount.set(a.slice.origDataId,s+1),o},t.prototype.stridedSlice=function(t,e,n,r){if(this.shouldExecuteOnCPU([t]))return this.cpuBackend.stridedSlice(t,e,n,r);var o=Lr(e,n,r);if(o.some(function(t){return 0===t}))return xn([],o);var a=new Vi(e,r,o);return this.compileAndRun(a,[t])},t.prototype.reverse=function(t,e){var n=i.getBool(\"WEBGL_PACK_ARRAY_OPERATIONS\")?new Fi(t.shape,e):new Oi(t.shape,e);return this.compileAndRun(n,[t])},t.prototype.concat=function(t,e){if(\"complex64\"===t[0].dtype){var n=t.map(function(t){return gn(t)}),r=t.map(function(t){return yn(t)});return mn(this.concat(n,e),this.concat(r,e))}if(this.shouldExecuteOnCPU(t))return this.cpuBackend.concat(t,e);if(1===t.length)return t[0];if(t.length>i.getNumber(\"WEBGL_MAX_TEXTURES_IN_SHADER\")){var o=Math.floor(t.length/2),a=this.concat(t.slice(0,o),e),s=this.concat(t.slice(o),e);return this.concat([a,s],e)}if(i.getBool(\"WEBGL_PACK_ARRAY_OPERATIONS\")&&t[0].rank>1){var u=new ma(t.map(function(t){return t.shape}),e);return this.compileAndRun(u,t)}var l=dn(t.map(function(t){return t.shape}),e),c=t.map(function(t){return t.as2D(-1,g(t.shape.slice(e)))}),h=new va(c.map(function(t){return t.shape}));return this.compileAndRun(h,c).reshape(l)},t.prototype.neg=function(t){if(this.shouldExecuteOnCPU([t]))return this.cpuBackend.neg(t);if(i.getBool(\"WEBGL_PACK_UNARY_OPERATIONS\"))return this.packedUnaryOp(t,rs,t.dtype);var e=new Yi(t.shape,rs);return this.compileAndRun(e,[t])},t.prototype.batchMatMul=function(t,e,n,r){var o=n?t.shape[2]:t.shape[1],a=r?e.shape[1]:e.shape[2],i=n?t.shape[1]:t.shape[2],s=t.shape[0];if((1===o||1===a)&&i>1e3){n&&(t=t.transpose([0,2,1])),r&&(e=e.transpose([0,2,1]));var u=1===a?t:t.as3D(s,i,1),l=1===a?2:1,c=1===a?e.as3D(s,1,i):e;return this.multiply(u,c).sum(l,!0)}var h=xt(t.dtype,e.dtype),p=new yi(t.shape,[s,o,a],n,r),f=this.makePackedTensor(p.outputShape,h);return this.compileAndRun(p,[t,e],f)},t.prototype.fusedBatchMatMul=function(t){var e=t.a,n=t.b,r=t.transposeA,o=t.transposeB,a=t.bias,i=t.activation,s=t.preluActivationWeights,u=r?e.shape[2]:e.shape[1],l=o?n.shape[1]:n.shape[2],c=e.shape[0],h=xt(e.dtype,n.dtype),p=null!=a,f=null!=s,d=i?bs(i,!0):null,v=new yi(e.shape,[c,u,l],r,o,p,d,f),m=this.makePackedTensor(v.outputShape,h),g=[e,n];return a&&g.push(a),s&&g.push(s),this.compileAndRun(v,g,m)},t.prototype.multiply=function(t,e){if(\"complex64\"===t.dtype){var n=this.texData.get(t.dataId),r=this.texData.get(e.dataId),o=new oa(na,t.shape,e.shape),a=new oa(ra,t.shape,e.shape),s=[this.makeComplexComponentTensorHandle(t,n.complexTensors.real),this.makeComplexComponentTensorHandle(t,n.complexTensors.imag),this.makeComplexComponentTensorHandle(e,r.complexTensors.real),this.makeComplexComponentTensorHandle(e,r.complexTensors.imag)],u=this.compileAndRun(o,s),l=this.compileAndRun(a,s),c=this.complex(u,l);return u.dispose(),l.dispose(),c}if(this.shouldExecuteOnCPU([t,e]))return this.cpuBackend.multiply(t,e);if(i.getBool(\"WEBGL_PACK_BINARY_OPERATIONS\"))return this.packedBinaryOp(t,e,sa,t.dtype);var h=new la(sa,t.shape,e.shape),p=this.makeOutputArray(h.outputShape,t.dtype);return this.compileAndRun(h,[t,e],p)},t.prototype.batchNormalization=function(t,e,n,r,o,a){var s=[t,e,n],u=null;null!=a&&(u=a.shape,s.push(a));var l=null;if(null!=o&&(l=o.shape,s.push(o)),i.getBool(\"WEBGL_PACK_NORMALIZATION\")){var c=new ea(t.shape,e.shape,n.shape,u,l,r);return this.compileAndRun(c,s)}var h=new ta(t.shape,e.shape,n.shape,u,l,r);return this.compileAndRun(h,s)},t.prototype.localResponseNormalization4D=function(t,e,n,r,o){var a=i.getBool(\"WEBGL_PACK_NORMALIZATION\")?new vi(t.shape,e,n,r,o):new fi(t.shape,e,n,r,o);return this.compileAndRun(a,[t])},t.prototype.LRNGrad=function(t,e,n,r,o,a,i){var s=new di(e.shape,r,o,a,i);return this.compileAndRun(s,[e,n,t])},t.prototype.tile=function(t,e){if(\"string\"===t.dtype){var n=this.readSync(t.dataId).map(function(t){return X(t)});return No(Zn(t.shape,t.dtype,n),e)}var r=new qi(t.shape,e);return this.compileAndRun(r,[t])},t.prototype.pad=function(t,e,n){var r=i.getBool(\"WEBGL_PACK_ARRAY_OPERATIONS\")?new Ei(t.shape,e,n):new Ci(t.shape,e,n);return this.compileAndRun(r,[t])},t.prototype.transpose=function(t,e){if(this.shouldExecuteOnCPU([t]))return this.cpuBackend.transpose(t,e);var n=i.getBool(\"WEBGL_PACK_ARRAY_OPERATIONS\")?new Ki(t.shape,e):new $i(t.shape,e);return this.compileAndRun(n,[t])},t.prototype.gather=function(t,e,n){if(this.shouldExecuteOnCPU([t,e]))return this.cpuBackend.gather(t,e,n);var r=new Ha(t.shape,e.size,n);return this.compileAndRun(r,[t,e])},t.prototype.batchToSpaceND=function(t,e,n){f(t.rank<=4,function(){return\"batchToSpaceND for rank > 4 with a WebGL backend not implemented yet\"});var r=e.reduce(function(t,e){return t*e}),o=Nr(t.shape,e,r),a=Sr(o.length,e.length),i=Ar(t.shape,e,r),s=Tr(n,e.length),u=Dr(i,n,e.length);return t.reshape(o).transpose(a).reshape(i).slice(s,u)},t.prototype.spaceToBatchND=function(t,e,n){f(t.rank<=4,function(){return\"spaceToBatchND for rank > 4 with a WebGL backend not implemented yet\"});var r=e.reduce(function(t,e){return t*e}),o=[[0,0]];o.push.apply(o,n);for(var a=1+e.length;a<t.shape.length;++a)o.push([0,0]);var i=t.pad(o),s=Nr(i.shape,e,r,!1),u=Sr(s.length,e.length,!1),l=Ar(i.shape,e,r,!1);return i.reshape(s).transpose(u).reshape(l)},t.prototype.reduce=function(t,e,n){var r=t.shape[0],o=t.shape[1],a=Fr(o),i=new ki({windowSize:a,inSize:o,batchSize:r},e),s=i.outputShape,u=s[0],l=s[1],c=this.makeOutputArray([u,l],n);return this.compileAndRun(i,[t],c),1===c.shape[1]?c:this.reduce(c,e,n)},t.prototype.argReduce=function(t,e,n){void 0===n&&(n=null);var r=t.shape[0],o=t.shape[1];null!=n&&(r=n.shape[0],o=n.shape[1]);var a=Fr(o),i=new _o({windowSize:a,inSize:o,batchSize:r},e,null==n),s=i.outputShape,u=s[0],l=s[1],c=this.makeOutputArray([u,l],\"int32\"),h=[t];return null!=n&&h.push(n),this.compileAndRun(i,h,c),1===c.shape[1]?c:this.argReduce(t,e,c)},t.prototype.argReducePacked=function(t,e,n){void 0===n&&(n=null);var r=null!=n?n.shape:t.shape,o=Fr(r[r.length-1]),a=new Qo(r,o,e,null==n),i=this.makePackedTensor(a.outputShape,\"int32\"),s=null==n?[t]:[t,n];return this.compileAndRun(a,s,i),i.rank===t.rank?this.argReducePacked(t,e,i):i},t.prototype.sum=function(t,e){ln(\"sum\",e,t.rank);var n=sn(t.shape,e),r=n[0],o=g(n[1]),a=t.as2D(-1,o),i=bt(t.dtype);return this.reduce(a,\"sum\",i).reshape(r)},t.prototype.prod=function(t,e){if(this.shouldExecuteOnCPU([t]))return this.cpuBackend.prod(t,e);var n=sn(t.shape,e),r=n[0],o=g(n[1]),a=t.as2D(-1,o),i=bt(t.dtype);return this.reduce(a,\"prod\",i).reshape(r)},t.prototype.unsortedSegmentSum=function(t,e,n){var r=0,o=cn([r],t.rank),a=t;null!=o&&(a=t.transpose(o),r=pn(1,t.rank)[0]);var i=function(t,e,n){for(var r=[],o=t.length,a=0;a<o;a++)a!==e?r.push(t[a]):r.push(n);return r}(a.shape,r,n),s=g([a.shape[r]]),u=a.as2D(-1,s),l=bt(t.dtype),c=this.segOpCompute(u,\"unsortedSegmentSum\",e,l,n).reshape(i);return null!=o&&(c=c.transpose(hn(o))),c},t.prototype.segOpCompute=function(t,e,n,r,o){var a=t.shape[0],i=t.shape[1],s=function(t,e){var n,r=!1;for(t<=Or?(n=t,r=!0):n=U(t,Math.floor(Math.sqrt(t)));!r;)n>e||n===t?r=!0:n=U(t,n+1);return n}(i,o),u=new Bi({windowSize:s,inSize:i,batchSize:a,numSegments:o},e),l=u.outputShape,c=l[0],h=l[1],p=this.makeOutputArray([c,h],r);return this.compileAndRun(u,[t,n],p),p.shape[1]===o?p:(n=_n(0,o).tile([i/s]),this.segOpCompute(p,e,n,r,o))},t.prototype.argMinMaxReduce=function(t,e,n){var r=[e];if(ln(\"arg\"+n.charAt(0).toUpperCase()+n.slice(1),r,t.rank),!i.getBool(\"WEBGL_PACK_REDUCE\")||t.rank<=2){var o=sn(t.shape,r),a=o[0],s=g(o[1]),u=t.as2D(-1,s);return this.argReduce(u,n).reshape(a)}return this.argReducePacked(t,n)},t.prototype.argMin=function(t,e){return this.argMinMaxReduce(t,e,\"min\")},t.prototype.argMax=function(t,e){return this.argMinMaxReduce(t,e,\"max\")},t.prototype.cumsum=function(t,e,n,r){if(e!==t.rank-1)throw new Error(\"WebGL cumsum shader expects an inner-most axis=\"+(t.rank-1)+\" but got axis=\"+e);var o=new Sa(t.shape,n,r);return this.compileAndRun(o,[t])},t.prototype.equal=function(t,e){if(i.getBool(\"WEBGL_PACK_BINARY_OPERATIONS\"))return this.packedBinaryOp(t,e,\"\\n  return vec4(equal(a, b));\\n\",\"bool\");var n=new la(\"return float(a == b);\",t.shape,e.shape),r=this.makeOutputArray(n.outputShape,\"bool\");return this.compileAndRun(n,[t,e],r)},t.prototype.notEqual=function(t,e){if(i.getBool(\"WEBGL_PACK_BINARY_OPERATIONS\"))return this.packedBinaryOp(t,e,\"\\n  return vec4(notEqual(a, b));\\n\",\"bool\");var n=new la(\"return float(a != b);\",t.shape,e.shape),r=this.makeOutputArray(n.outputShape,\"bool\");return this.compileAndRun(n,[t,e],r)},t.prototype.less=function(t,e){if(this.shouldExecuteOnCPU([t,e]))return this.cpuBackend.less(t,e);if(i.getBool(\"WEBGL_PACK_BINARY_OPERATIONS\"))return this.packedBinaryOp(t,e,\"\\n  return vec4(lessThan(a, b));\\n\",\"bool\");var n=new la(\"return float(a < b);\",t.shape,e.shape),r=this.makeOutputArray(n.outputShape,\"bool\");return this.compileAndRun(n,[t,e],r)},t.prototype.lessEqual=function(t,e){if(i.getBool(\"WEBGL_PACK_BINARY_OPERATIONS\"))return this.packedBinaryOp(t,e,\"\\n  return vec4(lessThanEqual(a, b));\\n\",\"bool\");var n=new la(\"return float(a <= b);\",t.shape,e.shape),r=this.makeOutputArray(n.outputShape,\"bool\");return this.compileAndRun(n,[t,e],r)},t.prototype.greater=function(t,e){if(this.shouldExecuteOnCPU([t,e]))return this.cpuBackend.greater(t,e);if(i.getBool(\"WEBGL_PACK_BINARY_OPERATIONS\"))return this.packedBinaryOp(t,e,\"\\n  return vec4(greaterThan(a, b));\\n\",\"bool\");var n=new la(\"return float(a > b);\",t.shape,e.shape),r=this.makeOutputArray(n.outputShape,\"bool\");return this.compileAndRun(n,[t,e],r)},t.prototype.greaterEqual=function(t,e){if(i.getBool(\"WEBGL_PACK_BINARY_OPERATIONS\"))return this.packedBinaryOp(t,e,\"\\n  return vec4(greaterThanEqual(a, b));\\n\",\"bool\");var n=new la(\"return float(a >= b);\",t.shape,e.shape),r=this.makeOutputArray(n.outputShape,\"bool\");return this.compileAndRun(n,[t,e],r)},t.prototype.logicalNot=function(t){var e=new Yi(t.shape,\"return float(!(x >= 1.0));\");return this.compileAndRun(e,[t])},t.prototype.logicalAnd=function(t,e){if(i.getBool(\"WEBGL_PACK_BINARY_OPERATIONS\"))return this.packedBinaryOp(t,e,\"\\n  return vec4(\\n    vec4(greaterThanEqual(a, vec4(1.0))) *\\n    vec4(greaterThanEqual(b, vec4(1.0))));\\n\",\"bool\");var n=new la(\"return float(a >= 1.0 && b >= 1.0);\",t.shape,e.shape),r=this.makeOutputArray(n.outputShape,\"bool\");return this.compileAndRun(n,[t,e],r)},t.prototype.logicalOr=function(t,e){if(i.getBool(\"WEBGL_PACK_BINARY_OPERATIONS\"))return this.packedBinaryOp(t,e,\"\\n  return min(\\n    vec4(greaterThanEqual(a, vec4(1.0))) +\\n    vec4(greaterThanEqual(b, vec4(1.0))),\\n    vec4(1.0));\\n\",\"bool\");var n=new la(\"return float(a >= 1.0 || b >= 1.0);\",t.shape,e.shape),r=this.makeOutputArray(n.outputShape,\"bool\");return this.compileAndRun(n,[t,e],r)},t.prototype.select=function(t,e,n){var r=new Pi(t.rank,e.shape,e.rank),o=this.makeOutputArray(r.outputShape,xt(e.dtype,n.dtype));return this.compileAndRun(r,[t,e,n],o)},t.prototype.where=function(t){Ze(\"tf.where() in webgl locks the UI thread. Call tf.whereAsync() instead\");var e=t.dataSync();return Ao(t.shape,e)},t.prototype.topk=function(t,e,n){return So(t.dataSync(),t.shape,t.dtype,e)},t.prototype.min=function(t,e){ln(\"min\",e,t.rank);var n=sn(t.shape,e),r=n[0],o=g(n[1]),a=t.as2D(-1,o);return this.reduce(a,\"min\",a.dtype).reshape(r)},t.prototype.minimum=function(t,e){if(this.shouldExecuteOnCPU([t,e]))return this.cpuBackend.minimum(t,e);var n=i.getBool(\"WEBGL_PACK_BINARY_OPERATIONS\")?new ha(\"\\n  vec4 result = vec4(min(a, b));\\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\\n  \\n  result.r = isNaN.r > 0. ? NAN : result.r;\\n  result.g = isNaN.g > 0. ? NAN : result.g;\\n  result.b = isNaN.b > 0. ? NAN : result.b;\\n  result.a = isNaN.a > 0. ? NAN : result.a;\\n\\n  return result;\\n\",t.shape,e.shape):new la(\"\\n  if (isnan(a)) return a;\\n  if (isnan(b)) return b;\\n\\n  return min(a, b);\\n\",t.shape,e.shape);return this.compileAndRun(n,[t,e])},t.prototype.mod=function(t,e){var n=i.getBool(\"WEBGL_PACK_BINARY_OPERATIONS\")?new ha(\"\\n  vec4 result = mod(a, b);\\n  vec4 isNaN = vec4(equal(b, vec4(0.0)));\\n  \\n  result.r = isNaN.r > 0. ? NAN : result.r;\\n  result.g = isNaN.g > 0. ? NAN : result.g;\\n  result.b = isNaN.b > 0. ? NAN : result.b;\\n  result.a = isNaN.a > 0. ? NAN : result.a;\\n\\n  return result;\\n\",t.shape,e.shape):new la(\"if (b == 0.0) return NAN;\\n  return mod(a, b);\",t.shape,e.shape);return this.compileAndRun(n,[t,e])},t.prototype.max=function(t,e){if(this.shouldExecuteOnCPU([t]))return this.cpuBackend.max(t,e);ln(\"max\",e,t.rank);var n=sn(t.shape,e),r=n[0],o=g(n[1]),a=t.as2D(-1,o);return this.reduce(a,\"max\",a.dtype).reshape(r)},t.prototype.maximum=function(t,e){if(this.shouldExecuteOnCPU([t,e]))return this.cpuBackend.maximum(t,e);var n=i.getBool(\"WEBGL_PACK_BINARY_OPERATIONS\")?new ha(\"\\n  vec4 result = vec4(max(a, b));\\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\\n  \\n  result.r = isNaN.r > 0. ? NAN : result.r;\\n  result.g = isNaN.g > 0. ? NAN : result.g;\\n  result.b = isNaN.b > 0. ? NAN : result.b;\\n  result.a = isNaN.a > 0. ? NAN : result.a;\\n\\n  return result;\\n\",t.shape,e.shape):new la(\"\\n  if (isnan(a)) return a;\\n  if (isnan(b)) return b;\\n\\n  return max(a, b);\\n\",t.shape,e.shape);return this.compileAndRun(n,[t,e])},t.prototype.all=function(t,e){ln(\"all\",e,t.rank);var n=sn(t.shape,e),r=n[0],o=g(n[1]),a=t.as2D(-1,o);return this.reduce(a,\"all\",a.dtype).reshape(r)},t.prototype.any=function(t,e){ln(\"any\",e,t.rank);var n=sn(t.shape,e),r=n[0],o=g(n[1]),a=t.as2D(-1,o);return this.reduce(a,\"any\",a.dtype).reshape(r)},t.prototype.squaredDifference=function(t,e){var n=i.getBool(\"WEBGL_PACK_BINARY_OPERATIONS\")?new ha(\"return (a - b) * (a - b);\",t.shape,e.shape):new la(\"return (a - b) * (a - b);\",t.shape,e.shape);return this.compileAndRun(n,[t,e])},t.prototype.realDivide=function(t,e){if(i.getBool(\"WEBGL_PACK_BINARY_OPERATIONS\")){return this.packedBinaryOp(t,e,\"\\n  // vec4 one = vec4(equal(a, b));\\n  // return one + (vec4(1.0) - one) * a / b;\\n  vec4 result = a / b;\\n  if(b.x == 0.0) {\\n    result.x = NAN;\\n  } else if(a.x == b.x) {\\n    result.x = 1.;\\n  }\\n  if(b.y == 0.0) {\\n    result.y = NAN;\\n  } else if(a.y == b.y) {\\n    result.y = 1.;\\n  }\\n  if(b.z == 0.0) {\\n    result.z = NAN;\\n  } else if(a.z == b.z) {\\n    result.z = 1.;\\n  }\\n  if(b.w == 0.0) {\\n    result.w = NAN;\\n  } else if(a.w == b.w) {\\n    result.w = 1.;\\n  }\\n\\n  return result;\\n\",\"float32\",!0)}var n=new la(\"\\nif (b == 0.0) {\\n  return NAN;\\n}\\nif (a == b) {\\n  return 1.0;\\n};\\nreturn a / b;\",t.shape,e.shape),r=this.makeOutputArray(n.outputShape,\"float32\");return this.compileAndRun(n,[t,e],r)},t.prototype.floorDiv=function(t,e){if(i.getBool(\"WEBGL_PACK_BINARY_OPERATIONS\"))return this.packedBinaryOp(t,e,\"\\n  ivec4 ia = round(a);\\n  ivec4 ib = round(b);\\n  bvec4 cond = notEqual(ib, ivec4(0));\\n  ivec4 result = ivec4(0);\\n  vec4 s = sign(a) * sign(b);\\n\\n  // Windows (D3D) wants guaranteed non-zero int division at compile-time.\\n  if (cond[0]) {\\n    result[0] = idiv(ia[0], ib[0], s[0]);\\n  }\\n  if (cond[1]) {\\n    result[1] = idiv(ia[1], ib[1], s[1]);\\n  }\\n  if (cond[2]) {\\n    result[2] = idiv(ia[2], ib[2], s[2]);\\n  }\\n  if (cond[3]) {\\n    result[3] = idiv(ia[3], ib[3], s[3]);\\n  }\\n  return vec4(result);\\n\",\"int32\");var n=new la(\"\\n  float s = sign(a) * sign(b);\\n  int ia = round(a);\\n  int ib = round(b);\\n  if (ib != 0) {\\n    // Windows (D3D) wants guaranteed non-zero int division at compile-time.\\n    return float(idiv(ia, ib, s));\\n  } else {\\n    return NAN;\\n  }\\n\",t.shape,e.shape),r=this.makeOutputArray(n.outputShape,\"int32\");return this.compileAndRun(n,[t,e],r)},t.prototype.add=function(t,e){if(\"complex64\"===t.dtype&&\"complex64\"===e.dtype)return this.complexSeparableBinaryOp(t,e,aa);if(this.shouldExecuteOnCPU([t,e]))return this.cpuBackend.add(t,e);var n=xt(t.dtype,e.dtype);if(i.getBool(\"WEBGL_PACK_BINARY_OPERATIONS\"))return this.packedBinaryOp(t,e,aa,n);var r=new la(aa,t.shape,e.shape),o=this.makeOutputArray(r.outputShape,n);return this.compileAndRun(r,[t,e],o)},t.prototype.packedUnaryOp=function(t,e,n){var r=new gs(t.shape,e),o=this.makePackedTensor(r.outputShape,n);return this.compileAndRun(r,[t],o)},t.prototype.packedBinaryOp=function(t,e,n,r,o){void 0===o&&(o=!1);var a=new ha(n,t.shape,e.shape,o),i=this.makePackedTensor(a.outputShape,r);return this.compileAndRun(a,[t,e],i)},t.prototype.complexSeparableBinaryOp=function(t,e,n){var r=this,o=this.texData.get(t.dataId),a=this.texData.get(e.dataId),i=[[o.complexTensors.real,a.complexTensors.real],[o.complexTensors.imag,a.complexTensors.imag]].map(function(o){var a=o[0],i=o[1],s=r.makeComplexComponentTensorHandle(t,a),u=r.makeComplexComponentTensorHandle(e,i),l=new la(n,t.shape,e.shape),c=r.makeOutputArray(l.outputShape,xt(a.dtype,i.dtype));return r.compileAndRun(l,[s,u],c)}),s=i[0],u=i[1],l=this.complex(s,u);return s.dispose(),u.dispose(),l},t.prototype.makeComplexComponentTensorHandle=function(t,e){return{dataId:e.dataId,dtype:e.dtype,shape:t.shape}},t.prototype.addN=function(t){if(1===t.length)return t[0];if(t.length>i.get(\"WEBGL_MAX_TEXTURES_IN_SHADER\")){var e=Math.floor(t.length/2),n=this.addN(t.slice(0,e)),r=this.addN(t.slice(e));return this.addN([n,r])}var o=t.map(function(t){return t.dtype}).reduce(function(t,e){return xt(t,e)}),a=t.map(function(t){return t.shape}),s=i.getBool(\"WEBGL_PACK\"),u=s?new Do(t[0].shape,a):new To(t[0].shape,a),l=s?this.makePackedTensor(u.outputShape,o):this.makeOutputArray(u.outputShape,o);return this.compileAndRun(u,t,l)},t.prototype.subtract=function(t,e){if(\"complex64\"===t.dtype&&\"complex64\"===e.dtype)return this.complexSeparableBinaryOp(t,e,ia);if(this.shouldExecuteOnCPU([t,e]))return this.cpuBackend.subtract(t,e);var n=xt(t.dtype,e.dtype);if(i.getBool(\"WEBGL_PACK_BINARY_OPERATIONS\"))return this.packedBinaryOp(t,e,ia,t.dtype);var r=new la(ia,t.shape,e.shape),o=this.makeOutputArray(r.outputShape,n);return this.compileAndRun(r,[t,e],o)},t.prototype.pow=function(t,e){var n=i.getBool(\"WEBGL_PACK_BINARY_OPERATIONS\"),r=n?new ha(\"\\n  // isModRound1 has 1 for components with round(mod(b, 2.0)) == 1, 0 otherwise.\\n  vec4 isModRound1 = vec4(equal(round(mod(b, 2.0)), ivec4(1)));\\n  vec4 multiplier = sign(a) * isModRound1 + (vec4(1.0) - isModRound1);\\n  vec4 result = multiplier * pow(abs(a), b);\\n\\n  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS\\n  bvec4 isExpZero = equal(b, vec4(0.0));\\n  result.r = isExpZero.r ? 1.0 : result.r;\\n  result.g = isExpZero.g ? 1.0 : result.g;\\n  result.b = isExpZero.b ? 1.0 : result.b;\\n  result.a = isExpZero.a ? 1.0 : result.a;\\n\\n  vec4 isNaN = vec4(lessThan(a, vec4(0.0))) * vec4(lessThan(floor(b), b));\\n  \\n  result.r = isNaN.r > 0. ? NAN : result.r;\\n  result.g = isNaN.g > 0. ? NAN : result.g;\\n  result.b = isNaN.b > 0. ? NAN : result.b;\\n  result.a = isNaN.a > 0. ? NAN : result.a;\\n\\n  return result;\\n\",t.shape,e.shape):new la(\"\\nif(a < 0.0 && floor(b) < b){\\n  return NAN;\\n}\\nif (b == 0.0) {\\n  return 1.0;\\n}\\nreturn (round(mod(b, 2.0)) != 1) ?\\n    pow(abs(a), b) : sign(a) * pow(abs(a), b);\\n\",t.shape,e.shape),o=xt(t.dtype,e.dtype),a=n?this.makePackedTensor(r.outputShape,o):this.makeOutputArray(r.outputShape,o);return this.compileAndRun(r,[t,e],a)},t.prototype.ceil=function(t){if(this.shouldExecuteOnCPU([t]))return this.cpuBackend.ceil(t);if(i.getBool(\"WEBGL_PACK_UNARY_OPERATIONS\"))return this.packedUnaryOp(t,os,t.dtype);var e=new Yi(t.shape,os);return this.compileAndRun(e,[t])},t.prototype.floor=function(t){if(this.shouldExecuteOnCPU([t]))return this.cpuBackend.floor(t);if(i.getBool(\"WEBGL_PACK_UNARY_OPERATIONS\"))return this.packedUnaryOp(t,as,t.dtype);var e=new Yi(t.shape,as);return this.compileAndRun(e,[t])},t.prototype.sign=function(t){var e=new Yi(t.shape,\"\\n  if (isnan(x)) { return 0.0; }\\n  return sign(x);\\n\");return this.compileAndRun(e,[t])},t.prototype.isNaN=function(t){var e=new Yi(t.shape,\"return float(isnan(x));\"),n=this.makeOutputArray(e.outputShape,\"bool\");return this.compileAndRun(e,[t],n)},t.prototype.isInf=function(t){var e=new Yi(t.shape,\"return float(isinf(x));\"),n=this.makeOutputArray(e.outputShape,\"bool\");return this.compileAndRun(e,[t],n)},t.prototype.isFinite=function(t){var e=new Yi(t.shape,\"return float(!isnan(x) && !isinf(x));\"),n=this.makeOutputArray(e.outputShape,\"bool\");return this.compileAndRun(e,[t],n)},t.prototype.round=function(t){var e=new Yi(t.shape,\"\\n  // OpenGL ES does not support round function.\\n  // The algorithm is based on banker's rounding.\\n  float base = floor(x);\\n  if ((x - base) < 0.5) {\\n    return floor(x);\\n  } else if ((x - base) > 0.5) {\\n    return ceil(x);\\n  } else {\\n    if (mod(base, 2.0) == 0.0) {\\n      return base;\\n    } else {\\n      return base + 1.0;\\n    }\\n  }\\n\");return this.compileAndRun(e,[t])},t.prototype.exp=function(t){if(this.shouldExecuteOnCPU([t]))return this.cpuBackend.exp(t);if(i.getBool(\"WEBGL_PACK_UNARY_OPERATIONS\"))return this.packedUnaryOp(t,is,t.dtype);var e=new Yi(t.shape,is);return this.compileAndRun(e,[t])},t.prototype.expm1=function(t){if(this.shouldExecuteOnCPU([t]))return this.cpuBackend.expm1(t);if(i.getBool(\"WEBGL_PACK_UNARY_OPERATIONS\"))return this.packedUnaryOp(t,ss,t.dtype);var e=new Yi(t.shape,ss);return this.compileAndRun(e,[t])},t.prototype.log=function(t){if(this.shouldExecuteOnCPU([t]))return this.cpuBackend.log(t);if(i.getBool(\"WEBGL_PACK_UNARY_OPERATIONS\"))return this.packedUnaryOp(t,\"\\n  vec4 result = log(x);\\n  vec4 isNaN = vec4(lessThan(x, vec4(0.0)));\\n  result.r = isNaN.r == 1.0 ? NAN : result.r;\\n  result.g = isNaN.g == 1.0 ? NAN : result.g;\\n  result.b = isNaN.b == 1.0 ? NAN : result.b;\\n  result.a = isNaN.a == 1.0 ? NAN : result.a;\\n\\n  return result;\\n\",t.dtype);var e=new Yi(t.shape,\"if (x < 0.0) return NAN;\\n  return log(x);\");return this.compileAndRun(e,[t])},t.prototype.log1p=function(t){var e=new Yi(t.shape,\"return log(1.0 + x);\");return this.compileAndRun(e,[t])},t.prototype.sqrt=function(t){var e=new Yi(t.shape,\"return sqrt(x);\");return this.compileAndRun(e,[t])},t.prototype.rsqrt=function(t){if(this.shouldExecuteOnCPU([t]))return this.cpuBackend.rsqrt(t);var e=new Yi(t.shape,\"return inversesqrt(x);\");return this.compileAndRun(e,[t])},t.prototype.square=function(t){var e=new Yi(t.shape,\"return x * x;\");return this.compileAndRun(e,[t])},t.prototype.reciprocal=function(t){var e=new Yi(t.shape,\"return 1.0 / x;\");return this.compileAndRun(e,[t])},t.prototype.relu=function(t){var e;return e=i.getBool(\"WEBGL_PACK\")?new gs(t.shape,vs):new Yi(t.shape,ts),this.compileAndRun(e,[t])},t.prototype.prelu=function(t,e){var n=i.getBool(\"WEBGL_PACK_BINARY_OPERATIONS\")?new ha(ca,t.shape,e.shape):new la(ua,t.shape,e.shape);return this.compileAndRun(n,[t,e])},t.prototype.elu=function(t){if(i.getBool(\"WEBGL_PACK_UNARY_OPERATIONS\"))return this.packedUnaryOp(t,ms,t.dtype);var e=new Yi(t.shape,es);return this.compileAndRun(e,[t])},t.prototype.eluDer=function(t,e){var n=i.getBool(\"WEBGL_PACK_BINARY_OPERATIONS\")?new ha(\"\\n  vec4 bGTEZero = vec4(greaterThanEqual(b, vec4(0.)));\\n  return (bGTEZero * a) + ((vec4(1.0) - bGTEZero) * (a * (b + vec4(1.0))));\\n\",t.shape,e.shape):new la(\"return (b >= 1.0) ? a : a * (b + 1.0);\",t.shape,e.shape);return this.compileAndRun(n,[t,e])},t.prototype.selu=function(t){var e=new Yi(t.shape,ns);return this.compileAndRun(e,[t])},t.prototype.int=function(t){var e=new Yi(t.shape,\"return float(int(x));\"),n=this.makeOutputArray(e.outputShape,\"int32\");return this.compileAndRun(e,[t],n)},t.prototype.clip=function(t,e,n){var r,o=(r=i.getBool(\"WEBGL_PACK_CLIP\")?new fa(t.shape):new pa(t.shape)).getCustomSetupFunc(e,n);return this.compileAndRun(r,[t],null,o)},t.prototype.abs=function(t){if(this.shouldExecuteOnCPU([t]))return this.cpuBackend.abs(t);if(i.getBool(\"WEBGL_PACK_UNARY_OPERATIONS\"))return this.packedUnaryOp(t,Zi,t.dtype);var e=new Yi(t.shape,Zi);return this.compileAndRun(e,[t])},t.prototype.complexAbs=function(t){var e=this.texData.get(t.dataId),n=new da(t.shape),r=[this.makeComplexComponentTensorHandle(t,e.complexTensors.real),this.makeComplexComponentTensorHandle(t,e.complexTensors.imag)];return this.compileAndRun(n,r)},t.prototype.sigmoid=function(t){var e=new Yi(t.shape,\"return 1.0 / (1.0 + exp(-1.0 * x));\");return this.compileAndRun(e,[t])},t.prototype.softplus=function(t){var e=new Yi(t.shape,\"\\n  float epsilon = 1.1920928955078125e-7;\\n  float threshold = log(epsilon) + 2.0;\\n\\n  bool too_large = x > -threshold;\\n  bool too_small = x < threshold;\\n\\n  float result;\\n  float exp_x = exp(x);\\n\\n  if (too_large){\\n    result = x;\\n  }\\n  else if (too_small){\\n    result = exp_x;\\n  }\\n  else{\\n    result = log(exp_x + 1.0);\\n  }\\n  return result;\\n\");return this.compileAndRun(e,[t])},t.prototype.sin=function(t){var e=new Yi(t.shape,us);return this.compileAndRun(e,[t])},t.prototype.cos=function(t){var e=new Yi(t.shape,ls);return this.compileAndRun(e,[t])},t.prototype.tan=function(t){var e=new Yi(t.shape,\"return tan(x);\");return this.compileAndRun(e,[t])},t.prototype.asin=function(t){var e=new Yi(t.shape,\"return asin(x);\");return this.compileAndRun(e,[t])},t.prototype.acos=function(t){var e=new Yi(t.shape,\"return acos(x);\");return this.compileAndRun(e,[t])},t.prototype.atan=function(t){var e=new Yi(t.shape,cs);return this.compileAndRun(e,[t])},t.prototype.atan2=function(t,e){var n=i.getBool(\"WEBGL_PACK_BINARY_OPERATIONS\")?new ha(\"\\n  vec4 result = atan(a, b);\\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\\n  \\n  result.r = isNaN.r > 0. ? NAN : result.r;\\n  result.g = isNaN.g > 0. ? NAN : result.g;\\n  result.b = isNaN.b > 0. ? NAN : result.b;\\n  result.a = isNaN.a > 0. ? NAN : result.a;\\n\\n  return result;\\n\",t.shape,e.shape):new la(\"\\n  if (isnan(a)) return a;\\n  if (isnan(b)) return b;\\n\\n  return atan(a, b);\\n\",t.shape,e.shape);return this.compileAndRun(n,[t,e])},t.prototype.sinh=function(t){var e=new Yi(t.shape,\"\\n  float e2x = exp(x);\\n  return (e2x - 1.0 / e2x) / 2.0;\\n\");return this.compileAndRun(e,[t])},t.prototype.cosh=function(t){var e=new Yi(t.shape,\"\\n  float e2x = exp(-x);\\n  return (e2x + 1.0 / e2x) / 2.0;\\n\");return this.compileAndRun(e,[t])},t.prototype.tanh=function(t){var e=new Yi(t.shape,\"\\n  float e2x = exp(-2.0 * abs(x));\\n  return sign(x) * (1.0 - e2x) / (1.0 + e2x);\\n\");return this.compileAndRun(e,[t])},t.prototype.asinh=function(t){var e=new Yi(t.shape,\"return log(x + sqrt(x * x + 1.0));\");return this.compileAndRun(e,[t])},t.prototype.acosh=function(t){var e=new Yi(t.shape,hs);return this.compileAndRun(e,[t])},t.prototype.atanh=function(t){var e=new Yi(t.shape,ps);return this.compileAndRun(e,[t])},t.prototype.erf=function(t){var e=new Yi(t.shape,'\\n  // Error function is calculated approximately with elementary function.\\n  // See \"Handbook of Mathematical Functions with Formulas,\\n  // Graphs, and Mathematical Tables\", Abramowitz and Stegun.\\n  float p = 0.3275911;\\n  float a1 = 0.254829592;\\n  float a2 = -0.284496736;\\n  float a3 = 1.421413741;\\n  float a4 = -1.453152027;\\n  float a5 = 1.061405429;\\n\\n  float t = 1.0 / (1.0 + p * x);\\n  return 1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*exp(-x*x);\\n');return this.compileAndRun(e,[t])},t.prototype.step=function(t,e){var n=new Yi(t.shape,function(t){return void 0===t&&(t=0),Qi+\"\\n    return x > 0.0 ? 1.0 : float(\"+t+\");\\n  \"}(e));return this.compileAndRun(n,[t])},t.prototype.conv2dByMatMul=function(t,e,n,r,o,a){var s=t.shape,u=this.texData.get(t.dataId),l=n.inChannels,c=s[0]*s[1]*s[2],h=n.outChannels,p=\"channelsLast\"===n.dataFormat,d=(1===c||1===h)&&l>1e3,v=s[2]%2!=0&&!!u.isPacked;if(d||!i.getBool(\"WEBGL_LAZILY_UNPACK\")||!i.getBool(\"WEBGL_PACK_BINARY_OPERATIONS\")||!v){var m=p?s[0]*s[1]*s[2]:s[0]*s[2]*s[3],g=this.reshape(t,[1,m,n.inChannels]),y=this.reshape(e,[1,n.inChannels,n.outChannels]);return this.reshape(this.fusedBatchMatMul({a:g,b:y,transposeA:!1,transposeB:!1,bias:r,activation:o,preluActivationWeights:a}),n.outShape)}var x=p?s[0]*s[1]*(s[2]+1):s[0]*s[2]*(s[3]+1),b=ct.make([1,x,n.inChannels],{dataId:t.dataId},t.dtype,this),w=u.shape;u.shape=u.shape.slice(),u.shape[u.shape.length-2]++,f(Ce(u.shape,b.shape),function(){return\"packed reshape \"+u.shape+\" to \"+b.shape+\" isn't free\"});var C=this.reshape(e,[1,n.inChannels,n.outChannels]),E=this.fusedBatchMatMul({a:b,b:C,transposeA:!1,transposeB:!1,bias:r,activation:o,preluActivationWeights:a}),R=this.texData.get(E.dataId);return f(R.isPacked,function(){return\"batchMatMul result is expected to be packed\"}),u.shape=w,R.shape=n.outShape,ct.make(n.outShape,{dataId:E.dataId},E.dtype,this)},t.prototype.conv2dWithIm2Row=function(t,e,n,r,o,a){var i=n.filterWidth,s=n.filterHeight,u=n.inChannels,l=n.outWidth,c=n.outHeight,h=\"channelsLast\"===n.dataFormat,p=i*s*u,f=c*l,d=[p,f],v=t.squeeze([0]),m=e.reshape([1,p,-1]),g=new pi(d,v.shape,n),y=this.compileAndRun(g,[v]).reshape([1,d[0],d[1]]),x=null!=r,b=null!=a,w=o?bs(o,!0):null,C=new yi(y.shape,[1,f,n.outChannels],!0,!1,x,w,b),E=[y,m];r&&E.push(r),b&&E.push(a);var R=this.compileAndRun(C,E);return h?R.reshape([1,c,l,n.outChannels]):R.reshape([1,n.outChannels,c,l])},t.prototype.fusedConv2d=function(t,e,n,r,o,a){if(1===n.filterHeight&&1===n.filterWidth&&1===n.dilationHeight&&1===n.dilationWidth&&1===n.strideHeight&&1===n.strideWidth&&(\"SAME\"===n.padInfo.type||\"VALID\"===n.padInfo.type))return this.conv2dByMatMul(t,e,n,r,o,a);if(i.getBool(\"WEBGL_CONV_IM2COL\")&&1===t.shape[0])return this.conv2dWithIm2Row(t,e,n,r,o,a);var s=null!=r,u=null!=a,l=o?bs(o,!1):null,c=new Ea(n,s,l,u),h=[t,e];return r&&h.push(r),a&&h.push(a),this.compileAndRun(c,h)},t.prototype.conv2d=function(t,e,n){if(1===n.filterHeight&&1===n.filterWidth&&1===n.dilationHeight&&1===n.dilationWidth&&1===n.strideHeight&&1===n.strideWidth&&(\"SAME\"===n.padInfo.type||\"VALID\"===n.padInfo.type))return this.conv2dByMatMul(t,e,n);if(i.getBool(\"WEBGL_CONV_IM2COL\")&&1===t.shape[0])return this.conv2dWithIm2Row(t,e,n);var r=new Ea(n);return this.compileAndRun(r,[t,e])},t.prototype.conv2dDerInput=function(t,e,n){var r=new ya(n);return this.compileAndRun(r,[t,e])},t.prototype.conv2dDerFilter=function(t,e,n){var r=new ga(n);return this.compileAndRun(r,[t,e])},t.prototype.depthwiseConv2D=function(t,e,n){var r;return i.getBool(\"WEBGL_PACK_DEPTHWISECONV\")&&n.strideWidth<=2&&n.outChannels/n.inChannels==1?(r=new ka(n),this.compileAndRun(r,[t,e],this.makePackedTensor(n.outShape,t.dtype))):(r=new Ia(n),this.compileAndRun(r,[t,e]))},t.prototype.depthwiseConv2DDerInput=function(t,e,n){var r=new Ca(n);return this.compileAndRun(r,[t,e])},t.prototype.depthwiseConv2DDerFilter=function(t,e,n){var r=new wa(n);return this.compileAndRun(r,[t,e])},t.prototype.conv3d=function(t,e,n){var r=new Ra(n);return this.compileAndRun(r,[t,e])},t.prototype.conv3dDerInput=function(t,e,n){var r=new ba(n);return this.compileAndRun(r,[t,e])},t.prototype.conv3dDerFilter=function(t,e,n){var r=new xa(n);return this.compileAndRun(r,[t,e])},t.prototype.maxPool=function(t,e){var n=new Ri(e,\"max\",!1),r=this.makeOutputArray(n.outputShape,t.dtype);return this.compileAndRun(n,[t],r)},t.prototype.avgPool=function(t,e){var n=new Ri(e,\"avg\",!1),r=this.makeOutputArray(n.outputShape,\"float32\");return this.compileAndRun(n,[t],r)},t.prototype.maxPoolBackprop=function(t,e,n,r){var o=new Ri(r,\"max\",!0),a=this.compileAndRun(o,[e]),i=new mi(r),s=this.makeOutputArray(i.outputShape,e.dtype),u=this.compileAndRun(i,[t,a],s);return a.dispose(),u},t.prototype.avgPoolBackprop=function(t,e,n){var r=new Jo(n),o=this.makeOutputArray(r.outputShape,e.dtype);return this.compileAndRun(r,[t],o)},t.prototype.cast=function(t,e){return mo(t,e,this)},t.prototype.unstack=function(t,e){for(var n=t.shape[e],r=new Array(t.rank-1),o=0,a=0;a<t.rank;a++)a!==e&&(r[o++]=t.shape[a]);var i=new Array(t.rank).fill(0),s=t.shape.slice();s[e]=1;var u=new Array(n);for(a=0;a<u.length;a++)i[e]=a,u[a]=this.slice(t,i,s).reshape(r);return u},t.prototype.avgPool3d=function(t,e){var n=new Ii(e,\"avg\",!1),r=this.makeOutputArray(n.outputShape,\"float32\");return this.compileAndRun(n,[t],r)},t.prototype.avgPool3dBackprop=function(t,e,n){var r=new Zo(n),o=this.makeOutputArray(r.outputShape,e.dtype);return this.compileAndRun(r,[t],o)},t.prototype.maxPool3d=function(t,e){var n=new Ii(e,\"max\",!1),r=this.makeOutputArray(n.outputShape,\"float32\");return this.compileAndRun(n,[t],r)},t.prototype.maxPool3dBackprop=function(t,e,n,r){var o=new Ii(r,\"max\",!0),a=this.compileAndRun(o,[e]),i=new gi(r),s=this.makeOutputArray(i.outputShape,e.dtype),u=this.compileAndRun(i,[t,a],s);return a.dispose(),u},t.prototype.reshape=function(t,e){var n=this.texData.get(t.dataId);return!n.isPacked||Ce(t.shape,e)||null!==n.texture&&Ce(n.shape,e)?go(t,e):this.packedReshape(t,e)},t.prototype.resizeBilinear=function(t,e,n,r){var o=i.getBool(\"WEBGL_PACK_IMAGE_OPERATIONS\")?new Ti(t.shape,e,n,r):new Ai(t.shape,e,n,r);return this.compileAndRun(o,[t])},t.prototype.resizeBilinearBackprop=function(t,e,n){var r=new Si(t,e,n);return this.compileAndRun(r,[t])},t.prototype.resizeNearestNeighbor=function(t,e,n,r){var o=new _i(t.shape,e,n,r);return this.compileAndRun(o,[t])},t.prototype.resizeNearestNeighborBackprop=function(t,e,n){var r=new Di(t,e,n);return this.compileAndRun(r,[t])},t.prototype.multinomial=function(t,e,n,r){var o=e?t:Yr(t),a=o.shape[0],i=o.shape[1],s=new xi(a,i,n),u=this.makeOutputArray(s.outputShape,\"int32\"),l=s.getCustomSetupFunc(r);return this.compileAndRun(s,[o],u,l)},t.prototype.oneHot=function(t,e,n,r){var o=new bi(t.size,e,n,r);return this.compileAndRun(o,[t])},t.prototype.diag=function(t){var e=new Oa(t.size);return this.compileAndRun(e,[t])},t.prototype.nonMaxSuppression=function(t,e,n,r,o){return Ze(\"tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead\"),Ro(t.dataSync(),e.dataSync(),n,r,o)},t.prototype.cropAndResize=function(t,e,n,r,o,a){var i=new Na(t.shape,e.shape,r,o,a);return this.compileAndRun(i,[t,e,n])},t.prototype.depthToSpace=function(t,e,n){f(e>1,function(){return\"blockSize should be > 1 for depthToSpace, but was: \"+e});var r=t.shape[0],o=\"NHWC\"===n?t.shape[1]:t.shape[2],a=\"NHWC\"===n?t.shape[2]:t.shape[3],i=\"NHWC\"===n?t.shape[3]:t.shape[1],s=o*e,u=a*e,l=i/(e*e),c=new _a(\"NHWC\"===n?[r,s,u,l]:[r,l,s,u],e,n);return this.compileAndRun(c,[t])},t.prototype.split=function(t,e,n){return ko(t,e,n)},t.prototype.scatterND=function(t,e,n){var r=Br(0,t,n),o=r.sliceRank,a=r.numUpdates,i=r.sliceSize,s=r.strides,u=r.outputSize,l=[u/i,i],c=t.reshape([a,o]),h=e.reshape([a,i]);if(0===u)return go(xn([]),n);var p=wn(0),f=new Mi(a,o,c.rank,h.rank,s,l);return this.compileAndRun(f,[h,c,p]).reshape(n)},t.prototype.sparseToDense=function(t,e,n,r){var o=Br(0,t,n),a=o.sliceRank,i=o.numUpdates,s=o.strides,u=o.outputSize,l=new Mi(i,a,t.rank,e.rank,s,[u,1],!1);return this.compileAndRun(l,[e,t,r]).reshape(n)},t.prototype.fft=function(t){return this.fftImpl(t,!1)},t.prototype.ifft=function(t){return this.fftImpl(t,!0)},t.prototype.fftImpl=function(t,e){var n=this.texData.get(t.dataId),r=new Ua(La,t.shape,e),o=new Ua(Wa,t.shape,e),a=[this.makeComplexComponentTensorHandle(t,n.complexTensors.real),this.makeComplexComponentTensorHandle(t,n.complexTensors.imag)],i=this.compileAndRun(r,a),s=this.compileAndRun(o,a),u=this.complex(i,s).as2D(t.shape[0],t.shape[1]);return i.dispose(),s.dispose(),u},t.prototype.gatherND=function(t,e){var n=e.shape,r=n[n.length-1],o=_r(t,e),a=o[0],i=o[1],s=o[2],u=o[3],l=e.reshape([i,r]),c=t.reshape([t.size/s,s]),h=new qa(r,u,[i,s]);return this.compileAndRun(h,[c,l]).reshape(a)},t.prototype.fill=function(t,e,n){if(\"string\"===(n=n||L(e))){var r=S(n,g(t));return r.fill(e),ct.make(t,{values:r},n)}var o=new Va(t,e),a=o.getCustomSetupFunc(e),i=this.makeOutputArray(t,n);return this.compileAndRun(o,[],i,a)},t.prototype.onesLike=function(t){if(\"string\"===t.dtype)throw new Error(\"onesLike is not supported under string dtype\");return this.fill(t.shape,1,t.dtype)},t.prototype.zerosLike=function(t){return this.fill(t.shape,\"string\"===t.dtype?\"\":0,t.dtype)},t.prototype.linspace=function(t,e,n){return yo(t,e,n)},t.prototype.makeOutputArray=function(t,e){return ct.make(t,{},e,this)},t.prototype.makePackedTensor=function(t,e){var n=ct.make(t,{},e,this);return this.texData.get(n.dataId).isPacked=!0,n},t.prototype.unpackTensor=function(t){var e=new ys(t.shape);return this.compileAndRun(e,[t],ct.make(e.outputShape,{},t.dtype,this))},t.prototype.packTensor=function(t){var e=new wi(t.shape);return this.compileAndRun(e,[t],this.makePackedTensor(t.shape,t.dtype),null,!0)},t.prototype.packedReshape=function(t,e){var n=t.reshape([ge(t.shape)].concat(ye(t.shape))),r=[ge(e)].concat(ye(e)),o=new Ni(r,n.shape);return this.compileAndRun(o,[n]).reshape(e)},t.prototype.decode=function(t){var e,n=this.texData.get(t),r=n.isPacked,o=n.shape,a=n.dtype,i=xe(o),s=Lt(o),u=this.makeTensorHandle(o,\"float32\");return this.texData.get(u.dataId).isPacked=!0,this.texData.get(u.dataId).dtype=a,this.texData.get(u.dataId).texShape=s.map(function(t){return 2*t}),e=r?new Da(i,s):new Ta(i,s),this.compileAndRun(e,[{shape:i,dtype:a,dataId:t}],u,null,!0),u},t.prototype.compileAndRun=function(t,e,n,r,o){var a=this;if(void 0===o&&(o=!1),null==n&&(n=t.usesPackedTextures?this.makePackedTensor(t.outputShape,e[0].dtype):this.makeOutputArray(t.outputShape,e[0].dtype)),0===n.size)return this.texData.get(n.dataId).values=N(n.dtype,0),n;var s=e.map(function(e){if(\"complex64\"===e.dtype)throw new Error(\"GPGPUProgram does not support complex64 input. For complex64 dtypes, please separate the program into real and imaginary parts.\");var n=a.texData.get(e.dataId);if(null==n.texture){if(!t.usesPackedTextures&&g(e.shape)<=i.getNumber(\"WEBGL_SIZE_UPLOAD_UNIFORM\"))return{shape:e.shape,texData:null,isUniform:!0,uniformValues:n.values};t.usesPackedTextures&&(n.isPacked=!0,n.shape=e.shape)}else if(!!n.isPacked!=!!t.usesPackedTextures)e=n.isPacked?a.unpackTensor(e):a.packTensor(e),n=a.texData.get(e.dataId);else if(n.isPacked&&!Ce(n.shape,e.shape)){var r=e,o=e.shape;e.shape=n.shape,e=a.packedReshape(e,o),n=a.texData.get(e.dataId),r.shape=o}return a.uploadToGPU(e.dataId),{shape:e.shape,texData:n,isUniform:!1}});this.uploadToGPU(n.dataId);var u,l={shape:n.shape,texData:this.texData.get(n.dataId),isUniform:!1},c=function(t,e,n){var r=\"\";e.concat(n).forEach(function(t){var e=null!=t.texData&&null!=t.texData.slice&&t.texData.slice.flatOffset>0,n=t.isUniform?\"uniform\":t.texData.texShape;r+=t.shape+\"_\"+n+\"_\"+e});var o=t.userCode,a=t.constructor.name;return a+=\"_\"+r+\"_\"+o}(t,s,l),h=this.getAndSaveBinary(c,function(){return function(t,e,n,r){var o=e.userCode,a=n.map(function(t,n){var r={logicalShape:t.shape,texShape:t.isUniform?null:t.texData.texShape,isUniform:t.isUniform,isPacked:!t.isUniform&&t.texData.isPacked,flatOffset:null};return null!=t.texData&&null!=t.texData.slice&&t.texData.slice.flatOffset>0&&(r.flatOffset=t.texData.slice.flatOffset),{name:e.variableNames[n],shapeInfo:r}}),s=a.map(function(t){return t.shapeInfo}),u={logicalShape:r.shape,texShape:r.texData.texShape,isUniform:!1,isPacked:r.texData.isPacked,flatOffset:null},l=Wo(a,u,o,e.usesPackedTextures),c=t.createProgram(l),h=null,p=t.getUniformLocation(c,\"NAN\",!1);1===i.getNumber(\"WEBGL_VERSION\")&&(h=t.getUniformLocation(c,\"INFINITY\",!1));for(var f={},d=0;d<e.variableNames.length;d++){var v=e.variableNames[d];f[v]=t.getUniformLocation(c,v,!1),f[\"offset\"+v]=t.getUniformLocation(c,\"offset\"+v,!1)}return{program:e,source:l,webGLProgram:c,uniformLocations:f,inShapeInfos:s,outShapeInfo:u,infLoc:h,nanLoc:p}}(a.gpgpu,t,s,l)}),p=null!=this.activeTimers;return p&&(u=this.startTimer()),function(t,e,n,r,o){hi(e.inShapeInfos,n),hi([e.outShapeInfo],[r]);var a=r.texData.texture,s=r.texData.texShape;r.texData.isPacked?t.setOutputPackedMatrixTexture(a,s[0],s[1]):t.setOutputMatrixTexture(a,s[0],s[1]),t.setProgram(e.webGLProgram),1===i.getNumber(\"WEBGL_VERSION\")&&null!==e.infLoc&&t.gl.uniform1f(e.infLoc,1/0),null!==e.nanLoc&&t.gl.uniform1f(e.nanLoc,NaN),n.forEach(function(n,r){var o=e.program.variableNames[r],a=e.uniformLocations[o],i=e.uniformLocations[\"offset\"+o];if(null!=a)if(n.isUniform)if(g(n.shape)<2)t.gl.uniform1f(a,n.uniformValues[0]);else{var s=n.uniformValues;s instanceof Float32Array||(s=new Float32Array(s)),t.gl.uniform1fv(a,s)}else null!=n.texData.slice&&null!=i&&t.gl.uniform1i(i,n.texData.slice.flatOffset),t.setInputMatrixTexture(n.texData.texture,a,r)}),null!=o&&o(t,e.webGLProgram),t.executeProgram()}(this.gpgpu,h,s,l,r),p&&(u=this.endTimer(u),this.activeTimers.push({name:t.constructor.name,query:this.getQueryTime(u)})),!i.getBool(\"WEBGL_LAZILY_UNPACK\")&&this.texData.get(n.dataId).isPacked&&!1===o?this.unpackTensor(n):n},t.prototype.getAndSaveBinary=function(t,e){return t in this.binaryCache||(this.binaryCache[t]=e()),this.binaryCache[t]},t.prototype.getTextureManager=function(){return this.textureManager},t.prototype.dispose=function(){this.disposed||(this.textureManager.dispose(),null!=this.canvas&&null!=this.canvas.remove?this.canvas.remove():this.canvas=null,null!=this.fromPixels2DContext&&this.fromPixels2DContext.canvas.remove&&this.fromPixels2DContext.canvas.remove(),this.gpgpuCreatedLocally&&(this.gpgpu.program=null,this.gpgpu.dispose()),this.disposed=!0)},t.prototype.floatPrecision=function(){var t=this;return null==this.floatPrecisionValue&&(this.floatPrecisionValue=Ue(function(){if(!i.get(\"WEBGL_RENDER_FLOAT32_ENABLED\")){var e=i.getBool(\"DEBUG\");i.set(\"DEBUG\",!1);var n=t.abs(wn(1e-8)).dataSync()[0];if(i.set(\"DEBUG\",e),n>0)return 32}return 16})),this.floatPrecisionValue},t.prototype.epsilon=function(){return 32===this.floatPrecision()?1e-7:1e-4},t.prototype.uploadToGPU=function(t){var e,n=this.texData.get(t),r=n.shape,o=n.dtype,a=n.values,i=n.texture,s=n.usage,u=n.isPacked;if(null==i){var l,c=null!=this.activeTimers;c&&(l=$());var h=n.texShape;if(null==h&&(h=be(r,u),n.texShape=h),null!=a){var p=xe(r),f=void 0,d=h[1],v=h[0],m=a instanceof Uint8Array;u?(d=(e=Wt(h[0],h[1]))[0],v=e[1],f=new Pa(p,[v,d],m)):f=new Ba(p,[v,d],m);var y=this.makeTensorHandle([v,d],o);this.texData.get(y.dataId).usage=m?Tt.PIXELS:Tt.UPLOAD,this.gpgpu.uploadDenseMatrixToTexture(this.getTexture(y.dataId),d,v,a);var x=this.makeTensorHandle(f.outputShape,y.dtype);x.size=g(f.outputShape),this.texData.get(x.dataId).isPacked=u,this.compileAndRun(f,[y],x);var b=this.texData.get(x.dataId);n.texture=b.texture,n.texShape=b.texShape,n.isPacked=b.isPacked,n.usage=b.usage,this.disposeData(y.dataId),this.texData.delete(x.dataId),n.values=null,c&&(this.uploadWaitMs+=$()-l)}else{var w=this.acquireTexture(h,s,o,u);n.texture=w}}},t.prototype.convertAndCacheOnCPU=function(t,e){var n=this.texData.get(t),r=n.dtype;return this.releaseGPUData(t),null!=e&&(n.values=function(t,e){if(\"float32\"===e||\"complex64\"===e)return t;if(\"int32\"===e||\"bool\"===e){for(var n=\"int32\"===e?new Int32Array(t.length):new Uint8Array(t.length),r=0;r<n.length;++r)n[r]=Math.round(t[r]);return n}throw new Error(\"Unknown dtype \"+e)}(e,r)),n.values},t.prototype.acquireTexture=function(t,e,n,r){if(this.numBytesInGPU+=this.computeBytes(t,n),!this.warnedAboutMemory&&this.numBytesInGPU>1024*this.numMBBeforeWarning*1024){var o=(this.numBytesInGPU/1024/1024).toFixed(2);this.warnedAboutMemory=!0,console.warn(\"High memory usage in GPU: \"+o+\" MB, most likely due to a memory leak\")}return this.textureManager.acquireTexture(t,e,r)},t.prototype.computeBytes=function(t,e){return t[0]*t[1]*O(e)},t}();At()&&St.registerBackend(\"webgl\",function(){return new Cs},2);var Es=vn({abs_:function(t){var e=nn(t,\"x\",\"abs\");return\"complex64\"===e.dtype?St.runKernel(function(t){return t.complexAbs(e)},{$x:e}):St.runKernel(function(t,n){var r=t.abs(e);return n([e]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return t.mul(n.toFloat().step(-1))}}})}}),Rs=vn({acos_:function(t){var e=nn(t,\"x\",\"acos\");return St.runKernel(function(t,n){var r=t.acos(e);return n([e]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return t.divStrict(wn(1).sub(n.toFloat().square()).sqrt()).neg()}}})}}),Is=vn({acosh_:function(t){var e=nn(t,\"x\",\"acosh\");return St.runKernel(function(t,n){var r=t.acosh(e);return n([e]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return t.divStrict(n.toFloat().square().sub(1).sqrt())}}})}}),ks=vn({asin_:function(t){var e=nn(t,\"x\",\"asin\");return St.runKernel(function(t,n){var r=t.asin(e);return n([e]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return t.divStrict(wn(1).sub(n.toFloat().square()).sqrt())}}})}}),Ns=vn({asinh_:function(t){var e=nn(t,\"x\",\"asinh\");return St.runKernel(function(t,n){var r=t.asinh(e);return n([e]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return t.divStrict(wn(1).add(n.toFloat().square()).sqrt())}}})}}),Ss=vn({atan_:function(t){var e=nn(t,\"x\",\"atan\");return St.runKernel(function(t,n){var r=t.atan(e);return n([e]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return t.div(n.toFloat().square().add(1))}}})}}),As=vn({atanh_:function(t){var e=nn(t,\"x\",\"atanh\");return St.runKernel(function(t,n){var r=t.atanh(e);return n([e]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return t.div(wn(1).sub(n.toFloat().square()))}}})}}),Ts=vn({ceil_:function(t){var e=nn(t,\"x\",\"ceil\");return St.runKernel(function(t){return t.ceil(e)},{$x:e},function(t){return{$x:function(){return Fn(t)}}})}}),Ds=vn({clipByValue_:function(t,e,n){var r=nn(t,\"x\",\"clipByValue\");return f(e<=n,function(){return\"Error in clip: min (\"+e+\") must be less than or equal to max (\"+n+\").\"}),St.runKernel(function(t,o){var a=t.clip(r,e,n);return o([r]),a},{$x:r},function(t,r){var o=r[0];return{$x:function(){return t.where(o.greaterEqual(e).logicalAnd(o.lessEqual(n)),Fn(t))}}})}}),_s=vn({cos_:function(t){var e=nn(t,\"x\",\"cos\");return St.runKernel(function(t,n){var r=t.cos(e);return n([e]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return n.toFloat().sin().neg().mul(t)}}})}}),Os=vn({cosh_:function(t){var e=nn(t,\"x\",\"cosh\");return St.runKernel(function(t,n){var r=t.cosh(e);return n([e]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return n.toFloat().sinh().mulStrict(t)}}})}}),Fs=vn({erf_:function(t){var e=nn(t,\"x\",\"erf\");return f(\"int32\"===e.dtype||\"float32\"===e.dtype,function(){return\"Input dtype must be `int32` or `float32`.\"}),\"int32\"===e.dtype&&(e=e.toFloat()),St.runKernel(function(t,n){var r=t.erf(e);return n([e]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return t.mul(n.square().neg().exp().mul(2/Math.sqrt(Math.PI)))}}})}}),Ms=vn({exp_:function(t){var e=nn(t,\"x\",\"exp\");return St.runKernel(function(t,n){var r=t.exp(e);return n([r]),r},{$x:e},function(t,e){return{$x:function(){return t.mulStrict(e[0])}}})}}),Bs=vn({expm1_:function(t){var e=nn(t,\"x\",\"expm1\");return St.runKernel(function(t,n){var r=t.expm1(e);return n([e]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return t.mul(n.exp())}}})}}),Ps=vn({floor_:function(t){var e=nn(t,\"x\",\"floor\");return St.runKernel(function(t){return t.floor(e)},{$x:e},function(t){return{$x:function(){return Fn(t)}}})}}),Ls=vn({log_:function(t){var e=nn(t,\"x\",\"log\");return St.runKernel(function(t,n){var r=t.log(e);return n([e]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return t.div(n.toFloat())}}})}}),Ws=vn({log1p_:function(t){var e=nn(t,\"x\",\"log1p\");return St.runKernel(function(t,n){var r=t.log1p(e);return n([e]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return t.div(n.add(1))}}})}}),Us=vn({logSigmoid_:function(t){var e=nn(t,\"x\",\"logSigmoid\");return St.runKernel(function(t,n){var r=t.softplus(e.neg()).neg();return n([e]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return t.mul(n.neg().sigmoid())}}})}}),Vs=vn({neg_:function(t){var e=nn(t,\"x\",\"neg\");return St.runKernel(function(t){return t.neg(e)},{$x:e},function(t){return{$x:function(){return t.neg()}}})}}),zs=vn({reciprocal_:function(t){var e=nn(t,\"x\",\"reciprocal\");return St.runKernel(function(t,n){var r=t.reciprocal(e);return n([e]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return t.div(n.square().neg())}}})}}),Gs=vn({round_:function(t){var e=nn(t,\"x\",\"round\");return St.runKernel(function(t){return t.round(e)},{$x:e},function(t){return{$x:function(){return Fn(t)}}})}}),Hs=vn({rsqrt_:function(t){var e=nn(t,\"x\",\"rsqrt\");return St.runKernel(function(t,n){var r=t.rsqrt(e);return n([e]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return t.div(n.pow(1.5).mul(2)).neg()}}})}}),qs=vn({sigmoid_:function(t){var e=nn(t,\"x\",\"sigmoid\");return St.runKernel(function(t,n){var r=t.sigmoid(e);return n([r]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return t.mul(n.mul(wn(1).sub(n)))}}})}}),$s=vn({sign_:function(t){var e=nn(t,\"x\",\"sign\");return St.runKernel(function(t){return t.sign(e)},{$x:e},function(t){return{$x:function(){return Fn(t)}}})}}),Ks=vn({isNaN_:function(t){var e=nn(t,\"x\",\"isNaN\");return St.runKernel(function(t){return t.isNaN(e)},{$x:e},function(t){return{$x:function(){return Fn(t)}}})}}),js=vn({isInf_:function(t){var e=nn(t,\"x\",\"isInf\");return St.runKernel(function(t){return t.isInf(e)},{$x:e},function(t){return{$x:function(){return Fn(t)}}})}}),Xs=vn({isFinite_:function(t){var e=nn(t,\"x\",\"isFinite\");return St.runKernel(function(t){return t.isFinite(e)},{$x:e},function(t){return{$x:function(){return Fn(t)}}})}}),Ys=vn({sin_:function(t){var e=nn(t,\"x\",\"sin\");return St.runKernel(function(t,n){var r=t.sin(e);return n([e]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return n.toFloat().cos().mul(t)}}})}}),Qs=vn({sinh_:function(t){var e=nn(t,\"x\",\"sinh\");return St.runKernel(function(t,n){var r=t.sinh(e);return n([e]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return n.toFloat().cosh().mulStrict(t)}}})}}),Js=vn({softplus_:function(t){var e=nn(t,\"x\",\"softplus\");return St.runKernel(function(t,n){var r=t.softplus(e);return n([e]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return t.mul(n.sigmoid())}}})}}),Zs=vn({sqrt_:function(t){var e=nn(t,\"x\",\"sqrt\");return St.runKernel(function(t,n){var r=t.sqrt(e);return n([e]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return t.div(n.toFloat().sqrt().mul(2))}}})}}),tu=vn({square_:function(t){var e=nn(t,\"x\",\"square\");return St.runKernel(function(t,n){return n([e]),t.square(e)},{$x:e},function(t,e){var n=e[0];return{$x:function(){return t.mul(n.toFloat().mul(2))}}})}}),eu=vn({step_:function(t,e){void 0===e&&(e=0);var n=nn(t,\"x\",\"step\");return St.runKernel(function(t){return t.step(n,e)},{$x:n},function(t){return{$x:function(){return Fn(t)}}})}}),nu=vn({tan_:function(t){var e=nn(t,\"x\",\"tan\");return St.runKernel(function(t,n){var r=t.tan(e);return n([e]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return t.div(n.cos().square())}}})}}),ru=vn({tanh_:function(t){var e=nn(t,\"x\",\"tanh\");return St.runKernel(function(t,n){var r=t.tanh(e);return n([r]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return wn(1).sub(n.square()).mulStrict(t)}}})}});function ou(t,e,n,r,o,a){var i,s,u=nn(t,\"x\",\"batchNorm\"),l=nn(e,\"mean\",\"batchNorm\"),c=nn(n,\"variance\",\"batchNorm\");return null!=o&&(i=nn(o,\"scale\",\"batchNorm\")),null!=r&&(s=nn(r,\"offset\",\"batchNorm\")),f(2===u.rank,function(){return\"Error in batchNorm3D: x must be rank 3 but got rank \"+u.rank+\".\"}),f(2===l.rank||1===l.rank,function(){return\"Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank \"+l.rank+\".\"}),f(2===c.rank||1===c.rank,function(){return\"Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank \"+c.rank+\".\"}),null!=i&&f(2===i.rank||1===i.rank,function(){return\"Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank \"+i.rank+\".\"}),null!=s&&f(2===s.rank||1===s.rank,function(){return\"Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank \"+s.rank+\".\"}),su(u,l,c,s,i,a)}function au(t,e,n,r,o,a){var i,s,u=nn(t,\"x\",\"batchNorm\"),l=nn(e,\"mean\",\"batchNorm\"),c=nn(n,\"variance\",\"batchNorm\");return null!=o&&(i=nn(o,\"scale\",\"batchNorm\")),null!=r&&(s=nn(r,\"offset\",\"batchNorm\")),f(3===u.rank,function(){return\"Error in batchNorm3D: x must be rank 3 but got rank \"+u.rank+\".\"}),f(3===l.rank||1===l.rank,function(){return\"Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank \"+l.rank+\".\"}),f(3===c.rank||1===c.rank,function(){return\"Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank \"+c.rank+\".\"}),null!=i&&f(3===i.rank||1===i.rank,function(){return\"Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank \"+i.rank+\".\"}),null!=s&&f(3===s.rank||1===s.rank,function(){return\"Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank \"+s.rank+\".\"}),su(u,l,c,s,i,a)}function iu(t,e,n,r,o,a){var i,s,u=nn(t,\"x\",\"batchNorm\"),l=nn(e,\"mean\",\"batchNorm\"),c=nn(n,\"variance\",\"batchNorm\");return null!=o&&(i=nn(o,\"scale\",\"batchNorm\")),null!=r&&(s=nn(r,\"offset\",\"batchNorm\")),f(4===u.rank,function(){return\"Error in batchNorm4D: x must be rank 4 but got rank \"+u.rank+\".\"}),f(4===l.rank||1===l.rank,function(){return\"Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank \"+l.rank+\".\"}),f(4===c.rank||1===c.rank,function(){return\"Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank \"+c.rank+\".\"}),null!=i&&f(4===i.rank||1===i.rank,function(){return\"Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank \"+i.rank+\".\"}),null!=s&&f(4===s.rank||1===s.rank,function(){return\"Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank \"+s.rank+\".\"}),su(u,l,c,s,i,a)}function su(t,e,n,r,o,a){null==a&&(a=.001);var i,s,u,l=nn(t,\"x\",\"batchNorm\"),c=nn(e,\"mean\",\"batchNorm\"),h=nn(n,\"variance\",\"batchNorm\");null!=o&&(i=nn(o,\"scale\",\"batchNorm\")),null!=r&&(s=nn(r,\"offset\",\"batchNorm\")),f(c.rank===h.rank,function(){return\"Batch normalization gradient requires mean and variance to have equal ranks.\"}),f(null==s||c.rank===s.rank,function(){return\"Batch normalization gradient requires mean and offset to have equal ranks.\"}),f(null==i||c.rank===i.rank,function(){return\"Batch normalization gradient requires mean and scale to have equal ranks.\"}),u=0===l.rank||1===l.rank?l.as4D(1,1,1,l.size):2===l.rank?l.as4D(1,1,l.shape[0],l.shape[1]):3===l.rank?l.as4D(1,l.shape[0],l.shape[1],l.shape[2]):l;return St.runKernel(function(t,e){var n=t.batchNormalization(u,uu(c),uu(h),a,uu(i),uu(s));return e([l,c,h,i]),n},{$x:l,$mean:c,$variance:h,$scale:i,$offset:s},function(t,e){var n=e,r=n[0],o=n[1],i=n[2],s=n[3],l=null==s?wn(1):s,c=eo(o.shape,u.shape),h=[];if(1===o.rank){for(var p=0;p<u.shape.length-1;++p)h.push(u.shape[p]);h.push(1)}var f=r.sub(o),d=t.mul(l),v=Hs(i.add(wn(a))),m=v.mul(v).mul(v).mul(wn(-.5));return{$x:function(){return 1===o.rank?t.mul(Er(v.as4D(1,1,1,o.shape[0]),h)).mul(l).reshape(r.shape):t.mul(v).mul(l).reshape(r.shape)},$mean:function(){var t=v.mul(wn(-1)).mul(d);return 1===o.rank&&(t=t.sum(c)),t.reshape(o.shape)},$variance:function(){var t=m.mul(f).mul(d);return 1===o.rank&&(t=t.sum(c)),t.reshape(o.shape)},$scale:function(){var e=f.mul(v),n=t.mul(e);return 1===o.rank&&(n=n.sum(c)),n.reshape(o.shape)},$offset:function(){var e=t;return 1===o.rank&&(e=e.sum(c)),e.reshape(o.shape)}}}).reshape(l.shape)}function uu(t){return null==t?null:0===t.rank?t.as1D():1===t.rank?t:2===t.rank?t.as4D(1,1,t.shape[0],t.shape[1]):3===t.rank?t.as4D(1,t.shape[0],t.shape[1],t.shape[2]):t}function lu(){Be(\"tf.batchNormalization() is going away. Use tf.batchNorm() instead, and note the positional argument change of scale, offset, and varianceEpsilon\")}var cu=vn({batchNormalization2d_:function(t,e,n,r,o,a){return void 0===r&&(r=.001),lu(),ou(t,e,n,a,o,r)}}),hu=vn({batchNormalization3d_:function(t,e,n,r,o,a){return void 0===r&&(r=.001),lu(),au(t,e,n,a,o,r)}}),pu=vn({batchNormalization4d_:function(t,e,n,r,o,a){return void 0===r&&(r=.001),lu(),iu(t,e,n,a,o,r)}}),fu=vn({batchNormalization_:function(t,e,n,r,o,a){return void 0===r&&(r=.001),lu(),su(t,e,n,a,o,r)}}),du=vn({batchNorm_:su}),vu=vn({batchNorm2d_:ou}),mu=vn({batchNorm3d_:au}),gu=vn({batchNorm4d_:iu});var yu=vn({logicalAnd_:function(t,e){var n=nn(t,\"a\",\"logicalAnd\",\"bool\"),r=nn(e,\"b\",\"logicalAnd\",\"bool\");return no(n.shape,r.shape),St.runKernel(function(t){return t.logicalAnd(n,r)},{$a:n,$b:r})}}),xu=vn({logicalNot_:function(t){var e=nn(t,\"x\",\"logicalNot\",\"bool\");return St.runKernel(function(t){return t.logicalNot(e)},{$x:e})}}),bu=vn({logicalOr_:function(t,e){var n=nn(t,\"a\",\"logicalOr\",\"bool\"),r=nn(e,\"b\",\"logicalOr\",\"bool\");return no(n.shape,r.shape),St.runKernel(function(t){return t.logicalOr(n,r)},{$a:n,$b:r})}}),wu=vn({logicalXor_:function(t,e){var n=nn(t,\"a\",\"logicalXor\",\"bool\"),r=nn(e,\"b\",\"logicalXor\",\"bool\");return no(n.shape,r.shape),bu(t,e).logicalAnd(yu(t,e).logicalNot())}}),Cu=vn({where_:function(t,e,n){var r=nn(e,\"a\",\"where\"),o=nn(n,\"b\",\"where\"),a=nn(t,\"condition\",\"where\",\"bool\");return d(r.shape,o.shape,\"Error in where: \"),1===a.rank?f(a.shape[0]===r.shape[0],function(){return\"The first dimension of `a` must match the size of `condition`.\"}):d(a.shape,o.shape,\"Error in where: \"),St.runKernel(function(t,e){var n=t.select(a,r,o);return e([a]),n},{$condition:a,$a:r,$b:o},function(t,e){var n=e[0];return{$condition:function(){return Fn(n).toFloat()},$a:function(){return t.mul(n.cast(t.dtype))},$b:function(){return t.mul(n.logicalNot().cast(t.dtype))}}})}}),Eu=function(t){return n(this,void 0,void 0,function(){var e,n,o;return r(this,function(r){switch(r.label){case 0:return[4,(e=nn(t,\"condition\",\"whereAsync\",\"bool\")).data()];case 1:return n=r.sent(),o=Ao(e.shape,n),t!==e&&e.dispose(),[2,o]}})})};var Ru=vn({add_:function(t,e){var n,r=nn(t,\"a\",\"add\"),o=nn(e,\"b\",\"add\");n=wt(r,o),r=n[0],o=n[1];var a=no(r.shape,o.shape);return St.runKernel(function(t){return t.add(r,o)},{$a:r,$b:o},function(t){return{$a:function(){var e=t,n=eo(r.shape,a);return n.length>0&&(e=e.sum(n)),e.reshape(r.shape)},$b:function(){var e=t,n=eo(o.shape,a);return n.length>0&&(e=e.sum(n)),e.reshape(o.shape)}}})}}),Iu=vn({addN_:function(t){f(Array.isArray(t),function(){return\"The argument passed to tf.addN() must be a list of tensors\"}),f(t.length>=1,function(){return\"Must pass at least one tensor to tf.addN(), but got \"+t.length});var e=t.map(function(t,e){return nn(t,\"tensors\"+e,\"addN\")}),n=e[0];e.forEach(function(t){if(t.dtype!==n.dtype)throw new Error(\"All tensors passed to tf.addN() must have the same dtype\")}),e.forEach(function(t){if(!y(t.shape,n.shape))throw new Error(\"All tensors passed to tf.addN() must have the same shape\")});var r=e;return St.runKernel(function(t){return t.addN(e)},r,function(t){var n={};return e.forEach(function(e,r){n[r]=function(){return t.clone()}}),n})}}),ku=vn({addStrict_:function(t,e){var n=nn(t,\"a\",\"addStrict\"),r=nn(e,\"b\",\"addStrict\");return d(n.shape,r.shape,\"Error in addStrict: \"),n.add(r)}}),Nu=vn({atan2_:function(t,e){var n,r=nn(t,\"a\",\"atan2\"),o=nn(e,\"b\",\"atan2\");n=wt(r,o),r=n[0],o=n[1];var a=no(r.shape,o.shape);return St.runKernel(function(t,e){var n=t.atan2(r,o);return e([r,o]),n},{$a:r,$b:o},function(t,e){var n=e[0],r=e[1];return{$a:function(){var e=Ru(n.square(),r.square()),o=t.mul(r.div(e)),i=eo(n.shape,a);return i.length>0&&(o=o.sum(i)),o.reshape(n.shape)},$b:function(){var e=Ru(n.square(),r.square()),o=Vs(t.mul(n.div(e))),i=eo(r.shape,a);return i.length>0&&(o=o.sum(i)),o.reshape(r.shape)}}})}}),Su=vn({div_:function(t,e){var n,r=nn(t,\"a\",\"div\"),o=nn(e,\"b\",\"div\");if(n=wt(r,o),r=n[0],o=n[1],\"int32\"===r.dtype&&\"int32\"===o.dtype)return Tu(r,o);var a=no(r.shape,o.shape);return St.runKernel(function(t,e){var n=t.realDivide(r,o);return e([r,o]),n},{$a:r,$b:o},function(t,e){var n=e[0],r=e[1];return{$a:function(){var e=t.div(r.toFloat()),o=eo(n.shape,a);return o.length>0?e.sum(o).reshape(n.shape):e},$b:function(){var e=t.mul(n.toFloat()),o=eo(r.shape,a);o.length>0&&(e=e.sum(o).reshape(r.shape));var i=r.square();return e.div(i.toFloat()).neg()}}})}}),Au=vn({divStrict_:function(t,e){var n=nn(t,\"a\",\"div\"),r=nn(e,\"b\",\"div\");return d(n.shape,r.shape,\"Error in divideStrict: \"),n.div(r)}}),Tu=vn({floorDiv_:function(t,e){var n,r=nn(t,\"a\",\"floorDiv\"),o=nn(e,\"b\",\"floorDiv\");n=wt(r,o),r=n[0],o=n[1];var a=no(r.shape,o.shape);return St.runKernel(function(t,e){var n=t.floorDiv(r,o);return e([r,o]),n},{$a:r,$b:o},function(t,e){var n=e[0],r=e[1];return{$a:function(){var e=t.div(r.toFloat()),o=eo(n.shape,a);return o.length>0?e.sum(o).reshape(n.shape):e},$b:function(){var e=t.mul(n.toFloat()),o=eo(r.shape,a);o.length>0&&(e=e.sum(o).reshape(r.shape));var i=r.square();return e.div(i.toFloat()).neg()}}})}}),Du=vn({maximum_:function(t,e){var n,r=nn(t,\"a\",\"maximum\"),o=nn(e,\"b\",\"maximum\");return n=wt(r,o),r=n[0],o=n[1],\"bool\"===r.dtype&&(r=r.toInt(),o=o.toInt()),no(r.shape,o.shape),St.runKernel(function(t,e){var n=t.maximum(r,o);return e([r,o]),n},{$a:r,$b:o},function(t,e){var n=e[0],r=e[1];return{$a:function(){return t.mul(n.greaterEqual(r).toFloat())},$b:function(){return t.mul(n.less(r).toFloat())}}})}}),_u=vn({maximumStrict_:function(t,e){var n=nn(t,\"a\",\"maximumStrict\"),r=nn(e,\"b\",\"maximumStrict\");return d(n.shape,r.shape,\"Error in maximumStrict: \"),n.maximum(r)}}),Ou=vn({minimum_:function(t,e){var n,r=nn(t,\"a\",\"minimum\"),o=nn(e,\"b\",\"minimum\");return n=wt(r,o),r=n[0],o=n[1],\"bool\"===r.dtype&&(r=r.toInt(),o=o.toInt()),no(r.shape,o.shape),St.runKernel(function(t,e){var n=t.minimum(r,o);return e([r,o]),n},{$a:r,$b:o},function(t,e){var n=e[0],r=e[1];return{$a:function(){return t.mul(n.lessEqual(r).toFloat())},$b:function(){return t.mul(n.greater(r).toFloat())}}})}}),Fu=vn({minimumStrict_:function(t,e){var n=nn(t,\"a\",\"minimumStrict\"),r=nn(e,\"b\",\"minimumStrict\");return d(n.shape,r.shape,\"Error in minimumStrict: \"),n.minimum(r)}}),Mu=vn({mod_:function(t,e){var n,r=nn(t,\"a\",\"mod\"),o=nn(e,\"b\",\"mod\");n=wt(r,o),r=n[0],o=n[1];var a=no(r.shape,o.shape);return St.runKernel(function(t,e){var n=t.mod(r,o);return e([r,o]),n},{$a:r,$b:o},function(t,e){var n=e[0],r=e[1];return{$a:function(){var e=eo(n.shape,a);return e.length>0?t.sum(e).reshape(n.shape):t},$b:function(){var e=t.mul(n.div(r).floor().neg()),o=eo(r.shape,a);return o.length>0?e.sum(o).reshape(r.shape):e}}})}}),Bu=vn({modStrict_:function(t,e){var n=nn(t,\"a\",\"modStrict\"),r=nn(e,\"b\",\"modStrict\");return d(n.shape,r.shape,\"Error in modStrict: \"),n.mod(r)}}),Pu=vn({mul_:function(t,e){var n,r=nn(t,\"a\",\"mul\"),o=nn(e,\"b\",\"mul\");n=wt(r,o),r=n[0],o=n[1];var a=no(r.shape,o.shape);return St.runKernel(function(t,e){var n=t.multiply(r,o);return e([r,o]),n},{$a:r,$b:o},function(t,e){var n=e[0],r=e[1];return{$a:function(){var e=t.mul(r.toFloat()),o=eo(n.shape,a);return o.length>0?e.sum(o).reshape(n.shape):e},$b:function(){var e=t.mul(n.toFloat()),o=eo(r.shape,a);return o.length>0?e.sum(o).reshape(r.shape):e}}})}}),Lu=vn({mulStrict_:function(t,e){var n=nn(t,\"a\",\"mul\"),r=nn(e,\"b\",\"mul\");return d(n.shape,r.shape,\"Error in multiplyStrict: \"),n.mul(r)}}),Wu=vn({pow_:function(t,e){var n=nn(t,\"base\",\"pow\"),r=nn(e,\"exp\",\"pow\"),o=no(n.shape,r.shape);return t=n.cast(xt(n.dtype,r.dtype)),e=r.cast(xt(n.dtype,r.dtype)),St.runKernel(function(t,e){var o=t.pow(n,r);return e([n,r,o]),o},{$base:n,$exp:r},function(t,e){var n=e[0],r=e[1],a=e[2];return{$base:function(){var e=r.toFloat(),a=t.mul(e.mul(n.pow(e.sub(wn(1))))),i=eo(n.shape,o);return i.length>0&&(a=a.sum(i)),a.reshape(n.shape)},$exp:function(){var e=n.greater(0),i=n.log().where(e,Fn(n)),s=t.mul(a.mul(i)),u=eo(r.shape,o);return u.length>0&&(s=s.sum(u)),s.reshape(r.shape)}}})}}),Uu=vn({powStrict_:function(t,e){return d(t.shape,e.shape,\"Error in powStrict: \"),t.pow(e)}}),Vu=vn({squaredDifference_:function(t,e){var n,r=nn(t,\"a\",\"squaredDifference\"),o=nn(e,\"b\",\"squaredDifference\");return n=wt(r,o),r=n[0],o=n[1],no(r.shape,o.shape),St.runKernel(function(t,e){var n=t.squaredDifference(r,o);return e([r,o]),n},{$a:r,$b:o},function(t,e){var n=e[0],r=e[1],o=wn(2);return{$a:function(){return t.mul(n.sub(r).mul(o))},$b:function(){return t.mul(r.sub(n).mul(o))}}})}}),zu=vn({squaredDifferenceStrict_:function(t,e){var n=nn(t,\"a\",\"squaredDifferenceStrict\"),r=nn(e,\"b\",\"squaredDifferenceStrict\");return d(n.shape,r.shape,\"Error in squaredDifferenceStrict: \"),n.squaredDifference(r)}}),Gu=vn({sub_:function(t,e){var n,r=nn(t,\"a\",\"sub\"),o=nn(e,\"b\",\"sub\");n=wt(r,o),r=n[0],o=n[1];var a=no(r.shape,o.shape);return St.runKernel(function(t){return t.subtract(r,o)},{$a:r,$b:o},function(t){return{$a:function(){var e=t,n=eo(r.shape,a);return n.length>0&&(e=e.sum(n)),e.reshape(r.shape)},$b:function(){var e=t,n=eo(o.shape,a);return n.length>0&&(e=e.sum(n)),e.neg().reshape(o.shape)}}})}}),Hu=vn({subStrict_:function(t,e){var n=nn(t,\"a\",\"subStrict\"),r=nn(e,\"b\",\"subStrict\");return d(n.shape,r.shape,\"Error in subStrict: \"),n.sub(r)}});var qu=vn({equal_:function(t,e){var n,r=nn(t,\"a\",\"equal\"),o=nn(e,\"b\",\"equal\");return n=wt(r,o),r=n[0],o=n[1],no(r.shape,o.shape),St.runKernel(function(t){return t.equal(r,o)},{$a:r,$b:o})}}),$u=vn({equalStrict_:function(t,e){var n=nn(t,\"a\",\"equalStrict\"),r=nn(e,\"b\",\"equalStrict\");return d(n.shape,r.shape,\"Error in equalStrict: \"),n.equal(r)}}),Ku=vn({greater_:function(t,e){var n,r=nn(t,\"a\",\"greater\"),o=nn(e,\"b\",\"greater\");return n=wt(r,o),r=n[0],o=n[1],no(r.shape,o.shape),St.runKernel(function(t){return t.greater(r,o)},{$a:r,$b:o})}}),ju=vn({greaterEqual_:function(t,e){var n,r=nn(t,\"a\",\"greaterEqual\"),o=nn(e,\"b\",\"greaterEqual\");return n=wt(r,o),r=n[0],o=n[1],no(r.shape,o.shape),St.runKernel(function(t,e){var n=t.greaterEqual(r,o);return e([r,o]),n},{$a:r,$b:o},function(t,e){var n=e[0],r=e[1];return{$a:function(){return Fn(n)},$b:function(){return Fn(r)}}})}}),Xu=vn({greaterEqualStrict_:function(t,e){var n=nn(t,\"a\",\"greaterEqualStrict\"),r=nn(e,\"b\",\"greaterEqualStrict\");return d(n.shape,r.shape,\"Error in greaterEqualStrict: \"),n.greaterEqual(r)}}),Yu=vn({greaterStrict_:function(t,e){var n=nn(t,\"a\",\"greaterStrict\"),r=nn(e,\"b\",\"greaterStrict\");return d(n.shape,r.shape,\"Error in greaterStrict: \"),n.greater(r)}}),Qu=vn({less_:function(t,e){var n,r=nn(t,\"a\",\"less\"),o=nn(e,\"b\",\"less\");return n=wt(r,o),r=n[0],o=n[1],no(r.shape,o.shape),St.runKernel(function(t){return t.less(r,o)},{$a:r,$b:o})}}),Ju=vn({lessEqual_:function(t,e){var n,r=nn(t,\"a\",\"lessEqual\"),o=nn(e,\"b\",\"lessEqual\");return n=wt(r,o),r=n[0],o=n[1],no(r.shape,o.shape),St.runKernel(function(t){return t.lessEqual(r,o)},{$a:r,$b:o})}}),Zu=vn({lessEqualStrict_:function(t,e){var n=nn(t,\"a\",\"lessEqualStrict\"),r=nn(e,\"b\",\"lessEqualStrict\");return d(n.shape,r.shape,\"Error in lessEqualStrict: \"),n.lessEqual(r)}}),tl=vn({lessStrict_:function(t,e){var n=nn(t,\"a\",\"lessStrict\"),r=nn(e,\"b\",\"lessStrict\");return d(n.shape,r.shape,\"Error in lessStrict: \"),n.less(r)}}),el=vn({notEqual_:function(t,e){var n,r=nn(t,\"a\",\"notEqual\"),o=nn(e,\"b\",\"notEqual\");return n=wt(r,o),r=n[0],o=n[1],no(r.shape,o.shape),St.runKernel(function(t){return t.notEqual(r,o)},{$a:r,$b:o})}}),nl=vn({notEqualStrict_:function(t,e){var n=nn(t,\"a\",\"notEqualStrict\"),r=nn(e,\"b\",\"notEqualStrict\");return d(n.shape,r.shape,\"Error in notEqualStrict: \"),n.notEqual(r)}});function rl(t,e){for(var n=[],r=t;r<e;++r)n.push(r);return n}function ol(t){for(var e=[],n=0;n<t.length;++n)for(var r=0;r<t[n].length;++r)e.push(t[n][r]);return e}var al=vn({gather_:function(t,e,n){void 0===n&&(n=0);var r=nn(t,\"x\",\"gather\"),o=nn(e,\"indices\",\"gather\",\"int32\");n=I(n,r.shape)[0];var a=function(t,e,n){for(var r=t.shape[n],o=[],a=1,i=1,s=0;s<n;s++)o.push(t.shape[s]),a*=t.shape[s];for(s=0;s<e.rank;s++)o.push(e.shape[s]);for(s=n+1;s<t.rank;s++)o.push(t.shape[s]),i*=t.shape[s];return{batchSize:a,sliceSize:i,dimSize:r,outputShape:o}}(r,o,n);return St.runKernel(function(t,e){var a=t.gather(r,o.flatten(),n);return e([o]),a},{$x:r},function(t,e){var o=e[0];return{$x:function(){var e=r.shape,a=o.size,i=e.slice(0,n),s=i.length,u=e.slice(n,e.length).slice(1),l=u.length,c=rl(0,s),h=rl(s+1,s+1+l),p=ol([i,[a],u]),f=t.reshape(p),d=o.reshape([a]),v=ol([[s],c,h]),m=f.transpose(v),g=il(m,d,r.shape[n]),y=hn(v);return g=g.transpose(y)}}}).reshape(a.outputShape)}}),il=vn({unsortedSegmentSum_:function(t,e,n){var r=nn(t,\"x\",\"unsortedSegmentSum\"),o=nn(e,\"segmentIds\",\"unsortedSegmentSum\",\"int32\");return f(x(n),function(){return\"numSegments must be of dtype int\"}),St.runKernel(function(t,e){var a=t.unsortedSegmentSum(r,o,n);return e([o]),a},{$x:r},function(t,e){var n=e[0];return{$x:function(){return function(t,e){for(var n=Du(e,Fn(e)),r=al(t,n),o=ju(e,wn(0,\"int32\")),a=r.rank-o.rank,i=0;i<a;++i)o=ir(o,i+1);o=yu(o,Sn(r.shape,\"bool\"));var s=Fn(r);return Cu(o,r,s)}(t,n)}}})}});var sl=function(t,e,o){return n(this,void 0,void 0,function(){var n,a,i,s,u,l,c,h,p,v,m,g,y;return r(this,function(r){switch(r.label){case 0:for(n=nn(t,\"tensor\",\"boolMask\"),a=nn(e,\"mask\",\"boolMask\",\"bool\"),i=null==o?0:o,s=a.rank,u=n.shape,f(s>0,function(){return\"mask cannot be scalar\"}),d(u.slice(i,i+s),a.shape,\"mask's shape must match the first K dimensions of tensor's shape,\"),l=1,c=i;c<i+s;c++)l*=u[c];return h=u.slice(0,i).concat([l],u.slice(i+s)),p=n.reshape(h),v=a.reshape([-1]),[4,Eu(v)];case 1:return m=r.sent(),g=m.squeeze([1]),y=al(p,g,i),t!==n&&n.dispose(),e!==a&&a.dispose(),g.dispose(),p.dispose(),v.dispose(),m.dispose(),[2,y]}})})};function ul(t,e,n,r,o,a,i){void 0===a&&(a=\"NHWC\"),f(t.length===e.rank,function(){return\"Length of inShape (\"+t.length+\") and rank of dy (\"+e.rank+\") must match\"});var s=t,u=e,l=!1;3===e.rank&&(l=!0,u=e.as4D(1,e.shape[0],e.shape[1],e.shape[2]),s=[1,t[0],t[1],t[2]]),f(4===s.length,function(){return\"Error in conv2dDerInput: inShape must be length 4, but got length \"+s.length+\".\"}),f(4===u.rank,function(){return\"Error in conv2dDerInput: dy must be rank 4, but got rank \"+u.rank}),f(4===n.rank,function(){return\"Error in conv2dDerInput: filter must be rank 4, but got rank \"+n.rank});var c=\"NHWC\"===a?s[3]:s[1],h=\"NHWC\"===a?u.shape[3]:u.shape[1];f(c===n.shape[2],function(){return\"Error in conv2dDerInput: depth of input (\"+c+\") must match input depth for filter \"+n.shape[2]+\".\"}),f(h===n.shape[3],function(){return\"Error in conv2dDerInput: depth of output (\"+h+\") must match output depth for filter \"+n.shape[3]+\".\"}),null!=i&&f(x(o),function(){return\"Error in conv2dDerInput: pad must be an integer when using, dimRoundingMode \"+i+\" but got pad \"+o+\".\"});var p=vo(a),d=ao(s,n.shape,r,1,o,i,!1,p),v=St.runKernel(function(t,e){var r=t.conv2dDerInput(u,n,d);return e([n,u]),r},{dy4D:u,filter:n},function(t,e){var n=e[0],s=e[1];return{dy4D:function(){return fl(t,n,r,o,a,1,i)},filter:function(){return vl(t,s,n.shape,r,o,a,i)}}});return l?v.as3D(v.shape[1],v.shape[2],v.shape[3]):v}function ll(t,e,n,r,o,a,i){void 0===a&&(a=\"NHWC\");var s=t;3===t.rank&&(s=t.as4D(1,t.shape[0],t.shape[1],t.shape[2]));var u=e;3===u.rank&&(u=e.as4D(1,e.shape[0],e.shape[1],e.shape[2])),f(4===s.rank,function(){return\"Error in conv2dDerFilter: input must be rank 4, but got shape \"+s.shape+\".\"}),f(4===u.rank,function(){return\"Error in conv2dDerFilter: dy must be rank 4, but got shape \"+u.shape+\".\"}),f(4===n.length,function(){return\"Error in conv2dDerFilter: filterShape must be length 4, but got \"+n+\".\"});var l=\"NHWC\"===a?s.shape[3]:s.shape[1],c=\"NHWC\"===a?u.shape[3]:u.shape[1];f(l===n[2],function(){return\"Error in conv2dDerFilter: depth of input \"+l+\") must match input depth in filter (\"+n[2]+\".\"}),f(c===n[3],function(){return\"Error in conv2dDerFilter: depth of dy (\"+c+\") must match output depth for filter (\"+n[3]+\").\"}),null!=i&&f(x(o),function(){return\"Error in conv2dDerFilter: pad must be an integer when using, dimRoundingMode \"+i+\" but got pad \"+o+\".\"});var h=vo(a),p=ao(s.shape,n,r,1,o,i,!1,h);return St.runKernel(function(t){return t.conv2dDerFilter(s,u,p)},{x4D:s,dy4D:u})}function cl(t){var e=function(t){return\"number\"==typeof t?[t,t,t]:2===t.length?[t[0],t[1],1]:t}(t),n=e[0],r=e[1],o=e[2];return 1===n&&1===r&&1===o}function hl(t,e,n,r,o){f(t.length===e.rank,function(){return\"Length of inShape (\"+t.length+\") and rank of dy (\"+e.rank+\") must match\"});var a=t,i=e,s=!1;4===e.rank&&(s=!0,i=e.as5D(1,e.shape[0],e.shape[1],e.shape[2],e.shape[3]),a=[1,t[0],t[1],t[2],t[3]]);var u=a[4],l=i.shape[4];f(5===a.length,function(){return\"Error in conv3dDerInput: inShape must be length 5, but got length \"+a.length+\".\"}),f(5===i.rank,function(){return\"Error in conv3dDerInput: dy must be rank 5, but got rank \"+i.rank}),f(5===n.rank,function(){return\"Error in conv3dDerInput: filter must be rank 5, but got rank \"+n.rank}),f(u===n.shape[3],function(){return\"Error in conv3dDerInput: depth of input (\"+u+\") must match input depth for filter \"+n.shape[3]+\".\"}),f(l===n.shape[4],function(){return\"Error in conv3dDerInput: depth of output (\"+l+\") must match output depth for filter \"+n.shape[4]+\".\"});var c=io(a,n.shape,r,1,o),h=St.runKernel(function(t){return t.conv3dDerInput(i,n,c)},{dy5D:i});return s?h.as4D(h.shape[1],h.shape[2],h.shape[3],h.shape[4]):h}var pl=vn({conv1d_:function(t,e,n,r,o,a,i){void 0===o&&(o=\"NWC\"),void 0===a&&(a=1);var s=nn(t,\"x\",\"conv1d\"),u=nn(e,\"filter\",\"conv1d\"),l=s,c=!1;2===s.rank&&(c=!0,l=s.as3D(1,s.shape[0],s.shape[1])),f(3===l.rank,function(){return\"Error in conv1d: input must be rank 3, but got rank \"+l.rank+\".\"}),f(3===u.rank,function(){return\"Error in conv1d: filter must be rank 3, but got rank \"+u.rank+\".\"}),null!=i&&f(x(r),function(){return\"Error in conv1d: pad must be an integer when using, dimRoundingMode \"+i+\" but got pad \"+r+\".\"}),f(l.shape[2]===u.shape[1],function(){return\"Error in conv1d: depth of input (\"+l.shape[2]+\") must match input depth for filter \"+u.shape[1]+\".\"}),f(fo(n,a),function(){return\"Error in conv1D: Either stride or dilation must be 1. Got stride \"+n+\" and dilation '\"+a+\"'\"}),f(\"NWC\"===o,function(){return\"Error in conv1d: got dataFormat of \"+o+\" but only NWC is currently supported.\"});var h=u.as4D(1,u.shape[0],u.shape[1],u.shape[2]),p=l.as4D(l.shape[0],1,l.shape[1],l.shape[2]),d=fl(p,h,[1,n],r,\"NHWC\",[1,a],i);return c?d.as2D(d.shape[2],d.shape[3]):d.as3D(d.shape[0],d.shape[2],d.shape[3])}}),fl=vn({conv2d_:function(t,e,n,r,o,a,i){void 0===o&&(o=\"NHWC\"),void 0===a&&(a=[1,1]);var s=nn(t,\"x\",\"conv2d\"),u=nn(e,\"filter\",\"conv2d\"),l=s,c=!1;3===s.rank&&(c=!0,l=s.as4D(1,s.shape[0],s.shape[1],s.shape[2])),f(4===l.rank,function(){return\"Error in conv2d: input must be rank 4, but got rank \"+l.rank+\".\"}),f(4===u.rank,function(){return\"Error in conv2d: filter must be rank 4, but got rank \"+u.rank+\".\"}),null!=i&&f(x(r),function(){return\"Error in conv2d: pad must be an integer when using, dimRoundingMode \"+i+\" but got pad \"+r+\".\"});var h=\"NHWC\"===o?l.shape[3]:l.shape[1];f(h===u.shape[2],function(){return\"Error in conv2d: depth of input (\"+h+\") must match input depth for filter \"+u.shape[2]+\".\"}),f(fo(n,a),function(){return\"Error in conv2D: Either strides or dilations must be 1. Got strides \"+n+\" and dilations '\"+a+\"'\"});var p=vo(o),d=ao(l.shape,u.shape,n,a,r,i,!1,p),v=St.runKernel(function(t,e){var n=t.conv2d(l,u,d);return e([u,l]),n},{x:l,$filter:u},function(t,e){var i=e,s=i[0],u=i[1];return f(po(a),function(){return\"Error in gradient of conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '\"+a+\"'\"}),{x:function(){return ul(u.shape,t,s,n,r,o)},$filter:function(){return ll(u,t,s.shape,n,r,o)}}});return c?v.as3D(v.shape[1],v.shape[2],v.shape[3]):v}}),dl=vn({conv3d_:function(t,e,n,r,o,a){void 0===o&&(o=\"NDHWC\"),void 0===a&&(a=[1,1,1]);var i=nn(t,\"x\",\"conv3d\"),s=nn(e,\"filter\",\"conv3d\"),u=i,l=!1;4===i.rank&&(l=!0,u=i.as5D(1,i.shape[0],i.shape[1],i.shape[2],i.shape[3])),f(5===u.rank,function(){return\"Error in conv3d: input must be rank 5, but got rank \"+u.rank+\".\"}),f(5===s.rank,function(){return\"Error in conv3d: filter must be rank 5, but got rank \"+s.rank+\".\"}),f(u.shape[4]===s.shape[3],function(){return\"Error in conv3d: depth of input (\"+u.shape[4]+\") must match input depth for filter \"+s.shape[3]+\".\"}),f(function(t,e){return cl(t)||cl(e)}(n,a),function(){return\"Error in conv3D: Either strides or dilations must be 1. Got strides \"+n+\" and dilations '\"+a+\"'\"}),f(\"NDHWC\"===o,function(){return\"Error in conv3d: got dataFormat of \"+o+\" but only NDHWC is currently supported.\"});var c=io(u.shape,s.shape,n,a,r),h=St.runKernel(function(t,e){var n=t.conv3d(u,s,c);return e([u,s]),n},{x:u,$filter:s},function(t,e){f(cl(a),function(){return\"Error in gradient of conv3D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '\"+a+\"'\"});var o=e[0],i=e[1];return{x:function(){return hl(o.shape,t,i,n,r)},$filter:function(){return function(t,e,n,r,o){var a=t;4===t.rank&&(a=t.as5D(1,t.shape[0],t.shape[1],t.shape[2],t.shape[3]));var i=e;4===i.rank&&(i=e.as5D(1,e.shape[0],e.shape[1],e.shape[2],e.shape[3])),f(5===a.rank,function(){return\"Error in conv3dDerFilter: input must be rank 5, but got shape \"+a.shape+\".\"}),f(5===i.rank,function(){return\"Error in conv3dDerFilter: dy must be rank 5, but got shape \"+i.shape+\".\"}),f(5===n.length,function(){return\"Error in conv3dDerFilter: filterShape must be length 5, but got \"+n+\".\"}),f(a.shape[4]===n[3],function(){return\"Error in conv3dDerFilter: depth of input \"+a.shape[4]+\") must match input depth in filter (\"+n[3]+\".\"}),f(i.shape[4]===n[4],function(){return\"Error in conv3dDerFilter: depth of dy (\"+i.shape[4]+\") must match output depth for filter (\"+n[4]+\").\"});var s=io(a.shape,n,r,1,o);return St.runKernel(function(t){return t.conv3dDerFilter(a,i,s)},{x5D:a,dy5D:i})}(o,t,i.shape,n,r)}}});return l?h.as4D(h.shape[1],h.shape[2],h.shape[3],h.shape[4]):h}}),vl=vn({conv2dDerFilter_:ll}),ml=vn({conv2dDerInput_:ul}),gl=vn({depthwiseConv2d_:function(t,e,n,r,o,a,i){void 0===o&&(o=\"NHWC\"),void 0===a&&(a=[1,1]);var s=nn(t,\"x\",\"depthwiseConv2d\"),u=nn(e,\"filter\",\"depthwiseConv2d\"),l=s,c=!1;3===s.rank&&(c=!0,l=s.as4D(1,s.shape[0],s.shape[1],s.shape[2])),f(4===l.rank,function(){return\"Error in depthwiseConv2d: input must be rank 4, but got rank \"+l.rank+\".\"}),f(4===u.rank,function(){return\"Error in depthwiseConv2d: filter must be rank 4, but got rank \"+u.rank+\".\"}),f(l.shape[3]===u.shape[2],function(){return\"Error in depthwiseConv2d: number of input channels (\"+l.shape[3]+\") must match the inChannels dimension in filter \"+u.shape[2]+\".\"}),null==a&&(a=[1,1]),f(fo(n,a),function(){return\"Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides \"+n+\" and dilations '\"+a+\"'\"}),null!=i&&f(x(r),function(){return\"Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode \"+i+\" but got pad \"+r+\".\"});var h=ao(l.shape,u.shape,n,a,r,i,!0),p=St.runKernel(function(t,e){var n=t.depthwiseConv2D(l,u,h);return e([l,u]),n},{x:l,$filter:u},function(t,e){f(po(a),function(){return\"Error in gradient of depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations '\"+a+\"'\"});var n=e[0],r=e[1];return{x:function(){return function(t,e,n,r){var o=e,a=!1;3===e.rank&&(a=!0,o=e.as4D(1,e.shape[0],e.shape[1],e.shape[2]));var i=St.runKernel(function(t){return t.depthwiseConv2DDerInput(o,n,r)},{dy4D:o});return a?i.as3D(i.shape[1],i.shape[2],i.shape[3]):i}(n.shape,t,r,h)},$filter:function(){return function(t,e,n,r){var o=t;3===t.rank&&(o=t.as4D(1,t.shape[0],t.shape[1],t.shape[2]));var a=e;return 3===a.rank&&(a=e.as4D(1,e.shape[0],e.shape[1],e.shape[2])),St.runKernel(function(t){return t.depthwiseConv2DDerFilter(o,a,r)},{x4D:o,dy4D:a})}(n,t,r.shape,h)}}});return c?p.as3D(p.shape[1],p.shape[2],p.shape[3]):p}}),yl=vn({separableConv2d_:function(t,e,n,r,o,a,i){void 0===a&&(a=[1,1]),void 0===i&&(i=\"NHWC\");var s=nn(t,\"x\",\"separableConv2d\"),u=nn(e,\"depthwiseFilter\",\"separableConv2d\"),l=nn(n,\"pointwiseFilter\",\"separableConv2d\"),c=s,h=!1;if(3===s.rank&&(h=!0,c=s.as4D(1,s.shape[0],s.shape[1],s.shape[2])),\"NCHW\"===i)throw new Error(\"separableConv2d currently does not support dataFormat NCHW; only NHWC is supported\");f(4===c.rank,function(){return\"Error in separableConv2d: input must be rank 4, but got rank \"+c.rank+\".\"}),f(4===u.rank,function(){return\"Error in separableConv2d: depthwise filter must be rank 4, but got rank \"+u.rank+\".\"}),f(4===l.rank,function(){return\"Error in separableConv2d: pointwise filter must be rank 4, but got rank \"+u.rank+\".\"}),f(1===l.shape[0],function(){return\"Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got \"+l.shape[0]+\".\"}),f(1===l.shape[1],function(){return\"Error in separableConv2d: the second dimension of pointwise filter must be 1, but got \"+l.shape[1]+\".\"});var p=u.shape[2],d=u.shape[3];f(l.shape[2]===p*d,function(){return\"Error in separableConv2d: the third dimension of pointwise filter must be \"+p*d+\", but got \"+l.shape[2]+\".\"});var v=gl(c,u,r,o,i,a),m=fl(v,l,1,\"valid\",i);return h?m.as3D(m.shape[1],m.shape[2],m.shape[3]):m}}),xl=vn({conv2dTranspose_:function(t,e,n,r,o,a){return ul(n,nn(t,\"x\",\"conv2dTranspose\"),nn(e,\"filter\",\"conv2dTranspose\"),r,o,\"NHWC\",a)}}),bl=vn({conv3dTranspose_:function(t,e,n,r,o){return hl(n,nn(t,\"x\",\"conv3dTranspose\"),nn(e,\"filter\",\"conv3dTranspose\"),r,o)}});var wl=vn({matMul_:function(t,e,n,r){var o;void 0===n&&(n=!1),void 0===r&&(r=!1);var a=nn(t,\"a\",\"matMul\"),i=nn(e,\"b\",\"matMul\");o=wt(a,i),a=o[0],i=o[1];var s=n?a.shape[a.rank-2]:a.shape[a.rank-1],u=r?i.shape[i.rank-1]:i.shape[i.rank-2],l=n?a.shape[a.rank-1]:a.shape[a.rank-2],c=r?i.shape[i.rank-2]:i.shape[i.rank-1],h=a.shape.slice(0,-2),p=i.shape.slice(0,-2),d=g(h),v=g(p);f(a.rank>=2&&i.rank>=2&&a.rank===i.rank,function(){return\"Error in matMul: inputs must have the same rank of at least 2, got ranks \"+a.rank+\" and \"+i.rank+\".\"}),f(y(h,p),function(){return\"Error in matMul: outer dimensions (\"+h+\") and (\"+p+\") of Tensors with shapes \"+a.shape+\" and \"+i.shape+\" must match.\"}),f(s===u,function(){return\"Error in matMul: inner shapes (\"+s+\") and (\"+u+\") of Tensors with shapes \"+a.shape+\" and \"+i.shape+\" and transposeA=\"+n+\" and transposeB=\"+r+\" must match.\"});var m=a.shape.slice(0,-2).concat([l,c]),x=n?a.as3D(d,s,l):a.as3D(d,l,s),b=r?i.as3D(v,c,u):i.as3D(v,u,c);return St.runKernel(function(t,e){var o=t.batchMatMul(x,b,n,r);return e([x,b]),o},{$a:x,$b:b},function(t,e){var o=e,a=o[0],i=o[1];return n||r?!n&&r?{$a:function(){return t.matMul(i,!1,!1)},$b:function(){return t.matMul(a,!0,!1)}}:n&&!r?{$a:function(){return i.matMul(t,!1,!0)},$b:function(){return a.matMul(t,!1,!1)}}:{$a:function(){return i.matMul(t,!0,!0)},$b:function(){return t.matMul(a,!0,!0)}}:{$a:function(){return t.matMul(i,!1,!0)},$b:function(){return a.matMul(t,!0,!1)}}}).reshape(m)}}),Cl=vn({dot_:function(t,e){var n=nn(t,\"t1\",\"dot\"),r=nn(e,\"t2\",\"dot\");f(!(1!==n.rank&&2!==n.rank||1!==r.rank&&2!==r.rank),function(){return\"Error in dot: inputs must all be rank 1 or 2, but got ranks \"+n.rank+\" and \"+r.rank+\".\"});var o=1===n.rank?n.size:n.shape[1],a=1===r.rank?r.size:r.shape[0];return f(o===a,function(){return\"Error in dot: inner dimensions of inputs must match, but got \"+o+\" and \"+a+\".\"}),1===n.rank&&1===r.rank?n.as2D(1,-1).matMul(r.as2D(-1,1)).asScalar():1===n.rank&&2===r.rank?n.as2D(1,-1).matMul(r.as2D(r.shape[0],r.shape[1])).as1D():2===n.rank&&1===r.rank?n.matMul(r.as2D(-1,1)).as1D():n.matMul(r.as2D(r.shape[0],r.shape[1]))}}),El=vn({outerProduct_:function(t,e){var n=nn(t,\"v1\",\"outerProduct\"),r=nn(e,\"v2\",\"outerProduct\");return f(1===n.rank&&1===r.rank,function(){return\"Error in outerProduct: inputs must be rank 1, but got ranks \"+n.rank+\" and \"+r.rank+\".\"}),n.as2D(-1,1).matMul(r.as2D(1,-1))}});var Rl=vn({reverse_:function(t,e){var n=nn(t,\"x\",\"reverse\");if(0===n.rank)return n.clone();var r=I(e,n.shape);return St.runKernel(function(t){return t.reverse(n,r)},{$x:n},function(t){return{$x:function(){return t.reverse(r)}}}).reshapeAs(n)}}),Il=vn({reverse1d_:function(t){var e=nn(t,\"x\",\"reverse\");return f(1===e.rank,function(){return\"Error in reverse1D: x must be rank 1 but got rank \"+e.rank+\".\"}),Rl(e,0)}}),kl=vn({reverse2d_:function(t,e){var n=nn(t,\"x\",\"reverse\");return f(2===n.rank,function(){return\"Error in reverse2D: x must be rank 2 but got rank \"+n.rank+\".\"}),Rl(n,e)}}),Nl=vn({reverse3d_:function(t,e){var n=nn(t,\"x\",\"reverse\");return f(3===n.rank,function(){return\"Error in reverse3D: x must be rank 3 but got rank \"+n.rank+\".\"}),Rl(n,e)}}),Sl=vn({reverse4d_:function(t,e){var n=nn(t,\"x\",\"reverse\");return f(4===n.rank,function(){return\"Error in reverse4D: x must be rank 4 but got rank \"+n.rank+\".\"}),Rl(n,e)}});function Al(t,e,n,r,o,a){var i=nn(t,\"x\",\"maxPool\"),s=i,u=!1;3===i.rank&&(u=!0,s=i.as4D(1,i.shape[0],i.shape[1],i.shape[2])),null==r&&(r=[1,1]),f(4===s.rank,function(){return\"Error in maxPool: input must be rank 4 but got rank \"+s.rank+\".\"}),f(fo(n,r),function(){return\"Error in maxPool: Either strides or dilations must be 1. Got strides \"+n+\" and dilations '\"+r+\"'\"}),null!=a&&f(x(o),function(){return\"Error in maxPool: pad must be an integer when using, dimRoundingMode \"+a+\" but got pad \"+o+\".\"});var l=ro(s.shape,e,n,r,o,a),c=St.runKernel(function(t,e){var n=t.maxPool(s,l);return e([s,n]),n},{x:s},function(t,a){var i=a[0],s=a[1];return{x:function(){return function(t,e,n,r,o,a,i,s){var u=nn(t,\"dy\",\"maxPoolBackprop\"),l=nn(e,\"input\",\"maxPoolBackprop\"),c=nn(n,\"output\",\"maxPoolBackprop\");f(l.rank===u.rank,function(){return\"Rank of input (\"+l.rank+\") does not match rank of dy (\"+u.rank+\")\"}),null==a&&(a=[1,1]),f(fo(o,a),function(){return\"Error in maxPoolBackProp: Either strides or dilations must be 1. Got strides \"+o+\" and dilations '\"+a+\"'\"}),f(4===u.rank,function(){return\"Error in maxPoolBackprop: dy must be rank 4 but got rank \"+u.rank+\".\"}),f(4===l.rank,function(){return\"Error in maxPoolBackprop: input must be rank 4 but got rank \"+l.rank+\".\"}),null!=s&&f(x(i),function(){return\"Error in maxPoolBackprop: pad must be an integer when using, dimRoundingMode \"+s+\" but got pad \"+i+\".\"});var h=ro(l.shape,r,o,a,i,s);return St.runKernel(function(t){return t.maxPoolBackprop(u,l,c,h)},{$dy:u,$input:l})}(t,i,s,e,n,r,o)}}});return u?c.as3D(c.shape[1],c.shape[2],c.shape[3]):c}function Tl(t,e,n,r,o,a){var i=nn(t,\"x\",\"avgPool\",\"float32\");null==r&&(r=[1,1]),f(fo(n,r),function(){return\"Error in avgPool: Either strides or dilations must be 1. Got strides \"+n+\" and dilations '\"+r+\"'\"});var s=i,u=!1;3===i.rank&&(u=!0,s=i.as4D(1,i.shape[0],i.shape[1],i.shape[2])),f(4===s.rank,function(){return\"Error in avgPool: x must be rank 4 but got rank \"+s.rank+\".\"}),null!=a&&f(x(o),function(){return\"Error in avgPool: pad must be an integer when using, dimRoundingMode \"+a+\" but got pad \"+o+\".\"});var l=ro(s.shape,e,n,r,o,a),c=St.runKernel(function(t){return t.avgPool(s,l)},{x:s},function(t){return{x:function(){return function(t,e,n,r,o,a){var i=nn(t,\"dy\",\"avgPoolBackprop\"),s=nn(e,\"input\",\"avgPoolBackprop\");f(s.rank===i.rank,function(){return\"Rank of input (\"+s.rank+\") does not match rank of dy (\"+i.rank+\")\"}),null==o&&(o=[1,1]),f(fo(r,o),function(){return\"Error in avgPoolBackprop: Either strides or dilations must be 1. Got strides \"+r+\" and dilations '\"+o+\"'\"});var u=s,l=i,c=!1;3===s.rank&&(c=!0,u=s.as4D(1,s.shape[0],s.shape[1],s.shape[2]),l=i.as4D(1,i.shape[0],i.shape[1],i.shape[2])),f(4===l.rank,function(){return\"Error in avgPoolBackprop: dy must be rank 4 but got rank \"+l.rank+\".\"}),f(4===u.rank,function(){return\"Error in avgPoolBackprop: input must be rank 4 but got rank \"+u.rank+\".\"});var h=ro(u.shape,n,r,o,a),p=St.runKernel(function(t){return t.avgPoolBackprop(l,u,h)},{dy4D:l,input4D:u});return c?p.as3D(p.shape[1],p.shape[2],p.shape[3]):p}(t,s,e,n,r,o)}}});return c=c.cast(i.dtype),u?c.as3D(c.shape[1],c.shape[2],c.shape[3]):c}var Dl=vn({maxPool_:function(t,e,n,r,o){return Al(t,e,n,1,r,o)}}),_l=vn({avgPool_:function(t,e,n,r,o){return Tl(t,e,n,1,r,o)}}),Ol=vn({pool_:function(t,e,n,r,o,a){null==o&&(o=[1,1]),null==a&&(a=1),0===r&&(r=\"valid\");var i=nn(t,\"x\",\"maxPool\"),s=i,u=!1;3===i.rank&&(u=!0,s=i.as4D(1,i.shape[0],i.shape[1],i.shape[2])),f(fo(a,o),function(){return\"Error in pool: Either strides or dilations must be 1. Got strides \"+a+\" and dilations '\"+o+\"'\"});var l,c=ro(s.shape,e,a,o,r),h=[c.dilationHeight,c.dilationWidth];l=\"same\"===r?function(t,e){var n=t.map(function(t,n){return t+(t-1)*(e[n]-1)}).map(function(t){return t-1}),r=n.map(function(t){return Math.floor(t/2)}),o=n.map(function(t,e){return t-r[e]});return n.map(function(t,e){return[r[e],o[e]]})}([c.filterHeight,c.filterWidth],h):[[0,0],[0,0]];var p=1===h[0]&&1===h[1],d=function(t,e,n){var r=n.map(function(t){return t[0]}),o=n.map(function(t){return t[1]}),a=t.concat(r,o),i=e.map(function(t,e){return(t-a[e]%t)%t}),s=o.map(function(t,e){return t+i[e]}),u=e.map(function(t,e){return[r[e],s[e]]}),l=e.map(function(t,e){return[0,i[e]]});return[u,l]}([c.inHeight,c.inWidth],h,l),v=d[0],m=d[1],g=p?r:\"valid\",y=p?s:br(s,h,v),x=(\"avg\"===n?function(){return Tl(y,e,a,1,g)}:function(){return Al(y,e,a,1,g)})(),b=p?x:er(x,h,m);return u?b.as3D(b.shape[1],b.shape[2],b.shape[3]):b}}),Fl=vn({maxPool3d_:function(t,e,n,r,o,a,i){void 0===a&&(a=\"NDHWC\");var s=nn(t,\"x\",\"maxPool3d\"),u=s,l=!1;4===s.rank&&(l=!0,u=s.as5D(1,s.shape[0],s.shape[1],s.shape[2],s.shape[3])),null==i&&(i=[1,1,1]),f(5===u.rank,function(){return\"Error in maxPool3d: x must be rank 5 but got rank \"+u.rank+\".\"}),f(\"NDHWC\"===a,function(){return\"Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of \"+a}),f(fo(n,i),function(){return\"Error in maxPool3d: Either strides or dilations must be 1. Got strides \"+n+\" and dilations '\"+i+\"'\"}),null!=o&&f(x(r),function(){return\"Error in maxPool3d: pad must be an integer when using, dimRoundingMode \"+o+\" but got pad \"+r+\".\"});var c=oo(u.shape,e,n,i,r,o,a),h=St.runKernel(function(t,e){var n=t.maxPool3d(u,c);return e([u,n]),n},{x:u},function(t,a){var s=a[0],u=a[1];return{x:function(){return function(t,e,n,r,o,a,i,s){var u=nn(t,\"dy\",\"maxPool3dBackprop\"),l=nn(e,\"input\",\"maxPool3dBackprop\"),c=nn(n,\"output\",\"maxPool3dBackprop\"),h=u,p=l,d=c,v=!1;4===l.rank&&(v=!0,h=u.as5D(1,u.shape[0],u.shape[1],u.shape[2],u.shape[3]),p=l.as5D(1,l.shape[0],l.shape[1],l.shape[2],l.shape[3]),d=c.as5D(1,c.shape[0],c.shape[1],c.shape[2],c.shape[3])),f(5===h.rank,function(){return\"Error in maxPool3dBackprop: dy must be rank 5 but got rank \"+h.rank+\".\"}),f(5===p.rank,function(){return\"Error in maxPool3dBackprop: input must be rank 5 but got rank \"+p.rank+\".\"}),f(5===d.rank,function(){return\"Error in maxPool3dBackprop: output must be rank 5 but got rank \"+d.rank+\".\"}),null==a&&(a=[1,1,1]),f(fo(o,a),function(){return\"Error in maxPool3dBackprop: Either strides or dilations must be 1. Got strides \"+o+\" and dilations '\"+a+\"'\"}),null!=s&&f(x(i),function(){return\"Error in maxPool3dBackprop: pad must be an integer when using, dimRoundingMode \"+s+\" but got pad \"+i+\".\"});var m=oo(p.shape,r,o,a,i,s),g=St.runKernel(function(t){return t.maxPool3dBackprop(h,p,d,m)},{dy5D:h,input5D:p});return v?g.as4D(g.shape[1],g.shape[2],g.shape[3],g.shape[4]):g}(t,s,u,e,n,i,r,o)}}});return l?h.as4D(h.shape[1],h.shape[2],h.shape[3],h.shape[4]):h}}),Ml=vn({avgPool3d_:function(t,e,n,r,o,a,i){void 0===a&&(a=\"NDHWC\");var s=nn(t,\"x\",\"avgPool3d\",\"float32\"),u=s,l=!1;4===s.rank&&(l=!0,u=s.as5D(1,s.shape[0],s.shape[1],s.shape[2],s.shape[3])),null==i&&(i=[1,1,1]),f(5===u.rank,function(){return\"Error in avgPool3d: x must be rank 5 but got rank \"+u.rank+\".\"}),f(\"NDHWC\"===a,function(){return\"Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of \"+a}),f(fo(n,i),function(){return\"Error in avgPool3d: Either strides or dilations must be 1. Got strides \"+n+\" and dilations '\"+i+\"'\"}),null!=o&&f(x(r),function(){return\"Error in avgPool3d: pad must be an integer when using, dimRoundingMode \"+o+\" but got pad \"+r+\".\"});var c=oo(u.shape,e,n,i,r,o,a),h=St.runKernel(function(t){return t.avgPool3d(u,c)},{x:u},function(t){return{x:function(){return function(t,e,n,r,o,a,i){var s=nn(t,\"dy\",\"avgPool3dBackprop\"),u=nn(e,\"input\",\"avgPool3dBackprop\"),l=s,c=u,h=!1;4===u.rank&&(h=!0,l=s.as5D(1,s.shape[0],s.shape[1],s.shape[2],s.shape[3]),c=u.as5D(1,u.shape[0],u.shape[1],u.shape[2],u.shape[3])),f(5===l.rank,function(){return\"Error in avgPool3dBackprop: dy must be rank 5 but got rank \"+l.rank+\".\"}),f(5===c.rank,function(){return\"Error in avgPool3dBackprop: input must be rank 5 but got rank \"+c.rank+\".\"}),null==o&&(o=[1,1,1]),f(fo(r,o),function(){return\"Error in avgPool3dBackprop: Either strides or dilations must be 1. Got strides \"+r+\" and dilations '\"+o+\"'\"}),null!=i&&f(x(a),function(){return\"Error in maxPool3dBackprop: pad must be an integer when using, dimRoundingMode \"+i+\" but got pad \"+a+\".\"});var p=oo(c.shape,n,r,o,a,i),d=St.runKernel(function(t){return t.avgPool3dBackprop(l,c,p)},{dy5D:l,input5D:c});return h?d.as4D(d.shape[1],d.shape[2],d.shape[3],d.shape[4]):d}(t,u,e,n,i,r,o)}}});return h=h.cast(u.dtype),l?h.as4D(h.shape[1],h.shape[2],h.shape[3],h.shape[4]):h}});var Bl=vn({slice_:function(t,e,n){var r,o,a=nn(t,\"x\",\"slice\");if(0===a.rank)throw new Error(\"Slicing scalar is not possible\");(r=\"number\"==typeof e?[e].concat(new Array(a.rank-1).fill(0)):e.length<a.rank?e.concat(new Array(a.rank-e.length).fill(0)):e.slice()).forEach(function(t){f(-1!==t,function(){return\"slice() does not support negative begin indexing.\"})}),o=(o=null==n?new Array(a.rank).fill(-1):\"number\"==typeof n?[n].concat(new Array(a.rank-1).fill(-1)):n.length<a.rank?n.concat(new Array(a.rank-n.length).fill(-1)):n).map(function(t,e){return t>=0?t:(f(-1===t,function(){return\"Negative size values should be exactly -1 but got \"+t+\" for the slice() size at index \"+e+\".\"}),a.shape[e]-r[e])}),function(t,e,n){f(t.rank===e.length,function(){return\"Error in slice\"+t.rank+\"D: Length of begin \"+e+\" must match the rank of the array (\"+t.rank+\").\"}),f(t.rank===n.length,function(){return\"Error in slice\"+t.rank+\"D: Length of size \"+n+\" must match the rank of the array (\"+t.rank+\").\"});for(var r=function(r){f(e[r]+n[r]<=t.shape[r],function(){return\"Error in slice\"+t.rank+\"D: begin[\"+r+\"] + size[\"+r+\"] (\"+(e[r]+n[r])+\") would overflow input.shape[\"+r+\"] (\"+t.shape[r]+\")\"})},o=0;o<t.rank;++o)r(o)}(a,r,o);var i=a.shape;return St.runKernel(function(t){return t.slice(a,r,o)},{$x:a},function(t){for(var e=[],n=0;n<t.rank;n++)e.push([r[n],i[n]-r[n]-o[n]]);return{$x:function(){return t.pad(e)}}})}}),Pl=vn({slice1d_:function(t,e,n){var r=nn(t,\"x\",\"slice1d\");return f(1===r.rank,function(){return\"slice1d expects a rank-1 tensor, but got a rank-\"+r.rank+\" tensor\"}),Bl(r,[e],[n])}}),Ll=vn({slice2d_:function(t,e,n){var r=nn(t,\"x\",\"slice2d\");return f(2===r.rank,function(){return\"slice2d expects a rank-2 tensor, but got a rank-\"+r.rank+\" tensor\"}),Bl(r,e,n)}}),Wl=vn({slice3d_:function(t,e,n){var r=nn(t,\"x\",\"slice3d\");return f(3===r.rank,function(){return\"slice3d expects a rank-3 tensor, but got a rank-\"+r.rank+\" tensor\"}),Bl(r,e,n)}}),Ul=vn({slice4d_:function(t,e,n){var r=nn(t,\"x\",\"slice4d\");return f(4===r.rank,function(){return\"slice4d expects a rank-4 tensor, but got a rank-\"+r.rank+\" tensor\"}),Bl(r,e,n)}});function Vl(t,e,n,r,o){return e.rank<n.rank&&(e=e.reshape(un(e.shape,r))),t.rank<n.rank&&(t=t.reshape(un(t.shape,r))),{$x:function(){var r=t.mul(n.equal(e).cast(t.dtype));return null==o?r:r.transpose(o)}}}var zl=vn({all_:function(t,e,n){void 0===e&&(e=null),void 0===n&&(n=!1);var r=nn(t,\"x\",\"all\",\"bool\"),o=I(e,r.shape),a=o,i=cn(a,r.rank);null!=i&&(r=r.transpose(i),a=pn(a.length,r.rank));var s=St.runKernel(function(t){return t.all(r,a)},{$x:r});if(n){var u=un(s.shape,o);return s.reshape(u)}return s}}),Gl=vn({any_:function(t,e,n){void 0===e&&(e=null),void 0===n&&(n=!1);var r=nn(t,\"x\",\"any\",\"bool\"),o=I(e,r.shape),a=o,i=cn(a,r.rank);null!=i&&(r=r.transpose(i),a=pn(a.length,r.rank));var s=St.runKernel(function(t){return t.any(r,a)},{$x:r});if(n){var u=un(s.shape,o);return s.reshape(u)}return s}}),Hl=vn({argMax_:function(t,e){void 0===e&&(e=0);var n=nn(t,\"x\",\"argMax\");null==e&&(e=0);var r=I(e,n.shape),o=cn(r,n.rank);return null!=o&&(n=n.transpose(o),r=pn(r.length,n.rank)),St.runKernel(function(t,e){var o=t.argMax(n,r[0]);return e([n]),o},{$x:n},function(t,e){var n=e[0];return{$x:function(){return Fn(n)}}})}}),ql=vn({argMin_:function(t,e){void 0===e&&(e=0);var n=nn(t,\"x\",\"argMin\");null==e&&(e=0);var r=I(e,n.shape),o=cn(r,n.rank);return null!=o&&(n=n.transpose(o),r=pn(r.length,n.rank)),St.runKernel(function(t,e){var o=t.argMin(n,r[0]);return e([n]),o},{$x:n},function(t,e){var n=e[0];return{$x:function(){return Fn(n)}}})}}),$l=vn({logSumExp_:function(t,e,n){void 0===e&&(e=null),void 0===n&&(n=!1);var r=nn(t,\"x\",\"logSumExp\"),o=I(e,r.shape),a=r.max(o,!0),i=r.sub(a).exp().sum(o).log(),s=a.reshape(i.shape).add(i);if(n){var u=un(s.shape,o);return s.reshape(u)}return s}}),Kl=vn({max_:function(t,e,n){void 0===e&&(e=null),void 0===n&&(n=!1);var r=nn(t,\"x\",\"max\"),o=r,a=I(e,r.shape),i=a,s=cn(i,r.rank);null!=s&&(r=r.transpose(s),i=pn(i.length,r.rank));var u=St.runKernel(function(t,e){var n=t.max(r,i);return e([o,n]),n},{$x:r},function(t,e){return Vl(t,e[1],e[0],a,s)});if(n){var l=un(u.shape,a);u=u.reshape(l)}return u}}),jl=vn({mean_:function(t,e,n){void 0===e&&(e=null),void 0===n&&(n=!1);var r=nn(t,\"x\",\"mean\"),o=I(e,r.shape),a=g(sn(r.shape,o)[1]);return jr(function(t){var r=wn(a);return{value:(r.dtype===t.dtype?t:t.cast(r.dtype)).div(r).sum(e,n),gradFunc:function(e){var n=t.shape.slice();return o.forEach(function(t){n[t]=1}),e.reshape(n).mul(Sn(t.shape,\"float32\")).div(a)}}})(r)}}),Xl=vn({min_:function(t,e,n){void 0===e&&(e=null),void 0===n&&(n=!1);var r=nn(t,\"x\",\"min\"),o=r,a=I(e,r.shape),i=a,s=cn(i,r.rank);null!=s&&(r=r.transpose(s),i=pn(i.length,r.rank));var u=St.runKernel(function(t,e){var n=t.min(r,i);return e([o,n]),n},{$x:r},function(t,e){return Vl(t,e[1],e[0],a,s)});if(n){var l=un(u.shape,a);u=u.reshape(l)}return u}}),Yl=vn({moments_:function(t,e,n){void 0===e&&(e=null),void 0===n&&(n=!1);var r=I(e,(t=nn(t,\"x\",\"moments\")).shape),o=t.mean(r,n),a=o.shape;n||(a=un(o.shape,r));var i=t.toFloat().sub(o.reshape(a)).square();return{mean:o,variance:i.mean(r,n)}}}),Ql=vn({sum_:function(t,e,n){void 0===e&&(e=null),void 0===n&&(n=!1);var r=nn(t,\"x\",\"sum\");\"bool\"===r.dtype&&(r=r.toInt());var o=I(e,r.shape);return jr(function(t){var e=cn(o,t.rank),r=o,a=t;null!=e&&(a=t.transpose(e),r=pn(r.length,t.rank));var i=St.runKernel(function(t){return t.sum(a,r)},{permutedX:a});if(n){var s=un(i.shape,o);i=i.reshape(s)}return{value:i,gradFunc:function(e){var n=t.shape.slice();return o.forEach(function(t){n[t]=1}),e.reshape(n).mul(Sn(t.shape,\"float32\"))}}})(r)}}),Jl=vn({prod_:function(t,e,n){void 0===e&&(e=null),void 0===n&&(n=!1);var r=nn(t,\"x\",\"prod\");\"bool\"===r.dtype&&(r=r.toInt());var o=I(e,r.shape),a=cn(o,r.rank),i=o,s=r;null!=a&&(s=r.transpose(a),i=pn(i.length,r.rank));var u=St.runKernel(function(t){return t.prod(s,i)},{permutedX:s});if(n){var l=un(u.shape,o);u=u.reshape(l)}return u}});var Zl=vn({elu_:function(t){var e=nn(t,\"x\",\"elu\");return St.runKernel(function(t,n){var r=t.elu(e);return n([r]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return St.runKernel(function(e){return e.eluDer(t,n)},{dy:t,y:n})}}})}}),tc=vn({leakyRelu_:function(t,e){void 0===e&&(e=.2);var n=nn(t,\"x\",\"leakyRelu\");return Du(wn(e).mul(n),n)}}),ec=vn({prelu_:function(t,e){var n=nn(t,\"x\",\"prelu\"),r=nn(e,\"alpha\",\"prelu\");return St.runKernel(function(t,e){var o=t.prelu(n,r);return e([n,r]),o},{$x:n,$alpha:r},function(t,e){var n=e[0],r=e[1],o=n.greater(0);return{$x:function(){return Cu(o,t,t.mul(r))},$alpha:function(){var e=Cu(o,Fn(t),t.mul(n)),a=eo(r.shape,t.shape);return a.length>0&&(e=e.sum(a)),e.reshape(r.shape)}}})}}),nc=vn({relu_:function(t){var e=nn(t,\"x\",\"relu\");return\"bool\"===e.dtype?e.toInt():St.runKernel(function(t,n){var r=t.relu(e);return n([e]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){return t.mulStrict(n.step().toFloat())}}})}}),rc=vn({selu_:function(t){var e=nn(t,\"x\",\"selu\");return St.runKernel(function(t,n){var r=t.selu(e);return n([e]),r},{$x:e},function(t,e){var n=e[0];return{$x:function(){var e=n.greater(wn(0)),r=wn(ji),o=wn(Xi),a=t.mul(o),i=t.mul(r).mul(n.toFloat().exp());return Cu(e,a,i)}}})}});var oc=vn({transpose_:function(t,e){var n=nn(t,\"x\",\"transpose\");return null==e&&(e=n.shape.map(function(t,e){return e}).reverse()),f(n.rank===e.length,function(){return\"Error in transpose: rank of input \"+n.rank+\" must match length of perm \"+e+\".\"}),e.forEach(function(t){f(t>=0&&t<n.rank,function(){return\"All entries in 'perm' must be between 0 and \"+(n.rank-1)+\" but got \"+e})}),n.rank<=1?n.clone():St.runKernel(function(t){return t.transpose(n,e)},{$x:n},function(t){var n=hn(e);return{$x:function(){return t.transpose(n)}}})}});var ac=vn({localResponseNormalization_:function(t,e,n,r,o){void 0===e&&(e=5),void 0===n&&(n=1),void 0===r&&(r=1),void 0===o&&(o=.5);var a=nn(t,\"x\",\"localResponseNormalization\");f(4===a.rank||3===a.rank,function(){return\"Error in localResponseNormalization: x must be rank 3 or 4 but got\\n               rank \"+a.rank+\".\"}),f(x(e),function(){return\"Error in localResponseNormalization: depthRadius must be an integer but got depthRadius \"+e+\".\"});var i=a,s=!1;3===a.rank&&(s=!0,i=a.as4D(1,a.shape[0],a.shape[1],a.shape[2]));var u=St.runKernel(function(t,a){var s=t.localResponseNormalization4D(i,e,n,r,o);return a([i,s]),s},{x4D:i},function(t,a){var i=a[0],s=a[1];return{x4D:function(){return St.runKernel(function(a){return a.LRNGrad(t,i,s,e,n,r,o)},{})}}});return s?u.as3D(u.shape[1],u.shape[2],u.shape[3]):u}});var ic=vn({norm_:function(t,e,n,r){void 0===e&&(e=\"euclidean\"),void 0===n&&(n=null),void 0===r&&(r=!1);var o=function t(e,n,r){if(void 0===r&&(r=null),0===e.rank)return e.abs();if(1!==e.rank&&null===r)return t(e.reshape([-1]),n,r);if(1===e.rank||\"number\"==typeof r||Array.isArray(r)&&1===r.length){if(1===n)return e.abs().sum(r);if(n===1/0)return e.abs().max(r);if(n===-1/0)return e.abs().min(r);if(\"euclidean\"===n||2===n)return e.abs().pow(wn(2,\"int32\")).sum(r).sqrt();throw new Error(\"Error in norm: invalid ord value: \"+n)}if(Array.isArray(r)&&2===r.length){if(1===n)return e.abs().sum(r[0]).max(r[1]-1);if(n===1/0)return e.abs().sum(r[1]).max(r[0]);if(n===-1/0)return e.abs().sum(r[1]).min(r[0]);if(\"fro\"===n||\"euclidean\"===n)return e.square().sum(r).sqrt();throw new Error(\"Error in norm: invalid ord value: \"+n)}throw new Error(\"Error in norm: invalid axis: \"+r)}(t=nn(t,\"x\",\"norm\"),e,n),a=o.shape;if(r){var i=I(n,t.shape);a=un(o.shape,i)}return o.reshape(a)}});var sc=vn({basicLSTMCell_:function(t,e,n,r,o,a){var i=nn(t,\"forgetBias\",\"basicLSTMCell\"),s=nn(e,\"lstmKernel\",\"basicLSTMCell\"),u=nn(n,\"lstmBias\",\"basicLSTMCell\"),l=nn(r,\"data\",\"basicLSTMCell\"),c=nn(o,\"c\",\"basicLSTMCell\"),h=nn(a,\"h\",\"basicLSTMCell\"),p=l.concat(h,1).matMul(s).add(u),f=p.shape[0],d=p.shape[1]/4,v=[f,d],m=p.slice([0,0],v),g=p.slice([0,d],v),y=p.slice([0,2*d],v),x=p.slice([0,3*d],v),b=m.sigmoid().mulStrict(g.tanh()).addStrict(c.mulStrict(i.add(y).sigmoid())),w=b.tanh().mulStrict(x.sigmoid());return[b,w]}}),uc=vn({multiRNNCell_:function(t,e,n,r){for(var o=nn(e,\"data\",\"multiRNNCell\"),a=rn(n,\"c\",\"multiRNNCell\"),i=rn(r,\"h\",\"multiRNNCell\"),s=o,u=[],l=0;l<t.length;l++){var c=t[l](s,a[l],i[l]);u.push(c[0]),u.push(c[1]),s=c[1]}var h=[],p=[];for(l=0;l<u.length;l+=2)h.push(u[l]),p.push(u[l+1]);return[h,p]}});var lc=vn({movingAverage_:function(t,e,n,r,o){void 0===o&&(o=!0);var a=nn(t,\"v\",\"movingAverage\"),i=nn(e,\"x\",\"movingAverage\"),s=nn(n,\"decay\",\"movingAverage\");Ct(a,i),f(y(a.shape,i.shape),function(){return\"Shape mismatch in v and x\"});var u=wn(1),l=u.sub(s),c=i.sub(a).mul(l);if(o){f(null!=r,function(){return\"When using zeroDebias: true, step is required.\"});var h=nn(r,\"step\",\"movingAverage\");c=c.div(u.sub(Wu(s,h)))}return a.add(c)}});var cc=vn({stridedSlice_:function(t,e,n,r,o,a,i,s,u){if(void 0===o&&(o=0),void 0===a&&(a=0),void 0===i&&(i=0),void 0===s&&(s=0),void 0===u&&(u=0),null==r&&(r=new Array(e.length)),0!==i)throw new Error(\"ellipsis mask is not yet supported\");var l=nn(t,\"x\",\"stridedSlice\"),c=Pr(s),h=l.shape.slice();c.forEach(function(t){e[t]=0,n[t]=1,h.splice(t,0,1)}),l=l.reshape(h);for(var p=0;p<l.rank;p++)e[p]=Wr(o,e,r,l.shape,p),n[p]=Ur(a,n,r,l.shape,p),r[p]=r[p]||1;var f=Pr(u);f.forEach(function(t){n[t]=e[t]+1,r[t]=1});var d=Lr(e,n,r),v=d.filter(function(t,e){return-1===f.indexOf(e)});return r.every(function(t){return 1===t})?Bl(l,e,d).reshape(v):St.runKernel(function(t){return t.stridedSlice(l,e,n,r)},{$x:l}).reshape(v)}});var hc=vn({topk_:function(t,e,n){void 0===e&&(e=1),void 0===n&&(n=!0);var r=nn(t,\"x\",\"topk\");if(0===r.rank)throw new Error(\"topk() expects the input to be of rank 1 or higher\");var o=r.shape[r.shape.length-1];if(e>o)throw new Error(\"'k' passed to topk() must be <= the last dimension (\"+o+\") but got \"+e);var a=St.runKernel(function(t){return t.topk(r,e,n)},{$x:r});return{values:a[0],indices:a[1]}}});var pc=vn({scatterND_:function(t,e,n){var r=nn(t,\"indices\",\"scatterND\",\"int32\"),o=nn(e,\"updates\",\"scatterND\");return Mr(o,r,n),St.runKernel(function(t){return t.scatterND(r,o,n)},{$indices:r,$updates:o})}});var fc=vn({fft_:function(t){f(\"complex64\"===t.dtype,function(){return\"The dtype for tf.spectral.fft() must be complex64 but got \"+t.dtype+\".\"});var e=t.shape[t.shape.length-1],n=t.size/e,r=t.as2D(n,e);return St.runKernel(function(t){return t.fft(r)},{input:t}).reshape(t.shape)}}),dc=vn({ifft_:function(t){f(\"complex64\"===t.dtype,function(){return\"The dtype for tf.spectral.ifft() must be complex64 but got \"+t.dtype+\".\"});var e=t.shape[t.shape.length-1],n=t.size/e,r=t.as2D(n,e);return St.runKernel(function(t){return t.ifft(r)},{input:t}).reshape(t.shape)}}),vc=vn({rfft_:function(t,e){f(\"float32\"===t.dtype,function(){return\"The dtype for rfft() must be real value but got \"+t.dtype});var n,r=t.shape[t.shape.length-1],o=t.size/r;if(null!=e&&e<r){var a=t.shape.map(function(t){return 0}),i=t.shape.map(function(t){return t});i[t.shape.length-1]=e,n=t.slice(a,i),r=e}else if(null!=e&&e>r){var s=t.shape.map(function(t){return t});s[t.shape.length-1]=e-r,n=t.concat(An(s),t.shape.length-1),r=e}else n=t;var u=n.zerosLike(),l=mn(n,u).as2D(o,r),c=fc(l),h=Math.floor(r/2)+1,p=gn(c),d=yn(c),v=p.split([h,r-h],p.shape.length-1),m=d.split([h,r-h],d.shape.length-1),g=n.shape.slice();return g[n.shape.length-1]=h,mn(v[0],m[0]).reshape(g)}}),mc=vn({irfft_:function(t){var e=t.shape[t.shape.length-1],n=t.size/e;if(e<=2){var r=t.as2D(n,e),o=dc(r);return gn(o)}var a=[n,2*(e-1)],i=gn(t).as2D(n,e),s=yn(t).as2D(n,e),u=i.slice([0,1],[n,e-2]).reverse(1),l=s.slice([0,1],[n,e-2]).reverse(1).mul(wn(-1)),c=i.concat(u,1),h=s.concat(l,1);return r=mn(c,h).as2D(a[0],a[1]),o=dc(r),gn(o)}}),gc=Object.freeze({fft:fc,ifft:dc,rfft:vc,irfft:mc});var yc=vn({sparseToDense_:function(t,e,n,r){void 0===r&&(r=0);var o=nn(t,\"sparseIndices\",\"sparseToDense\",\"int32\"),a=nn(e,\"sparseValues\",\"sparseToDense\"),i=nn(r,\"defaultValue\",\"sparseToDense\",a.dtype);return function(t,e,n,r){if(\"int32\"!==t.dtype)throw new Error(\"tf.sparseToDense() expects the indices to be int32 type, but the dtype was \"+t.dtype+\".\");if(t.rank>2)throw new Error(\"sparseIndices should be a scalar, vector, or matrix, but got shape \"+t.shape+\".\");var o=t.rank>0?t.shape[0]:1,a=t.rank>1?t.shape[1]:1;if(n.length!==a)throw new Error(\"outputShape has incorrect number of elements:, \"+n.length+\", should be: \"+a+\".\");var i=e.size;if(0!==e.rank&&(1!==e.rank||i!==o))throw new Error(\"sparseValues has incorrect shape \"+e.shape+\", should be [] or [\"+o+\"]\");if(e.dtype!==r.dtype)throw new Error(\"sparseValues.dtype must match defaultValues.dtype\")}(o,a,n,i),St.runKernel(function(t){return t.sparseToDense(o,a,n,i)},{$sparseIndices:o,$sparseValues:a,$defaultValue:i})}});var xc=vn({gatherND_:function(t,e){var n=nn(e,\"indices\",\"gatherND\",\"int32\"),r=nn(t,\"x\",\"gatherND\");return St.runKernel(function(t){return t.gatherND(r,n)},{$x:r,$indices:n})}});var bc=vn({diag_:function(t){var e=nn(t,\"x\",\"diag\").flatten(),n=t.shape.concat(t.shape);return St.runKernel(function(t){return t.diag(e)},{$x:e}).reshape(n)}});var wc=vn({dropout_:function(t,e,n,r){var o=nn(t,\"x\",\"dropout\");if(f(\"float32\"===o.dtype,function(){return\"x has to be a floating point tensor since it's going to be scaled, but got a \"+o.dtype+\" tensor instead.\"}),f(e>=0&&e<1,function(){return\"rate must be a float in the range [0, 1), but got \"+e+\".\"}),0===e)return t instanceof ct?o.clone():o;var a=function(t,e){if(null==e)return t.shape.slice();if(y(t.shape,e))return e;if(t.shape.length===e.length){for(var n=[],r=0;r<t.shape.length;r++)null==e[r]&&null!=t.shape[r]?n.push(t.shape[r]):n.push(e[r]);return n}return e}(o,n),i=1-e,s=yr(a,0,1,\"float32\",r).add(i).floor().div(i);return o.mul(s)}});function Cc(t,e,n){for(var r=1-t%2,o=new Float32Array(t),a=0;a<t;++a){var i=2*Math.PI*a/(t+r-1);o[a]=e-n*Math.cos(i)}return Cn(o,\"float32\")}var Ec=vn({hannWindow_:function(t){return Cc(t,.5,.5)}}),Rc=vn({hammingWindow_:function(t){return Cc(t,.54,.46)}}),Ic=vn({frame_:function(t,e,n,r,o){void 0===r&&(r=!1),void 0===o&&(o=0);for(var a=0,i=[];a+e<=t.size;)i.push(Bl(t,a,e)),a+=n;if(r)for(;a<t.size;){var s=a+e-t.size,u=Mn([Bl(t,a,e-s),Tn([s],o)]);i.push(u),a+=n}return 0===i.length?En([],[0,e]):Mn(i).as2D(i.length,e)}}),kc=vn({stft_:function(t,e,n,r,o){var a;void 0===o&&(o=Ec),null==r&&(a=e,r=Math.floor(Math.pow(2,Math.ceil(Math.log(a)/Math.log(2)))));for(var i=Ic(t,e,n),s=Pu(i,o(e)),u=[],l=0;l<i.shape[0];l++)u.push(vc(s.slice([l,0],[1,e]),r));return Mn(u)}}),Nc=Object.freeze({hannWindow:Ec,hammingWindow:Rc,frame:Ic,stft:kc});var Sc,Ac=function(t,e,o){return void 0===o&&(o=1),n(this,void 0,void 0,function(){var n,a,i,s,u,l,c,h,p,v,m,g,y,x;return r(this,function(r){switch(r.label){case 0:return n=nn(t,\"predictions\",\"inTopK\"),a=nn(e,\"targets\",\"inTopK\"),f(n.rank>1,function(){return\"inTopK() expects the predictions to be of rank 2 or higher, but got \"+n.rank}),f(n.rank-1===a.rank,function(){return\"predictions rank should be 1 larger than targets rank, but got predictions rank \"+n.rank+\" and targets rank \"+a.rank}),d(n.shape.slice(0,n.shape.length-1),a.shape,\"predictions's shape should be align with the targets' shape, except the last dimension.\"),i=n.shape[n.shape.length-1],f(o>0&&o<=i,function(){return\"'k' passed to inTopK() must be > 0 && <= the predictions last dimension (\"+i+\"), but got \"+o}),[4,n.data()];case 1:return s=r.sent(),[4,a.data()];case 2:for(u=r.sent(),l=[s.length/i,i],h=l[1],p=N(\"bool\",c=l[0]),v=0;v<c;v++){for(m=v*h,g=s.subarray(m,m+h),y=[],x=0;x<g.length;x++)y.push({value:g[x],index:x});for(y.sort(function(t,e){return e.value-t.value}),p[v]=0,x=0;x<o;x++)if(y[x].index===u[v]){p[v]=1;break}}return t!==n&&n.dispose(),e!==a&&a.dispose(),[2,xn(p,a.shape,\"bool\")]}})})};!function(t){t[t.NONE=0]=\"NONE\",t[t.MEAN=1]=\"MEAN\",t[t.SUM=2]=\"SUM\",t[t.SUM_BY_NONZERO_WEIGHTS=3]=\"SUM_BY_NONZERO_WEIGHTS\"}(Sc||(Sc={}));var Tc=vn({absoluteDifference_:function(t,e,n,r){void 0===r&&(r=Sc.SUM_BY_NONZERO_WEIGHTS);var o=nn(t,\"labels\",\"absoluteDifference\"),a=nn(e,\"predictions\",\"absoluteDifference\"),i=null;null!=n&&(i=nn(n,\"weights\",\"absoluteDifference\")),d(o.shape,a.shape,\"Error in absoluteDifference: \");var s=o.sub(a).abs();return Dc(s,i,r)}}),Dc=vn({computeWeightedLoss_:function(t,e,n){void 0===n&&(n=Sc.SUM_BY_NONZERO_WEIGHTS);var r=nn(t,\"losses\",\"computeWeightedLoss\"),o=null;null!=e&&(o=nn(e,\"weights\",\"computeWeightedLoss\"));var a=null==o?r:r.mul(o);if(n===Sc.NONE)return a;if(n===Sc.SUM)return a.sum();if(n===Sc.MEAN){if(null==o)return a.mean();var i=r.size/o.size,s=a.sum().div(o.sum());return i>1?s.div(wn(i)):s}if(n===Sc.SUM_BY_NONZERO_WEIGHTS){if(null==o)return a.sum().div(wn(r.size));var u=o.mul(Sn(r.shape)).notEqual(wn(0)).sum().toFloat();return a.sum().div(u)}throw Error(\"Unknown reduction: \"+n)}}),_c=vn({cosineDistance_:function(t,e,n,r,o){void 0===o&&(o=Sc.SUM_BY_NONZERO_WEIGHTS);var a=nn(t,\"labels\",\"cosineDistance\"),i=nn(e,\"predictions\",\"cosineDistance\"),s=null;null!=r&&(s=nn(r,\"weights\",\"cosineDistance\")),d(a.shape,i.shape,\"Error in cosineDistance: \");var u=wn(1).sub(a.mul(i).sum(n,!0));return Dc(u,s,o)}}),Oc=vn({hingeLoss_:function(t,e,n,r){void 0===r&&(r=Sc.SUM_BY_NONZERO_WEIGHTS);var o=nn(t,\"labels\",\"hingeLoss\"),a=nn(e,\"predictions\",\"hingeLoss\"),i=null;null!=n&&(i=nn(n,\"weights\",\"hingeLoss\")),d(o.shape,a.shape,\"Error in hingeLoss: \");var s=wn(1);o=wn(2).mul(o).sub(s);var u=s.sub(o.mul(a)).relu();return Dc(u,i,r)}}),Fc=vn({huberLoss_:function(t,e,n,r,o){void 0===r&&(r=1),void 0===o&&(o=Sc.SUM_BY_NONZERO_WEIGHTS);var a=nn(t,\"labels\",\"huberLoss\"),i=nn(e,\"predictions\",\"huberLoss\"),s=null;null!=n&&(s=nn(n,\"weights\",\"huberLoss\")),d(a.shape,i.shape,\"Error in huberLoss: \");var u=wn(r),l=i.sub(a).abs(),c=Ou(l,u),h=l.sub(c),p=wn(.5).mul(c.square()).add(u.mul(h));return Dc(p,s,o)}}),Mc=vn({logLoss_:function(t,e,n,r,o){void 0===r&&(r=1e-7),void 0===o&&(o=Sc.SUM_BY_NONZERO_WEIGHTS);var a=nn(t,\"labels\",\"logLoss\"),i=nn(e,\"predictions\",\"logLoss\"),s=null;null!=n&&(s=nn(n,\"weights\",\"logLoss\")),d(a.shape,i.shape,\"Error in logLoss: \");var u=wn(1),l=wn(r),c=a.mul(i.add(l).log()).neg().sub(u.sub(a).mul(u.sub(i).add(l).log()));return Dc(c,s,o)}}),Bc=vn({meanSquaredError_:function(t,e,n,r){void 0===r&&(r=Sc.SUM_BY_NONZERO_WEIGHTS);var o=nn(t,\"labels\",\"meanSquaredError\"),a=nn(e,\"predictions\",\"meanSquaredError\"),i=null;null!=n&&(i=nn(n,\"weights\",\"meanSquaredError\")),d(o.shape,a.shape,\"Error in meanSquaredError: \");var s=o.squaredDifference(a);return Dc(s,i,r)}}),Pc=vn({sigmoidCrossEntropy_:function(t,e,n,r,o){void 0===r&&(r=0),void 0===o&&(o=Sc.SUM_BY_NONZERO_WEIGHTS);var a=nn(t,\"multiClassLabels\",\"sigmoidCrossEntropy\"),i=nn(e,\"logits\",\"sigmoidCrossEntropy\"),s=null;if(null!=n&&(s=nn(n,\"weights\",\"sigmoidCrossEntropy\")),d(a.shape,i.shape,\"Error in sigmoidCrossEntropy: \"),r>0){var u=wn(r),l=wn(1),c=wn(.5);a=a.mul(l.sub(u)).add(c.mul(u))}var h=function(t,e){var n=nn(t,\"labels\",\"sigmoidCrossEntropyWithLogits\"),r=nn(e,\"logits\",\"sigmoidCrossEntropyWithLogits\");d(n.shape,r.shape,\"Error in sigmoidCrossEntropyWithLogits: \");var o=r.relu(),a=r.mul(n),i=r.abs().neg().exp().log1p();return o.sub(a).add(i)}(a,i);return Dc(h,s,o)}}),Lc=vn({softmaxCrossEntropy_:function(t,e,n,r,o){void 0===r&&(r=0),void 0===o&&(o=Sc.SUM_BY_NONZERO_WEIGHTS);var a=nn(t,\"onehotLabels\",\"softmaxCrossEntropy\"),i=nn(e,\"logits\",\"softmaxCrossEntropy\"),s=null;if(null!=n&&(s=nn(n,\"weights\",\"softmaxCrossEntropy\")),d(a.shape,i.shape,\"Error in softmaxCrossEntropy: \"),r>0){var u=wn(r),l=wn(1),c=wn(a.shape[1]);a=a.mul(l.sub(u)).add(u.div(c))}var h=function(t,e,n){if(void 0===n&&(n=-1),-1===n&&(n=e.rank-1),n!==e.rank-1)throw Error(\"Softmax cross entropy along a non-last dimension is not yet supported. Labels / logits was rank \"+e.rank+\" and dim was \"+n);return jr(function(t,e,r){var o=e.logSumExp([n],!0),a=e.toFloat().sub(o);return r([t,a]),{value:a.mul(t).neg().sum([n]),gradFunc:function(t,e){var r=e[0],o=e[1],a=un(t.shape,[n]);return[t.reshape(a).mul(r.toFloat().sub(o.exp())),t.reshape(a).mul(o.exp().sub(r.toFloat()))]}}})(t,e)}(a,i);return Dc(h,s,o)}}),Wc=Object.freeze({get Reduction(){return Sc},absoluteDifference:Tc,computeWeightedLoss:Dc,cosineDistance:_c,hingeLoss:Oc,huberLoss:Fc,logLoss:Mc,meanSquaredError:Bc,sigmoidCrossEntropy:Pc,softmaxCrossEntropy:Lc});function Uc(t,e){return void 0===e&&(e=!1),St.tidy(function(){if(2!==t.shape.length)throw new Error(\"qr2d() requires a 2D Tensor, but got a \"+t.shape.length+\"D Tensor.\");for(var n=t.shape[0],r=t.shape[1],o=sr(n),a=t.clone(),i=En([[1]],[1,1]),s=i.clone(),u=n>=r?r:n,l=function(t){var e,u=a,l=s,c=o;e=St.tidy(function(){var e=a.slice([t,t],[n-t,1]),u=e.norm(),l=a.slice([t,t],[1,1]),c=En([[-1]]).where(l.greater(0),En([[1]])),h=l.sub(c.mul(u)),p=e.div(h);s=1===p.shape[0]?i.clone():i.concat(p.slice([1,0],[p.shape[0]-1,p.shape[1]]),0);var f=c.matMul(h).div(u).neg(),d=a.slice([t,0],[n-t,r]),v=f.mul(s);if(0===t)a=d.sub(v.matMul(s.transpose().matMul(d)));else{var m=d.sub(v.matMul(s.transpose().matMul(d)));a=a.slice([0,0],[t,r]).concat(m,0)}var g=o.slice([0,t],[n,o.shape[1]-t]);if(0===t)o=g.sub(g.matMul(s).matMul(v.transpose()));else{var y=g.sub(g.matMul(s).matMul(v.transpose()));o=o.slice([0,0],[n,t]).concat(y,1)}return[s,a,o]}),s=e[0],a=e[1],o=e[2],Ve([u,l,c])},c=0;c<u;++c)l(c);return!e&&n>r&&(o=o.slice([0,0],[n,r]),a=a.slice([0,0],[r,r])),[o,a]})}var Vc=vn({gramSchmidt_:function(t){var e;if(Array.isArray(t)){e=!1,f(null!=t&&t.length>0,function(){return\"Gram-Schmidt process: input must not be null, undefined, or empty\"});for(var n=t[0].shape[0],r=function(e){f(t[e].shape[0]===n,function(){return\"Gram-Schmidt: Non-unique lengths found in the input vectors: (\"+t[e].shape[0]+\" vs. \"+n+\")\"})},o=1;o<t.length;++o)r(o)}else e=!0,t=Un(t,t.shape[0],0).map(function(t){return wr(t,[0])});f(t.length<=t[0].shape[0],function(){return\"Gram-Schmidt: Number of vectors (\"+t.length+\") exceeds number of dimensions (\"+t[0].shape[0]+\").\"});var a=[],i=t,s=function(t){a.push(St.tidy(function(){var e=i[t];if(t>0)for(var n=0;n<t;++n){var r=Ql(a[n].mulStrict(e)).mul(a[n]);e=e.sub(r)}return e.div(ic(e,\"euclidean\"))}))};for(o=0;o<t.length;++o)s(o);return e?Cr(a,0):a}}),zc=vn({qr_:function(t,e){if(void 0===e&&(e=!1),t.rank<2)throw new Error(\"qr() requires input tensor to have a rank >= 2, but got rank \"+t.rank);if(2===t.rank)return Uc(t,e);var n=t.shape.slice(0,t.shape.length-2).reduce(function(t,e){return t*e}),r=Ir(t.reshape([n,t.shape[t.shape.length-2],t.shape[t.shape.length-1]]),0),o=[],a=[];return r.forEach(function(t){var n=Uc(t,e),r=n[0],i=n[1];o.push(r),a.push(i)}),[Cr(o,0).reshape(t.shape),Cr(a,0).reshape(t.shape)]}}),Gc=Object.freeze({gramSchmidt:Vc,qr:zc});function Hc(t,e,n,r,o){null==r&&(r=.5),null==o&&(o=Number.NEGATIVE_INFINITY);var a=t.shape[0];return n=Math.min(n,a),f(0<=r&&r<=1,function(){return\"iouThreshold must be in [0, 1], but was '\"+r+\"'\"}),f(2===t.rank,function(){return\"boxes must be a 2D tensor, but was of rank '\"+t.rank+\"'\"}),f(4===t.shape[1],function(){return\"boxes must have 4 columns, but 2nd dimension was \"+t.shape[1]}),f(1===e.rank,function(){return\"scores must be a 1D tensor\"}),f(e.shape[0]===a,function(){return\"scores has incompatible shape with boxes. Expected \"+a+\", but was \"+e.shape[0]}),{maxOutputSize:n,iouThreshold:r,scoreThreshold:o}}var qc=vn({resizeBilinear_:function(t,e,n){void 0===n&&(n=!1);var r=nn(t,\"images\",\"resizeBilinear\");f(3===r.rank||4===r.rank,function(){return\"Error in resizeBilinear: x must be rank 3 or 4, but got rank \"+r.rank+\".\"}),f(2===e.length,function(){return\"Error in resizeBilinear: new shape must 2D, but got shape \"+e+\".\"});var o=r,a=!1;3===r.rank&&(a=!0,o=r.as4D(1,r.shape[0],r.shape[1],r.shape[2]));var i=e[0],s=e[1],u=St.runKernel(function(t,e){return e([o]),t.resizeBilinear(o,i,s,n)},{batchImages:o},function(t,e){return{batchImages:function(){return St.runKernel(function(r){return r.resizeBilinearBackprop(t,e[0],n)},{})}}});return a?u.as3D(u.shape[1],u.shape[2],u.shape[3]):u}}),$c=vn({resizeNearestNeighbor_:function(t,e,n){void 0===n&&(n=!1);var r=nn(t,\"images\",\"resizeNearestNeighbor\");f(3===r.rank||4===r.rank,function(){return\"Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank \"+r.rank+\".\"}),f(2===e.length,function(){return\"Error in resizeNearestNeighbor: new shape must 2D, but got shape \"+e+\".\"}),f(\"float32\"===r.dtype||\"int32\"===r.dtype,function(){return\"`images` must have `int32` or `float32` as dtype\"});var o=r,a=!1;3===r.rank&&(a=!0,o=r.as4D(1,r.shape[0],r.shape[1],r.shape[2]));var i=e[0],s=e[1],u=St.runKernel(function(t,e){return e([o]),t.resizeNearestNeighbor(o,i,s,n)},{batchImages:o},function(t,e){return{batchImages:function(){return St.runKernel(function(r){return r.resizeNearestNeighborBackprop(t,e[0],n)},{})}}});return a?u.as3D(u.shape[1],u.shape[2],u.shape[3]):u}}),Kc=vn({nonMaxSuppression_:function(t,e,n,r,o){void 0===r&&(r=.5),void 0===o&&(o=Number.NEGATIVE_INFINITY);var a=nn(t,\"boxes\",\"nonMaxSuppression\"),i=nn(e,\"scores\",\"nonMaxSuppression\"),s=Hc(a,i,n,r,o);return n=s.maxOutputSize,r=s.iouThreshold,o=s.scoreThreshold,St.runKernel(function(t){return t.nonMaxSuppression(a,i,n,r,o)},{$boxes:a})}}),jc=function(t,e,o,a,i){return void 0===a&&(a=.5),void 0===i&&(i=Number.NEGATIVE_INFINITY),n(this,void 0,void 0,function(){var n,s,u,l,c,h,p;return r(this,function(r){switch(r.label){case 0:return n=nn(t,\"boxes\",\"nonMaxSuppressionAsync\"),s=nn(e,\"scores\",\"nonMaxSuppressionAsync\"),u=Hc(n,s,o,a,i),o=u.maxOutputSize,a=u.iouThreshold,i=u.scoreThreshold,[4,Promise.all([n.data(),s.data()])];case 1:return l=r.sent(),c=l[0],h=l[1],p=Ro(c,h,o,a,i),n!==t&&n.dispose(),s!==e&&s.dispose(),[2,p]}})})},Xc=vn({cropAndResize_:function(t,e,n,r,o,a){var i=nn(t,\"image\",\"cropAndResize\",\"float32\"),s=nn(e,\"boxes\",\"cropAndResize\",\"float32\"),u=nn(n,\"boxInd\",\"cropAndResize\",\"int32\");o=o||\"bilinear\",a=a||0;var l=s.shape[0];return f(4===i.rank,function(){return\"Error in cropAndResize: image must be rank 4,but got rank \"+i.rank+\".\"}),f(2===s.rank&&4===s.shape[1],function(){return\"Error in cropAndResize: boxes must be have size [\"+l+\",4] but had shape \"+s.shape+\".\"}),f(1===u.rank&&u.shape[0]===l,function(){return\"Error in cropAndResize: boxInd must be have size [\"+l+\"] but had shape \"+s.shape+\".\"}),f(2===r.length,function(){return\"Error in cropAndResize: cropSize must be of length 2, but got length \"+r.length+\".\"}),f(r[0]>=1&&r[1]>=1,function(){return\"cropSize must be atleast [1,1], but was \"+r}),f(\"bilinear\"===o||\"nearest\"===o,function(){return\"method must be bilinear or nearest, but was \"+o}),St.runKernel(function(t,e){return t.cropAndResize(i,s,u,r,o,a)},{$image:i,$boxes:s})}}),Yc=Object.freeze({resizeBilinear:qc,resizeNearestNeighbor:$c,nonMaxSuppression:Kc,nonMaxSuppressionAsync:jc,cropAndResize:Xc});var Qc=vn({matMul_:function(t){var e,n=t.a,r=t.b,o=t.transposeA,a=void 0!==o&&o,i=t.transposeB,s=void 0!==i&&i,u=t.bias,l=t.activation,c=void 0===l?\"linear\":l,h=t.preluActivationWeights,p=nn(n,\"a\",\"fused matMul\"),d=nn(r,\"b\",\"fused matMul\");e=wt(p,d),p=e[0],d=e[1];var v=a?p.shape[p.rank-2]:p.shape[p.rank-1],m=s?d.shape[d.rank-1]:d.shape[d.rank-2],x=a?p.shape[p.rank-1]:p.shape[p.rank-2],b=s?d.shape[d.rank-2]:d.shape[d.rank-1],w=p.shape.slice(0,-2),C=d.shape.slice(0,-2),E=g(w),R=g(C);f(p.rank>=2&&d.rank>=2&&p.rank===d.rank,function(){return\"Error in fused matMul: inputs must have the same rank of at least 2, got ranks \"+p.rank+\" and \"+d.rank+\".\"}),f(y(w,C),function(){return\"Error in fused matMul: outer dimensions (\"+w+\") and (\"+C+\") of Tensors with shapes \"+p.shape+\" and \"+d.shape+\" must match.\"}),f(v===m,function(){return\"Error in fused matMul: inner shapes (\"+v+\") and (\"+m+\") of Tensors with shapes \"+p.shape+\" and \"+d.shape+\" and transposeA=\"+a+\" and transposeB=\"+s+\" must match.\"});var I,k,N=p.shape.slice(0,-2).concat([x,b]),S=a?p.as3D(E,v,x):p.as3D(E,x,v),A=s?d.as3D(R,b,m):d.as3D(R,m,b);null!=u&&no(N,(I=wt(I=nn(u,\"bias\",\"fused matMul\"),p)[0]).shape),null!=h&&(k=nn(h,\"prelu weights\",\"fused matMul\"));var T={$a:S,$b:A};return null!=u&&(T.$bias=I),null!=h&&(T.$preluActivationWeights=k),St.runKernel(function(t,e){var n=t.fusedBatchMatMul({a:S,b:A,transposeA:a,transposeB:s,bias:I,activation:c,preluActivationWeights:k});return e([S,A,n]),n},T,function(t,e){var n,r=e[0],o=e[1],i=e[2];if(null==c||\"linear\"===c)n=t;else{if(\"relu\"!==c)throw new Error(\"Gradient for activation \"+c+\" has not been implemented yet.\");n=t.mul(i.step())}var l={};return null!=u&&(l={$bias:function(){var t=n,e=eo(I.shape,n.shape);return e.length>0&&(t=t.sum(e)),t.reshape(I.shape)}}),a||s?!a&&s?Object.assign({$a:function(){return n.matMul(o,!1,!1)},$b:function(){return n.matMul(r,!0,!1)}},l):a&&!s?Object.assign({$a:function(){return o.matMul(n,!1,!0)},$b:function(){return r.matMul(n,!1,!1)}},l):Object.assign({$a:function(){return o.matMul(n,!0,!0)},$b:function(){return n.matMul(r,!0,!0)}},l):Object.assign({$a:function(){return n.matMul(o,!1,!0)},$b:function(){return r.matMul(n,!0,!1)}},l)}).reshape(N)}}),Jc=vn({conv2d_:function(t){var e=t.x,n=t.filter,r=t.strides,o=t.pad,a=t.dataFormat,i=void 0===a?\"NHWC\":a,s=t.dilations,u=void 0===s?[1,1]:s,l=t.dimRoundingMode,c=t.bias,h=t.activation,p=void 0===h?\"linear\":h,d=t.preluActivationWeights,v=nn(e,\"x\",\"conv2d\"),m=nn(n,\"filter\",\"conv2d\"),g=v,y=!1;3===v.rank&&(y=!0,g=v.as4D(1,v.shape[0],v.shape[1],v.shape[2])),f(4===g.rank,function(){return\"Error in fused conv2d: input must be rank 4, but got rank \"+g.rank+\".\"}),f(4===m.rank,function(){return\"Error in fused conv2d: filter must be rank 4, but got rank \"+m.rank+\".\"}),null!=l&&f(x(o),function(){return\"Error in fused conv2d: pad must be an integer when using, dimRoundingMode \"+l+\" but got pad \"+o+\".\"}),f(g.shape[3]===m.shape[2],function(){return\"Error in conv2d: depth of input (\"+g.shape[3]+\") must match input depth for filter \"+m.shape[2]+\".\"}),f(fo(r,u),function(){return\"Error in conv2D: Either strides or dilations must be 1. Got strides \"+r+\" and dilations '\"+u+\"'\"}),f(\"NHWC\"===i,function(){return\"Error in conv2d: got dataFormat of \"+i+\" but only NHWC is currently supported.\"});var b,w,C=ao(g.shape,m.shape,r,u,o,l);null!=c&&(b=wt(b=nn(c,\"bias\",\"fused conv2d\"),v)[0],no(C.outShape,b.shape)),null!=d&&(w=nn(d,\"prelu weights\",\"fused conv2d\"));var E={x:g,$filter:m};null!=c&&(E.$bias=b),null!=d&&(E.$preluActivationWeights=w);var R=St.runKernel(function(t,e){var n=t.fusedConv2d(g,m,C,b,p,w);return e([m,g,n]),n},E,function(t,e){var n,a=e,i=a[0],s=a[1],l=a[2];if(null==p||\"linear\"===p)n=t;else{if(\"relu\"!==p)throw new Error(\"Gradient for activation \"+p+\" has not been implemented yet.\");n=t.mul(l.step())}f(po(u),function(){return\"Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '\"+u+\"'\"});var h={};return null!=c&&(h={$bias:function(){var t=n,e=eo(b.shape,n.shape);return e.length>0&&(t=t.sum(e)),t.reshape(b.shape)}}),Object.assign({x:function(){return ml(s.shape,n,i,r,o)},$filter:function(){return vl(s,n,i.shape,r,o)}},h)});return y?R.as3D(R.shape[1],R.shape[2],R.shape[3]):R}}),Zc=Object.freeze({matMul:Qc,conv2d:Jc}),th=Object.freeze({image:Yc,linalg:Gc,losses:Wc,spectral:gc,fused:Zc,signal:Nc,op:vn,batchNormalization2d:cu,batchNormalization3d:hu,batchNormalization4d:pu,batchNormalization:fu,batchNorm:du,batchNorm2d:vu,batchNorm3d:mu,batchNorm4d:gu,booleanMaskAsync:sl,complex:mn,real:gn,imag:yn,concat:Mn,concat1d:Bn,concat2d:Pn,concat3d:Ln,concat4d:Wn,split:Un,conv1d:pl,conv2d:fl,conv3d:dl,conv2dDerFilter:vl,conv2dDerInput:ml,depthwiseConv2d:gl,separableConv2d:yl,conv2dTranspose:xl,conv3dTranspose:bl,matMul:wl,dot:Cl,outerProduct:El,reverse:Rl,reverse1d:Il,reverse2d:kl,reverse3d:Nl,reverse4d:Sl,maxPool:Dl,avgPool:_l,pool:Ol,maxPool3d:Fl,avgPool3d:Ml,slice:Bl,slice1d:Pl,slice2d:Ll,slice3d:Wl,slice4d:Ul,abs:Es,acos:Rs,acosh:Is,asin:ks,asinh:Ns,atan:Ss,atanh:As,ceil:Ts,clipByValue:Ds,cos:_s,cosh:Os,erf:Fs,exp:Ms,expm1:Bs,floor:Ps,log:Ls,log1p:Ws,logSigmoid:Us,neg:Vs,reciprocal:zs,round:Gs,rsqrt:Hs,sigmoid:qs,sign:$s,isNaN:Ks,isInf:js,isFinite:Xs,sin:Ys,sinh:Qs,softplus:Js,sqrt:Zs,square:tu,step:eu,tan:nu,tanh:ru,all:zl,any:Gl,argMax:Hl,argMin:ql,logSumExp:$l,max:Kl,mean:jl,min:Xl,moments:Yl,sum:Ql,prod:Jl,equal:qu,equalStrict:$u,greater:Ku,greaterEqual:ju,greaterEqualStrict:Xu,greaterStrict:Yu,less:Qu,lessEqual:Ju,lessEqualStrict:Zu,lessStrict:tl,notEqual:el,notEqualStrict:nl,add:Ru,addN:Iu,addStrict:ku,atan2:Nu,div:Su,divStrict:Au,floorDiv:Tu,maximum:Du,maximumStrict:_u,minimum:Ou,minimumStrict:Fu,mod:Mu,modStrict:Bu,mul:Pu,mulStrict:Lu,pow:Wu,powStrict:Uu,squaredDifference:Vu,squaredDifferenceStrict:zu,sub:Gu,subStrict:Hu,elu:Zl,leakyRelu:tc,prelu:ec,relu:nc,selu:rc,logicalAnd:yu,logicalNot:xu,logicalOr:bu,logicalXor:wu,where:Cu,whereAsync:Eu,buffer:Zn,print:tr,batchToSpaceND:er,cast:nr,clone:rr,cumsum:or,depthToSpace:ar,expandDims:ir,eye:sr,multinomial:ur,oneHot:lr,pad:cr,pad1d:hr,pad2d:pr,pad3d:fr,pad4d:dr,rand:vr,randomNormal:mr,randomGamma:gr,randomUniform:yr,reshape:xr,spaceToBatchND:br,squeeze:wr,stack:Cr,tile:Er,truncatedNormal:Rr,unstack:Ir,setdiff1dAsync:kr,fill:Tn,linspace:Dn,ones:Sn,range:_n,scalar:wn,tensor:xn,tensor1d:Cn,tensor2d:En,tensor3d:Rn,tensor4d:In,tensor5d:kn,tensor6d:Nn,zeros:An,onesLike:On,zerosLike:Fn,transpose:oc,softmax:Yr,logSoftmax:Qr,localResponseNormalization:ac,norm:ic,gather:al,unsortedSegmentSum:il,basicLSTMCell:sc,multiRNNCell:uc,movingAverage:lc,stridedSlice:cc,topk:hc,scatterND:pc,fft:fc,ifft:dc,rfft:vc,irfft:mc,sparseToDense:yc,gatherND:xc,diag:bc,dropout:wc,hannWindow:Ec,hammingWindow:Rc,frame:Ic,stft:kc,inTopKAsync:Ac});function eh(t,e,n,r){if(\"linear\"===n)return t.linear(e);if(\"relu\"===n)return t.relu(e);if(\"elu\"===n)return t.elu(e);if(\"prelu\"===n)return t.prelu(e,r);throw new Error(\"Activation \"+n+\" has not been implemented for the CPU backend.\")}var nh=function(){function t(){if(this.blockSize=48,this.firstUse=!0,i.get(\"IS_BROWSER\")){var t=\"undefined\"!=typeof OffscreenCanvas?new OffscreenCanvas(300,150):\"undefined\"!=typeof document?document.createElement(\"canvas\"):null;null!==t&&(this.fromPixels2DContext=t.getContext(\"2d\"))}this.data=new Jr(this,St)}return t.prototype.register=function(t,e,n){if(this.firstUse&&(this.firstUse=!1,i.get(\"IS_NODE\")&&Ze(\"\\n============================\\nHi there 👋. Looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, which binds to TensorFlow C++, by running npm i @tensorflow/tfjs-node, or npm i @tensorflow/tfjs-node-gpu if you have CUDA. Then call require('@tensorflow/tfjs-node'); (-gpu suffix for CUDA) at the start of your program. Visit https://github.com/tensorflow/tfjs-node for more details.\\n============================\\n\")),this.data.has(t))throw new Error(\"Data buffer is already registered\");this.data.set(t,{dtype:n})},t.prototype.write=function(t,e){if(null==e)throw new Error(\"MathBackendCPU.write(): values can not be null\");this.data.get(t).values=e},t.prototype.fromPixels=function(t,e){if(null==t)throw new Error(\"pixels passed to tf.browser.fromPixels() can not be null\");var n,r,o=t.data instanceof Uint8Array,a=\"undefined\"!=typeof ImageData&&t instanceof ImageData,s=\"undefined\"!=typeof HTMLVideoElement&&t instanceof HTMLVideoElement,u=\"undefined\"!=typeof HTMLImageElement&&t instanceof HTMLImageElement,l=s?[t.videoWidth,t.videoHeight]:[t.width,t.height],c=l[0],h=l[1];if(i.get(\"IS_NODE\")&&null==t.getContext)throw new Error(\"When running in node, pixels must be an HTMLCanvasElement like the one returned by the `canvas` npm package\");if(null!=t.getContext)n=t.getContext(\"2d\").getImageData(0,0,c,h).data;else if(a||o)n=t.data;else{if(!u&&!s)throw new Error(\"pixels passed to tf.browser.fromPixels() must be either an HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData or {data: Uint32Array, width: number, height: number}, but was \"+t.constructor.name);if(null==this.fromPixels2DContext)throw new Error(\"Can't read pixels from HTMLImageElement outside the browser.\");this.fromPixels2DContext.canvas.width=c,this.fromPixels2DContext.canvas.height=h,this.fromPixels2DContext.drawImage(t,0,0,c,h),n=this.fromPixels2DContext.getImageData(0,0,c,h).data}if(4===e)r=new Int32Array(n);else{var p=c*h;r=new Int32Array(p*e);for(var f=0;f<p;f++)for(var d=0;d<e;++d)r[f*e+d]=n[4*f+d]}return Rn(r,[h,c,e],\"int32\")},t.prototype.read=function(t){return n(this,void 0,void 0,function(){return r(this,function(e){return[2,this.readSync(t)]})})},t.prototype.readSync=function(t){var e=this.data.get(t),n=e.dtype,r=e.complexTensors;return\"complex64\"===n?bo(this.readSync(r.real.dataId),this.readSync(r.imag.dataId)):this.data.get(t).values},t.prototype.bufferSync=function(t){var e=this.readSync(t.dataId),n=e;if(\"string\"===t.dtype)try{n=e.map(function(t){return X(t)})}catch(t){throw new Error(\"Failed to decode encoded string bytes into utf-8\")}return Zn(t.shape,t.dtype,n)},t.prototype.disposeData=function(t){if(this.data.has(t)){var e=this.data.get(t).complexTensors;null!=e&&(e.real.dispose(),e.imag.dispose()),this.data.delete(t)}},t.prototype.time=function(t){return n(this,void 0,void 0,function(){var e;return r(this,function(n){return e=$(),t(),[2,{kernelMs:$()-e}]})})},t.prototype.memory=function(){return{unreliable:!0,reasons:[\"The reported memory is an upper bound. Due to automatic garbage collection, the true allocated memory may be less.\"]}},t.prototype.complex=function(t,e){var n=ct.make(t.shape,{},\"complex64\");return this.data.get(n.dataId).complexTensors={real:St.keep(t.clone()),imag:St.keep(e.clone())},n},t.prototype.real=function(t){return this.data.get(t.dataId).complexTensors.real.clone()},t.prototype.imag=function(t){return this.data.get(t.dataId).complexTensors.imag.clone()},t.prototype.assertNotComplex=function(t,e){Array.isArray(t)||(t=[t]),t.forEach(function(t){null!=t&&f(\"complex64\"!==t.dtype,function(){return e+\" does not support complex64 tensors.\"})})},t.prototype.slice=function(t,e,n){if(this.assertNotComplex(t,\"slice\"),Vr(t.shape,e,n)){var r=zr(e,t.strides),o=g(n);return xn(this.readSync(t.dataId).subarray(r,r+o),n,t.dtype)}for(var a=Zn(n,t.dtype),i=this.bufferSync(t),s=0;s<a.size;++s){var u=a.indexToLoc(s).map(function(t,n){return t+e[n]});a.values[s]=i.get.apply(i,u)}return a.toTensor()},t.prototype.stridedSlice=function(t,e,n,r){this.assertNotComplex(t,\"stridedSlice\");var o=Lr(e,n,r);if(o.some(function(t){return 0===t}))return xn([],o);for(var a=Zn(o,t.dtype),i=this.bufferSync(t),s=0;s<a.size;s++){for(var u=a.indexToLoc(s),l=new Array(u.length),c=0;c<l.length;c++)l[c]=u[c]*r[c]+e[c];a.set.apply(a,[i.get.apply(i,l)].concat(u))}return a.toTensor()},t.prototype.diag=function(t){for(var e=this.readSync(t.dataId),n=Zn([t.size,t.size],t.dtype),r=n.values,o=0;o<e.length;o++)r[o*t.size+o]=e[o];return n.toTensor()},t.prototype.unstack=function(t,e){for(var n=t.shape[e],r=new Array(t.rank-1),o=0,a=0;a<t.rank;a++)a!==e&&(r[o++]=t.shape[a]);var i=new Array(t.rank).fill(0),s=t.shape.slice();s[e]=1;var u=new Array(n);for(a=0;a<u.length;a++)i[e]=a,u[a]=this.slice(t,i,s).reshape(r);return u},t.prototype.reverse=function(t,e){this.assertNotComplex(t,\"reverse\");for(var n=Zn(t.shape,t.dtype),r=this.bufferSync(t),o=function(o){var a=n.indexToLoc(o),i=a.slice();e.forEach(function(e){return i[e]=t.shape[e]-1-i[e]}),n.set.apply(n,[r.get.apply(r,i)].concat(a))},a=0;a<n.size;a++)o(a);return n.toTensor()},t.prototype.concat=function(t,e){var n=this;if(\"complex64\"===t[0].dtype){var r=t.map(function(t){return gn(t)}),o=t.map(function(t){return yn(t)});return mn(this.concat(r,e),this.concat(o,e))}var a=t.map(function(t){var n=g(t.shape.slice(e));return t.as2D(-1,n)}),i=dn(a.map(function(t){return t.shape}),1),s=Zn(i,t[0].dtype).values;if(1===a[0].shape[0]){var u=0;a.forEach(function(t){s.set(n.readSync(t.dataId),u),u+=t.size})}else{var l=0;a.forEach(function(t){for(var e=n.readSync(t.dataId),r=0,o=0;o<t.shape[0];++o)for(var a=o*i[1]+l,u=0;u<t.shape[1];++u)s[a+u]=e[r++];l+=t.shape[1]})}var c=dn(t.map(function(t){return t.shape}),e);return xn(s,c,t[0].dtype)},t.prototype.neg=function(t){return this.assertNotComplex(t,\"neg\"),this.multiply(wn(-1),t)},t.prototype.add=function(t,e){return\"complex64\"===t.dtype||\"complex64\"===e.dtype?this.broadcastedBinaryComplexOp(t.cast(\"complex64\"),e.cast(\"complex64\"),function(t,e,n,r){return{real:t+n,imag:e+r}}):this.broadcastedBinaryOp(t,e,xt(t.dtype,e.dtype),function(t,e){return t+e})},t.prototype.addN=function(t){var e=this;this.assertNotComplex(t,\"addN\");for(var n=t.map(function(t){return e.readSync(t.dataId)}),r=Zn(t[0].shape,t[0].dtype),o=r.values,a=0;a<t.length;a++)for(var i=n[a],s=0;s<o.length;s++)o[s]+=i[s];return r.toTensor()},t.prototype.subtract=function(t,e){return\"complex64\"===t.dtype||\"complex64\"===e.dtype?this.broadcastedBinaryComplexOp(t.cast(\"complex64\"),e.cast(\"complex64\"),function(t,e,n,r){return{real:t-n,imag:e-r}}):this.broadcastedBinaryOp(t,e,xt(t.dtype,e.dtype),function(t,e){return t-e})},t.prototype.pow=function(t,e){return this.assertNotComplex([t,e],\"pow\"),this.broadcastedBinaryOp(t,e,t.dtype,function(t,e){return Math.pow(t,e)})},t.prototype.batchMatMul=function(t,e,n,r){this.assertNotComplex([t,e],\"matMul\");for(var o=n?t.shape[1]:t.shape[2],a=n?t.shape[2]:t.shape[1],i=r?e.shape[1]:e.shape[2],s=t.shape[0],u=this.readSync(t.dataId),l=this.readSync(e.dataId),c=n?[t.strides[0],1,t.strides[1]]:[t.strides[0],t.strides[1],1],h=c[0],p=c[1],f=c[2],d=r?[1,e.strides[1],e.strides[0]]:[e.strides[1],1,e.strides[0]],v=d[0],m=d[1],g=d[2],y=a*i,x=Zn([s,a,i],t.dtype),b=x.values,w=this.blockSize,C=0;C<s;C++)for(var E=0;E<a;E+=w)for(var R=0;R<i;R+=w)for(var I=0;I<o;I+=w)for(var k=Math.min(E+w,a),N=Math.min(R+w,i),S=Math.min(I+w,o),A=E;A<k;A++)for(var T=R;T<N;T++){for(var D=0,_=I;_<S;_++)D+=u[C*h+A*p+_*f]*l[_*v+T*m+C*g];b[C*y+(A*i+T)]+=D}return x.toTensor()},t.prototype.fusedBatchMatMul=function(t){var e=t.a,n=t.b,r=t.transposeA,o=t.transposeB,a=t.bias,i=t.activation,s=t.preluActivationWeights,u=this.batchMatMul(e,n,r,o);return a&&(u=this.add(u,a)),i&&(u=eh(this,u,i,s)),u},t.prototype.multiply=function(t,e){return\"complex64\"===t.dtype||\"complex64\"===e.dtype?this.broadcastedBinaryComplexOp(t.cast(\"complex64\"),e.cast(\"complex64\"),function(t,e,n,r){return{real:t*n-e*r,imag:t*r+e*n}}):this.broadcastedBinaryOp(t,e,xt(t.dtype,e.dtype),function(t,e){return t*e})},t.prototype.realDivide=function(t,e){this.assertNotComplex([t,e],\"realDivide\");return this.broadcastedBinaryOp(t,e,\"float32\",function(t,e){return t/e})},t.prototype.floorDiv=function(t,e){this.assertNotComplex([t,e],\"floorDiv\");return this.broadcastedBinaryOp(t,e,\"int32\",function(t,e){return Math.floor(t/e)})},t.prototype.sum=function(t,e){this.assertNotComplex(t,\"sum\"),ln(\"sum\",e,t.rank);for(var n=sn(t.shape,e),r=n[0],o=n[1],a=An(r,xt(t.dtype,\"int32\")),i=g(o),s=this.readSync(a.dataId),u=this.readSync(t.dataId),l=0;l<s.length;++l){for(var c=l*i,h=0,p=0;p<i;++p)h+=u[c+p];s[l]=h}return a},t.prototype.prod=function(t,e){this.assertNotComplex(t,\"sum\");for(var n=sn(t.shape,e),r=n[0],o=n[1],a=An(r,xt(t.dtype,\"int32\")),i=g(o),s=this.readSync(a.dataId),u=this.readSync(t.dataId),l=0;l<s.length;++l){for(var c=l*i,h=1,p=0;p<i;++p)h*=u[c+p];s[l]=h}return a},t.prototype.unsortedSegmentSum=function(t,e,n){this.assertNotComplex(t,\"unsortedSegmentSum\");for(var r=[],o=t.rank-e.rank,a=0;a<o;++a)e=e.expandDims(a+1);for(a=0;a<n;++a){var i=wn(a,\"int32\"),s=qu(i,e).asType(\"float32\").mul(t).sum(0);r.push(s)}return Cr(r)},t.prototype.argMin=function(t,e){this.assertNotComplex(t,\"argMin\");var n=[e];ln(\"argMin\",n,t.rank);for(var r=sn(t.shape,n),o=r[0],a=r[1],i=An(o,\"int32\"),s=g(a),u=this.readSync(i.dataId),l=this.readSync(t.dataId),c=0;c<u.length;++c){for(var h=c*s,p=l[h],f=0,d=0;d<s;++d){var v=l[h+d];v<p&&(p=v,f=d)}u[c]=f}return i},t.prototype.argMax=function(t,e){this.assertNotComplex(t,\"argMax\");var n=[e];ln(\"argMax\",n,t.rank);for(var r=sn(t.shape,n),o=r[0],a=r[1],i=An(o,\"int32\"),s=g(a),u=this.readSync(i.dataId),l=this.readSync(t.dataId),c=0;c<u.length;++c){for(var h=c*s,p=l[h],f=0,d=0;d<s;++d){var v=l[h+d];v>p&&(p=v,f=d)}u[c]=f}return i},t.prototype.cumsum=function(t,e,n,r){if(this.assertNotComplex(t,\"cumsum\"),e!==t.rank-1)throw new Error(\"backend.cumsum in CPU expects an inner-most axis=\"+(t.rank-1)+\" but got axis=\"+e);for(var o=xt(t.dtype,\"int32\"),a=An(t.shape,o),i=this.readSync(a.dataId),s=this.readSync(t.dataId),u=t.shape[t.rank-1],l=r?function(t,e){return t+u-e-1}:function(t,e){return t+e},c=0;c<s.length;c+=u)for(var h=0;h<u;h++){var p=l(c,h);if(0===h)i[p]=n?0:s[p];else{var f=l(c,h-1);i[p]=n?s[f]+i[f]:s[p]+i[f]}}return a},t.prototype.equal=function(t,e){return this.assertNotComplex([t,e],\"equal\"),this.broadcastedBinaryOp(t,e,\"bool\",function(t,e){return t===e?1:0})},t.prototype.notEqual=function(t,e){return this.assertNotComplex([t,e],\"notEqual\"),this.broadcastedBinaryOp(t,e,\"bool\",function(t,e){return t!==e?1:0})},t.prototype.less=function(t,e){return this.assertNotComplex([t,e],\"less\"),this.broadcastedBinaryOp(t,e,\"bool\",function(t,e){return t<e?1:0})},t.prototype.lessEqual=function(t,e){return this.assertNotComplex([t,e],\"lessEqual\"),this.broadcastedBinaryOp(t,e,\"bool\",function(t,e){return t<=e?1:0})},t.prototype.greater=function(t,e){return this.assertNotComplex([t,e],\"greater\"),this.broadcastedBinaryOp(t,e,\"bool\",function(t,e){return t>e?1:0})},t.prototype.greaterEqual=function(t,e){return this.assertNotComplex([t,e],\"greaterEqual\"),this.broadcastedBinaryOp(t,e,\"bool\",function(t,e){return t>=e?1:0})},t.prototype.logicalNot=function(t){this.assertNotComplex(t,\"logicalNot\");for(var e=this.readSync(t.dataId),n=new Uint8Array(e.length),r=0;r<e.length;++r)n[r]=e[r]?0:1;return ct.make(t.shape,{values:n},\"bool\")},t.prototype.logicalAnd=function(t,e){return this.assertNotComplex([t,e],\"logicalAnd\"),this.broadcastedBinaryOp(t,e,\"bool\",function(t,e){return t&&e})},t.prototype.logicalOr=function(t,e){return this.assertNotComplex([t,e],\"logicalOr\"),this.broadcastedBinaryOp(t,e,\"bool\",function(t,e){return t||e})},t.prototype.select=function(t,e,n){this.assertNotComplex([t,e,n],\"select\");for(var r=this.readSync(t.dataId),o=this.readSync(e.dataId),a=this.readSync(n.dataId),i=An(e.shape,xt(e.dtype,n.dtype)),s=this.readSync(i.dataId),u=0,l=0===t.rank||t.rank>1||1===e.rank?1:e.shape[1],c=0;c<r.length;c++)for(var h=0;h<l;h++)1===r[c]?s[u++]=o[c]:s[u++]=a[c];return i},t.prototype.where=function(t){this.assertNotComplex([t],\"where\");var e=this.readSync(t.dataId);return Ao(t.shape,e)},t.prototype.topk=function(t,e,n){return this.assertNotComplex(t,\"topk\"),So(this.readSync(t.dataId),t.shape,t.dtype,e)},t.prototype.min=function(t,e){this.assertNotComplex(t,\"min\"),ln(\"min\",e,t.rank);for(var n=sn(t.shape,e),r=n[0],o=n[1],a=An(r,t.dtype),i=g(o),s=this.readSync(a.dataId),u=this.readSync(t.dataId),l=0;l<s.length;++l){for(var c=l*i,h=u[c],p=0;p<i;++p){var f=u[c+p];f<h&&(h=f)}s[l]=h}return a},t.prototype.minimum=function(t,e){return this.assertNotComplex([t,e],\"minimum\"),this.broadcastedBinaryOp(t,e,t.dtype,function(t,e){return Math.min(t,e)})},t.prototype.mod=function(t,e){return this.assertNotComplex([t,e],\"mod\"),this.broadcastedBinaryOp(t,e,t.dtype,function(t,e){var n=t%e;return t<0&&e<0||t>=0&&e>=0?n:(n+e)%e})},t.prototype.max=function(t,e){this.assertNotComplex(t,\"max\"),ln(\"max\",e,t.rank);for(var n=sn(t.shape,e),r=n[0],o=n[1],a=An(r,t.dtype),i=g(o),s=this.readSync(a.dataId),u=this.readSync(t.dataId),l=0;l<s.length;++l){for(var c=l*i,h=u[c],p=0;p<i;++p){var f=u[c+p];f>h&&(h=f)}s[l]=h}return a},t.prototype.maximum=function(t,e){return this.assertNotComplex([t,e],\"maximum\"),this.broadcastedBinaryOp(t,e,t.dtype,function(t,e){return Math.max(t,e)})},t.prototype.all=function(t,e){this.assertNotComplex(t,\"all\"),ln(\"all\",e,t.rank);for(var n=sn(t.shape,e),r=n[0],o=n[1],a=An(r,t.dtype),i=g(o),s=this.readSync(a.dataId),u=this.readSync(t.dataId),l=0;l<s.length;++l){for(var c=l*i,h=u[c],p=0;p<i;++p){var f=u[c+p];h=h&&f}s[l]=h}return a},t.prototype.any=function(t,e){this.assertNotComplex(t,\"any\"),ln(\"any\",e,t.rank);for(var n=sn(t.shape,e),r=n[0],o=n[1],a=An(r,t.dtype),i=g(o),s=this.readSync(a.dataId),u=this.readSync(t.dataId),l=0;l<s.length;++l){for(var c=l*i,h=u[c],p=0;p<i;++p){var f=u[c+p];h=h||f}s[l]=h}return a},t.prototype.squaredDifference=function(t,e){return this.assertNotComplex([t,e],\"squaredDifference\"),this.broadcastedBinaryOp(t,e,t.dtype,function(t,e){var n=t-e;return n*n})},t.prototype.ceil=function(t){this.assertNotComplex(t,\"ceil\");for(var e=this.readSync(t.dataId),n=new Float32Array(e.length),r=0;r<e.length;++r)n[r]=Math.ceil(e[r]);return ct.make(t.shape,{values:n})},t.prototype.floor=function(t){this.assertNotComplex(t,\"floor\");for(var e=this.readSync(t.dataId),n=new Float32Array(e.length),r=0;r<e.length;++r)n[r]=Math.floor(e[r]);return ct.make(t.shape,{values:n})},t.prototype.sign=function(t){this.assertNotComplex(t,\"x\");for(var e=this.readSync(t.dataId),n=new Float32Array(e.length),r=0;r<e.length;++r)e[r]<0?n[r]=-1:e[r]>0?n[r]=1:n[r]=0;return ct.make(t.shape,{values:n})},t.prototype.isNaN=function(t){this.assertNotComplex(t,\"x\");for(var e=this.readSync(t.dataId),n=new Uint8Array(e.length),r=0;r<e.length;++r)Number.isNaN(e[r])&&(n[r]=1);return ct.make(t.shape,{values:n},\"bool\")},t.prototype.isInf=function(t){this.assertNotComplex(t,\"x\");for(var e=this.readSync(t.dataId),n=new Uint8Array(e.length),r=0;r<e.length;++r)Math.abs(e[r])===1/0&&(n[r]=1);return ct.make(t.shape,{values:n},\"bool\")},t.prototype.isFinite=function(t){this.assertNotComplex(t,\"x\");for(var e=this.readSync(t.dataId),n=new Uint8Array(e.length),r=0;r<e.length;++r)Number.isFinite(e[r])&&(n[r]=1);return ct.make(t.shape,{values:n},\"bool\")},t.prototype.round=function(t){this.assertNotComplex(t,\"round\");for(var e=this.readSync(t.dataId),n=new Float32Array(e.length),r=0;r<e.length;++r){var o=Math.floor(e[r]);e[r]-o<.5?n[r]=Math.floor(e[r]):e[r]-o>.5?n[r]=Math.ceil(e[r]):n[r]=o%2==0?o:o+1}return ct.make(t.shape,{values:n})},t.prototype.exp=function(t){this.assertNotComplex(t,\"exp\");for(var e=this.readSync(t.dataId),n=new Float32Array(e.length),r=0;r<e.length;++r)n[r]=Math.exp(e[r]);return ct.make(t.shape,{values:n})},t.prototype.expm1=function(t){this.assertNotComplex(t,\"expm1\");for(var e=this.readSync(t.dataId),n=new Float32Array(e.length),r=0;r<e.length;++r)n[r]=Math.expm1(e[r]);return ct.make(t.shape,{values:n})},t.prototype.log=function(t){this.assertNotComplex(t,\"log\");for(var e=this.readSync(t.dataId),n=new Float32Array(e.length),r=0;r<e.length;++r){var o=e[r];n[r]=Math.log(o)}return ct.make(t.shape,{values:n})},t.prototype.log1p=function(t){this.assertNotComplex(t,\"log1p\");for(var e=this.readSync(t.dataId),n=new Float32Array(e.length),r=0;r<e.length;++r){var o=e[r];n[r]=Math.log1p(o)}return ct.make(t.shape,{values:n})},t.prototype.sqrt=function(t){this.assertNotComplex(t,\"sqrt\");for(var e=this.readSync(t.dataId),n=new Float32Array(e.length),r=0;r<e.length;++r){var o=e[r];n[r]=Math.sqrt(o)}return ct.make(t.shape,{values:n})},t.prototype.rsqrt=function(t){this.assertNotComplex(t,\"rsqrt\");for(var e=this.readSync(t.dataId),n=new Float32Array(e.length),r=0;r<e.length;++r){var o=e[r];n[r]=1/Math.sqrt(o)}return ct.make(t.shape,{values:n})},t.prototype.square=function(t){this.assertNotComplex(t,\"square\");for(var e=this.readSync(t.dataId),n=new Float32Array(e.length),r=0;r<e.length;++r){var o=e[r];n[r]=o*o}return ct.make(t.shape,{values:n})},t.prototype.reciprocal=function(t){this.assertNotComplex(t,\"reciprocal\");for(var e=this.readSync(t.dataId),n=new Float32Array(e.length),r=0;r<e.length;++r)n[r]=1/e[r];return ct.make(t.shape,{values:n})},t.prototype.linear=function(t){return t},t.prototype.relu=function(t){this.assertNotComplex(t,\"relu\");for(var e=An(t.shape,t.dtype),n=this.readSync(e.dataId),r=this.readSync(t.dataId),o=0;o<r.length;++o)n[o]=Math.max(0,r[o]);return e},t.prototype.prelu=function(t,e){return this.assertNotComplex([t,e],\"prelu\"),this.broadcastedBinaryOp(t,e,t.dtype,function(t,e){return t<0?e*t:t})},t.prototype.elu=function(t){this.assertNotComplex(t,\"elu\");for(var e=new Float32Array(t.size),n=this.readSync(t.dataId),r=0;r<n.length;++r){var o=n[r];e[r]=o>=0?o:Math.exp(o)-1}return ct.make(t.shape,{values:e})},t.prototype.eluDer=function(t,e){this.assertNotComplex([t,e],\"eluDer\");for(var n=new Float32Array(e.size),r=this.readSync(e.dataId),o=this.readSync(t.dataId),a=0;a<r.length;++a){var i=r[a];n[a]=i>=1?o[a]:o[a]*(i+1)}return ct.make(e.shape,{values:n})},t.prototype.selu=function(t){this.assertNotComplex(t,\"selu\");for(var e=ji,n=Xi,r=new Float32Array(t.size),o=this.readSync(t.dataId),a=0;a<o.length;++a){var i=o[a];r[a]=i>=0?n*i:e*(Math.exp(i)-1)}return ct.make(t.shape,{values:r})},t.prototype.clip=function(t,e,n){this.assertNotComplex(t,\"clip\");for(var r=new Float32Array(t.size),o=this.readSync(t.dataId),a=0;a<o.length;++a){var i=o[a];r[a]=i>n?n:i<e?e:i}return ct.make(t.shape,{values:r})},t.prototype.abs=function(t){for(var e=new Float32Array(t.size),n=this.readSync(t.dataId),r=0;r<n.length;++r)e[r]=Math.abs(n[r]);return ct.make(t.shape,{values:e})},t.prototype.complexAbs=function(t){for(var e=new Float32Array(t.size),n=this.readSync(t.dataId),r=0;r<t.size;++r){var o=n[2*r],a=n[2*r+1];e[r]=Math.hypot(o,a)}return ct.make(t.shape,{values:e})},t.prototype.int=function(t){this.assertNotComplex(t,\"int\");for(var e=new Int32Array(t.size),n=this.readSync(t.dataId),r=0;r<n.length;++r)e[r]=n[r];return ct.make(t.shape,{values:e},\"int32\")},t.prototype.sigmoid=function(t){this.assertNotComplex(t,\"sigmoid\");for(var e=new Float32Array(t.size),n=this.readSync(t.dataId),r=0;r<n.length;++r)e[r]=1/(1+Math.exp(-n[r]));return ct.make(t.shape,{values:e})},t.prototype.softplus=function(t){this.assertNotComplex(t,\"softplus\");for(var e=Math.log(1.1920928955078125e-7)+2,n=new Float32Array(t.size),r=this.readSync(t.dataId),o=0;o<r.length;++o){var a=r[o]>-e,i=r[o]<e,s=Math.exp(r[o]),u=void 0;u=i?s:a?r[o]:Math.log(1+s),n[o]=u}return ct.make(t.shape,{values:n})},t.prototype.sin=function(t){this.assertNotComplex(t,\"sin\");for(var e=new Float32Array(t.size),n=this.readSync(t.dataId),r=0;r<n.length;++r)e[r]=Math.sin(n[r]);return ct.make(t.shape,{values:e})},t.prototype.cos=function(t){this.assertNotComplex(t,\"cos\");for(var e=new Float32Array(t.size),n=this.readSync(t.dataId),r=0;r<n.length;++r)e[r]=Math.cos(n[r]);return ct.make(t.shape,{values:e})},t.prototype.tan=function(t){this.assertNotComplex(t,\"tan\");for(var e=new Float32Array(t.size),n=this.readSync(t.dataId),r=0;r<n.length;++r)e[r]=Math.tan(n[r]);return ct.make(t.shape,{values:e})},t.prototype.asin=function(t){this.assertNotComplex(t,\"asin\");for(var e=new Float32Array(t.size),n=this.readSync(t.dataId),r=0;r<n.length;++r)e[r]=Math.asin(n[r]);return ct.make(t.shape,{values:e})},t.prototype.acos=function(t){this.assertNotComplex(t,\"acos\");for(var e=new Float32Array(t.size),n=this.readSync(t.dataId),r=0;r<n.length;++r)e[r]=Math.acos(n[r]);return ct.make(t.shape,{values:e})},t.prototype.atan=function(t){this.assertNotComplex(t,\"atan\");for(var e=new Float32Array(t.size),n=this.readSync(t.dataId),r=0;r<n.length;++r)e[r]=Math.atan(n[r]);return ct.make(t.shape,{values:e})},t.prototype.atan2=function(t,e){return this.assertNotComplex([t,e],\"atan2\"),this.broadcastedBinaryOp(t,e,t.dtype,function(t,e){return Math.atan2(t,e)})},t.prototype.sinh=function(t){this.assertNotComplex(t,\"sinh\");for(var e=new Float32Array(t.size),n=this.readSync(t.dataId),r=0;r<n.length;++r)e[r]=Math.sinh(n[r]);return ct.make(t.shape,{values:e})},t.prototype.cosh=function(t){this.assertNotComplex(t,\"cosh\");for(var e=new Float32Array(t.size),n=this.readSync(t.dataId),r=0;r<n.length;++r)e[r]=Math.cosh(n[r]);return ct.make(t.shape,{values:e})},t.prototype.tanh=function(t){this.assertNotComplex(t,\"tanh\");for(var e=new Float32Array(t.size),n=this.readSync(t.dataId),r=0;r<n.length;++r)e[r]=b(n[r]);return ct.make(t.shape,{values:e})},t.prototype.asinh=function(t){this.assertNotComplex(t,\"asinh\");for(var e=new Float32Array(t.size),n=this.readSync(t.dataId),r=0;r<n.length;++r)e[r]=Math.asinh(n[r]);return ct.make(t.shape,{values:e})},t.prototype.acosh=function(t){this.assertNotComplex(t,\"acosh\");for(var e=new Float32Array(t.size),n=this.readSync(t.dataId),r=0;r<n.length;++r)e[r]=Math.acosh(n[r]);return ct.make(t.shape,{values:e})},t.prototype.atanh=function(t){this.assertNotComplex(t,\"atanh\");for(var e=new Float32Array(t.size),n=this.readSync(t.dataId),r=0;r<n.length;++r)e[r]=Math.atanh(n[r]);return ct.make(t.shape,{values:e})},t.prototype.erf=function(t){this.assertNotComplex(t,\"erf\");for(var e=new Float32Array(t.size),n=this.readSync(t.dataId),r=0;r<n.length;++r){var o=n[r],a=1/(1+.3275911*o);e[r]=1-((((1.061405429*a-1.453152027)*a+1.421413741)*a-.284496736)*a+.254829592)*a*Math.exp(-o*o)}return ct.make(t.shape,{values:e})},t.prototype.step=function(t,e){void 0===e&&(e=0),this.assertNotComplex(t,\"step\");for(var n=new Float32Array(t.size),r=this.readSync(t.dataId),o=0;o<r.length;++o){var a=r[o];isNaN(a)?n[o]=NaN:n[o]=a>0?1:e}return ct.make(t.shape,{values:n})},t.prototype.fusedConv2d=function(t,e,n,r,o,a){var i=this.conv2d(t,e,n);return r&&(i=this.add(i,r)),o&&(i=eh(this,i,o,a)),i},t.prototype.conv2d=function(t,e,n){this.assertNotComplex([t,e],\"conv2d\");for(var r=n.filterHeight,o=n.filterWidth,a=n.dilationHeight,i=n.dilationWidth,s=n.padInfo.left,u=n.padInfo.top,l=\"channelsLast\"===n.dataFormat,c=Zn(n.outShape,t.dtype),h=t.strides[0],p=l?t.strides[1]:t.strides[2],f=l?t.strides[2]:1,d=l?1:t.strides[1],v=c.strides[0],m=l?c.strides[1]:c.strides[2],g=l?c.strides[2]:1,y=l?1:c.strides[1],x=this.readSync(t.dataId),b=this.readSync(e.dataId),w=c.values,C=0;C<n.batchSize;++C)for(var E=C*h,R=C*v,I=0;I<n.outHeight;++I)for(var k=R+I*m,N=I*n.strideHeight-u,S=0;S<r;S++){var A=N+S*a;if(!(A<0||A>=n.inHeight))for(var T=S*e.strides[0],D=E+A*p,_=0;_<n.outWidth;++_)for(var O=k+_*g,F=_*n.strideWidth-s,M=0;M<o;M++){var B=F+M*i;if(!(B<0||B>=n.inWidth))for(var P=D+B*f,L=T+M*e.strides[1],W=0;W<n.inChannels;++W){for(var U=x[P+W*d],V=0;V<n.outChannels;++V)w[O+V*y]+=U*b[L+V];L+=n.outChannels}}}return c.toTensor()},t.prototype.conv3d=function(t,e,n){for(var r=n.filterDepth,o=n.filterHeight,a=n.filterWidth,i=n.dilationDepth,s=n.dilationHeight,u=n.dilationWidth,l=n.padInfo.front,c=n.padInfo.left,h=n.padInfo.top,p=Zn(n.outShape,t.dtype),f=this.readSync(t.dataId),d=this.readSync(e.dataId),v=p.values,m=0;m<n.batchSize;++m)for(var g=m*t.strides[0],y=m*p.strides[0],x=0;x<n.outDepth;++x)for(var b=y+x*p.strides[1],w=x*n.strideDepth-l,C=0;C<r;C++){var E=w+C*i;if(!(E<0||E>=n.inDepth))for(var R=C*e.strides[0],I=g+E*t.strides[1],k=0;k<n.outHeight;++k)for(var N=b+k*p.strides[2],S=k*n.strideHeight-h,A=0;A<o;A++){var T=S+A*s;if(!(T<0||T>=n.inHeight))for(var D=R+A*e.strides[1],_=I+T*t.strides[2],O=0;O<n.outWidth;++O)for(var F=N+O*n.outChannels,M=O*n.strideWidth-c,B=0;B<a;B++){var P=M+B*u;if(!(P<0||P>=n.inWidth))for(var L=D+B*e.strides[2],W=_+P*n.inChannels,U=L,V=0;V<n.inChannels;++V){for(var z=f[W+V],G=0;G<n.outChannels;++G)v[F+G]+=z*d[U+G];U+=n.outChannels}}}}return p.toTensor()},t.prototype.conv2dDerInput=function(t,e,n){this.assertNotComplex([t,e],\"conv2dDerInput\");for(var r=Zn(n.inShape,\"float32\"),o=r.values,a=this.readSync(t.dataId),i=this.readSync(e.dataId),s=e.strides,u=s[0],l=s[1],c=s[2],h=n.batchSize,p=n.filterHeight,f=n.filterWidth,d=n.inChannels,v=n.inHeight,m=n.inWidth,g=n.outChannels,y=n.outHeight,x=n.outWidth,b=n.strideHeight,w=n.strideWidth,C=n.dataFormat,E=p-1-n.padInfo.top,R=f-1-n.padInfo.left,I=\"channelsLast\"===C,k=r.strides[0],N=I?r.strides[1]:r.strides[2],S=I?r.strides[2]:1,A=I?1:r.strides[1],T=t.strides[0],D=I?t.strides[1]:t.strides[2],_=I?t.strides[2]:1,O=I?1:t.strides[1],F=0;F<h;++F)for(var M=0;M<d;++M)for(var B=0;B<v;++B)for(var P=B-E,L=Math.max(0,Math.ceil(P/b)),W=Math.min(y,(p+P)/b),U=0;U<m;++U){for(var V=U-R,z=Math.max(0,Math.ceil(V/w)),G=Math.min(x,(f+V)/w),H=0,q=L;q<W;++q)for(var $=q*b-P,K=z;K<G;++K)for(var j=T*F+D*q+_*K,X=u*(p-1-$)+l*(f-1-(K*w-V))+c*M,Y=0;Y<g;++Y){H+=a[j+O*Y]*i[X+Y]}o[k*F+N*B+S*U+A*M]=H}return r.toTensor()},t.prototype.conv3dDerInput=function(t,e,n){for(var r=Zn(n.inShape,\"float32\"),o=r.values,a=r.strides,i=a[0],s=a[1],u=a[2],l=a[3],c=this.readSync(t.dataId),h=t.strides,p=h[0],f=h[1],d=h[2],v=h[3],m=this.readSync(e.dataId),g=e.strides,y=g[0],x=g[1],b=g[2],w=g[3],C=n.batchSize,E=n.filterDepth,R=n.filterHeight,I=n.filterWidth,k=n.inChannels,N=n.inDepth,S=n.inHeight,A=n.inWidth,T=n.outChannels,D=n.outDepth,_=n.outHeight,O=n.outWidth,F=n.strideDepth,M=n.strideHeight,B=n.strideWidth,P=E-1-n.padInfo.front,L=R-1-n.padInfo.top,W=I-1-n.padInfo.left,U=0;U<C;++U)for(var V=0;V<k;++V)for(var z=0;z<N;++z)for(var G=z-P,H=Math.max(0,Math.ceil(G/F)),q=Math.min(D,(E+G)/F),$=0;$<S;++$)for(var K=$-L,j=Math.max(0,Math.ceil(K/M)),X=Math.min(_,(R+K)/M),Y=0;Y<A;++Y){for(var Q=Y-W,J=Math.max(0,Math.ceil(Q/B)),Z=Math.min(O,(I+Q)/B),tt=0,et=H;et<q;++et)for(var nt=et*F-G,rt=j;rt<X;++rt)for(var ot=rt*M-K,at=J;at<Z;++at)for(var it=p*U+f*et+d*rt+v*at,st=y*(E-1-nt)+x*(R-1-ot)+b*(I-1-(at*B-Q))+w*V,ut=0;ut<T;++ut){tt+=c[it+ut]*m[st+ut]}o[i*U+s*z+u*$+l*Y+V]=tt}return r.toTensor()},t.prototype.conv2dDerFilter=function(t,e,n){this.assertNotComplex([t,e],\"conv2dDerFilter\");for(var r=n.strideHeight,o=n.strideWidth,a=n.filterHeight,i=n.filterWidth,s=\"channelsLast\"===n.dataFormat,u=Zn(n.filterShape,\"float32\"),l=n.padInfo.left,c=n.padInfo.top,h=this.bufferSync(t),p=this.bufferSync(e),f=0;f<a;++f)for(var d=Math.max(0,Math.ceil((c-f)/r)),v=Math.min(n.outHeight,(n.inHeight+c-f)/r),m=0;m<i;++m)for(var g=Math.max(0,Math.ceil((l-m)/o)),y=Math.min(n.outWidth,(n.inWidth+l-m)/o),x=0;x<n.inChannels;++x)for(var b=0;b<n.outChannels;++b){for(var w=0,C=0;C<n.batchSize;++C)for(var E=d;E<v;++E)for(var R=f+E*r-c,I=g;I<y;++I){var k=m+I*o-l;w+=s?h.get(C,R,k,x)*p.get(C,E,I,b):h.get(C,x,R,k)*p.get(C,b,E,I)}u.set(w,f,m,x,b)}return u.toTensor()},t.prototype.conv3dDerFilter=function(t,e,n){for(var r=n.strideDepth,o=n.strideHeight,a=n.strideWidth,i=n.filterDepth,s=n.filterHeight,u=n.filterWidth,l=Zn(n.filterShape,\"float32\"),c=l.values,h=l.strides,p=h[0],f=h[1],d=h[2],v=h[3],m=this.readSync(e.dataId),g=e.strides,y=g[0],x=g[1],b=g[2],w=g[3],C=this.readSync(t.dataId),E=t.strides,R=E[0],I=E[1],k=E[2],N=E[3],S=n.padInfo.front,A=n.padInfo.left,T=n.padInfo.top,D=0;D<i;++D)for(var _=Math.max(0,Math.ceil((S-D)/r)),O=Math.min(n.outDepth,(n.inDepth+S-D)/r),F=D*p,M=0;M<s;++M)for(var B=Math.max(0,Math.ceil((T-M)/o)),P=Math.min(n.outHeight,(n.inHeight+T-M)/o),L=M*f+F,W=0;W<u;++W)for(var U=Math.max(0,Math.ceil((A-W)/a)),V=Math.min(n.outWidth,(n.inWidth+A-W)/a),z=W*d+L,G=0;G<n.inChannels;++G)for(var H=G*v+z,q=0;q<n.outChannels;++q){for(var $=0,K=0;K<n.batchSize;++K)for(var j=K*R,X=K*y,Y=_;Y<O;++Y)for(var Q=(D+Y*r-S)*I+j,J=Y*x+X,Z=B;Z<P;++Z)for(var tt=(M+Z*o-T)*k+Q,et=Z*b+J,nt=U;nt<V;++nt){var rt=nt*w+et;$+=C[(W+nt*a-A)*N+tt+G]*m[rt+q]}c[H+q]=$}return l.toTensor()},t.prototype.depthwiseConv2D=function(t,e,n){this.assertNotComplex([t,e],\"depthwiseConv2D\");for(var r=n.filterHeight,o=n.filterWidth,a=n.dilationHeight,i=n.dilationWidth,s=n.padInfo.left,u=n.padInfo.top,l=n.outChannels/n.inChannels,c=Zn(n.outShape,t.dtype),h=this.readSync(t.dataId),p=this.readSync(e.dataId),f=c.values,d=0;d<n.batchSize;++d)for(var v=d*t.strides[0],m=d*c.strides[0],g=0;g<n.outHeight;++g)for(var y=m+g*c.strides[1],x=g*n.strideHeight-s,b=0;b<r;++b){var w=x+b*a;if(!(w<0||w>=n.inHeight))for(var C=b*e.strides[0],E=v+w*t.strides[1],R=0;R<n.outWidth;++R)for(var I=y+R*c.strides[2],k=R*n.strideWidth-u,N=0;N<o;++N){var S=k+N*i;if(!(S<0||S>=n.inWidth))for(var A=C+N*e.strides[1],T=E+S*n.inChannels,D=I,_=A,O=0;O<n.inChannels;++O){for(var F=h[T+O],M=0;M<l;++M)f[D+M]+=F*p[_+M];D+=l,_+=l}}}return c.toTensor()},t.prototype.depthwiseConv2DDerInput=function(t,e,n){this.assertNotComplex([t,e],\"depthwiseConv2DDerInput\");for(var r=Zn(n.inShape,\"float32\"),o=r.values,a=r.strides,i=a[0],s=a[1],u=a[2],l=this.readSync(t.dataId),c=t.strides,h=c[0],p=c[1],f=c[2],d=this.readSync(e.dataId),v=e.strides,m=v[0],g=v[1],y=v[2],x=n.batchSize,b=n.filterHeight,w=n.filterWidth,C=n.inChannels,E=n.inHeight,R=n.inWidth,I=n.outChannels,k=n.outHeight,N=n.outWidth,S=n.strideHeight,A=n.strideWidth,T=b-1-n.padInfo.top,D=w-1-n.padInfo.left,_=I/C,O=0;O<x;++O)for(var F=0;F<C;++F)for(var M=0;M<E;++M)for(var B=M-T,P=Math.max(0,Math.ceil(B/S)),L=Math.min(k,(b+B)/S),W=0;W<R;++W){for(var U=W-D,V=Math.max(0,Math.ceil(U/A)),z=Math.min(N,(w+U)/A),G=0,H=P;H<L;++H)for(var q=H*S-B,$=V;$<z;++$)for(var K=h*O+p*H+f*$,j=m*(b-1-q)+g*(w-1-($*A-U))+y*F,X=0;X<_;++X){G+=l[K+(F*_+X)]*d[j+X]}o[i*O+s*M+u*W+F]=G}return r.toTensor()},t.prototype.depthwiseConv2DDerFilter=function(t,e,n){this.assertNotComplex([t,e],\"depthwiseConv2DDerFilter\");for(var r=n.strideHeight,o=n.strideWidth,a=n.filterHeight,i=n.filterWidth,s=Zn(n.filterShape,\"float32\"),u=n.padInfo.left,l=n.padInfo.top,c=n.outChannels/n.inChannels,h=this.bufferSync(t),p=this.bufferSync(e),f=0;f<a;++f)for(var d=Math.max(0,Math.ceil((l-f)/r)),v=Math.min(n.outHeight,(n.inHeight+l-f)/r),m=0;m<i;++m)for(var g=Math.max(0,Math.ceil((u-m)/o)),y=Math.min(n.outWidth,(n.inWidth+u-m)/o),x=0;x<n.outChannels;++x){for(var b=Math.trunc(x/c),w=x%c,C=0,E=0;E<n.batchSize;++E)for(var R=d;R<v;++R)for(var I=f+R*r-l,k=g;k<y;++k){var N=m+k*o-u;C+=h.get(E,I,N,b)*p.get(E,R,k,x)}s.set(C,f,m,b,w)}return s.toTensor()},t.prototype.tile=function(t,e){return this.assertNotComplex(t,\"tile\"),No(this.bufferSync(t),e)},t.prototype.pad=function(t,e,n){this.assertNotComplex(t,\"pad\");var r=e.map(function(e,n){return e[0]+t.shape[n]+e[1]}),o=e.map(function(t){return t[0]}),a=this.bufferSync(t),i=Zn(r,t.dtype);0!==n&&i.values.fill(n);for(var s=0;s<t.size;s++){var u=a.indexToLoc(s),l=u.map(function(t,e){return t+o[e]});i.set.apply(i,[a.get.apply(a,u)].concat(l))}return i.toTensor()},t.prototype.transpose=function(t,e){this.assertNotComplex(t,\"transpose\");for(var n=new Array(t.rank),r=0;r<n.length;r++)n[r]=t.shape[e[r]];var o=this.readSync(t.dataId),a=Zn(n,t.dtype),i=this.bufferSync(t);for(r=0;r<t.size;++r){for(var s=i.indexToLoc(r),u=new Array(s.length),l=0;l<u.length;l++)u[l]=s[e[l]];var c=a.locToIndex(u);a.values[c]=o[r]}return a.toTensor()},t.prototype.gather=function(t,e,n){this.assertNotComplex([t,e],\"gather\");var r=t.shape.slice(),o=this.readSync(e.dataId);r[n]=o.length;for(var a=Zn(r,t.dtype),i=this.bufferSync(t),s=0;s<a.size;++s){var u=a.indexToLoc(s),l=u.slice();l[n]=o[u[n]];var c=i.locToIndex(l);a.values[s]=i.values[c]}return a.toTensor()},t.prototype.batchToSpaceND=function(t,e,n){this.assertNotComplex([t],\"batchToSpaceND\");var r=e.reduce(function(t,e){return t*e}),o=Nr(t.shape,e,r),a=Sr(o.length,e.length),i=Ar(t.shape,e,r),s=Tr(n,e.length),u=Dr(i,n,e.length);return t.reshape(o).transpose(a).reshape(i).slice(s,u)},t.prototype.spaceToBatchND=function(t,e,n){this.assertNotComplex([t],\"spaceToBatchND\");var r=e.reduce(function(t,e){return t*e}),o=[[0,0]];o.push.apply(o,n);for(var a=1+e.length;a<t.shape.length;++a)o.push([0,0]);var i=t.pad(o),s=Nr(i.shape,e,r,!1),u=Sr(s.length,e.length,!1),l=Ar(i.shape,e,r,!1);return i.reshape(s).transpose(u).reshape(l)},t.prototype.pool=function(t,e,n){this.assertNotComplex(t,\"pool\");for(var r=e.strideHeight,o=e.strideWidth,a=e.dilationHeight,i=e.dilationWidth,s=e.effectiveFilterHeight,u=e.effectiveFilterWidth,l=e.padInfo.top,c=e.padInfo.left,h=\"max\"===n?Number.NEGATIVE_INFINITY:Number.POSITIVE_INFINITY,p=this.readSync(t.dataId),f=Zn(e.outShape,t.dtype),d=f.values,v=e.outShape[1]*e.outShape[2]*e.outShape[3],m=e.outShape[2]*e.outShape[3],g=e.outShape[3],y=0;y<e.batchSize;++y)for(var x=y*v,b=y*t.strides[0],w=0;w<e.inChannels;++w)for(var C=0;C<e.outHeight;++C)for(var E=C*r-l,R=Math.max(0,E),I=Math.min(e.inHeight,s+E),k=x+C*m,N=0;N<e.outWidth;++N){for(var S=N*o-c,A=Math.max(0,S),T=Math.min(e.inWidth,u+S),D=h,_=0,O=0,F=R;F<I;F+=a){for(var M=b+F*t.strides[1],B=A;B<T;B+=i){var P=p[M+B*t.strides[2]+w];\"max\"===n&&P>D?D=P:\"avg\"===n&&(_+=P,O++)}if(isNaN(D))break}d[k+N*g+w]=\"avg\"===n?_/O:D}return f.toTensor()},t.prototype.maxPool=function(t,e){return this.pool(t,e,\"max\")},t.prototype.maxPoolPositions=function(t,e){for(var n=Zn(e.outShape,\"int32\"),r=e.strideHeight,o=e.strideWidth,a=e.dilationHeight,i=e.dilationWidth,s=e.effectiveFilterHeight,u=e.effectiveFilterWidth,l=e.padInfo.top,c=e.padInfo.left,h=this.bufferSync(t),p=0;p<e.batchSize;++p)for(var f=0;f<e.inChannels;++f)for(var d=0;d<e.outHeight;++d){for(var v=d*r-l,m=v;m<0;)m+=a;for(var g=Math.min(e.inHeight,s+v),y=0;y<e.outWidth;++y){for(var x=y*o-c,b=x;b<0;)b+=i;for(var w=Math.min(e.inWidth,u+x),C=Number.NEGATIVE_INFINITY,E=-1,R=m;R<g;R+=a)for(var I=R-v,k=b;k<w;k+=i){var N=k-x,S=h.get(p,R,k,f);S>C&&(C=S,E=I*u+N)}n.set(E,p,d,y,f)}}return n.toTensor()},t.prototype.maxPoolBackprop=function(t,e,n,r){this.assertNotComplex([e,n],\"maxPoolBackprop\");for(var o=this.maxPoolPositions(e,r),a=r.strideHeight,i=r.strideWidth,s=r.dilationHeight,u=r.dilationWidth,l=r.effectiveFilterHeight,c=r.effectiveFilterWidth,h=c-1-r.padInfo.left,p=l-1-r.padInfo.top,f=Zn(e.shape,\"float32\"),d=this.bufferSync(o),v=this.bufferSync(t),m=0;m<r.batchSize;++m)for(var g=0;g<r.inChannels;++g)for(var y=0;y<r.inHeight;++y)for(var x=0;x<r.inWidth;++x){for(var b=y-p,w=x-h,C=0,E=0;E<l;E+=s){var R=(b+E)/a;if(!(R<0||R>=r.outHeight||Math.floor(R)!==R))for(var I=0;I<c;I+=u){var k=(w+I)/i;if(!(k<0||k>=r.outWidth||Math.floor(k)!==k)){var N=l*c-1-d.get(m,R,k,g)===E*c+I?1:0;if(0!==N)C+=v.get(m,R,k,g)*N}}}f.set(C,m,y,x,g)}return f.toTensor()},t.prototype.avgPoolBackprop=function(t,e,n){this.assertNotComplex([t,e],\"avgPoolBackprop\");for(var r=n.strideHeight,o=n.strideWidth,a=n.filterHeight,i=n.filterWidth,s=n.dilationHeight,u=n.dilationWidth,l=n.effectiveFilterHeight,c=n.effectiveFilterWidth,h=c-1-n.padInfo.left,p=l-1-n.padInfo.top,f=Zn(e.shape,\"float32\"),d=1/(a*i),v=this.bufferSync(t),m=0;m<n.batchSize;++m)for(var g=0;g<n.inChannels;++g)for(var y=0;y<n.inHeight;++y)for(var x=0;x<n.inWidth;++x){for(var b=y-p,w=x-h,C=0,E=0;E<l;E+=s){var R=(b+E)/r;if(!(R<0||R>=n.outHeight||Math.floor(R)!==R))for(var I=0;I<c;I+=u){var k=(w+I)/o;if(!(k<0||k>=n.outWidth||Math.floor(k)!==k))C+=v.get(m,R,k,g)}}f.set(C*d,m,y,x,g)}return f.toTensor()},t.prototype.pool3d=function(t,e,n){this.assertNotComplex(t,\"pool3d\");for(var r=e.strideDepth,o=e.strideHeight,a=e.strideWidth,i=e.dilationDepth,s=e.dilationHeight,u=e.dilationWidth,l=e.effectiveFilterDepth,c=e.effectiveFilterHeight,h=e.effectiveFilterWidth,p=e.padInfo.front,f=e.padInfo.top,d=e.padInfo.left,v=\"max\"===n?Number.NEGATIVE_INFINITY:Number.POSITIVE_INFINITY,m=this.readSync(t.dataId),g=Zn(e.outShape,t.dtype),y=g.values,x=e.outShape[1]*e.outShape[2]*e.outShape[3]*e.outShape[4],b=e.outShape[2]*e.outShape[3]*e.outShape[4],w=e.outShape[3]*e.outShape[4],C=e.outShape[4],E=0;E<e.batchSize;++E)for(var R=E*x,I=E*t.strides[0],k=0;k<e.inChannels;++k)for(var N=0;N<e.outDepth;++N){for(var S=N*r-p,A=S;A<0;)A+=i;for(var T=Math.min(e.inDepth,l+S),D=R+N*b,_=0;_<e.outHeight;++_){for(var O=_*o-f,F=O;F<0;)F+=s;for(var M=Math.min(e.inHeight,c+O),B=D+_*w,P=0;P<e.outWidth;++P){for(var L=P*a-d,W=L;W<0;)W+=u;for(var U=Math.min(e.inWidth,h+L),V=B+P*C,z=v,G=0,H=0,q=A;q<T;q+=i){for(var $=I+q*t.strides[1],K=F;K<M;K+=s){for(var j=$+K*t.strides[2],X=W;X<U;X+=u){var Y=m[j+X*t.strides[3]+k];if(\"max\"===n&&Y>z?z=Y:\"avg\"===n&&(G+=Y,H++),isNaN(z))break}if(isNaN(z))break}if(isNaN(z))break}y[V+k]=\"avg\"===n?G/H:z}}}return g.toTensor()},t.prototype.avgPool3d=function(t,e){return this.assertNotComplex(t,\"avgPool3d\"),this.pool3d(t,e,\"avg\").toFloat()},t.prototype.avgPool3dBackprop=function(t,e,n){this.assertNotComplex([t,e],\"avgPool3dBackprop\");for(var r=n.strideDepth,o=n.strideHeight,a=n.strideWidth,i=n.filterDepth,s=n.filterHeight,u=n.filterWidth,l=n.dilationDepth,c=n.dilationHeight,h=n.dilationWidth,p=n.effectiveFilterDepth,f=n.effectiveFilterHeight,d=n.effectiveFilterWidth,v=p-1-n.padInfo.front,m=d-1-n.padInfo.left,g=f-1-n.padInfo.top,y=Zn(e.shape,\"float32\"),x=1/(i*s*u),b=this.bufferSync(t),w=0;w<n.batchSize;++w)for(var C=0;C<n.inChannels;++C)for(var E=0;E<n.inDepth;++E)for(var R=0;R<n.inHeight;++R)for(var I=0;I<n.inWidth;++I){for(var k=E-v,N=R-g,S=I-m,A=0,T=0;T<p;T+=l){var D=(k+T)/r;if(!(D<0||D>=n.outDepth||Math.floor(D)!==D))for(var _=0;_<f;_+=c){var O=(N+_)/o;if(!(O<0||O>=n.outHeight||Math.floor(O)!==O))for(var F=0;F<d;F+=h){var M=(S+F)/a;if(!(M<0||M>=n.outWidth||Math.floor(M)!==M))A+=b.get(w,D,O,M,C)}}}y.set(A*x,w,E,R,I,C)}return y.toTensor()},t.prototype.maxPool3d=function(t,e){return this.assertNotComplex(t,\"maxPool3d\"),this.pool3d(t,e,\"max\").toFloat()},t.prototype.maxPool3dPositions=function(t,e){for(var n=Zn(e.outShape,\"int32\"),r=e.strideDepth,o=e.strideHeight,a=e.strideWidth,i=e.dilationDepth,s=e.dilationHeight,u=e.dilationWidth,l=e.effectiveFilterDepth,c=e.effectiveFilterHeight,h=e.effectiveFilterWidth,p=e.padInfo.front,f=e.padInfo.top,d=e.padInfo.left,v=this.bufferSync(t),m=0;m<e.batchSize;++m)for(var g=0;g<e.inChannels;++g)for(var y=0;y<e.outDepth;++y){for(var x=y*r-p,b=x;b<0;)b+=i;for(var w=Math.min(e.inDepth,l+x),C=0;C<e.outHeight;++C){for(var E=C*o-f,R=E;R<0;)R+=s;for(var I=Math.min(e.inHeight,c+E),k=0;k<e.outWidth;++k){for(var N=k*a-d,S=N;S<0;)S+=u;for(var A=Math.min(e.inWidth,h+N),T=Number.NEGATIVE_INFINITY,D=-1,_=b;_<w;_+=i)for(var O=_-x,F=R;F<I;F+=s)for(var M=F-E,B=S;B<A;B+=u){var P=B-N,L=v.get(m,_,F,B,g);L>=T&&(T=L,D=O*c*h+M*c+P)}n.set(D,m,y,C,k,g)}}}return n.toTensor()},t.prototype.maxPool3dBackprop=function(t,e,n,r){this.assertNotComplex([e,n],\"maxPool3dBackprop\");for(var o=this.maxPool3dPositions(e,r),a=r.strideDepth,i=r.strideHeight,s=r.strideWidth,u=r.dilationDepth,l=r.dilationHeight,c=r.dilationWidth,h=r.effectiveFilterDepth,p=r.effectiveFilterHeight,f=r.effectiveFilterWidth,d=h-1-r.padInfo.front,v=f-1-r.padInfo.left,m=p-1-r.padInfo.top,g=Zn(e.shape,\"float32\"),y=this.bufferSync(o),x=this.bufferSync(t),b=0;b<r.batchSize;++b)for(var w=0;w<r.inChannels;++w)for(var C=0;C<r.inDepth;++C)for(var E=0;E<r.inHeight;++E)for(var R=0;R<r.inWidth;++R){for(var I=C-d,k=E-m,N=R-v,S=0,A=0;A<h;A+=u){var T=(I+A)/a;if(!(T<0||T>=r.outDepth||Math.floor(T)!==T))for(var D=0;D<p;D+=l){var _=(k+D)/i;if(!(_<0||_>=r.outHeight||Math.floor(_)!==_))for(var O=0;O<f;O+=c){var F=(N+O)/s;if(!(F<0||F>=r.outWidth||Math.floor(F)!==F)){var M=h*p*f-1-y.get(b,T,_,F,w)===A*p*f+D*f+O?1:0;if(0!==M)S+=x.get(b,T,_,F,w)*M}}}}g.set(S,b,C,E,R,w)}return g.toTensor()},t.prototype.cast=function(t,e){return mo(t,e,this)},t.prototype.reshape=function(t,e){return go(t,e)},t.prototype.avgPool=function(t,e){return this.assertNotComplex(t,\"avgPool\"),this.pool(t,e,\"avg\").toFloat()},t.prototype.resizeBilinear=function(t,e,n,r){this.assertNotComplex(t,\"resizeBilinear\");for(var o=t.shape,a=o[0],i=o[1],s=o[2],u=o[3],l=this.readSync(t.dataId),c=new Float32Array(g([a,e,n,u])),h=[r&&e>1?i-1:i,r&&n>1?s-1:s],p=[r&&e>1?e-1:e,r&&n>1?n-1:n],f=0,d=h[0]/p[0],v=h[1]/p[1],m=0;m<a;m++)for(var y=0;y<e;y++)for(var x=d*y,b=Math.floor(x),w=x-b,C=Math.min(i-1,Math.ceil(x)),E=m*t.strides[0]+b*t.strides[1],R=m*t.strides[0]+C*t.strides[1],I=0;I<n;I++)for(var k=v*I,N=Math.floor(k),S=k-N,A=Math.min(s-1,Math.ceil(k)),T=E+N*t.strides[2],D=R+N*t.strides[2],_=E+ +A*t.strides[2],O=R+A*t.strides[2],F=0;F<u;F++){var M=l[T+F],B=l[D+F],P=M+(l[_+F]-M)*S,L=P+(B+(l[O+F]-B)*S-P)*w;c[f++]=L}return xn(c,[a,e,n,u])},t.prototype.resizeBilinearBackprop=function(t,e,n){this.assertNotComplex([t,e],\"resizeBilinearBackprop\");for(var r=e.shape,o=r[0],a=r[1],i=r[2],s=r[3],u=t.shape,l=u[1],c=u[2],h=new Float32Array(o*a*i*s),p=[n&&l>1?a-1:a,n&&c>1?i-1:i],f=[n&&l>1?l-1:l,n&&c>1?c-1:c],d=p[0]/f[0],v=p[1]/f[1],m=this.readSync(t.dataId),g=0,y=0;y<o;y++)for(var x=y*e.strides[0],b=0;b<l;b++)for(var w=b*d,C=Math.floor(w),E=Math.min(Math.ceil(w),a-1),R=x+C*e.strides[1],I=x+E*e.strides[1],k=w-C,N=1-k,S=0;S<c;S++)for(var A=S*v,T=Math.floor(A),D=Math.min(Math.ceil(A),i-1),_=A-T,O=1-_,F=R+T*e.strides[2],M=R+D*e.strides[2],B=I+T*e.strides[2],P=I+D*e.strides[2],L=N*O,W=N*_,U=k*O,V=k*_,z=0;z<s;z++){var G=m[g++];h[F+z]+=G*L,h[M+z]+=G*W,h[B+z]+=G*U,h[P+z]+=G*V}return In(h,[o,i,a,s],e.dtype)},t.prototype.resizeNearestNeighbor=function(t,e,n,r){this.assertNotComplex(t,\"resizeNearestNeighbor\");for(var o=t.shape,a=o[0],i=o[1],s=o[2],u=o[3],l=this.readSync(t.dataId),c=new Float32Array(a*e*n*u),h=[r&&e>1?i-1:i,r&&n>1?s-1:s],p=[r&&e>1?e-1:e,r&&n>1?n-1:n],f=h[0]/p[0],d=h[1]/p[1],v=0,m=0;m<a;m++)for(var g=m*t.strides[0],y=0;y<e;y++)for(var x=f*y,b=g+Math.min(i-1,r?Math.round(x):Math.floor(x))*t.strides[1],w=0;w<n;w++)for(var C=d*w,E=b+Math.min(s-1,r?Math.round(C):Math.floor(C))*t.strides[2],R=0;R<u;R++){var I=l[E+R];c[v++]=I}return xn(c,[a,e,n,u],t.dtype)},t.prototype.resizeNearestNeighborBackprop=function(t,e,n){this.assertNotComplex([t,e],\"resizeNearestNeighborBackprop\");for(var r=e.shape,o=r[0],a=r[1],i=r[2],s=r[3],u=t.shape,l=u[1],c=u[2],h=new Float32Array(o*a*i*s),p=this.readSync(t.dataId),f=[n&&l>1?a-1:a,n&&c>1?i-1:i],d=[n&&l>1?l-1:l,n&&c>1?c-1:c],v=f[0]/d[0],m=f[1]/d[1],g=1/v,y=1/m,x=2*Math.ceil(g)+2,b=2*Math.ceil(y)+2,w=0;w<o;w++)for(var C=w*e.strides[0],E=0;E<a;E++)for(var R=C+E*e.strides[1],I=Math.floor(E*g),k=Math.floor(I-x/2),N=0;N<i;N++)for(var S=R+N*e.strides[2],A=Math.floor(N*y),T=Math.floor(A-b/2),D=0;D<s;D++){for(var _=0,O=0;O<x;O++){var F=O+k;if(!(F<0||F>=l)){var M=C+F*t.strides[1],B=F*v;if(E===Math.min(a-1,n?Math.round(B):Math.floor(B)))for(var P=0;P<b;P++){var L=P+T;if(!(L<0||L>=c)){var W=M+L*t.strides[2],U=L*m;N===Math.min(i-1,n?Math.round(U):Math.floor(U))&&(_+=p[W+D])}}}}h[S+D]=_}return In(h,e.shape,e.dtype)},t.prototype.batchNormalization=function(t,e,n,r,o,a){this.assertNotComplex([t,e,n,o,a],\"batchNorm\");for(var i=this.readSync(t.dataId),s=this.readSync(e.dataId),u=this.readSync(n.dataId),l=o?this.readSync(o.dataId):new Float32Array([1]),c=a?this.readSync(a.dataId):new Float32Array([0]),h=new Float32Array(i.length),p=c.length,f=l.length,d=u.length,v=s.length,m=0,g=0,y=0,x=0,b=0;b<i.length;++b)h[b]=c[m++]+(i[b]-s[g++])*l[y++]/Math.sqrt(u[x++]+r),m>=p&&(m=0),g>=v&&(g=0),y>=f&&(y=0),x>=d&&(x=0);return In(h,t.shape)},t.prototype.localResponseNormalization4D=function(t,e,n,r,o){this.assertNotComplex(t,\"localResponseNormalization4D\");var a=t.shape[3],i=a-1,s=this.readSync(t.dataId),u=t.size,l=new Float32Array(u);function c(t){for(var n=t%a,r=t-n+Math.max(0,n-e),o=t-n+Math.min(n+e,i),u=0;r<=o;r++){var l=s[r];u+=l*l}return u}for(var h=0;h<u;h++){var p=c(h),f=s[h]*Math.pow(n+r*p,-o);l[h]=f}return In(l,t.shape)},t.prototype.LRNGrad=function(t,e,n,r,o,a,i){this.assertNotComplex(t,\"LRNGrad\");for(var s=t.shape[3],u=this.readSync(t.dataId),l=this.readSync(e.dataId),c=this.readSync(n.dataId),h=new Float32Array(t.size),p=t.size,f=0;f<p;f++){for(var d=f%s,v=f-d+Math.max(0,d-r),m=f-d+Math.min(s,d+r+1),g=0,y=v;y<m;y++)g+=Math.pow(l[y],2);g=a*g+o;for(y=v;y<m;y++){var x=-2*a*i*l[y]*c[f]/g;f===y&&(x+=Math.pow(g,-i)),x*=u[f],h[y]+=x}}return In(h,t.shape)},t.prototype.multinomial=function(t,e,n,r){this.assertNotComplex(t,\"multinomial\");for(var o=e?t:Yr(t),a=o.shape[0],i=o.shape[1],s=An([a,n],\"int32\"),u=this.readSync(s.dataId),l=this.readSync(o.dataId),c=0;c<a;++c){var h=c*i,p=new Float32Array(i-1);p[0]=l[h];for(var f=1;f<p.length;++f)p[f]=p[f-1]+l[h+f];for(var d=Xn(r.toString()),v=c*n,m=0;m<n;++m){var g=d();u[v+m]=p.length;for(var y=0;y<p.length;y++)if(g<p[y]){u[v+m]=y;break}}}return s},t.prototype.oneHot=function(t,e,n,r){this.assertNotComplex(t,\"oneHot\");var o=new Float32Array(t.size*e);o.fill(r);for(var a=this.readSync(t.dataId),i=0;i<t.size;++i)a[i]>=0&&a[i]<e&&(o[i*e+a[i]]=n);return En(o,[t.size,e],\"int32\")},t.prototype.nonMaxSuppression=function(t,e,n,r,o){return this.assertNotComplex(t,\"nonMaxSuppression\"),Ro(this.readSync(t.dataId),this.readSync(e.dataId),n,r,o)},t.prototype.fft=function(t){return this.fftBatch(t,!1)},t.prototype.ifft=function(t){return this.fftBatch(t,!0)},t.prototype.fftBatch=function(t,e){for(var n=t.shape[0],r=t.shape[1],o=Zn(t.shape,\"float32\"),a=Zn(t.shape,\"float32\"),i=gn(t).as2D(n,r),s=yn(t).as2D(n,r),u=0;u<n;u++)for(var l=i.slice([u,0],[1,r]),c=s.slice([u,0],[1,r]),h=mn(l,c),p=this.readSync(this.fftImpl(h,e).dataId),f=0;f<r;f++){var d=wo(p,f);o.values[u*r+f]=d.real,a.values[u*r+f]=d.imag}return mn(o.toTensor(),a.toTensor()).as2D(n,r)},t.prototype.fftImpl=function(t,e){var n=t.as1D(),r=n.size;if(this.isExponentOf2(r)){var o=this.fftRadix2(n,r,e).as2D(t.shape[0],t.shape[1]);return e&&(o=mn(gn(o).div(wn(r)),yn(o).div(wn(r)))),o}var a=this.readSync(t.dataId),i=function(t){for(var e=new Float32Array(t.length/2),n=new Float32Array(t.length/2),r=0;r<t.length;r+=2)e[r/2]=t[r],n[r/2]=t[r+1];return{real:e,imag:n}}(this.fourierTransformByMatmul(a,r,e));return mn(i.real,i.imag).as2D(t.shape[0],t.shape[1])},t.prototype.isExponentOf2=function(t){return 0==(t&t-1)},t.prototype.fftRadix2=function(t,e,n){if(1===e)return t;var r=this.readSync(t.dataId),o=e/2,a=function(t){for(var e=Math.ceil(t.length/4),n=new Float32Array(e),r=new Float32Array(e),o=0;o<t.length;o+=4)n[Math.floor(o/4)]=t[o],r[Math.floor(o/4)]=t[o+1];return{real:n,imag:r}}(r),i=mn(a.real,a.imag).as1D(),s=function(t){for(var e=Math.floor(t.length/4),n=new Float32Array(e),r=new Float32Array(e),o=2;o<t.length;o+=4)n[Math.floor(o/4)]=t[o],r[Math.floor(o/4)]=t[o+1];return{real:n,imag:r}}(r),u=mn(s.real,s.imag).as1D();i=this.fftRadix2(i,o,n),u=this.fftRadix2(u,o,n);var l=function(t,e){for(var n=new Float32Array(t/2),r=new Float32Array(t/2),o=0;o<Math.ceil(t/2);o++){var a=(e?2:-2)*Math.PI*(o/t);n[o]=Math.cos(a),r[o]=Math.sin(a)}return{real:n,imag:r}}(e,n),c=mn(l.real,l.imag).mul(u),h=i.add(c),p=i.sub(c),f=gn(h).concat(gn(p)),d=yn(h).concat(yn(p));return mn(f,d).as1D()},t.prototype.fourierTransformByMatmul=function(t,e,n){for(var r=new Float32Array(2*e),o=0;o<e;o++){for(var a=0,i=0,s=0;s<e;s++){var u=Eo(o*s,e,n),l=wo(t,s);a+=l.real*u.real-l.imag*u.imag,i+=l.real*u.imag+l.imag*u.real}n&&(a/=e,i/=e),Co(r,a,i,o)}return r},t.prototype.depthToSpace=function(t,e,n){f(\"NHWC\"===n,function(){return\"Only NHWC dataFormat supported on CPU for depthToSpace. Got \"+n}),f(e>1,function(){return\"blockSize should be > 1 for depthToSpace, but was: \"+e});for(var r=t.shape[0],o=t.shape[1],a=t.shape[2],i=t.shape[3],s=o*e,u=a*e,l=i/(e*e),c=this.readSync(t.dataId),h=new Float32Array(r*s*u*l),p=0,d=0;d<r;++d)for(var v=0;v<s;++v)for(var m=Math.floor(v/e),g=v%e,y=0;y<u;++y)for(var x=Math.floor(y/e),b=(g*e+y%e)*l,w=0;w<l;++w){var C=w+b+i*(x+a*(m+o*d));h[p++]=c[C]}return In(h,[r,s,u,l])},t.prototype.broadcastedBinaryOp=function(t,e,n,r){var o=no(t.shape,e.shape),a=Zn(o,n),i=this.readSync(t.dataId),s=this.readSync(e.dataId),u=to(t.shape,o),l=to(e.shape,o),c=a.values;if(u.length+l.length===0)for(var h=0;h<c.length;++h)c[h]=r(i[h%i.length],s[h%s.length]);else{var p=this.bufferSync(t),f=this.bufferSync(e),d=function(n){var o=a.indexToLoc(n),h=o.slice(-t.rank);u.forEach(function(t){return h[t]=0});var d=p.locToIndex(h),v=o.slice(-e.rank);l.forEach(function(t){return v[t]=0});var m=f.locToIndex(v);c[n]=r(i[d],s[m])};for(h=0;h<c.length;++h)d(h)}return a.toTensor()},t.prototype.broadcastedBinaryComplexOp=function(t,e,n){var r=no(t.shape,e.shape),o=Zn(r,\"float32\"),a=Zn(r,\"float32\"),i=this.readSync(t.dataId),s=this.readSync(e.dataId),u=to(t.shape,r),l=to(e.shape,r),c=o.values,h=a.values;if(u.length+l.length===0)for(var p=0;p<c.length;p++){var f=p%i.length,d=p%s.length,v=n(i[2*f],i[2*f+1],s[2*d],s[2*d+1]);c[p]=v.real,h[p]=v.imag}else{var m=this.bufferSync(this.data.get(t.dataId).complexTensors.real),g=this.bufferSync(this.data.get(e.dataId).complexTensors.real),y=function(r){var a=o.indexToLoc(r),p=a.slice(-t.rank);u.forEach(function(t){return p[t]=0});var f=m.locToIndex(p),d=a.slice(-e.rank);l.forEach(function(t){return d[t]=0});var v=g.locToIndex(d),y=n(i[2*f],i[2*f+1],s[2*v],s[2*v+1]);c[r]=y.real,h[r]=y.imag};for(p=0;p<c.length;p++)y(p)}return this.complex(o.toTensor(),a.toTensor())},t.prototype.split=function(t,e,n){return ko(t,e,n)},t.prototype.dispose=function(){},t.prototype.floatPrecision=function(){return 32},t.prototype.epsilon=function(){return 1e-7},t.prototype.cropAndResize=function(t,e,n,r,o,a){for(var i=t.shape,s=i[0],u=i[1],l=i[2],c=i[3],h=e.shape[0],p=r[0],f=r[1],d=Zn([h,p,f,c],t.dtype),v=this.readSync(e.dataId),m=this.readSync(n.dataId),g=this.readSync(t.dataId),y=t.strides,x=d.strides,b=0;b<h;b++){var w=4*b,C=v[w],E=v[w+1],R=v[w+2],I=v[w+3],k=m[b];if(!(k>=s))for(var N=p>1?(R-C)*(u-1)/(p-1):0,S=f>1?(I-E)*(l-1)/(f-1):0,A=0;A<p;A++){var T=p>1?C*(u-1)+A*N:.5*(C+R)*(u-1);if(T<0||T>u-1)for(var D=0;D<f;D++)for(var _=0;_<c;_++){var O=_+D*x[2]+A*x[1]+b*x[0];d.values[O]=a}else if(\"bilinear\"===o){var F=Math.floor(T),M=Math.ceil(T),B=T-F;for(D=0;D<f;D++){if((q=f>1?E*(l-1)+D*S:.5*(E+I)*(l-1))<0||q>l-1)for(_=0;_<c;_++){O=_+D*x[2]+A*x[1]+b*x[0];d.values[O]=a}else{var P=Math.floor(q),L=Math.ceil(q),W=q-P;for(_=0;_<c;_++){var U=g[O=_+P*y[2]+F*y[1]+k*y[0]],V=g[O=_+L*y[2]+F*y[1]+k*y[0]],z=g[O=_+P*y[2]+M*y[1]+k*y[0]],G=U+(V-U)*W,H=z+(g[O=_+L*y[2]+M*y[1]+k*y[0]]-z)*W;O=_+D*x[2]+A*x[1]+b*x[0],d.values[O]=G+(H-G)*B}}}}else for(D=0;D<f;++D){var q;if((q=f>1?E*(l-1)+D*S:.5*(E+I)*(l-1))<0||q>l-1)for(_=0;_<c;_++){O=_+D*x[2]+A*x[1]+b*x[0];d.values[O]=a}else{var $=Math.round(q),K=Math.round(T);for(_=0;_<c;_++){var j=_+$*y[2]+K*y[1]+k*y[0],X=_+D*x[2]+A*x[1]+b*x[0];d.values[X]=g[j]}}}}}return d.toTensor()},t.prototype.sparseToDense=function(t,e,n,r){var o=Br(0,t,n),a=o.sliceRank,i=o.numUpdates,s=o.sliceSize,u=o.strides,l=o.outputSize;return this.scatter(t,e,n,l,s,i,a,u,r,!1)},t.prototype.gatherND=function(t,e){var n=e.shape,r=n[n.length-1],o=_r(t,e),a=o[0],i=o[1],s=o[2],u=o[3];if(0===i)return xn([],a,t.dtype);for(var l=new it([i,s],t.dtype),c=this.readSync(e.dataId),h=this.readSync(t.dataId),p=0;p<i;p++){for(var f=[],d=0,v=0;v<r;v++){var m=c[p*r+v];d+=m*u[v],f.push(m)}if(d<0||d>=t.size/s)throw new Error(\"Invalid indices: \"+f+\" does not index into \"+t.shape);for(var g=0;g<s;g++)l.values[p*s+g]=h[d*s+g]}return l.toTensor().reshape(a)},t.prototype.scatterND=function(t,e,n){var r=Br(0,t,n),o=r.sliceRank,a=r.numUpdates,i=r.sliceSize,s=r.strides,u=r.outputSize,l=wn(0);return this.scatter(t,e,n,u,i,a,o,s,l,!0)},t.prototype.fill=function(t,e,n){var r=S(n=n||L(e),g(t));return r.fill(e),ct.make(t,{values:r},n)},t.prototype.onesLike=function(t){if(\"string\"===t.dtype)throw new Error(\"onesLike is not supported for string tensors\");return this.fill(t.shape,1,t.dtype)},t.prototype.zerosLike=function(t){var e=S(t.dtype,g(t.shape));return ct.make(t.shape,{values:e},t.dtype)},t.prototype.linspace=function(t,e,n){return yo(t,e,n)},t.prototype.scatter=function(t,e,n,r,o,a,i,s,u,l){var c=[r/o,o],h=this.readSync(t.dataId),p=this.readSync(e.dataId);if(0===r)return xn([],n,e.dtype);var f=new it(c,e.dtype);f.values.fill(this.readSync(u.dataId)[0]);for(var d=0;d<a;d++){for(var v=[],m=0,g=0;g<i;g++){var y=h[d*i+g];v.push(y),m+=y*s[g]}if(m<0||m>=r/o)throw new Error(\"Invalid indices: \"+v+\" does not index into \"+n);for(var x=0;x<o;x++)l?f.values[m*o+x]+=p[d*o+x]:f.values[m*o+x]=0===e.rank?p[0]:p[d*o+x]}return f.toTensor().reshape(n)},t}();St.registerBackend(\"cpu\",function(){return new nh},1);var rh=function(){function t(){this.textEncoder=new TextEncoder}return t.prototype.fetch=function(t,e){return fetch(t,e)},t.prototype.now=function(){return performance.now()},t.prototype.encode=function(t,e){if(\"utf-8\"!==e&&\"utf8\"!==e)throw new Error(\"Browser's encoder only supports utf-8, but got \"+e);return this.textEncoder.encode(t)},t.prototype.decode=function(t,e){return new TextDecoder(e).decode(t)},t}();i.get(\"IS_BROWSER\")&&i.setPlatform(\"browser\",new rh);var oh,ah=function(){return __webpack_require__(/*! node-fetch */ 1)},ih=function(){function t(){this.util=__webpack_require__(/*! util */ 2),this.textEncoder=new this.util.TextEncoder}return t.prototype.fetch=function(t,e){return null!=i.global.fetch?i.global.fetch(t,e):(null==oh&&(oh=ah()),oh(t,e))},t.prototype.now=function(){var t=process.hrtime();return 1e3*t[0]+t[1]/1e6},t.prototype.encode=function(t,e){if(\"utf-8\"!==e&&\"utf8\"!==e)throw new Error(\"Node built-in encoder only supports utf-8, but got \"+e);return this.textEncoder.encode(t)},t.prototype.decode=function(t,e){return 0===t.length?\"\":new this.util.TextDecoder(e).decode(t)},t}();i.get(\"IS_NODE\")&&i.setPlatform(\"node\",new ih);var sh={float32:4,int32:4,uint16:2,uint8:1,bool:1},uh=4;function lh(t,e){for(var n={},r=0,o=function(e){var o=e.name,a=e.dtype,i=e.shape,s=g(i),u=void 0;if(\"quantization\"in e){var l=e.quantization;if(\"uint8\"!==l.dtype&&\"uint16\"!==l.dtype)throw new Error(\"Weight \"+e.name+\" has unknown quantization dtype \"+l.dtype+\". Supported quantization dtypes are: 'uint8' and 'uint16'.\");var c=sh[l.dtype],h=t.slice(r,r+s*c),p=\"uint8\"===l.dtype?new Uint8Array(h):new Uint16Array(h);if(\"float32\"===a)u=Float32Array.from(p,function(t){return t*l.scale+l.min});else{if(\"int32\"!==a)throw new Error(\"Unsupported dtype in weight '\"+o+\"': \"+a);u=Int32Array.from(p,function(t){return Math.round(t*l.scale+l.min)})}r+=s*c}else if(\"string\"===a){var f=g(e.shape);u=[];for(var d=0;d<f;d++){var v=new Uint32Array(t.slice(r,r+uh))[0];r+=uh;var m=new Uint8Array(t.slice(r,r+v));u.push(m),r+=v}}else{var y=sh[a];h=t.slice(r,r+s*y);if(\"float32\"===a)u=new Float32Array(h);else if(\"int32\"===a)u=new Int32Array(h);else{if(\"bool\"!==a)throw new Error(\"Unsupported dtype in weight '\"+o+\"': \"+a);u=new Uint8Array(h)}r+=s*y}n[o]=xn(u,i,a)},a=0,i=e;a<i.length;a++){o(i[a])}return n}function ch(t){if(null===t)throw new Error(\"Invalid input value: \"+JSON.stringify(t));var e=0,n=[];t.forEach(function(t){if(e+=t.byteLength,n.push(t.byteLength===t.buffer.byteLength?t:new t.constructor(t)),!(t instanceof Float32Array||t instanceof Int32Array||t instanceof Uint8Array))throw new Error(\"Unsupported TypedArray subtype: \"+t.constructor.name)});var r=new Uint8Array(e),o=0;return n.forEach(function(t){r.set(new Uint8Array(t.buffer),o),o+=t.byteLength}),r.buffer}var hh=\"undefined\"!=typeof Buffer&&(\"undefined\"==typeof Blob||\"undefined\"==typeof atob||\"undefined\"==typeof btoa);function ph(t){return hh?Buffer.byteLength(t):new Blob([t]).size}function fh(t){var e=0;t.forEach(function(t){e+=t.byteLength});var n=new Uint8Array(e),r=0;return t.forEach(function(t){n.set(new Uint8Array(t),r),r+=t.byteLength}),n.buffer}function dh(t){for(t=t.trim();t.endsWith(\"/\");)t=t.slice(0,t.length-1);var e=t.split(\"/\");return e[e.length-1]}function vh(t){if(t.modelTopology instanceof ArrayBuffer)throw new Error(\"Expected JSON model topology, received ArrayBuffer.\");return{dateSaved:new Date,modelTopologyType:\"JSON\",modelTopologyBytes:null==t.modelTopology?0:ph(JSON.stringify(t.modelTopology)),weightSpecsBytes:null==t.weightSpecs?0:ph(JSON.stringify(t.weightSpecs)),weightDataBytes:null==t.weightData?0:t.weightData.byteLength}}var mh=function(){function t(){this.saveRouters=[],this.loadRouters=[]}return t.getInstance=function(){return null==t.instance&&(t.instance=new t),t.instance},t.registerSaveRouter=function(e){t.getInstance().saveRouters.push(e)},t.registerLoadRouter=function(e){t.getInstance().loadRouters.push(e)},t.getSaveHandlers=function(e){return t.getHandlers(e,\"save\")},t.getLoadHandlers=function(e,n){return t.getHandlers(e,\"load\",n)},t.getHandlers=function(e,n,r){var o=[];return(\"load\"===n?t.getInstance().loadRouters:t.getInstance().saveRouters).forEach(function(t){var n=t(e,r);null!==n&&o.push(n)}),o},t}(),gh=\"://\",yh=function(){function t(){this.managers={}}return t.getInstance=function(){return null==t.instance&&(t.instance=new t),t.instance},t.registerManager=function(e,n){f(null!=e,function(){return\"scheme must not be undefined or null.\"}),e.endsWith(gh)&&(e=e.slice(0,e.indexOf(gh))),f(e.length>0,function(){return\"scheme must not be an empty string.\"});var r=t.getInstance();f(null==r.managers[e],function(){return\"A model store manager is already registered for scheme '\"+e+\"'.\"}),r.managers[e]=n},t.getManager=function(t){var e=this.getInstance().managers[t];if(null==e)throw new Error(\"Cannot find model manager for scheme '\"+t+\"'\");return e},t.getSchemes=function(){return Object.keys(this.getInstance().managers)},t}();function xh(t){if(-1===t.indexOf(gh))throw new Error(\"The url string provided does not contain a scheme. Supported schemes are: \"+yh.getSchemes().join(\",\"));return{scheme:t.split(gh)[0],path:t.split(gh)[1]}}function bh(t,e,o){return void 0===o&&(o=!1),n(this,void 0,void 0,function(){var n,a,i,s,u,l,c,h,p;return r(this,function(r){switch(r.label){case 0:return f(t!==e,function(){return\"Old path and new path are the same: '\"+t+\"'\"}),f((n=mh.getLoadHandlers(t)).length>0,function(){return\"Copying failed because no load handler is found for source URL \"+t+\".\"}),f(n.length<2,function(){return\"Copying failed because more than one (\"+n.length+\") load handlers for source URL \"+t+\".\"}),a=n[0],f((i=mh.getSaveHandlers(e)).length>0,function(){return\"Copying failed because no save handler is found for destination URL \"+e+\".\"}),f(i.length<2,function(){return\"Copying failed because more than one (\"+n.length+\") save handlers for destination URL \"+e+\".\"}),s=i[0],u=xh(t).scheme,l=xh(t).path,c=u===xh(t).scheme,[4,a.load()];case 1:return h=r.sent(),o&&c?[4,yh.getManager(u).removeModel(l)]:[3,3];case 2:r.sent(),r.label=3;case 3:return[4,s.save(h)];case 4:return p=r.sent(),!o||c?[3,6]:[4,yh.getManager(u).removeModel(l)];case 5:r.sent(),r.label=6;case 6:return[2,p.modelArtifactsInfo]}})})}var wh=\"models_store\",Ch=\"model_info_store\";function Eh(){if(!i.getBool(\"IS_BROWSER\"))throw new Error(\"Failed to obtain IndexedDB factory because the current environmentis not a web browser.\");var t=window,e=t.indexedDB||t.mozIndexedDB||t.webkitIndexedDB||t.msIndexedDB||t.shimIndexedDB;if(null==e)throw new Error(\"The current browser does not appear to support IndexedDB.\");return e}function Rh(t){var e=t.result;e.createObjectStore(wh,{keyPath:\"modelPath\"}),e.createObjectStore(Ch,{keyPath:\"modelPath\"})}var Ih=function(){function t(t){if(this.indexedDB=Eh(),null==t||!t)throw new Error(\"For IndexedDB, modelPath must not be null, undefined or empty.\");this.modelPath=t}return t.prototype.save=function(t){return n(this,void 0,void 0,function(){return r(this,function(e){if(t.modelTopology instanceof ArrayBuffer)throw new Error(\"BrowserLocalStorage.save() does not support saving model topology in binary formats yet.\");return[2,this.databaseAction(this.modelPath,t)]})})},t.prototype.load=function(){return n(this,void 0,void 0,function(){return r(this,function(t){return[2,this.databaseAction(this.modelPath)]})})},t.prototype.databaseAction=function(t,e){var n=this;return new Promise(function(t,r){var o=n.indexedDB.open(\"tensorflowjs\",1);o.onupgradeneeded=function(){return Rh(o)},o.onsuccess=function(){var a=o.result;if(null==e){var i=a.transaction(wh,\"readonly\"),s=i.objectStore(wh).get(n.modelPath);s.onsuccess=function(){if(null==s.result)return a.close(),r(new Error(\"Cannot find model with path '\"+n.modelPath+\"' in IndexedDB.\"));t(s.result.modelArtifacts)},s.onerror=function(t){return a.close(),r(s.error)},i.oncomplete=function(){return a.close()}}else{var u,l=vh(e),c=a.transaction(Ch,\"readwrite\"),h=c.objectStore(Ch),p=h.put({modelPath:n.modelPath,modelArtifactsInfo:l});p.onsuccess=function(){var o=(u=a.transaction(wh,\"readwrite\")).objectStore(wh).put({modelPath:n.modelPath,modelArtifacts:e,modelArtifactsInfo:l});o.onsuccess=function(){return t({modelArtifactsInfo:l})},o.onerror=function(t){var e=(h=c.objectStore(Ch)).delete(n.modelPath);e.onsuccess=function(){return a.close(),r(o.error)},e.onerror=function(t){return a.close(),r(o.error)}}},p.onerror=function(t){return a.close(),r(p.error)},c.oncomplete=function(){null==u?a.close():u.oncomplete=function(){return a.close()}}}},o.onerror=function(t){return r(o.error)}})},t.URL_SCHEME=\"indexeddb://\",t}(),kh=function(t){return i.getBool(\"IS_BROWSER\")&&!Array.isArray(t)&&t.startsWith(Ih.URL_SCHEME)?(e=t.slice(Ih.URL_SCHEME.length),new Ih(e)):null;var e};mh.registerSaveRouter(kh),mh.registerLoadRouter(kh);var Nh=function(){function t(){this.indexedDB=Eh()}return t.prototype.listModels=function(){return n(this,void 0,void 0,function(){var t=this;return r(this,function(e){return[2,new Promise(function(e,n){var r=t.indexedDB.open(\"tensorflowjs\",1);r.onupgradeneeded=function(){return Rh(r)},r.onsuccess=function(){var t=r.result,o=t.transaction(Ch,\"readonly\"),a=o.objectStore(Ch).getAll();a.onsuccess=function(){for(var t={},n=0,r=a.result;n<r.length;n++){var o=r[n];t[o.modelPath]=o.modelArtifactsInfo}e(t)},a.onerror=function(e){return t.close(),n(a.error)},o.oncomplete=function(){return t.close()}},r.onerror=function(t){return n(r.error)}})]})})},t.prototype.removeModel=function(t){return n(this,void 0,void 0,function(){var e=this;return r(this,function(n){var r;return t=(r=t).startsWith(Ih.URL_SCHEME)?r.slice(Ih.URL_SCHEME.length):r,[2,new Promise(function(n,r){var o=e.indexedDB.open(\"tensorflowjs\",1);o.onupgradeneeded=function(){return Rh(o)},o.onsuccess=function(){var e,a=o.result,i=a.transaction(Ch,\"readwrite\"),s=i.objectStore(Ch),u=s.get(t);u.onsuccess=function(){if(null==u.result)return a.close(),r(new Error(\"Cannot find model with path '\"+t+\"' in IndexedDB.\"));var o=s.delete(t),i=function(){var o=(e=a.transaction(wh,\"readwrite\")).objectStore(wh).delete(t);o.onsuccess=function(){return n(u.result.modelArtifactsInfo)},o.onerror=function(t){return r(u.error)}};o.onsuccess=i,o.onerror=function(t){return i(),a.close(),r(u.error)}},u.onerror=function(t){return a.close(),r(u.error)},i.oncomplete=function(){null==e?a.close():e.oncomplete=function(){return a.close()}}},o.onerror=function(t){return r(o.error)}})]})})},t}();if(i.getBool(\"IS_BROWSER\"))try{yh.registerManager(Ih.URL_SCHEME,new Nh)}catch(t){}var Sh=\"/\",Ah=\"tensorflowjs_models\",Th=\"info\",Dh=\"model_topology\",_h=\"weight_specs\",Oh=\"weight_data\",Fh=\"model_metadata\";function Mh(t){return{info:[Ah,t,Th].join(Sh),topology:[Ah,t,Dh].join(Sh),weightSpecs:[Ah,t,_h].join(Sh),weightData:[Ah,t,Oh].join(Sh),modelMetadata:[Ah,t,Fh].join(Sh)}}function Bh(t){var e=t.split(Sh);if(e.length<3)throw new Error(\"Invalid key format: \"+t);return e.slice(1,e.length-1).join(Sh)}var Ph=function(){function t(t){if(!i.getBool(\"IS_BROWSER\")||void 0===window.localStorage)throw new Error(\"The current environment does not support local storage.\");if(this.LS=window.localStorage,null==t||!t)throw new Error(\"For local storage, modelPath must not be null, undefined or empty.\");this.modelPath=t,this.keys=Mh(this.modelPath)}return t.prototype.save=function(t){return n(this,void 0,void 0,function(){var e,n,o;return r(this,function(r){if(t.modelTopology instanceof ArrayBuffer)throw new Error(\"BrowserLocalStorage.save() does not support saving model topology in binary formats yet.\");e=JSON.stringify(t.modelTopology),n=JSON.stringify(t.weightSpecs),o=vh(t);try{return this.LS.setItem(this.keys.info,JSON.stringify(o)),this.LS.setItem(this.keys.topology,e),this.LS.setItem(this.keys.weightSpecs,n),this.LS.setItem(this.keys.weightData,(a=t.weightData,hh?Buffer.from(a).toString(\"base64\"):btoa(String.fromCharCode.apply(null,new Uint8Array(a))))),this.LS.setItem(this.keys.modelMetadata,JSON.stringify({format:t.format,generatedBy:t.generatedBy,convertedBy:t.convertedBy})),[2,{modelArtifactsInfo:o}]}catch(t){throw this.LS.removeItem(this.keys.info),this.LS.removeItem(this.keys.topology),this.LS.removeItem(this.keys.weightSpecs),this.LS.removeItem(this.keys.weightData),this.LS.removeItem(this.keys.modelMetadata),new Error(\"Failed to save model '\"+this.modelPath+\"' to local storage: size quota being exceeded is a possible cause of this failure: modelTopologyBytes=\"+o.modelTopologyBytes+\", weightSpecsBytes=\"+o.weightSpecsBytes+\", weightDataBytes=\"+o.weightDataBytes+\".\")}var a;return[2]})})},t.prototype.load=function(){return n(this,void 0,void 0,function(){var t,e,n,o,a,i,s;return r(this,function(r){if(null==(t=JSON.parse(this.LS.getItem(this.keys.info))))throw new Error(\"In local storage, there is no model with name '\"+this.modelPath+\"'\");if(\"JSON\"!==t.modelTopologyType)throw new Error(\"BrowserLocalStorage does not support loading non-JSON model topology yet.\");if(e={},null==(n=JSON.parse(this.LS.getItem(this.keys.topology))))throw new Error(\"In local storage, the topology of model '\"+this.modelPath+\"' is missing.\");if(e.modelTopology=n,null==(o=JSON.parse(this.LS.getItem(this.keys.weightSpecs))))throw new Error(\"In local storage, the weight specs of model '\"+this.modelPath+\"' are missing.\");if(e.weightSpecs=o,null!=(a=this.LS.getItem(this.keys.modelMetadata))&&(i=JSON.parse(a),e.format=i.format,e.generatedBy=i.generatedBy,e.convertedBy=i.convertedBy),null==(s=this.LS.getItem(this.keys.weightData)))throw new Error(\"In local storage, the binary weight values of model '\"+this.modelPath+\"' are missing.\");return e.weightData=function(t){if(hh){var e=Buffer.from(t,\"base64\");return e.buffer.slice(e.byteOffset,e.byteOffset+e.byteLength)}for(var n=atob(t),r=new Uint8Array(n.length),o=0;o<n.length;++o)r.set([n.charCodeAt(o)],o);return r.buffer}(s),[2,e]})})},t.URL_SCHEME=\"localstorage://\",t}(),Lh=function(t){return i.getBool(\"IS_BROWSER\")&&!Array.isArray(t)&&t.startsWith(Ph.URL_SCHEME)?(e=t.slice(Ph.URL_SCHEME.length),new Ph(e)):null;var e};mh.registerSaveRouter(Lh),mh.registerLoadRouter(Lh);var Wh=function(){function t(){f(i.getBool(\"IS_BROWSER\"),function(){return\"Current environment is not a web browser\"}),f(void 0!==window.localStorage,function(){return\"Current browser does not appear to support localStorage\"}),this.LS=window.localStorage}return t.prototype.listModels=function(){return n(this,void 0,void 0,function(){var t,e,n,o,a,i;return r(this,function(r){for(t={},e=Ah+Sh,n=Sh+Th,o=0;o<this.LS.length;++o)(a=this.LS.key(o)).startsWith(e)&&a.endsWith(n)&&(i=Bh(a),t[i]=JSON.parse(this.LS.getItem(a)));return[2,t]})})},t.prototype.removeModel=function(t){return n(this,void 0,void 0,function(){var e,n;return r(this,function(r){var o;if(t=(o=t).startsWith(Ph.URL_SCHEME)?o.slice(Ph.URL_SCHEME.length):o,e=Mh(t),null==this.LS.getItem(e.info))throw new Error(\"Cannot find model at path '\"+t+\"'\");return n=JSON.parse(this.LS.getItem(e.info)),this.LS.removeItem(e.info),this.LS.removeItem(e.topology),this.LS.removeItem(e.weightSpecs),this.LS.removeItem(e.weightData),[2,n]})})},t}();if(i.getBool(\"IS_BROWSER\"))try{yh.registerManager(Ph.URL_SCHEME,new Wh)}catch(t){}var Uh=\"model\",Vh=\".json\",zh=\".weights.bin\";function Gh(t){return new Promise(function(t){return setTimeout(t)}).then(t)}var Hh=function(){function t(e){if(!i.getBool(\"IS_BROWSER\"))throw new Error(\"browserDownloads() cannot proceed because the current environment is not a browser.\");e.startsWith(t.URL_SCHEME)&&(e=e.slice(t.URL_SCHEME.length)),null!=e&&0!==e.length||(e=Uh),this.modelTopologyFileName=e+Vh,this.weightDataFileName=e+zh}return t.prototype.save=function(t){return n(this,void 0,void 0,function(){var e,n,o,a,i,s;return r(this,function(r){switch(r.label){case 0:if(\"undefined\"==typeof document)throw new Error(\"Browser downloads are not supported in this environment since `document` is not present\");if(e=window.URL.createObjectURL(new Blob([t.weightData],{type:\"application/octet-stream\"})),!(t.modelTopology instanceof ArrayBuffer))return[3,1];throw new Error(\"BrowserDownloads.save() does not support saving model topology in binary formats yet.\");case 1:return n=[{paths:[\"./\"+this.weightDataFileName],weights:t.weightSpecs}],o={modelTopology:t.modelTopology,format:t.format,generatedBy:t.generatedBy,convertedBy:t.convertedBy,weightsManifest:n},a=window.URL.createObjectURL(new Blob([JSON.stringify(o)],{type:\"application/json\"})),(i=null==this.jsonAnchor?document.createElement(\"a\"):this.jsonAnchor).download=this.modelTopologyFileName,i.href=a,[4,Gh(function(){return i.dispatchEvent(new MouseEvent(\"click\"))})];case 2:return r.sent(),null==t.weightData?[3,4]:((s=null==this.weightDataAnchor?document.createElement(\"a\"):this.weightDataAnchor).download=this.weightDataFileName,s.href=e,[4,Gh(function(){return s.dispatchEvent(new MouseEvent(\"click\"))})]);case 3:r.sent(),r.label=4;case 4:return[2,{modelArtifactsInfo:vh(t)}]}})})},t.URL_SCHEME=\"downloads://\",t}(),qh=function(){function t(t){if(null==t||t.length<1)throw new Error(\"When calling browserFiles, at least 1 file is required, but received \"+t);this.files=t}return t.prototype.load=function(){return n(this,void 0,void 0,function(){var t,e,n=this;return r(this,function(r){return t=this.files[0],e=this.files.slice(1),[2,new Promise(function(r,o){var a=new FileReader;a.onload=function(a){var i=JSON.parse(a.target.result),s=i.modelTopology;if(null!=s){0===e.length&&r({modelTopology:s});var u=i.weightsManifest;if(null!=u){var l;try{l=n.checkManifestAndWeightFiles(u,e)}catch(t){return void o(t)}var c=[],h=[],p=[];u.forEach(function(t){t.paths.forEach(function(t){h.push(t),p.push(null)}),c.push.apply(c,t.weights)}),u.forEach(function(t){t.paths.forEach(function(t){var e=new FileReader;e.onload=function(e){var n=e.target.result,o=h.indexOf(t);p[o]=n,-1===p.indexOf(null)&&r({modelTopology:s,weightSpecs:c,weightData:fh(p)})},e.onerror=function(e){return o(\"Failed to weights data from file of path '\"+t+\"'.\")},e.readAsArrayBuffer(l[t])})})}else o(new Error(\"weightManifest field is missing from file \"+t.name))}else o(new Error(\"modelTopology field is missing from file \"+t.name))},a.onerror=function(e){return o(\"Failed to read model topology and weights manifest JSON from file '\"+t.name+\"'. BrowserFiles supports loading Keras-style tf.Model artifacts only.\")},a.readAsText(t)})]})})},t.prototype.checkManifestAndWeightFiles=function(t,e){for(var n=[],r=e.map(function(t){return dh(t.name)}),o={},a=0,i=t;a<i.length;a++){i[a].paths.forEach(function(t){var a=dh(t);if(-1!==n.indexOf(a))throw new Error(\"Duplicate file basename found in weights manifest: '\"+a+\"'\");if(n.push(a),-1===r.indexOf(a))throw new Error(\"Weight file with basename '\"+a+\"' is not provided.\");o[t]=e[r.indexOf(a)]})}if(n.length!==e.length)throw new Error(\"Mismatch in the number of files in weights manifest (\"+n.length+\") and the number of weight files provided (\"+e.length+\").\");return o},t}();function $h(t,e,n,r){!function(t){f(null!=t&&Array.isArray(t)&&t.length>0,function(){return\"promises must be a none empty array\"})}(t),function(t,e){f(t>=0&&t<=1,function(){return\"Progress fraction must be in range [0, 1], but got startFraction \"+t}),f(e>=0&&e<=1,function(){return\"Progress fraction must be in range [0, 1], but got endFraction \"+e}),f(e>=t,function(){return\"startFraction must be no more than endFraction, but got startFraction \"+t+\" and endFraction \"+e})}(n=null==n?0:n,r=null==r?1:r);var o=0;return Promise.all(t.map(function(a){return a.then(function(a){var i=n+ ++o/t.length*(r-n);return e(i),a}),a}))}function Kh(t,e){return n(this,void 0,void 0,function(){var n,o,a,s,u,l,c,h,p;return r(this,function(r){switch(r.label){case 0:return null==e&&(e={}),n=null==e.fetchFunc?i.platform.fetch:e.fetchFunc,o=t.map(function(t){return n(t,e.requestInit,{isBinary:!0})}),a=0,s=.5,null!=e.onProgress?[3,2]:[4,Promise.all(o)];case 1:return u=r.sent(),[3,4];case 2:return[4,$h(o,e.onProgress,a,s)];case 3:u=r.sent(),r.label=4;case 4:return l=u.map(function(t){return t.arrayBuffer()}),c=.5,h=1,null!=e.onProgress?[3,6]:[4,Promise.all(l)];case 5:return p=r.sent(),[3,8];case 6:return[4,$h(l,e.onProgress,c,h)];case 7:p=r.sent(),r.label=8;case 8:return[2,p]}})})}function jh(t){var e=this;return function(o,a,i){return void 0===a&&(a=\"\"),n(e,void 0,void 0,function(){var e,n,s,u,l,c,h,p,f,d;return r(this,function(r){switch(r.label){case 0:if(e=o.map(function(){return!1}),n={},s=null!=i?i.map(function(){return!1}):[],u=[],o.forEach(function(t,r){var o=0;t.weights.forEach(function(t){var a=\"quantization\"in t?t.quantization.dtype:t.dtype,l=sh[a]*g(t.shape),c=function(){e[r]=!0,null==n[r]&&(n[r]=[]),n[r].push({manifestEntry:t,groupOffset:o,sizeBytes:l})};null!=i?i.forEach(function(e,n){e===t.name&&(c(),s[n]=!0)}):c(),u.push(t.name),o+=l})}),!s.every(function(t){return t}))throw l=i.filter(function(t,e){return!s[e]}),new Error(\"Could not find weights in manifest with names: \"+l.join(\", \")+\". \\nManifest JSON has weights with names: \"+u.join(\", \")+\".\");return c=e.reduce(function(t,e,n){return e&&t.push(n),t},[]),h=[],c.forEach(function(t){o[t].paths.forEach(function(t){var e=a+(a.endsWith(\"/\")?\"\":\"/\")+t;h.push(e)})}),[4,t(h)];case 1:return p=r.sent(),f={},d=0,c.forEach(function(t){for(var e=o[t].paths.length,r=0,a=0;a<e;a++)r+=p[d+a].byteLength;for(var i=new ArrayBuffer(r),s=new Uint8Array(i),u=0,l=0;l<e;l++){var c=new Uint8Array(p[d+l]);s.set(c,u),u+=c.byteLength}n[t].forEach(function(t){var e=lh(i.slice(t.groupOffset,t.groupOffset+t.sizeBytes),[t.manifestEntry]);for(var n in e)f[n]=e[n]}),d+=e}),[2,f]}})})}}mh.registerSaveRouter(function(t){return i.getBool(\"IS_BROWSER\")&&!Array.isArray(t)&&t.startsWith(Hh.URL_SCHEME)?(e=t.slice(Hh.URL_SCHEME.length),void 0===e&&(e=\"model\"),new Hh(e)):null;var e});var Xh=function(){function t(t,e){if(this.DEFAULT_METHOD=\"POST\",null==e&&(e={}),this.weightPathPrefix=e.weightPathPrefix,this.onProgress=e.onProgress,null!=e.fetchFunc?(f(\"function\"==typeof e.fetchFunc,function(){return\"Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)\"}),this.fetch=e.fetchFunc):this.fetch=i.platform.fetch,f(null!=t&&t.length>0,function(){return\"URL path for http must not be null, undefined or empty.\"}),Array.isArray(t)&&f(2===t.length,function(){return\"URL paths for http must have a length of 2, (actual length is \"+t.length+\").\"}),this.path=t,null!=e.requestInit&&null!=e.requestInit.body)throw new Error(\"requestInit is expected to have no pre-existing body, but has one.\");this.requestInit=e.requestInit||{}}return t.prototype.save=function(t){return n(this,void 0,void 0,function(){var e,n,o,a;return r(this,function(r){switch(r.label){case 0:if(t.modelTopology instanceof ArrayBuffer)throw new Error(\"BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.\");return(e=Object.assign({method:this.DEFAULT_METHOD},this.requestInit)).body=new FormData,n=[{paths:[\"./model.weights.bin\"],weights:t.weightSpecs}],o={modelTopology:t.modelTopology,format:t.format,generatedBy:t.generatedBy,convertedBy:t.convertedBy,weightsManifest:n},e.body.append(\"model.json\",new Blob([JSON.stringify(o)],{type:\"application/json\"}),\"model.json\"),null!=t.weightData&&e.body.append(\"model.weights.bin\",new Blob([t.weightData],{type:\"application/octet-stream\"}),\"model.weights.bin\"),[4,this.fetch(this.path,e)];case 1:if((a=r.sent()).ok)return[2,{modelArtifactsInfo:vh(t),responses:[a]}];throw new Error(\"BrowserHTTPRequest.save() failed due to HTTP response status \"+a.status+\".\")}})})},t.prototype.load=function(){return n(this,void 0,void 0,function(){var t,e,n,o,a,i,s,u;return r(this,function(r){switch(r.label){case 0:return[4,this.fetch(this.path,this.requestInit)];case 1:if(!(t=r.sent()).ok)throw new Error(\"Request to \"+this.path+\" failed with status code \"+t.status+\". Please verify this URL points to the model JSON of the model to load.\");r.label=2;case 2:return r.trys.push([2,4,,5]),[4,t.json()];case 3:return e=r.sent(),[3,5];case 4:throw r.sent(),n=\"Failed to parse model JSON of response from \"+this.path+\".\",this.path.endsWith(\".pb\")?n+=\" Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository.\":n+=\" Please make sure the server is serving valid JSON for this request.\",new Error(n);case 5:if(o=e.modelTopology,a=e.weightsManifest,null==o&&null==a)throw new Error(\"The JSON from HTTP path \"+this.path+\" contains neither model topology or manifest for weights.\");return null==a?[3,7]:[4,this.loadWeights(a)];case 6:u=r.sent(),i=u[0],s=u[1],r.label=7;case 7:return[2,{modelTopology:o,weightSpecs:i,weightData:s}]}})})},t.prototype.loadWeights=function(t){return n(this,void 0,void 0,function(){var e,n,o,a,i,s,u,l,c,h,p;return r(this,function(r){switch(r.label){case 0:for(e=Array.isArray(this.path)?this.path[1]:this.path,n=function(t){var e=t.lastIndexOf(\"/\"),n=t.lastIndexOf(\"?\"),r=t.substring(0,e),o=n>e?t.substring(n):\"\";return[r+\"/\",o]}(e),o=n[0],a=n[1],i=this.weightPathPrefix||o,s=[],u=0,l=t;u<l.length;u++)c=l[u],s.push.apply(s,c.weights);return h=[],t.forEach(function(t){t.paths.forEach(function(t){h.push(i+t+a)})}),[4,Kh(h,{requestInit:this.requestInit,fetchFunc:this.fetch,onProgress:this.onProgress})];case 1:return p=r.sent(),[2,[s,fh(p)]]}})})},t.URL_SCHEME_REGEX=/^https?:\\/\\//,t}();function Yh(t){return null!=t.match(Xh.URL_SCHEME_REGEX)}var Qh=function(t,e){if(\"undefined\"==typeof fetch)return null;return(Array.isArray(t)?t.every(function(t){return Yh(t)}):Yh(t))?Jh(t,{onProgress:e}):null};function Jh(t,e){return new Xh(t,e)}mh.registerSaveRouter(Qh),mh.registerLoadRouter(Qh);var Zh=function(){function t(t){this.modelArtifacts=t}return t.prototype.load=function(){return n(this,void 0,void 0,function(){return r(this,function(t){return[2,this.modelArtifacts]})})},t}(),tp=function(){function t(t){this.saveHandler=t}return t.prototype.save=function(t){return n(this,void 0,void 0,function(){return r(this,function(e){return[2,this.saveHandler(t)]})})},t}();var ep=Object.freeze({browserFiles:function(t){return new qh(t)},browserHTTPRequest:function(t,e){return Jh(t,e)},concatenateArrayBuffers:fh,decodeWeights:lh,encodeWeights:function(t,e){return n(this,void 0,void 0,function(){var o,a,i,s,u,l=this;return r(this,function(c){switch(c.label){case 0:for(o=[],a=[],i=Array.isArray(t)?t.map(function(t){return t.name}):Object.keys(t),s=function(s){var u=i[s],c=Array.isArray(t)?t[s].tensor:t[u];if(\"float32\"!==c.dtype&&\"int32\"!==c.dtype&&\"bool\"!==c.dtype&&\"string\"!==c.dtype)throw new Error(\"Unsupported dtype in weight '\"+u+\"': \"+c.dtype);var h={name:u,shape:c.shape,dtype:c.dtype};if(\"string\"===c.dtype){var p=new Promise(function(t){return n(l,void 0,void 0,function(){var e,n,o,a,i,s,u;return r(this,function(r){switch(r.label){case 0:return[4,c.bytes()];case 1:for(e=r.sent(),n=e.reduce(function(t,e){return t+e.length},0)+uh*e.length,o=new Uint8Array(n),a=0,i=0;i<e.length;i++)s=e[i],u=new Uint8Array(new Uint32Array([s.length]).buffer),o.set(u,a),a+=uh,o.set(s,a),a+=s.length;return t(o),[2]}})})});a.push(p)}else a.push(c.data());null!=e&&(h.group=e),o.push(h)},u=0;u<i.length;++u)s(u);return[4,Promise.all(a)];case 1:return[2,{data:ch(c.sent()),specs:o}]}})})},fromMemory:function(t,e,n,r){return 1===arguments.length?null!=t.modelTopology||null!=t.weightSpecs?new Zh(t):(console.warn(\"Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release.\"),new Zh({modelTopology:t})):(console.warn(\"Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release.\"),new Zh({modelTopology:t,weightSpecs:e,weightData:n,trainingConfig:r}))},getLoadHandlers:function(t,e){return mh.getLoadHandlers(t,e)},getModelArtifactsInfoForJSON:vh,getSaveHandlers:function(t){return mh.getSaveHandlers(t)},http:Jh,isHTTPScheme:Yh,loadWeights:function(t,e,o,a){return void 0===e&&(e=\"\"),n(this,void 0,void 0,function(){return r(this,function(n){return[2,jh(function(t){return Kh(t,{requestInit:a})})(t,e,o)]})})},registerLoadRouter:function(t){return mh.registerLoadRouter(t)},registerSaveRouter:function(t){return mh.registerSaveRouter(t)},weightsLoaderFactory:jh,withSaveHandler:function(t){return new tp(t)},copyModel:function(t,e){return n(this,void 0,void 0,function(){return r(this,function(n){return[2,bh(t,e,!1)]})})},listModels:function(){return n(this,void 0,void 0,function(){var t,e,n,o,a,i,s;return r(this,function(r){switch(r.label){case 0:t=yh.getSchemes(),e={},n=0,o=t,r.label=1;case 1:return n<o.length?(a=o[n],[4,yh.getManager(a).listModels()]):[3,4];case 2:for(s in i=r.sent())e[a+gh+s]=i[s];r.label=3;case 3:return n++,[3,1];case 4:return[2,e]}})})},moveModel:function(t,e){return n(this,void 0,void 0,function(){return r(this,function(n){return[2,bh(t,e,!0)]})})},removeModel:function(t){return n(this,void 0,void 0,function(){var e;return r(this,function(n){return e=xh(t),[2,yh.getManager(e.scheme).removeModel(e.path)]})})}});var np=vn({confusionMatrix_:function(t,e,n){var r=nn(t,\"labels\",\"confusionMatrix\"),o=nn(e,\"predictions\",\"confusionMatrix\");f(null==n||n>0&&Number.isInteger(n),function(){return\"If provided, numClasses must be a positive integer, but got \"+n}),f(1===r.rank,function(){return\"Expected the rank of labels to be 1, but got \"+r.rank}),f(1===o.rank,function(){return\"Expected the rank of predictions to be 1, but got \"+o.rank}),f(r.shape[0]===o.shape[0],function(){return\"Mismatch in the number of examples: \"+r.shape[0]+\" vs. \"+o.shape[0]+\". Labels and predictions should have the same number of elements.\"}),f(n>0&&Number.isInteger(n),function(){return\"numClasses is required to be a positive integer, but got \"+n});var a=lr(r.asType(\"int32\"),n),i=lr(o.asType(\"int32\"),n);return a.transpose().matMul(i).asType(\"int32\")}}),rp=Object.freeze({confusionMatrix:np});var op=vn({fromPixels_:function(t,e){if(void 0===e&&(e=3),e>4)throw new Error(\"Cannot construct Tensor with more than 4 channels from pixels.\");var n=\"undefined\"!=typeof HTMLVideoElement&&t instanceof HTMLVideoElement;if(n&&n&&t.readyState<2)throw new Error(\"The video element has not loaded data yet. Please wait for `loadeddata` event on the <video> element.\");return St.fromPixels(t,e)}}),ap=Object.freeze({toPixels:function(t,e){return n(this,void 0,void 0,function(){var n,o,a,i,s,u,l,c,h,p,f,d,v,m,g,y,x,b,w,C,E,R,I;return r(this,function(r){switch(r.label){case 0:if(n=nn(t,\"img\",\"toPixels\"),t instanceof ct||(n=n.toInt()),2!==n.rank&&3!==n.rank)throw new Error(\"toPixels only supports rank 2 or 3 tensors, got rank \"+n.rank+\".\");if(o=n.shape.slice(0,2),a=o[0],i=o[1],(s=2===n.rank?1:n.shape[2])>4||2===s)throw new Error(\"toPixels only supports depth of size 1, 3 or 4 but got \"+s);return[4,n.data()];case 1:return u=r.sent(),l=n.min(),c=n.max(),[4,Promise.all([l.data(),c.data()])];case 2:if(h=r.sent(),p=h[0],f=h[1],d=p[0],v=f[0],l.dispose(),c.dispose(),\"float32\"===n.dtype){if(d<0||v>1)throw new Error(\"Tensor values for a float32 Tensor must be in the range [0 - 1] but got range [\"+d+\" - \"+v+\"].\")}else{if(\"int32\"!==n.dtype)throw new Error(\"Unsupported type for toPixels: \"+n.dtype+\". Please use float32 or int32 tensors.\");if(d<0||v>255)throw new Error(\"Tensor values for a int32 Tensor must be in the range [0 - 255] but got range [\"+d+\" - \"+v+\"].\")}for(m=\"float32\"===n.dtype?255:1,g=new Uint8ClampedArray(i*a*4),y=0;y<a*i;++y)x=void 0,b=void 0,w=void 0,C=void 0,1===s?(x=u[y]*m,b=u[y]*m,w=u[y]*m,C=255):3===s?(x=u[3*y]*m,b=u[3*y+1]*m,w=u[3*y+2]*m,C=255):4===s&&(x=u[4*y]*m,b=u[4*y+1]*m,w=u[4*y+2]*m,C=u[4*y+3]*m),g[0+(E=4*y)]=Math.round(x),g[E+1]=Math.round(b),g[E+2]=Math.round(w),g[E+3]=Math.round(C);return null!=e&&(e.width=i,e.height=a,R=e.getContext(\"2d\"),I=new ImageData(g,i,a),R.putImageData(I,0,0)),n!==t&&n.dispose(),[2,g]}})})},fromPixels:op}),ip=function(){function t(){}return t.prototype.getClassName=function(){return this.constructor.className},t.fromConfig=function(t,e){return new t(e)},t}(),sp=function(){function t(){this.classNameMap={}}return t.getMap=function(){return null==t.instance&&(t.instance=new t),t.instance},t.register=function(e){t.getMap().classNameMap[e.className]=[e,e.fromConfig]},t}();function up(t){f(null!=t.className,function(){return\"Class being registered does not have the static className property defined.\"}),f(\"string\"==typeof t.className,function(){return\"className is required to be a string, but got type \"+typeof t.className}),f(t.className.length>0,function(){return\"Class being registered has an empty-string as its className, which is disallowed.\"}),sp.register(t)}var lp=Object.freeze({Serializable:ip,SerializationMap:sp,registerClass:up}),cp=.001,hp=.1;function pp(){return 32===St.backend.floatPrecision()?cp:hp}function fp(t,e,n){var r=!0;if((_(t)||_(e))&&(r=!1),_(t)&&_(e)&&(r=!0),r){var o=t.constructor.name,a=e.constructor.name;if(o!==a)throw new Error(\"Arrays are of different type. Actual: \"+o+\". Expected: \"+a)}if(Array.isArray(t)&&Array.isArray(e)){var i=tn(t),s=tn(e);if(!y(i,s))throw new Error(\"Arrays have different shapes. Actual: [\"+i+\"]. Expected: [\"+s+\"]\")}var u=_(t)?t:m(t),l=_(e)?e:m(e);if(u.length!==l.length)throw new Error(\"Arrays have different lengths actual: \"+u.length+\" vs expected: \"+l.length+\".\\nActual:   \"+u+\".\\nExpected: \"+l+\".\");for(var c=0;c<l.length;++c){var h=u[c],p=l[c];if(!n(h,p))throw new Error(\"Arrays differ: actual[\"+c+\"] = \"+h+\", expected[\"+c+\"] = \"+p+\".\\nActual:   \"+u+\".\\nExpected: \"+l+\".\")}}function dp(t,e,n){return!isFinite(t)&&!isFinite(e)||!(isNaN(t)||isNaN(e)||Math.abs(t-e)>n)}var vp=Object.freeze({TEST_EPSILON_FLOAT16:hp,expectArraysClose:function(t,e,n){return null==n&&(n=pp()),fp(t,e,function(t,e){return dp(t,e,n)})},testEpsilon:pp,expectPromiseToFail:function(t,e){t().then(function(){return e.fail()},function(){return e()})},expectArraysEqual:function(t,e){var n=\"string\"==typeof e||\"number\"==typeof e||\"boolean\"==typeof e?[e]:e;return M(t)||M(t[0])||M(e)||M(e[0])?fp(t,n,function(t,e){return t==e}):fp(t,e,function(t,e){return dp(t,e,0)})},expectNumbersClose:function(t,e,n){if(null==n&&(n=pp()),!dp(t,e,n))throw new Error(\"Numbers differ: actual === \"+t+\", expected === \"+e)},expectValuesInRange:function(t,e,n){for(var r=0;r<t.length;r++)if(t[r]<e||t[r]>n)throw new Error(\"Value out of range:\"+t[r]+\" low: \"+e+\", high: \"+n)},expectArrayBuffersEqual:function(t,e){expect(new Float32Array(t)).toEqual(new Float32Array(e))}}),mp=\"1.2.9\";var gp=Object.freeze({gpgpu_util:li,webgl_util:_e,forceHalfFloat:function(){i.set(\"WEBGL_FORCE_F16_TEXTURES\",!0)},MathBackendWebGL:Cs,setWebGLContext:Ft,GPGPUContext:ci}),yp=function(t){function o(){return null!==t&&t.apply(this,arguments)||this}return e(o,t),o.prototype.minimize=function(t,e,n){void 0===e&&(e=!1);var r=this.computeGradients(t,n),o=r.value,a=r.grads;if(null!=n){var i=n.map(function(t){return{name:t.name,tensor:a[t.name]}});this.applyGradients(i)}else this.applyGradients(a);return Ve(a),e?o:(o.dispose(),null)},Object.defineProperty(o.prototype,\"iterations\",{get:function(){return null==this.iterations_&&(this.iterations_=0),this.iterations_},enumerable:!0,configurable:!0}),o.prototype.incrementIterations=function(){this.iterations_=this.iterations+1},o.prototype.computeGradients=function(t,e){return Kr(t,e)},o.prototype.dispose=function(){null!=this.iterations_&&Ve(this.iterations_)},o.prototype.saveIterations=function(){return n(this,void 0,void 0,function(){return r(this,function(t){return null==this.iterations_&&(this.iterations_=0),[2,{name:\"iter\",tensor:wn(this.iterations_,\"int32\")}]})})},o.prototype.getWeights=function(){return n(this,void 0,void 0,function(){return r(this,function(t){throw new Error(\"getWeights() is not implemented for this optimizer yet.\")})})},o.prototype.setWeights=function(t){return n(this,void 0,void 0,function(){return r(this,function(t){throw new Error(\"setWeights() is not implemented for this optimizer class \"+this.getClassName())})})},o.prototype.extractIterations=function(t){return n(this,void 0,void 0,function(){var e;return r(this,function(n){switch(n.label){case 0:return e=this,[4,t[0].tensor.data()];case 1:return e.iterations_=n.sent()[0],[2,t.slice(1)]}})})},o}(ip);Object.defineProperty(yp,Symbol.hasInstance,{value:function(t){return null!=t.minimize&&null!=t.computeGradients&&null!=t.applyGradients}});var xp=function(t){function o(e,n,r){void 0===r&&(r=null);var o=t.call(this)||this;return o.learningRate=e,o.rho=n,o.epsilon=r,o.accumulatedGrads=[],o.accumulatedUpdates=[],null==r&&(o.epsilon=St.backend.epsilon()),o}return e(o,t),o.prototype.applyGradients=function(t){var e=this;(Array.isArray(t)?t.map(function(t){return t.name}):Object.keys(t)).forEach(function(n,r){var o=St.registeredVariables[n];null==e.accumulatedGrads[r]&&(e.accumulatedGrads[r]={originalName:n+\"/accum_grad\",variable:Ue(function(){return Fn(o).variable(!1)})}),null==e.accumulatedUpdates[r]&&(e.accumulatedUpdates[r]={originalName:n+\"/accum_var\",variable:Ue(function(){return Fn(o).variable(!1)})});var a=Array.isArray(t)?t[r].tensor:t[n];if(null!=a){var i=e.accumulatedGrads[r].variable,s=e.accumulatedUpdates[r].variable;Ue(function(){var t=i.mul(e.rho).add(a.square().mul(1-e.rho)),n=s.add(e.epsilon).sqrt().div(i.add(e.epsilon).sqrt()).mul(a),r=s.mul(e.rho).add(n.square().mul(1-e.rho));i.assign(t),s.assign(r);var u=n.mul(-e.learningRate).add(o);o.assign(u)})}}),this.incrementIterations()},o.prototype.dispose=function(){null!=this.accumulatedUpdates&&(Ve(this.accumulatedGrads.map(function(t){return t.variable})),Ve(this.accumulatedUpdates.map(function(t){return t.variable})))},o.prototype.getWeights=function(){return n(this,void 0,void 0,function(){var t;return r(this,function(e){switch(e.label){case 0:return t=this.accumulatedGrads.concat(this.accumulatedUpdates),[4,this.saveIterations()];case 1:return[2,[e.sent()].concat(t.map(function(t){return{name:t.originalName,tensor:t.variable}}))]}})})},o.prototype.setWeights=function(t){return n(this,void 0,void 0,function(){var e;return r(this,function(n){switch(n.label){case 0:return[4,this.extractIterations(t)];case 1:return t=n.sent(),e=t.length/2,!1,this.accumulatedGrads=t.slice(0,e).map(function(t){return{originalName:t.name,variable:t.tensor.variable(!1)}}),this.accumulatedUpdates=t.slice(e,2*e).map(function(t){return{originalName:t.name,variable:t.tensor.variable(!1)}}),[2]}})})},o.prototype.getConfig=function(){return{learningRate:this.learningRate,rho:this.rho,epsilon:this.epsilon}},o.fromConfig=function(t,e){return new t(e.learningRate,e.rho,e.epsilon)},o.className=\"Adadelta\",o}(yp);up(xp);var bp=function(t){function o(e,n){void 0===n&&(n=.1);var r=t.call(this)||this;return r.learningRate=e,r.initialAccumulatorValue=n,r.accumulatedGrads=[],r}return e(o,t),o.prototype.applyGradients=function(t){var e=this;(Array.isArray(t)?t.map(function(t){return t.name}):Object.keys(t)).forEach(function(n,r){var o=St.registeredVariables[n];if(null==e.accumulatedGrads[r]){e.accumulatedGrads[r]={originalName:n+\"/accumulator\",variable:Ue(function(){return Tn(o.shape,e.initialAccumulatorValue).variable(!1)})}}var a=Array.isArray(t)?t[r].tensor:t[n];if(null!=a){var i=e.accumulatedGrads[r].variable;Ue(function(){var t=i.add(a.square());i.assign(t);var n=a.div(t.add(St.backend.epsilon()).sqrt()).mul(-e.learningRate).add(o);o.assign(n)})}}),this.incrementIterations()},o.prototype.dispose=function(){null!=this.accumulatedGrads&&Ve(this.accumulatedGrads.map(function(t){return t.variable}))},o.prototype.getWeights=function(){return n(this,void 0,void 0,function(){return r(this,function(t){switch(t.label){case 0:return[4,this.saveIterations()];case 1:return[2,[t.sent()].concat(this.accumulatedGrads.map(function(t){return{name:t.originalName,tensor:t.variable}}))]}})})},o.prototype.setWeights=function(t){return n(this,void 0,void 0,function(){return r(this,function(e){switch(e.label){case 0:return[4,this.extractIterations(t)];case 1:return t=e.sent(),!1,this.accumulatedGrads=t.map(function(t){return{originalName:t.name,variable:t.tensor.variable(!1)}}),[2]}})})},o.prototype.getConfig=function(){return{learningRate:this.learningRate,initialAccumulatorValue:this.initialAccumulatorValue}},o.fromConfig=function(t,e){return new t(e.learningRate,e.initialAccumulatorValue)},o.className=\"Adagrad\",o}(yp);up(bp);var wp=function(t){function o(e,n,r,o){void 0===o&&(o=null);var a=t.call(this)||this;return a.learningRate=e,a.beta1=n,a.beta2=r,a.epsilon=o,a.accumulatedFirstMoment=[],a.accumulatedSecondMoment=[],Ue(function(){a.accBeta1=wn(n).variable(),a.accBeta2=wn(r).variable()}),null==o&&(a.epsilon=St.backend.epsilon()),a}return e(o,t),o.prototype.applyGradients=function(t){var e=this,n=Array.isArray(t)?t.map(function(t){return t.name}):Object.keys(t);Ue(function(){var r=Gu(1,e.accBeta1),o=Gu(1,e.accBeta2);n.forEach(function(n,a){var i=St.registeredVariables[n];null==e.accumulatedFirstMoment[a]&&(e.accumulatedFirstMoment[a]={originalName:n+\"/m\",variable:Ue(function(){return Fn(i).variable(!1)})}),null==e.accumulatedSecondMoment[a]&&(e.accumulatedSecondMoment[a]={originalName:n+\"/v\",variable:Ue(function(){return Fn(i).variable(!1)})});var s=Array.isArray(t)?t[a].tensor:t[n];if(null!=s){var u=e.accumulatedFirstMoment[a].variable,l=e.accumulatedSecondMoment[a].variable,c=u.mul(e.beta1).add(s.mul(1-e.beta1)),h=l.mul(e.beta2).add(s.square().mul(1-e.beta2)),p=c.div(r),f=h.div(o);u.assign(c),l.assign(h);var d=p.div(f.sqrt().add(e.epsilon)).mul(-e.learningRate).add(i);i.assign(d)}}),e.accBeta1.assign(e.accBeta1.mul(e.beta1)),e.accBeta2.assign(e.accBeta2.mul(e.beta2))}),this.incrementIterations()},o.prototype.dispose=function(){this.accBeta1.dispose(),this.accBeta2.dispose(),null!=this.accumulatedFirstMoment&&Ve(this.accumulatedFirstMoment.map(function(t){return t.variable})),null!=this.accumulatedSecondMoment&&Ve(this.accumulatedSecondMoment.map(function(t){return t.variable}))},o.prototype.getWeights=function(){return n(this,void 0,void 0,function(){var t;return r(this,function(e){switch(e.label){case 0:return t=this.accumulatedFirstMoment.concat(this.accumulatedSecondMoment),[4,this.saveIterations()];case 1:return[2,[e.sent()].concat(t.map(function(t){return{name:t.originalName,tensor:t.variable}}))]}})})},o.prototype.setWeights=function(t){return n(this,void 0,void 0,function(){var e,n=this;return r(this,function(r){switch(r.label){case 0:return[4,this.extractIterations(t)];case 1:return t=r.sent(),Ue(function(){n.accBeta1.assign(Wu(n.beta1,n.iterations_+1)),n.accBeta2.assign(Wu(n.beta2,n.iterations_+1))}),e=t.length/2,!1,this.accumulatedFirstMoment=t.slice(0,e).map(function(t){return{originalName:t.name,variable:t.tensor.variable(!1)}}),this.accumulatedSecondMoment=t.slice(e,2*e).map(function(t){return{originalName:t.name,variable:t.tensor.variable(!1)}}),[2]}})})},o.prototype.getConfig=function(){return{learningRate:this.learningRate,beta1:this.beta1,beta2:this.beta2,epsilon:this.epsilon}},o.fromConfig=function(t,e){return new t(e.learningRate,e.beta1,e.beta2,e.epsilon)},o.className=\"Adam\",o}(yp);up(wp);var Cp=function(t){function o(e,n,r,o,a){void 0===o&&(o=null),void 0===a&&(a=0);var i=t.call(this)||this;return i.learningRate=e,i.beta1=n,i.beta2=r,i.epsilon=o,i.decay=a,i.accumulatedFirstMoment=[],i.accumulatedWeightedInfNorm=[],Ue(function(){i.iteration=wn(0).variable(),i.accBeta1=wn(n).variable()}),null==o&&(i.epsilon=St.backend.epsilon()),i}return e(o,t),o.prototype.applyGradients=function(t){var e=this,n=Array.isArray(t)?t.map(function(t){return t.name}):Object.keys(t);Ue(function(){var r=Gu(1,e.accBeta1),o=Su(-e.learningRate,e.iteration.mul(e.decay).add(1));n.forEach(function(n,a){var i=St.registeredVariables[n];null==e.accumulatedFirstMoment[a]&&(e.accumulatedFirstMoment[a]={originalName:n+\"/m\",variable:Fn(i).variable(!1)}),null==e.accumulatedWeightedInfNorm[a]&&(e.accumulatedWeightedInfNorm[a]={originalName:n+\"/v\",variable:Fn(i).variable(!1)});var s=Array.isArray(t)?t[a].tensor:t[n];if(null!=s){var u=e.accumulatedFirstMoment[a].variable,l=e.accumulatedWeightedInfNorm[a].variable,c=u.mul(e.beta1).add(s.mul(1-e.beta1)),h=l.mul(e.beta2),p=s.abs(),f=h.maximum(p);u.assign(c),l.assign(f);var d=o.div(r).mul(c.div(f.add(e.epsilon))).add(i);i.assign(d)}}),e.iteration.assign(e.iteration.add(1)),e.accBeta1.assign(e.accBeta1.mul(e.beta1))}),this.incrementIterations()},o.prototype.dispose=function(){this.accBeta1.dispose(),this.iteration.dispose(),null!=this.accumulatedFirstMoment&&Ve(this.accumulatedFirstMoment.map(function(t){return t.variable})),null!=this.accumulatedWeightedInfNorm&&Ve(this.accumulatedWeightedInfNorm.map(function(t){return t.variable}))},o.prototype.getWeights=function(){return n(this,void 0,void 0,function(){return r(this,function(t){throw new Error(\"getWeights() is not implemented for Adamax yet.\")})})},o.prototype.setWeights=function(t){return n(this,void 0,void 0,function(){return r(this,function(t){throw new Error(\"setWeights() is not implemented for Adamax yet.\")})})},o.prototype.getConfig=function(){return{learningRate:this.learningRate,beta1:this.beta1,beta2:this.beta2,epsilon:this.epsilon,decay:this.decay}},o.fromConfig=function(t,e){return new t(e.learningRate,e.beta1,e.beta2,e.epsilon,e.decay)},o.className=\"Adamax\",o}(yp);up(Cp);var Ep=function(t){function o(e){var n=t.call(this)||this;return n.learningRate=e,n.setLearningRate(e),n}return e(o,t),o.prototype.applyGradients=function(t){var e=this;(Array.isArray(t)?t.map(function(t){return t.name}):Object.keys(t)).forEach(function(n,r){var o=Array.isArray(t)?t[r].tensor:t[n];if(null!=o){var a=St.registeredVariables[n];Ue(function(){var t=e.c.mul(o).add(a);a.assign(t)})}}),this.incrementIterations()},o.prototype.setLearningRate=function(t){this.learningRate=t,null!=this.c&&this.c.dispose(),this.c=ze(wn(-t))},o.prototype.dispose=function(){this.c.dispose()},o.prototype.getWeights=function(){return n(this,void 0,void 0,function(){return r(this,function(t){switch(t.label){case 0:return[4,this.saveIterations()];case 1:return[2,[t.sent()]]}})})},o.prototype.setWeights=function(t){return n(this,void 0,void 0,function(){return r(this,function(e){switch(e.label){case 0:return[4,this.extractIterations(t)];case 1:if(0!==(t=e.sent()).length)throw new Error(\"SGD optimizer does not have settable weights.\");return[2]}})})},o.prototype.getConfig=function(){return{learningRate:this.learningRate}},o.fromConfig=function(t,e){return new t(e.learningRate)},o.className=\"SGD\",o}(yp);up(Ep);var Rp=function(t){function o(e,n,r){void 0===r&&(r=!1);var o=t.call(this,e)||this;return o.learningRate=e,o.momentum=n,o.useNesterov=r,o.accumulations=[],o.m=wn(o.momentum),o}return e(o,t),o.prototype.applyGradients=function(t){var e=this;(Array.isArray(t)?t.map(function(t){return t.name}):Object.keys(t)).forEach(function(n,r){var o=St.registeredVariables[n];if(null==e.accumulations[r]){e.accumulations[r]={originalName:n+\"/momentum\",variable:Ue(function(){return Fn(o).variable(!1)})}}var a=e.accumulations[r].variable,i=Array.isArray(t)?t[r].tensor:t[n];null!=i&&Ue(function(){var t,n=e.m.mul(a).add(i);t=e.useNesterov?e.c.mul(i.add(n.mul(e.m))).add(o):e.c.mul(n).add(o),a.assign(n),o.assign(t)})}),this.incrementIterations()},o.prototype.dispose=function(){this.m.dispose(),null!=this.accumulations&&Ve(this.accumulations.map(function(t){return t.variable}))},o.prototype.setMomentum=function(t){this.momentum=t},o.prototype.getWeights=function(){return n(this,void 0,void 0,function(){return r(this,function(t){switch(t.label){case 0:return[4,this.saveIterations()];case 1:return[2,[t.sent()].concat(this.accumulations.map(function(t){return{name:t.originalName,tensor:t.variable}}))]}})})},o.prototype.setWeights=function(t){return n(this,void 0,void 0,function(){return r(this,function(e){switch(e.label){case 0:return[4,this.extractIterations(t)];case 1:return t=e.sent(),!1,this.accumulations=t.map(function(t){return{originalName:t.name,variable:t.tensor.variable(!1)}}),[2]}})})},o.prototype.getConfig=function(){return{learningRate:this.learningRate,momentum:this.momentum,useNesterov:this.useNesterov}},o.fromConfig=function(t,e){return new t(e.learningRate,e.momentum,e.useNesterov)},o.className=\"Momentum\",o}(Ep);up(Rp);var Ip=function(t){function o(e,n,r,o,a){void 0===n&&(n=.9),void 0===r&&(r=0),void 0===o&&(o=null),void 0===a&&(a=!1);var i=t.call(this)||this;return i.learningRate=e,i.decay=n,i.momentum=r,i.epsilon=o,i.accumulatedMeanSquares=[],i.accumulatedMoments=[],i.accumulatedMeanGrads=[],i.centered=a,null==o&&(i.epsilon=St.backend.epsilon()),i}return e(o,t),o.prototype.applyGradients=function(t){var e=this;(Array.isArray(t)?t.map(function(t){return t.name}):Object.keys(t)).forEach(function(n,r){var o=St.registeredVariables[n];null==e.accumulatedMeanSquares[r]&&(e.accumulatedMeanSquares[r]={originalName:n+\"/rms\",variable:Ue(function(){return Fn(o).variable(!1)})}),null==e.accumulatedMoments[r]&&(e.accumulatedMoments[r]={originalName:n+\"/momentum\",variable:Ue(function(){return Fn(o).variable(!1)})}),null==e.accumulatedMeanGrads[r]&&e.centered&&(e.accumulatedMeanGrads[r]={originalName:n+\"/mg\",variable:Ue(function(){return Fn(o).variable(!1)})});var a=Array.isArray(t)?t[r].tensor:t[n];if(null!=a){var i=e.accumulatedMeanSquares[r].variable,s=e.accumulatedMoments[r].variable;Ue(function(){var t=i.mul(e.decay).add(a.square().mul(1-e.decay));if(e.centered){var n=e.accumulatedMeanGrads[r].variable,u=n.mul(e.decay).add(a.mul(1-e.decay)),l=s.mul(e.momentum).add(a.mul(e.learningRate).div(t.sub(u.square().add(e.epsilon)).sqrt()));i.assign(t),n.assign(u),s.assign(l);var c=o.sub(l);o.assign(c)}else{var h=i.mul(e.decay).add(a.square().mul(1-e.decay));l=s.mul(e.momentum).add(a.mul(e.learningRate).div(h.add(e.epsilon).sqrt()));i.assign(h),s.assign(l);c=o.sub(l);o.assign(c)}})}}),this.incrementIterations()},o.prototype.dispose=function(){null!=this.accumulatedMeanSquares&&Ve(this.accumulatedMeanSquares.map(function(t){return t.variable})),null!=this.accumulatedMeanGrads&&this.centered&&Ve(this.accumulatedMeanGrads.map(function(t){return t.variable})),null!=this.accumulatedMoments&&Ve(this.accumulatedMoments.map(function(t){return t.variable}))},o.prototype.getWeights=function(){return n(this,void 0,void 0,function(){var t;return r(this,function(e){switch(e.label){case 0:return t=this.accumulatedMeanSquares.concat(this.accumulatedMoments),this.centered&&t.push.apply(t,this.accumulatedMeanGrads),[4,this.saveIterations()];case 1:return[2,[e.sent()].concat(t.map(function(t){return{name:t.originalName,tensor:t.variable}}))]}})})},o.prototype.setWeights=function(t){return n(this,void 0,void 0,function(){var e;return r(this,function(n){switch(n.label){case 0:return[4,this.extractIterations(t)];case 1:return t=n.sent(),e=this.centered?t.length/3:t.length/2,!1,this.accumulatedMeanSquares=t.slice(0,e).map(function(t){return{originalName:t.name,variable:t.tensor.variable(!1)}}),this.accumulatedMoments=t.slice(e,2*e).map(function(t){return{originalName:t.name,variable:t.tensor.variable(!1)}}),this.centered&&(this.accumulatedMeanGrads=t.slice(2*e,3*e).map(function(t){return{originalName:t.name,variable:t.tensor.variable(!1)}})),[2]}})})},o.prototype.getConfig=function(){return{learningRate:this.learningRate,decay:this.decay,momentum:this.momentum,epsilon:this.epsilon,centered:this.centered}},o.fromConfig=function(t,e){return new t(e.learningRate,e.decay,e.momentum,e.epsilon,e.centered)},o.className=\"RMSProp\",o}(yp);up(Ip);var kp=function(){function t(){}return t.sgd=function(t){return new Ep(t)},t.momentum=function(t,e,n){return void 0===n&&(n=!1),new Rp(t,e,n)},t.rmsprop=function(t,e,n,r,o){return void 0===e&&(e=.9),void 0===n&&(n=0),void 0===r&&(r=null),void 0===o&&(o=!1),new Ip(t,e,n,r,o)},t.adam=function(t,e,n,r){return void 0===t&&(t=.001),void 0===e&&(e=.9),void 0===n&&(n=.999),void 0===r&&(r=null),new wp(t,e,n,r)},t.adadelta=function(t,e,n){return void 0===t&&(t=.001),void 0===e&&(e=.95),void 0===n&&(n=null),new xp(t,e,n)},t.adamax=function(t,e,n,r,o){return void 0===t&&(t=.002),void 0===e&&(e=.9),void 0===n&&(n=.999),void 0===r&&(r=null),void 0===o&&(o=0),new Cp(t,e,n,r,o)},t.adagrad=function(t,e){return void 0===e&&(e=.1),new bp(t,e)},t}(),Np={sgd:kp.sgd,momentum:kp.momentum,adadelta:kp.adadelta,adagrad:kp.adagrad,rmsprop:kp.rmsprop,adamax:kp.adamax,adam:kp.adam},Sp=\"undefined\"!=typeof requestAnimationFrame?requestAnimationFrame:\"undefined\"!=typeof setImmediate?setImmediate:function(t){return t()};function Ap(){return new Promise(function(t){return Sp(function(){return t()})})}ut=th;\n//# sourceMappingURL=tf-core.esm.js.map\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\"), __webpack_require__(/*! ./../../../process/browser.js */ \"./node_modules/process/browser.js\"), __webpack_require__(/*! ./../../../buffer/index.js */ \"./node_modules/buffer/index.js\").Buffer, __webpack_require__(/*! ./../../../timers-browserify/main.js */ \"./node_modules/timers-browserify/main.js\").setImmediate))\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js?");

/***/ }),

/***/ "./node_modules/base64-js/index.js":
/*!*****************************************!*\
  !*** ./node_modules/base64-js/index.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nexports.byteLength = byteLength\nexports.toByteArray = toByteArray\nexports.fromByteArray = fromByteArray\n\nvar lookup = []\nvar revLookup = []\nvar Arr = typeof Uint8Array !== 'undefined' ? Uint8Array : Array\n\nvar code = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'\nfor (var i = 0, len = code.length; i < len; ++i) {\n  lookup[i] = code[i]\n  revLookup[code.charCodeAt(i)] = i\n}\n\n// Support decoding URL-safe base64 strings, as Node.js does.\n// See: https://en.wikipedia.org/wiki/Base64#URL_applications\nrevLookup['-'.charCodeAt(0)] = 62\nrevLookup['_'.charCodeAt(0)] = 63\n\nfunction getLens (b64) {\n  var len = b64.length\n\n  if (len % 4 > 0) {\n    throw new Error('Invalid string. Length must be a multiple of 4')\n  }\n\n  // Trim off extra bytes after placeholder bytes are found\n  // See: https://github.com/beatgammit/base64-js/issues/42\n  var validLen = b64.indexOf('=')\n  if (validLen === -1) validLen = len\n\n  var placeHoldersLen = validLen === len\n    ? 0\n    : 4 - (validLen % 4)\n\n  return [validLen, placeHoldersLen]\n}\n\n// base64 is 4/3 + up to two characters of the original data\nfunction byteLength (b64) {\n  var lens = getLens(b64)\n  var validLen = lens[0]\n  var placeHoldersLen = lens[1]\n  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen\n}\n\nfunction _byteLength (b64, validLen, placeHoldersLen) {\n  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen\n}\n\nfunction toByteArray (b64) {\n  var tmp\n  var lens = getLens(b64)\n  var validLen = lens[0]\n  var placeHoldersLen = lens[1]\n\n  var arr = new Arr(_byteLength(b64, validLen, placeHoldersLen))\n\n  var curByte = 0\n\n  // if there are placeholders, only get up to the last complete 4 chars\n  var len = placeHoldersLen > 0\n    ? validLen - 4\n    : validLen\n\n  for (var i = 0; i < len; i += 4) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 18) |\n      (revLookup[b64.charCodeAt(i + 1)] << 12) |\n      (revLookup[b64.charCodeAt(i + 2)] << 6) |\n      revLookup[b64.charCodeAt(i + 3)]\n    arr[curByte++] = (tmp >> 16) & 0xFF\n    arr[curByte++] = (tmp >> 8) & 0xFF\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  if (placeHoldersLen === 2) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 2) |\n      (revLookup[b64.charCodeAt(i + 1)] >> 4)\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  if (placeHoldersLen === 1) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 10) |\n      (revLookup[b64.charCodeAt(i + 1)] << 4) |\n      (revLookup[b64.charCodeAt(i + 2)] >> 2)\n    arr[curByte++] = (tmp >> 8) & 0xFF\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  return arr\n}\n\nfunction tripletToBase64 (num) {\n  return lookup[num >> 18 & 0x3F] +\n    lookup[num >> 12 & 0x3F] +\n    lookup[num >> 6 & 0x3F] +\n    lookup[num & 0x3F]\n}\n\nfunction encodeChunk (uint8, start, end) {\n  var tmp\n  var output = []\n  for (var i = start; i < end; i += 3) {\n    tmp =\n      ((uint8[i] << 16) & 0xFF0000) +\n      ((uint8[i + 1] << 8) & 0xFF00) +\n      (uint8[i + 2] & 0xFF)\n    output.push(tripletToBase64(tmp))\n  }\n  return output.join('')\n}\n\nfunction fromByteArray (uint8) {\n  var tmp\n  var len = uint8.length\n  var extraBytes = len % 3 // if we have 1 byte left, pad 2 bytes\n  var parts = []\n  var maxChunkLength = 16383 // must be multiple of 3\n\n  // go through the array every three bytes, we'll deal with trailing stuff later\n  for (var i = 0, len2 = len - extraBytes; i < len2; i += maxChunkLength) {\n    parts.push(encodeChunk(\n      uint8, i, (i + maxChunkLength) > len2 ? len2 : (i + maxChunkLength)\n    ))\n  }\n\n  // pad the end with zeros, but make sure to not forget the extra bytes\n  if (extraBytes === 1) {\n    tmp = uint8[len - 1]\n    parts.push(\n      lookup[tmp >> 2] +\n      lookup[(tmp << 4) & 0x3F] +\n      '=='\n    )\n  } else if (extraBytes === 2) {\n    tmp = (uint8[len - 2] << 8) + uint8[len - 1]\n    parts.push(\n      lookup[tmp >> 10] +\n      lookup[(tmp >> 4) & 0x3F] +\n      lookup[(tmp << 2) & 0x3F] +\n      '='\n    )\n  }\n\n  return parts.join('')\n}\n\n\n//# sourceURL=webpack:///./node_modules/base64-js/index.js?");

/***/ }),

/***/ "./node_modules/buffer/index.js":
/*!**************************************!*\
  !*** ./node_modules/buffer/index.js ***!
  \**************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(global) {/*!\n * The buffer module from node.js, for the browser.\n *\n * @author   Feross Aboukhadijeh <feross@feross.org> <http://feross.org>\n * @license  MIT\n */\n/* eslint-disable no-proto */\n\n\n\nvar base64 = __webpack_require__(/*! base64-js */ \"./node_modules/base64-js/index.js\")\nvar ieee754 = __webpack_require__(/*! ieee754 */ \"./node_modules/ieee754/index.js\")\nvar isArray = __webpack_require__(/*! isarray */ \"./node_modules/isarray/index.js\")\n\nexports.Buffer = Buffer\nexports.SlowBuffer = SlowBuffer\nexports.INSPECT_MAX_BYTES = 50\n\n/**\n * If `Buffer.TYPED_ARRAY_SUPPORT`:\n *   === true    Use Uint8Array implementation (fastest)\n *   === false   Use Object implementation (most compatible, even IE6)\n *\n * Browsers that support typed arrays are IE 10+, Firefox 4+, Chrome 7+, Safari 5.1+,\n * Opera 11.6+, iOS 4.2+.\n *\n * Due to various browser bugs, sometimes the Object implementation will be used even\n * when the browser supports typed arrays.\n *\n * Note:\n *\n *   - Firefox 4-29 lacks support for adding new properties to `Uint8Array` instances,\n *     See: https://bugzilla.mozilla.org/show_bug.cgi?id=695438.\n *\n *   - Chrome 9-10 is missing the `TypedArray.prototype.subarray` function.\n *\n *   - IE10 has a broken `TypedArray.prototype.subarray` function which returns arrays of\n *     incorrect length in some situations.\n\n * We detect these buggy browsers and set `Buffer.TYPED_ARRAY_SUPPORT` to `false` so they\n * get the Object implementation, which is slower but behaves correctly.\n */\nBuffer.TYPED_ARRAY_SUPPORT = global.TYPED_ARRAY_SUPPORT !== undefined\n  ? global.TYPED_ARRAY_SUPPORT\n  : typedArraySupport()\n\n/*\n * Export kMaxLength after typed array support is determined.\n */\nexports.kMaxLength = kMaxLength()\n\nfunction typedArraySupport () {\n  try {\n    var arr = new Uint8Array(1)\n    arr.__proto__ = {__proto__: Uint8Array.prototype, foo: function () { return 42 }}\n    return arr.foo() === 42 && // typed array instances can be augmented\n        typeof arr.subarray === 'function' && // chrome 9-10 lack `subarray`\n        arr.subarray(1, 1).byteLength === 0 // ie10 has broken `subarray`\n  } catch (e) {\n    return false\n  }\n}\n\nfunction kMaxLength () {\n  return Buffer.TYPED_ARRAY_SUPPORT\n    ? 0x7fffffff\n    : 0x3fffffff\n}\n\nfunction createBuffer (that, length) {\n  if (kMaxLength() < length) {\n    throw new RangeError('Invalid typed array length')\n  }\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    // Return an augmented `Uint8Array` instance, for best performance\n    that = new Uint8Array(length)\n    that.__proto__ = Buffer.prototype\n  } else {\n    // Fallback: Return an object instance of the Buffer class\n    if (that === null) {\n      that = new Buffer(length)\n    }\n    that.length = length\n  }\n\n  return that\n}\n\n/**\n * The Buffer constructor returns instances of `Uint8Array` that have their\n * prototype changed to `Buffer.prototype`. Furthermore, `Buffer` is a subclass of\n * `Uint8Array`, so the returned instances will have all the node `Buffer` methods\n * and the `Uint8Array` methods. Square bracket notation works as expected -- it\n * returns a single octet.\n *\n * The `Uint8Array` prototype remains unmodified.\n */\n\nfunction Buffer (arg, encodingOrOffset, length) {\n  if (!Buffer.TYPED_ARRAY_SUPPORT && !(this instanceof Buffer)) {\n    return new Buffer(arg, encodingOrOffset, length)\n  }\n\n  // Common case.\n  if (typeof arg === 'number') {\n    if (typeof encodingOrOffset === 'string') {\n      throw new Error(\n        'If encoding is specified then the first argument must be a string'\n      )\n    }\n    return allocUnsafe(this, arg)\n  }\n  return from(this, arg, encodingOrOffset, length)\n}\n\nBuffer.poolSize = 8192 // not used by this implementation\n\n// TODO: Legacy, not needed anymore. Remove in next major version.\nBuffer._augment = function (arr) {\n  arr.__proto__ = Buffer.prototype\n  return arr\n}\n\nfunction from (that, value, encodingOrOffset, length) {\n  if (typeof value === 'number') {\n    throw new TypeError('\"value\" argument must not be a number')\n  }\n\n  if (typeof ArrayBuffer !== 'undefined' && value instanceof ArrayBuffer) {\n    return fromArrayBuffer(that, value, encodingOrOffset, length)\n  }\n\n  if (typeof value === 'string') {\n    return fromString(that, value, encodingOrOffset)\n  }\n\n  return fromObject(that, value)\n}\n\n/**\n * Functionally equivalent to Buffer(arg, encoding) but throws a TypeError\n * if value is a number.\n * Buffer.from(str[, encoding])\n * Buffer.from(array)\n * Buffer.from(buffer)\n * Buffer.from(arrayBuffer[, byteOffset[, length]])\n **/\nBuffer.from = function (value, encodingOrOffset, length) {\n  return from(null, value, encodingOrOffset, length)\n}\n\nif (Buffer.TYPED_ARRAY_SUPPORT) {\n  Buffer.prototype.__proto__ = Uint8Array.prototype\n  Buffer.__proto__ = Uint8Array\n  if (typeof Symbol !== 'undefined' && Symbol.species &&\n      Buffer[Symbol.species] === Buffer) {\n    // Fix subarray() in ES2016. See: https://github.com/feross/buffer/pull/97\n    Object.defineProperty(Buffer, Symbol.species, {\n      value: null,\n      configurable: true\n    })\n  }\n}\n\nfunction assertSize (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('\"size\" argument must be a number')\n  } else if (size < 0) {\n    throw new RangeError('\"size\" argument must not be negative')\n  }\n}\n\nfunction alloc (that, size, fill, encoding) {\n  assertSize(size)\n  if (size <= 0) {\n    return createBuffer(that, size)\n  }\n  if (fill !== undefined) {\n    // Only pay attention to encoding if it's a string. This\n    // prevents accidentally sending in a number that would\n    // be interpretted as a start offset.\n    return typeof encoding === 'string'\n      ? createBuffer(that, size).fill(fill, encoding)\n      : createBuffer(that, size).fill(fill)\n  }\n  return createBuffer(that, size)\n}\n\n/**\n * Creates a new filled Buffer instance.\n * alloc(size[, fill[, encoding]])\n **/\nBuffer.alloc = function (size, fill, encoding) {\n  return alloc(null, size, fill, encoding)\n}\n\nfunction allocUnsafe (that, size) {\n  assertSize(size)\n  that = createBuffer(that, size < 0 ? 0 : checked(size) | 0)\n  if (!Buffer.TYPED_ARRAY_SUPPORT) {\n    for (var i = 0; i < size; ++i) {\n      that[i] = 0\n    }\n  }\n  return that\n}\n\n/**\n * Equivalent to Buffer(num), by default creates a non-zero-filled Buffer instance.\n * */\nBuffer.allocUnsafe = function (size) {\n  return allocUnsafe(null, size)\n}\n/**\n * Equivalent to SlowBuffer(num), by default creates a non-zero-filled Buffer instance.\n */\nBuffer.allocUnsafeSlow = function (size) {\n  return allocUnsafe(null, size)\n}\n\nfunction fromString (that, string, encoding) {\n  if (typeof encoding !== 'string' || encoding === '') {\n    encoding = 'utf8'\n  }\n\n  if (!Buffer.isEncoding(encoding)) {\n    throw new TypeError('\"encoding\" must be a valid string encoding')\n  }\n\n  var length = byteLength(string, encoding) | 0\n  that = createBuffer(that, length)\n\n  var actual = that.write(string, encoding)\n\n  if (actual !== length) {\n    // Writing a hex string, for example, that contains invalid characters will\n    // cause everything after the first invalid character to be ignored. (e.g.\n    // 'abxxcd' will be treated as 'ab')\n    that = that.slice(0, actual)\n  }\n\n  return that\n}\n\nfunction fromArrayLike (that, array) {\n  var length = array.length < 0 ? 0 : checked(array.length) | 0\n  that = createBuffer(that, length)\n  for (var i = 0; i < length; i += 1) {\n    that[i] = array[i] & 255\n  }\n  return that\n}\n\nfunction fromArrayBuffer (that, array, byteOffset, length) {\n  array.byteLength // this throws if `array` is not a valid ArrayBuffer\n\n  if (byteOffset < 0 || array.byteLength < byteOffset) {\n    throw new RangeError('\\'offset\\' is out of bounds')\n  }\n\n  if (array.byteLength < byteOffset + (length || 0)) {\n    throw new RangeError('\\'length\\' is out of bounds')\n  }\n\n  if (byteOffset === undefined && length === undefined) {\n    array = new Uint8Array(array)\n  } else if (length === undefined) {\n    array = new Uint8Array(array, byteOffset)\n  } else {\n    array = new Uint8Array(array, byteOffset, length)\n  }\n\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    // Return an augmented `Uint8Array` instance, for best performance\n    that = array\n    that.__proto__ = Buffer.prototype\n  } else {\n    // Fallback: Return an object instance of the Buffer class\n    that = fromArrayLike(that, array)\n  }\n  return that\n}\n\nfunction fromObject (that, obj) {\n  if (Buffer.isBuffer(obj)) {\n    var len = checked(obj.length) | 0\n    that = createBuffer(that, len)\n\n    if (that.length === 0) {\n      return that\n    }\n\n    obj.copy(that, 0, 0, len)\n    return that\n  }\n\n  if (obj) {\n    if ((typeof ArrayBuffer !== 'undefined' &&\n        obj.buffer instanceof ArrayBuffer) || 'length' in obj) {\n      if (typeof obj.length !== 'number' || isnan(obj.length)) {\n        return createBuffer(that, 0)\n      }\n      return fromArrayLike(that, obj)\n    }\n\n    if (obj.type === 'Buffer' && isArray(obj.data)) {\n      return fromArrayLike(that, obj.data)\n    }\n  }\n\n  throw new TypeError('First argument must be a string, Buffer, ArrayBuffer, Array, or array-like object.')\n}\n\nfunction checked (length) {\n  // Note: cannot use `length < kMaxLength()` here because that fails when\n  // length is NaN (which is otherwise coerced to zero.)\n  if (length >= kMaxLength()) {\n    throw new RangeError('Attempt to allocate Buffer larger than maximum ' +\n                         'size: 0x' + kMaxLength().toString(16) + ' bytes')\n  }\n  return length | 0\n}\n\nfunction SlowBuffer (length) {\n  if (+length != length) { // eslint-disable-line eqeqeq\n    length = 0\n  }\n  return Buffer.alloc(+length)\n}\n\nBuffer.isBuffer = function isBuffer (b) {\n  return !!(b != null && b._isBuffer)\n}\n\nBuffer.compare = function compare (a, b) {\n  if (!Buffer.isBuffer(a) || !Buffer.isBuffer(b)) {\n    throw new TypeError('Arguments must be Buffers')\n  }\n\n  if (a === b) return 0\n\n  var x = a.length\n  var y = b.length\n\n  for (var i = 0, len = Math.min(x, y); i < len; ++i) {\n    if (a[i] !== b[i]) {\n      x = a[i]\n      y = b[i]\n      break\n    }\n  }\n\n  if (x < y) return -1\n  if (y < x) return 1\n  return 0\n}\n\nBuffer.isEncoding = function isEncoding (encoding) {\n  switch (String(encoding).toLowerCase()) {\n    case 'hex':\n    case 'utf8':\n    case 'utf-8':\n    case 'ascii':\n    case 'latin1':\n    case 'binary':\n    case 'base64':\n    case 'ucs2':\n    case 'ucs-2':\n    case 'utf16le':\n    case 'utf-16le':\n      return true\n    default:\n      return false\n  }\n}\n\nBuffer.concat = function concat (list, length) {\n  if (!isArray(list)) {\n    throw new TypeError('\"list\" argument must be an Array of Buffers')\n  }\n\n  if (list.length === 0) {\n    return Buffer.alloc(0)\n  }\n\n  var i\n  if (length === undefined) {\n    length = 0\n    for (i = 0; i < list.length; ++i) {\n      length += list[i].length\n    }\n  }\n\n  var buffer = Buffer.allocUnsafe(length)\n  var pos = 0\n  for (i = 0; i < list.length; ++i) {\n    var buf = list[i]\n    if (!Buffer.isBuffer(buf)) {\n      throw new TypeError('\"list\" argument must be an Array of Buffers')\n    }\n    buf.copy(buffer, pos)\n    pos += buf.length\n  }\n  return buffer\n}\n\nfunction byteLength (string, encoding) {\n  if (Buffer.isBuffer(string)) {\n    return string.length\n  }\n  if (typeof ArrayBuffer !== 'undefined' && typeof ArrayBuffer.isView === 'function' &&\n      (ArrayBuffer.isView(string) || string instanceof ArrayBuffer)) {\n    return string.byteLength\n  }\n  if (typeof string !== 'string') {\n    string = '' + string\n  }\n\n  var len = string.length\n  if (len === 0) return 0\n\n  // Use a for loop to avoid recursion\n  var loweredCase = false\n  for (;;) {\n    switch (encoding) {\n      case 'ascii':\n      case 'latin1':\n      case 'binary':\n        return len\n      case 'utf8':\n      case 'utf-8':\n      case undefined:\n        return utf8ToBytes(string).length\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return len * 2\n      case 'hex':\n        return len >>> 1\n      case 'base64':\n        return base64ToBytes(string).length\n      default:\n        if (loweredCase) return utf8ToBytes(string).length // assume utf8\n        encoding = ('' + encoding).toLowerCase()\n        loweredCase = true\n    }\n  }\n}\nBuffer.byteLength = byteLength\n\nfunction slowToString (encoding, start, end) {\n  var loweredCase = false\n\n  // No need to verify that \"this.length <= MAX_UINT32\" since it's a read-only\n  // property of a typed array.\n\n  // This behaves neither like String nor Uint8Array in that we set start/end\n  // to their upper/lower bounds if the value passed is out of range.\n  // undefined is handled specially as per ECMA-262 6th Edition,\n  // Section 13.3.3.7 Runtime Semantics: KeyedBindingInitialization.\n  if (start === undefined || start < 0) {\n    start = 0\n  }\n  // Return early if start > this.length. Done here to prevent potential uint32\n  // coercion fail below.\n  if (start > this.length) {\n    return ''\n  }\n\n  if (end === undefined || end > this.length) {\n    end = this.length\n  }\n\n  if (end <= 0) {\n    return ''\n  }\n\n  // Force coersion to uint32. This will also coerce falsey/NaN values to 0.\n  end >>>= 0\n  start >>>= 0\n\n  if (end <= start) {\n    return ''\n  }\n\n  if (!encoding) encoding = 'utf8'\n\n  while (true) {\n    switch (encoding) {\n      case 'hex':\n        return hexSlice(this, start, end)\n\n      case 'utf8':\n      case 'utf-8':\n        return utf8Slice(this, start, end)\n\n      case 'ascii':\n        return asciiSlice(this, start, end)\n\n      case 'latin1':\n      case 'binary':\n        return latin1Slice(this, start, end)\n\n      case 'base64':\n        return base64Slice(this, start, end)\n\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return utf16leSlice(this, start, end)\n\n      default:\n        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)\n        encoding = (encoding + '').toLowerCase()\n        loweredCase = true\n    }\n  }\n}\n\n// The property is used by `Buffer.isBuffer` and `is-buffer` (in Safari 5-7) to detect\n// Buffer instances.\nBuffer.prototype._isBuffer = true\n\nfunction swap (b, n, m) {\n  var i = b[n]\n  b[n] = b[m]\n  b[m] = i\n}\n\nBuffer.prototype.swap16 = function swap16 () {\n  var len = this.length\n  if (len % 2 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 16-bits')\n  }\n  for (var i = 0; i < len; i += 2) {\n    swap(this, i, i + 1)\n  }\n  return this\n}\n\nBuffer.prototype.swap32 = function swap32 () {\n  var len = this.length\n  if (len % 4 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 32-bits')\n  }\n  for (var i = 0; i < len; i += 4) {\n    swap(this, i, i + 3)\n    swap(this, i + 1, i + 2)\n  }\n  return this\n}\n\nBuffer.prototype.swap64 = function swap64 () {\n  var len = this.length\n  if (len % 8 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 64-bits')\n  }\n  for (var i = 0; i < len; i += 8) {\n    swap(this, i, i + 7)\n    swap(this, i + 1, i + 6)\n    swap(this, i + 2, i + 5)\n    swap(this, i + 3, i + 4)\n  }\n  return this\n}\n\nBuffer.prototype.toString = function toString () {\n  var length = this.length | 0\n  if (length === 0) return ''\n  if (arguments.length === 0) return utf8Slice(this, 0, length)\n  return slowToString.apply(this, arguments)\n}\n\nBuffer.prototype.equals = function equals (b) {\n  if (!Buffer.isBuffer(b)) throw new TypeError('Argument must be a Buffer')\n  if (this === b) return true\n  return Buffer.compare(this, b) === 0\n}\n\nBuffer.prototype.inspect = function inspect () {\n  var str = ''\n  var max = exports.INSPECT_MAX_BYTES\n  if (this.length > 0) {\n    str = this.toString('hex', 0, max).match(/.{2}/g).join(' ')\n    if (this.length > max) str += ' ... '\n  }\n  return '<Buffer ' + str + '>'\n}\n\nBuffer.prototype.compare = function compare (target, start, end, thisStart, thisEnd) {\n  if (!Buffer.isBuffer(target)) {\n    throw new TypeError('Argument must be a Buffer')\n  }\n\n  if (start === undefined) {\n    start = 0\n  }\n  if (end === undefined) {\n    end = target ? target.length : 0\n  }\n  if (thisStart === undefined) {\n    thisStart = 0\n  }\n  if (thisEnd === undefined) {\n    thisEnd = this.length\n  }\n\n  if (start < 0 || end > target.length || thisStart < 0 || thisEnd > this.length) {\n    throw new RangeError('out of range index')\n  }\n\n  if (thisStart >= thisEnd && start >= end) {\n    return 0\n  }\n  if (thisStart >= thisEnd) {\n    return -1\n  }\n  if (start >= end) {\n    return 1\n  }\n\n  start >>>= 0\n  end >>>= 0\n  thisStart >>>= 0\n  thisEnd >>>= 0\n\n  if (this === target) return 0\n\n  var x = thisEnd - thisStart\n  var y = end - start\n  var len = Math.min(x, y)\n\n  var thisCopy = this.slice(thisStart, thisEnd)\n  var targetCopy = target.slice(start, end)\n\n  for (var i = 0; i < len; ++i) {\n    if (thisCopy[i] !== targetCopy[i]) {\n      x = thisCopy[i]\n      y = targetCopy[i]\n      break\n    }\n  }\n\n  if (x < y) return -1\n  if (y < x) return 1\n  return 0\n}\n\n// Finds either the first index of `val` in `buffer` at offset >= `byteOffset`,\n// OR the last index of `val` in `buffer` at offset <= `byteOffset`.\n//\n// Arguments:\n// - buffer - a Buffer to search\n// - val - a string, Buffer, or number\n// - byteOffset - an index into `buffer`; will be clamped to an int32\n// - encoding - an optional encoding, relevant is val is a string\n// - dir - true for indexOf, false for lastIndexOf\nfunction bidirectionalIndexOf (buffer, val, byteOffset, encoding, dir) {\n  // Empty buffer means no match\n  if (buffer.length === 0) return -1\n\n  // Normalize byteOffset\n  if (typeof byteOffset === 'string') {\n    encoding = byteOffset\n    byteOffset = 0\n  } else if (byteOffset > 0x7fffffff) {\n    byteOffset = 0x7fffffff\n  } else if (byteOffset < -0x80000000) {\n    byteOffset = -0x80000000\n  }\n  byteOffset = +byteOffset  // Coerce to Number.\n  if (isNaN(byteOffset)) {\n    // byteOffset: it it's undefined, null, NaN, \"foo\", etc, search whole buffer\n    byteOffset = dir ? 0 : (buffer.length - 1)\n  }\n\n  // Normalize byteOffset: negative offsets start from the end of the buffer\n  if (byteOffset < 0) byteOffset = buffer.length + byteOffset\n  if (byteOffset >= buffer.length) {\n    if (dir) return -1\n    else byteOffset = buffer.length - 1\n  } else if (byteOffset < 0) {\n    if (dir) byteOffset = 0\n    else return -1\n  }\n\n  // Normalize val\n  if (typeof val === 'string') {\n    val = Buffer.from(val, encoding)\n  }\n\n  // Finally, search either indexOf (if dir is true) or lastIndexOf\n  if (Buffer.isBuffer(val)) {\n    // Special case: looking for empty string/buffer always fails\n    if (val.length === 0) {\n      return -1\n    }\n    return arrayIndexOf(buffer, val, byteOffset, encoding, dir)\n  } else if (typeof val === 'number') {\n    val = val & 0xFF // Search for a byte value [0-255]\n    if (Buffer.TYPED_ARRAY_SUPPORT &&\n        typeof Uint8Array.prototype.indexOf === 'function') {\n      if (dir) {\n        return Uint8Array.prototype.indexOf.call(buffer, val, byteOffset)\n      } else {\n        return Uint8Array.prototype.lastIndexOf.call(buffer, val, byteOffset)\n      }\n    }\n    return arrayIndexOf(buffer, [ val ], byteOffset, encoding, dir)\n  }\n\n  throw new TypeError('val must be string, number or Buffer')\n}\n\nfunction arrayIndexOf (arr, val, byteOffset, encoding, dir) {\n  var indexSize = 1\n  var arrLength = arr.length\n  var valLength = val.length\n\n  if (encoding !== undefined) {\n    encoding = String(encoding).toLowerCase()\n    if (encoding === 'ucs2' || encoding === 'ucs-2' ||\n        encoding === 'utf16le' || encoding === 'utf-16le') {\n      if (arr.length < 2 || val.length < 2) {\n        return -1\n      }\n      indexSize = 2\n      arrLength /= 2\n      valLength /= 2\n      byteOffset /= 2\n    }\n  }\n\n  function read (buf, i) {\n    if (indexSize === 1) {\n      return buf[i]\n    } else {\n      return buf.readUInt16BE(i * indexSize)\n    }\n  }\n\n  var i\n  if (dir) {\n    var foundIndex = -1\n    for (i = byteOffset; i < arrLength; i++) {\n      if (read(arr, i) === read(val, foundIndex === -1 ? 0 : i - foundIndex)) {\n        if (foundIndex === -1) foundIndex = i\n        if (i - foundIndex + 1 === valLength) return foundIndex * indexSize\n      } else {\n        if (foundIndex !== -1) i -= i - foundIndex\n        foundIndex = -1\n      }\n    }\n  } else {\n    if (byteOffset + valLength > arrLength) byteOffset = arrLength - valLength\n    for (i = byteOffset; i >= 0; i--) {\n      var found = true\n      for (var j = 0; j < valLength; j++) {\n        if (read(arr, i + j) !== read(val, j)) {\n          found = false\n          break\n        }\n      }\n      if (found) return i\n    }\n  }\n\n  return -1\n}\n\nBuffer.prototype.includes = function includes (val, byteOffset, encoding) {\n  return this.indexOf(val, byteOffset, encoding) !== -1\n}\n\nBuffer.prototype.indexOf = function indexOf (val, byteOffset, encoding) {\n  return bidirectionalIndexOf(this, val, byteOffset, encoding, true)\n}\n\nBuffer.prototype.lastIndexOf = function lastIndexOf (val, byteOffset, encoding) {\n  return bidirectionalIndexOf(this, val, byteOffset, encoding, false)\n}\n\nfunction hexWrite (buf, string, offset, length) {\n  offset = Number(offset) || 0\n  var remaining = buf.length - offset\n  if (!length) {\n    length = remaining\n  } else {\n    length = Number(length)\n    if (length > remaining) {\n      length = remaining\n    }\n  }\n\n  // must be an even number of digits\n  var strLen = string.length\n  if (strLen % 2 !== 0) throw new TypeError('Invalid hex string')\n\n  if (length > strLen / 2) {\n    length = strLen / 2\n  }\n  for (var i = 0; i < length; ++i) {\n    var parsed = parseInt(string.substr(i * 2, 2), 16)\n    if (isNaN(parsed)) return i\n    buf[offset + i] = parsed\n  }\n  return i\n}\n\nfunction utf8Write (buf, string, offset, length) {\n  return blitBuffer(utf8ToBytes(string, buf.length - offset), buf, offset, length)\n}\n\nfunction asciiWrite (buf, string, offset, length) {\n  return blitBuffer(asciiToBytes(string), buf, offset, length)\n}\n\nfunction latin1Write (buf, string, offset, length) {\n  return asciiWrite(buf, string, offset, length)\n}\n\nfunction base64Write (buf, string, offset, length) {\n  return blitBuffer(base64ToBytes(string), buf, offset, length)\n}\n\nfunction ucs2Write (buf, string, offset, length) {\n  return blitBuffer(utf16leToBytes(string, buf.length - offset), buf, offset, length)\n}\n\nBuffer.prototype.write = function write (string, offset, length, encoding) {\n  // Buffer#write(string)\n  if (offset === undefined) {\n    encoding = 'utf8'\n    length = this.length\n    offset = 0\n  // Buffer#write(string, encoding)\n  } else if (length === undefined && typeof offset === 'string') {\n    encoding = offset\n    length = this.length\n    offset = 0\n  // Buffer#write(string, offset[, length][, encoding])\n  } else if (isFinite(offset)) {\n    offset = offset | 0\n    if (isFinite(length)) {\n      length = length | 0\n      if (encoding === undefined) encoding = 'utf8'\n    } else {\n      encoding = length\n      length = undefined\n    }\n  // legacy write(string, encoding, offset, length) - remove in v0.13\n  } else {\n    throw new Error(\n      'Buffer.write(string, encoding, offset[, length]) is no longer supported'\n    )\n  }\n\n  var remaining = this.length - offset\n  if (length === undefined || length > remaining) length = remaining\n\n  if ((string.length > 0 && (length < 0 || offset < 0)) || offset > this.length) {\n    throw new RangeError('Attempt to write outside buffer bounds')\n  }\n\n  if (!encoding) encoding = 'utf8'\n\n  var loweredCase = false\n  for (;;) {\n    switch (encoding) {\n      case 'hex':\n        return hexWrite(this, string, offset, length)\n\n      case 'utf8':\n      case 'utf-8':\n        return utf8Write(this, string, offset, length)\n\n      case 'ascii':\n        return asciiWrite(this, string, offset, length)\n\n      case 'latin1':\n      case 'binary':\n        return latin1Write(this, string, offset, length)\n\n      case 'base64':\n        // Warning: maxLength not taken into account in base64Write\n        return base64Write(this, string, offset, length)\n\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return ucs2Write(this, string, offset, length)\n\n      default:\n        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)\n        encoding = ('' + encoding).toLowerCase()\n        loweredCase = true\n    }\n  }\n}\n\nBuffer.prototype.toJSON = function toJSON () {\n  return {\n    type: 'Buffer',\n    data: Array.prototype.slice.call(this._arr || this, 0)\n  }\n}\n\nfunction base64Slice (buf, start, end) {\n  if (start === 0 && end === buf.length) {\n    return base64.fromByteArray(buf)\n  } else {\n    return base64.fromByteArray(buf.slice(start, end))\n  }\n}\n\nfunction utf8Slice (buf, start, end) {\n  end = Math.min(buf.length, end)\n  var res = []\n\n  var i = start\n  while (i < end) {\n    var firstByte = buf[i]\n    var codePoint = null\n    var bytesPerSequence = (firstByte > 0xEF) ? 4\n      : (firstByte > 0xDF) ? 3\n      : (firstByte > 0xBF) ? 2\n      : 1\n\n    if (i + bytesPerSequence <= end) {\n      var secondByte, thirdByte, fourthByte, tempCodePoint\n\n      switch (bytesPerSequence) {\n        case 1:\n          if (firstByte < 0x80) {\n            codePoint = firstByte\n          }\n          break\n        case 2:\n          secondByte = buf[i + 1]\n          if ((secondByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0x1F) << 0x6 | (secondByte & 0x3F)\n            if (tempCodePoint > 0x7F) {\n              codePoint = tempCodePoint\n            }\n          }\n          break\n        case 3:\n          secondByte = buf[i + 1]\n          thirdByte = buf[i + 2]\n          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0xF) << 0xC | (secondByte & 0x3F) << 0x6 | (thirdByte & 0x3F)\n            if (tempCodePoint > 0x7FF && (tempCodePoint < 0xD800 || tempCodePoint > 0xDFFF)) {\n              codePoint = tempCodePoint\n            }\n          }\n          break\n        case 4:\n          secondByte = buf[i + 1]\n          thirdByte = buf[i + 2]\n          fourthByte = buf[i + 3]\n          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80 && (fourthByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0xF) << 0x12 | (secondByte & 0x3F) << 0xC | (thirdByte & 0x3F) << 0x6 | (fourthByte & 0x3F)\n            if (tempCodePoint > 0xFFFF && tempCodePoint < 0x110000) {\n              codePoint = tempCodePoint\n            }\n          }\n      }\n    }\n\n    if (codePoint === null) {\n      // we did not generate a valid codePoint so insert a\n      // replacement char (U+FFFD) and advance only 1 byte\n      codePoint = 0xFFFD\n      bytesPerSequence = 1\n    } else if (codePoint > 0xFFFF) {\n      // encode to utf16 (surrogate pair dance)\n      codePoint -= 0x10000\n      res.push(codePoint >>> 10 & 0x3FF | 0xD800)\n      codePoint = 0xDC00 | codePoint & 0x3FF\n    }\n\n    res.push(codePoint)\n    i += bytesPerSequence\n  }\n\n  return decodeCodePointsArray(res)\n}\n\n// Based on http://stackoverflow.com/a/22747272/680742, the browser with\n// the lowest limit is Chrome, with 0x10000 args.\n// We go 1 magnitude less, for safety\nvar MAX_ARGUMENTS_LENGTH = 0x1000\n\nfunction decodeCodePointsArray (codePoints) {\n  var len = codePoints.length\n  if (len <= MAX_ARGUMENTS_LENGTH) {\n    return String.fromCharCode.apply(String, codePoints) // avoid extra slice()\n  }\n\n  // Decode in chunks to avoid \"call stack size exceeded\".\n  var res = ''\n  var i = 0\n  while (i < len) {\n    res += String.fromCharCode.apply(\n      String,\n      codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH)\n    )\n  }\n  return res\n}\n\nfunction asciiSlice (buf, start, end) {\n  var ret = ''\n  end = Math.min(buf.length, end)\n\n  for (var i = start; i < end; ++i) {\n    ret += String.fromCharCode(buf[i] & 0x7F)\n  }\n  return ret\n}\n\nfunction latin1Slice (buf, start, end) {\n  var ret = ''\n  end = Math.min(buf.length, end)\n\n  for (var i = start; i < end; ++i) {\n    ret += String.fromCharCode(buf[i])\n  }\n  return ret\n}\n\nfunction hexSlice (buf, start, end) {\n  var len = buf.length\n\n  if (!start || start < 0) start = 0\n  if (!end || end < 0 || end > len) end = len\n\n  var out = ''\n  for (var i = start; i < end; ++i) {\n    out += toHex(buf[i])\n  }\n  return out\n}\n\nfunction utf16leSlice (buf, start, end) {\n  var bytes = buf.slice(start, end)\n  var res = ''\n  for (var i = 0; i < bytes.length; i += 2) {\n    res += String.fromCharCode(bytes[i] + bytes[i + 1] * 256)\n  }\n  return res\n}\n\nBuffer.prototype.slice = function slice (start, end) {\n  var len = this.length\n  start = ~~start\n  end = end === undefined ? len : ~~end\n\n  if (start < 0) {\n    start += len\n    if (start < 0) start = 0\n  } else if (start > len) {\n    start = len\n  }\n\n  if (end < 0) {\n    end += len\n    if (end < 0) end = 0\n  } else if (end > len) {\n    end = len\n  }\n\n  if (end < start) end = start\n\n  var newBuf\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    newBuf = this.subarray(start, end)\n    newBuf.__proto__ = Buffer.prototype\n  } else {\n    var sliceLen = end - start\n    newBuf = new Buffer(sliceLen, undefined)\n    for (var i = 0; i < sliceLen; ++i) {\n      newBuf[i] = this[i + start]\n    }\n  }\n\n  return newBuf\n}\n\n/*\n * Need to make sure that buffer isn't trying to write out of bounds.\n */\nfunction checkOffset (offset, ext, length) {\n  if ((offset % 1) !== 0 || offset < 0) throw new RangeError('offset is not uint')\n  if (offset + ext > length) throw new RangeError('Trying to access beyond buffer length')\n}\n\nBuffer.prototype.readUIntLE = function readUIntLE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  var val = this[offset]\n  var mul = 1\n  var i = 0\n  while (++i < byteLength && (mul *= 0x100)) {\n    val += this[offset + i] * mul\n  }\n\n  return val\n}\n\nBuffer.prototype.readUIntBE = function readUIntBE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) {\n    checkOffset(offset, byteLength, this.length)\n  }\n\n  var val = this[offset + --byteLength]\n  var mul = 1\n  while (byteLength > 0 && (mul *= 0x100)) {\n    val += this[offset + --byteLength] * mul\n  }\n\n  return val\n}\n\nBuffer.prototype.readUInt8 = function readUInt8 (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 1, this.length)\n  return this[offset]\n}\n\nBuffer.prototype.readUInt16LE = function readUInt16LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  return this[offset] | (this[offset + 1] << 8)\n}\n\nBuffer.prototype.readUInt16BE = function readUInt16BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  return (this[offset] << 8) | this[offset + 1]\n}\n\nBuffer.prototype.readUInt32LE = function readUInt32LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return ((this[offset]) |\n      (this[offset + 1] << 8) |\n      (this[offset + 2] << 16)) +\n      (this[offset + 3] * 0x1000000)\n}\n\nBuffer.prototype.readUInt32BE = function readUInt32BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset] * 0x1000000) +\n    ((this[offset + 1] << 16) |\n    (this[offset + 2] << 8) |\n    this[offset + 3])\n}\n\nBuffer.prototype.readIntLE = function readIntLE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  var val = this[offset]\n  var mul = 1\n  var i = 0\n  while (++i < byteLength && (mul *= 0x100)) {\n    val += this[offset + i] * mul\n  }\n  mul *= 0x80\n\n  if (val >= mul) val -= Math.pow(2, 8 * byteLength)\n\n  return val\n}\n\nBuffer.prototype.readIntBE = function readIntBE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  var i = byteLength\n  var mul = 1\n  var val = this[offset + --i]\n  while (i > 0 && (mul *= 0x100)) {\n    val += this[offset + --i] * mul\n  }\n  mul *= 0x80\n\n  if (val >= mul) val -= Math.pow(2, 8 * byteLength)\n\n  return val\n}\n\nBuffer.prototype.readInt8 = function readInt8 (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 1, this.length)\n  if (!(this[offset] & 0x80)) return (this[offset])\n  return ((0xff - this[offset] + 1) * -1)\n}\n\nBuffer.prototype.readInt16LE = function readInt16LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  var val = this[offset] | (this[offset + 1] << 8)\n  return (val & 0x8000) ? val | 0xFFFF0000 : val\n}\n\nBuffer.prototype.readInt16BE = function readInt16BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  var val = this[offset + 1] | (this[offset] << 8)\n  return (val & 0x8000) ? val | 0xFFFF0000 : val\n}\n\nBuffer.prototype.readInt32LE = function readInt32LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset]) |\n    (this[offset + 1] << 8) |\n    (this[offset + 2] << 16) |\n    (this[offset + 3] << 24)\n}\n\nBuffer.prototype.readInt32BE = function readInt32BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset] << 24) |\n    (this[offset + 1] << 16) |\n    (this[offset + 2] << 8) |\n    (this[offset + 3])\n}\n\nBuffer.prototype.readFloatLE = function readFloatLE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n  return ieee754.read(this, offset, true, 23, 4)\n}\n\nBuffer.prototype.readFloatBE = function readFloatBE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n  return ieee754.read(this, offset, false, 23, 4)\n}\n\nBuffer.prototype.readDoubleLE = function readDoubleLE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 8, this.length)\n  return ieee754.read(this, offset, true, 52, 8)\n}\n\nBuffer.prototype.readDoubleBE = function readDoubleBE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 8, this.length)\n  return ieee754.read(this, offset, false, 52, 8)\n}\n\nfunction checkInt (buf, value, offset, ext, max, min) {\n  if (!Buffer.isBuffer(buf)) throw new TypeError('\"buffer\" argument must be a Buffer instance')\n  if (value > max || value < min) throw new RangeError('\"value\" argument is out of bounds')\n  if (offset + ext > buf.length) throw new RangeError('Index out of range')\n}\n\nBuffer.prototype.writeUIntLE = function writeUIntLE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) {\n    var maxBytes = Math.pow(2, 8 * byteLength) - 1\n    checkInt(this, value, offset, byteLength, maxBytes, 0)\n  }\n\n  var mul = 1\n  var i = 0\n  this[offset] = value & 0xFF\n  while (++i < byteLength && (mul *= 0x100)) {\n    this[offset + i] = (value / mul) & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeUIntBE = function writeUIntBE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) {\n    var maxBytes = Math.pow(2, 8 * byteLength) - 1\n    checkInt(this, value, offset, byteLength, maxBytes, 0)\n  }\n\n  var i = byteLength - 1\n  var mul = 1\n  this[offset + i] = value & 0xFF\n  while (--i >= 0 && (mul *= 0x100)) {\n    this[offset + i] = (value / mul) & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeUInt8 = function writeUInt8 (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 1, 0xff, 0)\n  if (!Buffer.TYPED_ARRAY_SUPPORT) value = Math.floor(value)\n  this[offset] = (value & 0xff)\n  return offset + 1\n}\n\nfunction objectWriteUInt16 (buf, value, offset, littleEndian) {\n  if (value < 0) value = 0xffff + value + 1\n  for (var i = 0, j = Math.min(buf.length - offset, 2); i < j; ++i) {\n    buf[offset + i] = (value & (0xff << (8 * (littleEndian ? i : 1 - i)))) >>>\n      (littleEndian ? i : 1 - i) * 8\n  }\n}\n\nBuffer.prototype.writeUInt16LE = function writeUInt16LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value & 0xff)\n    this[offset + 1] = (value >>> 8)\n  } else {\n    objectWriteUInt16(this, value, offset, true)\n  }\n  return offset + 2\n}\n\nBuffer.prototype.writeUInt16BE = function writeUInt16BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 8)\n    this[offset + 1] = (value & 0xff)\n  } else {\n    objectWriteUInt16(this, value, offset, false)\n  }\n  return offset + 2\n}\n\nfunction objectWriteUInt32 (buf, value, offset, littleEndian) {\n  if (value < 0) value = 0xffffffff + value + 1\n  for (var i = 0, j = Math.min(buf.length - offset, 4); i < j; ++i) {\n    buf[offset + i] = (value >>> (littleEndian ? i : 3 - i) * 8) & 0xff\n  }\n}\n\nBuffer.prototype.writeUInt32LE = function writeUInt32LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset + 3] = (value >>> 24)\n    this[offset + 2] = (value >>> 16)\n    this[offset + 1] = (value >>> 8)\n    this[offset] = (value & 0xff)\n  } else {\n    objectWriteUInt32(this, value, offset, true)\n  }\n  return offset + 4\n}\n\nBuffer.prototype.writeUInt32BE = function writeUInt32BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 24)\n    this[offset + 1] = (value >>> 16)\n    this[offset + 2] = (value >>> 8)\n    this[offset + 3] = (value & 0xff)\n  } else {\n    objectWriteUInt32(this, value, offset, false)\n  }\n  return offset + 4\n}\n\nBuffer.prototype.writeIntLE = function writeIntLE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) {\n    var limit = Math.pow(2, 8 * byteLength - 1)\n\n    checkInt(this, value, offset, byteLength, limit - 1, -limit)\n  }\n\n  var i = 0\n  var mul = 1\n  var sub = 0\n  this[offset] = value & 0xFF\n  while (++i < byteLength && (mul *= 0x100)) {\n    if (value < 0 && sub === 0 && this[offset + i - 1] !== 0) {\n      sub = 1\n    }\n    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeIntBE = function writeIntBE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) {\n    var limit = Math.pow(2, 8 * byteLength - 1)\n\n    checkInt(this, value, offset, byteLength, limit - 1, -limit)\n  }\n\n  var i = byteLength - 1\n  var mul = 1\n  var sub = 0\n  this[offset + i] = value & 0xFF\n  while (--i >= 0 && (mul *= 0x100)) {\n    if (value < 0 && sub === 0 && this[offset + i + 1] !== 0) {\n      sub = 1\n    }\n    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeInt8 = function writeInt8 (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 1, 0x7f, -0x80)\n  if (!Buffer.TYPED_ARRAY_SUPPORT) value = Math.floor(value)\n  if (value < 0) value = 0xff + value + 1\n  this[offset] = (value & 0xff)\n  return offset + 1\n}\n\nBuffer.prototype.writeInt16LE = function writeInt16LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value & 0xff)\n    this[offset + 1] = (value >>> 8)\n  } else {\n    objectWriteUInt16(this, value, offset, true)\n  }\n  return offset + 2\n}\n\nBuffer.prototype.writeInt16BE = function writeInt16BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 8)\n    this[offset + 1] = (value & 0xff)\n  } else {\n    objectWriteUInt16(this, value, offset, false)\n  }\n  return offset + 2\n}\n\nBuffer.prototype.writeInt32LE = function writeInt32LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value & 0xff)\n    this[offset + 1] = (value >>> 8)\n    this[offset + 2] = (value >>> 16)\n    this[offset + 3] = (value >>> 24)\n  } else {\n    objectWriteUInt32(this, value, offset, true)\n  }\n  return offset + 4\n}\n\nBuffer.prototype.writeInt32BE = function writeInt32BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)\n  if (value < 0) value = 0xffffffff + value + 1\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 24)\n    this[offset + 1] = (value >>> 16)\n    this[offset + 2] = (value >>> 8)\n    this[offset + 3] = (value & 0xff)\n  } else {\n    objectWriteUInt32(this, value, offset, false)\n  }\n  return offset + 4\n}\n\nfunction checkIEEE754 (buf, value, offset, ext, max, min) {\n  if (offset + ext > buf.length) throw new RangeError('Index out of range')\n  if (offset < 0) throw new RangeError('Index out of range')\n}\n\nfunction writeFloat (buf, value, offset, littleEndian, noAssert) {\n  if (!noAssert) {\n    checkIEEE754(buf, value, offset, 4, 3.4028234663852886e+38, -3.4028234663852886e+38)\n  }\n  ieee754.write(buf, value, offset, littleEndian, 23, 4)\n  return offset + 4\n}\n\nBuffer.prototype.writeFloatLE = function writeFloatLE (value, offset, noAssert) {\n  return writeFloat(this, value, offset, true, noAssert)\n}\n\nBuffer.prototype.writeFloatBE = function writeFloatBE (value, offset, noAssert) {\n  return writeFloat(this, value, offset, false, noAssert)\n}\n\nfunction writeDouble (buf, value, offset, littleEndian, noAssert) {\n  if (!noAssert) {\n    checkIEEE754(buf, value, offset, 8, 1.7976931348623157E+308, -1.7976931348623157E+308)\n  }\n  ieee754.write(buf, value, offset, littleEndian, 52, 8)\n  return offset + 8\n}\n\nBuffer.prototype.writeDoubleLE = function writeDoubleLE (value, offset, noAssert) {\n  return writeDouble(this, value, offset, true, noAssert)\n}\n\nBuffer.prototype.writeDoubleBE = function writeDoubleBE (value, offset, noAssert) {\n  return writeDouble(this, value, offset, false, noAssert)\n}\n\n// copy(targetBuffer, targetStart=0, sourceStart=0, sourceEnd=buffer.length)\nBuffer.prototype.copy = function copy (target, targetStart, start, end) {\n  if (!start) start = 0\n  if (!end && end !== 0) end = this.length\n  if (targetStart >= target.length) targetStart = target.length\n  if (!targetStart) targetStart = 0\n  if (end > 0 && end < start) end = start\n\n  // Copy 0 bytes; we're done\n  if (end === start) return 0\n  if (target.length === 0 || this.length === 0) return 0\n\n  // Fatal error conditions\n  if (targetStart < 0) {\n    throw new RangeError('targetStart out of bounds')\n  }\n  if (start < 0 || start >= this.length) throw new RangeError('sourceStart out of bounds')\n  if (end < 0) throw new RangeError('sourceEnd out of bounds')\n\n  // Are we oob?\n  if (end > this.length) end = this.length\n  if (target.length - targetStart < end - start) {\n    end = target.length - targetStart + start\n  }\n\n  var len = end - start\n  var i\n\n  if (this === target && start < targetStart && targetStart < end) {\n    // descending copy from end\n    for (i = len - 1; i >= 0; --i) {\n      target[i + targetStart] = this[i + start]\n    }\n  } else if (len < 1000 || !Buffer.TYPED_ARRAY_SUPPORT) {\n    // ascending copy from start\n    for (i = 0; i < len; ++i) {\n      target[i + targetStart] = this[i + start]\n    }\n  } else {\n    Uint8Array.prototype.set.call(\n      target,\n      this.subarray(start, start + len),\n      targetStart\n    )\n  }\n\n  return len\n}\n\n// Usage:\n//    buffer.fill(number[, offset[, end]])\n//    buffer.fill(buffer[, offset[, end]])\n//    buffer.fill(string[, offset[, end]][, encoding])\nBuffer.prototype.fill = function fill (val, start, end, encoding) {\n  // Handle string cases:\n  if (typeof val === 'string') {\n    if (typeof start === 'string') {\n      encoding = start\n      start = 0\n      end = this.length\n    } else if (typeof end === 'string') {\n      encoding = end\n      end = this.length\n    }\n    if (val.length === 1) {\n      var code = val.charCodeAt(0)\n      if (code < 256) {\n        val = code\n      }\n    }\n    if (encoding !== undefined && typeof encoding !== 'string') {\n      throw new TypeError('encoding must be a string')\n    }\n    if (typeof encoding === 'string' && !Buffer.isEncoding(encoding)) {\n      throw new TypeError('Unknown encoding: ' + encoding)\n    }\n  } else if (typeof val === 'number') {\n    val = val & 255\n  }\n\n  // Invalid ranges are not set to a default, so can range check early.\n  if (start < 0 || this.length < start || this.length < end) {\n    throw new RangeError('Out of range index')\n  }\n\n  if (end <= start) {\n    return this\n  }\n\n  start = start >>> 0\n  end = end === undefined ? this.length : end >>> 0\n\n  if (!val) val = 0\n\n  var i\n  if (typeof val === 'number') {\n    for (i = start; i < end; ++i) {\n      this[i] = val\n    }\n  } else {\n    var bytes = Buffer.isBuffer(val)\n      ? val\n      : utf8ToBytes(new Buffer(val, encoding).toString())\n    var len = bytes.length\n    for (i = 0; i < end - start; ++i) {\n      this[i + start] = bytes[i % len]\n    }\n  }\n\n  return this\n}\n\n// HELPER FUNCTIONS\n// ================\n\nvar INVALID_BASE64_RE = /[^+\\/0-9A-Za-z-_]/g\n\nfunction base64clean (str) {\n  // Node strips out invalid characters like \\n and \\t from the string, base64-js does not\n  str = stringtrim(str).replace(INVALID_BASE64_RE, '')\n  // Node converts strings with length < 2 to ''\n  if (str.length < 2) return ''\n  // Node allows for non-padded base64 strings (missing trailing ===), base64-js does not\n  while (str.length % 4 !== 0) {\n    str = str + '='\n  }\n  return str\n}\n\nfunction stringtrim (str) {\n  if (str.trim) return str.trim()\n  return str.replace(/^\\s+|\\s+$/g, '')\n}\n\nfunction toHex (n) {\n  if (n < 16) return '0' + n.toString(16)\n  return n.toString(16)\n}\n\nfunction utf8ToBytes (string, units) {\n  units = units || Infinity\n  var codePoint\n  var length = string.length\n  var leadSurrogate = null\n  var bytes = []\n\n  for (var i = 0; i < length; ++i) {\n    codePoint = string.charCodeAt(i)\n\n    // is surrogate component\n    if (codePoint > 0xD7FF && codePoint < 0xE000) {\n      // last char was a lead\n      if (!leadSurrogate) {\n        // no lead yet\n        if (codePoint > 0xDBFF) {\n          // unexpected trail\n          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n          continue\n        } else if (i + 1 === length) {\n          // unpaired lead\n          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n          continue\n        }\n\n        // valid lead\n        leadSurrogate = codePoint\n\n        continue\n      }\n\n      // 2 leads in a row\n      if (codePoint < 0xDC00) {\n        if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n        leadSurrogate = codePoint\n        continue\n      }\n\n      // valid surrogate pair\n      codePoint = (leadSurrogate - 0xD800 << 10 | codePoint - 0xDC00) + 0x10000\n    } else if (leadSurrogate) {\n      // valid bmp char, but last char was a lead\n      if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n    }\n\n    leadSurrogate = null\n\n    // encode utf8\n    if (codePoint < 0x80) {\n      if ((units -= 1) < 0) break\n      bytes.push(codePoint)\n    } else if (codePoint < 0x800) {\n      if ((units -= 2) < 0) break\n      bytes.push(\n        codePoint >> 0x6 | 0xC0,\n        codePoint & 0x3F | 0x80\n      )\n    } else if (codePoint < 0x10000) {\n      if ((units -= 3) < 0) break\n      bytes.push(\n        codePoint >> 0xC | 0xE0,\n        codePoint >> 0x6 & 0x3F | 0x80,\n        codePoint & 0x3F | 0x80\n      )\n    } else if (codePoint < 0x110000) {\n      if ((units -= 4) < 0) break\n      bytes.push(\n        codePoint >> 0x12 | 0xF0,\n        codePoint >> 0xC & 0x3F | 0x80,\n        codePoint >> 0x6 & 0x3F | 0x80,\n        codePoint & 0x3F | 0x80\n      )\n    } else {\n      throw new Error('Invalid code point')\n    }\n  }\n\n  return bytes\n}\n\nfunction asciiToBytes (str) {\n  var byteArray = []\n  for (var i = 0; i < str.length; ++i) {\n    // Node's code seems to be doing this and not & 0x7F..\n    byteArray.push(str.charCodeAt(i) & 0xFF)\n  }\n  return byteArray\n}\n\nfunction utf16leToBytes (str, units) {\n  var c, hi, lo\n  var byteArray = []\n  for (var i = 0; i < str.length; ++i) {\n    if ((units -= 2) < 0) break\n\n    c = str.charCodeAt(i)\n    hi = c >> 8\n    lo = c % 256\n    byteArray.push(lo)\n    byteArray.push(hi)\n  }\n\n  return byteArray\n}\n\nfunction base64ToBytes (str) {\n  return base64.toByteArray(base64clean(str))\n}\n\nfunction blitBuffer (src, dst, offset, length) {\n  for (var i = 0; i < length; ++i) {\n    if ((i + offset >= dst.length) || (i >= src.length)) break\n    dst[i + offset] = src[i]\n  }\n  return i\n}\n\nfunction isnan (val) {\n  return val !== val // eslint-disable-line no-self-compare\n}\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\")))\n\n//# sourceURL=webpack:///./node_modules/buffer/index.js?");

/***/ }),

/***/ "./node_modules/dat.gui/build/dat.gui.module.js":
/*!******************************************************!*\
  !*** ./node_modules/dat.gui/build/dat.gui.module.js ***!
  \******************************************************/
/*! exports provided: color, controllers, dom, gui, GUI, default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"color\", function() { return color; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"controllers\", function() { return controllers; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"dom\", function() { return dom$1; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"gui\", function() { return gui; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"GUI\", function() { return GUI$1; });\n/**\n * dat-gui JavaScript Controller Library\n * http://code.google.com/p/dat-gui\n *\n * Copyright 2011 Data Arts Team, Google Creative Lab\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n */\n\nfunction ___$insertStyle(css) {\n  if (!css) {\n    return;\n  }\n  if (typeof window === 'undefined') {\n    return;\n  }\n\n  var style = document.createElement('style');\n\n  style.setAttribute('type', 'text/css');\n  style.innerHTML = css;\n  document.head.appendChild(style);\n\n  return css;\n}\n\nfunction colorToString (color, forceCSSHex) {\n  var colorFormat = color.__state.conversionName.toString();\n  var r = Math.round(color.r);\n  var g = Math.round(color.g);\n  var b = Math.round(color.b);\n  var a = color.a;\n  var h = Math.round(color.h);\n  var s = color.s.toFixed(1);\n  var v = color.v.toFixed(1);\n  if (forceCSSHex || colorFormat === 'THREE_CHAR_HEX' || colorFormat === 'SIX_CHAR_HEX') {\n    var str = color.hex.toString(16);\n    while (str.length < 6) {\n      str = '0' + str;\n    }\n    return '#' + str;\n  } else if (colorFormat === 'CSS_RGB') {\n    return 'rgb(' + r + ',' + g + ',' + b + ')';\n  } else if (colorFormat === 'CSS_RGBA') {\n    return 'rgba(' + r + ',' + g + ',' + b + ',' + a + ')';\n  } else if (colorFormat === 'HEX') {\n    return '0x' + color.hex.toString(16);\n  } else if (colorFormat === 'RGB_ARRAY') {\n    return '[' + r + ',' + g + ',' + b + ']';\n  } else if (colorFormat === 'RGBA_ARRAY') {\n    return '[' + r + ',' + g + ',' + b + ',' + a + ']';\n  } else if (colorFormat === 'RGB_OBJ') {\n    return '{r:' + r + ',g:' + g + ',b:' + b + '}';\n  } else if (colorFormat === 'RGBA_OBJ') {\n    return '{r:' + r + ',g:' + g + ',b:' + b + ',a:' + a + '}';\n  } else if (colorFormat === 'HSV_OBJ') {\n    return '{h:' + h + ',s:' + s + ',v:' + v + '}';\n  } else if (colorFormat === 'HSVA_OBJ') {\n    return '{h:' + h + ',s:' + s + ',v:' + v + ',a:' + a + '}';\n  }\n  return 'unknown format';\n}\n\nvar ARR_EACH = Array.prototype.forEach;\nvar ARR_SLICE = Array.prototype.slice;\nvar Common = {\n  BREAK: {},\n  extend: function extend(target) {\n    this.each(ARR_SLICE.call(arguments, 1), function (obj) {\n      var keys = this.isObject(obj) ? Object.keys(obj) : [];\n      keys.forEach(function (key) {\n        if (!this.isUndefined(obj[key])) {\n          target[key] = obj[key];\n        }\n      }.bind(this));\n    }, this);\n    return target;\n  },\n  defaults: function defaults(target) {\n    this.each(ARR_SLICE.call(arguments, 1), function (obj) {\n      var keys = this.isObject(obj) ? Object.keys(obj) : [];\n      keys.forEach(function (key) {\n        if (this.isUndefined(target[key])) {\n          target[key] = obj[key];\n        }\n      }.bind(this));\n    }, this);\n    return target;\n  },\n  compose: function compose() {\n    var toCall = ARR_SLICE.call(arguments);\n    return function () {\n      var args = ARR_SLICE.call(arguments);\n      for (var i = toCall.length - 1; i >= 0; i--) {\n        args = [toCall[i].apply(this, args)];\n      }\n      return args[0];\n    };\n  },\n  each: function each(obj, itr, scope) {\n    if (!obj) {\n      return;\n    }\n    if (ARR_EACH && obj.forEach && obj.forEach === ARR_EACH) {\n      obj.forEach(itr, scope);\n    } else if (obj.length === obj.length + 0) {\n      var key = void 0;\n      var l = void 0;\n      for (key = 0, l = obj.length; key < l; key++) {\n        if (key in obj && itr.call(scope, obj[key], key) === this.BREAK) {\n          return;\n        }\n      }\n    } else {\n      for (var _key in obj) {\n        if (itr.call(scope, obj[_key], _key) === this.BREAK) {\n          return;\n        }\n      }\n    }\n  },\n  defer: function defer(fnc) {\n    setTimeout(fnc, 0);\n  },\n  debounce: function debounce(func, threshold, callImmediately) {\n    var timeout = void 0;\n    return function () {\n      var obj = this;\n      var args = arguments;\n      function delayed() {\n        timeout = null;\n        if (!callImmediately) func.apply(obj, args);\n      }\n      var callNow = callImmediately || !timeout;\n      clearTimeout(timeout);\n      timeout = setTimeout(delayed, threshold);\n      if (callNow) {\n        func.apply(obj, args);\n      }\n    };\n  },\n  toArray: function toArray(obj) {\n    if (obj.toArray) return obj.toArray();\n    return ARR_SLICE.call(obj);\n  },\n  isUndefined: function isUndefined(obj) {\n    return obj === undefined;\n  },\n  isNull: function isNull(obj) {\n    return obj === null;\n  },\n  isNaN: function (_isNaN) {\n    function isNaN(_x) {\n      return _isNaN.apply(this, arguments);\n    }\n    isNaN.toString = function () {\n      return _isNaN.toString();\n    };\n    return isNaN;\n  }(function (obj) {\n    return isNaN(obj);\n  }),\n  isArray: Array.isArray || function (obj) {\n    return obj.constructor === Array;\n  },\n  isObject: function isObject(obj) {\n    return obj === Object(obj);\n  },\n  isNumber: function isNumber(obj) {\n    return obj === obj + 0;\n  },\n  isString: function isString(obj) {\n    return obj === obj + '';\n  },\n  isBoolean: function isBoolean(obj) {\n    return obj === false || obj === true;\n  },\n  isFunction: function isFunction(obj) {\n    return Object.prototype.toString.call(obj) === '[object Function]';\n  }\n};\n\nvar INTERPRETATIONS = [\n{\n  litmus: Common.isString,\n  conversions: {\n    THREE_CHAR_HEX: {\n      read: function read(original) {\n        var test = original.match(/^#([A-F0-9])([A-F0-9])([A-F0-9])$/i);\n        if (test === null) {\n          return false;\n        }\n        return {\n          space: 'HEX',\n          hex: parseInt('0x' + test[1].toString() + test[1].toString() + test[2].toString() + test[2].toString() + test[3].toString() + test[3].toString(), 0)\n        };\n      },\n      write: colorToString\n    },\n    SIX_CHAR_HEX: {\n      read: function read(original) {\n        var test = original.match(/^#([A-F0-9]{6})$/i);\n        if (test === null) {\n          return false;\n        }\n        return {\n          space: 'HEX',\n          hex: parseInt('0x' + test[1].toString(), 0)\n        };\n      },\n      write: colorToString\n    },\n    CSS_RGB: {\n      read: function read(original) {\n        var test = original.match(/^rgb\\(\\s*(.+)\\s*,\\s*(.+)\\s*,\\s*(.+)\\s*\\)/);\n        if (test === null) {\n          return false;\n        }\n        return {\n          space: 'RGB',\n          r: parseFloat(test[1]),\n          g: parseFloat(test[2]),\n          b: parseFloat(test[3])\n        };\n      },\n      write: colorToString\n    },\n    CSS_RGBA: {\n      read: function read(original) {\n        var test = original.match(/^rgba\\(\\s*(.+)\\s*,\\s*(.+)\\s*,\\s*(.+)\\s*,\\s*(.+)\\s*\\)/);\n        if (test === null) {\n          return false;\n        }\n        return {\n          space: 'RGB',\n          r: parseFloat(test[1]),\n          g: parseFloat(test[2]),\n          b: parseFloat(test[3]),\n          a: parseFloat(test[4])\n        };\n      },\n      write: colorToString\n    }\n  }\n},\n{\n  litmus: Common.isNumber,\n  conversions: {\n    HEX: {\n      read: function read(original) {\n        return {\n          space: 'HEX',\n          hex: original,\n          conversionName: 'HEX'\n        };\n      },\n      write: function write(color) {\n        return color.hex;\n      }\n    }\n  }\n},\n{\n  litmus: Common.isArray,\n  conversions: {\n    RGB_ARRAY: {\n      read: function read(original) {\n        if (original.length !== 3) {\n          return false;\n        }\n        return {\n          space: 'RGB',\n          r: original[0],\n          g: original[1],\n          b: original[2]\n        };\n      },\n      write: function write(color) {\n        return [color.r, color.g, color.b];\n      }\n    },\n    RGBA_ARRAY: {\n      read: function read(original) {\n        if (original.length !== 4) return false;\n        return {\n          space: 'RGB',\n          r: original[0],\n          g: original[1],\n          b: original[2],\n          a: original[3]\n        };\n      },\n      write: function write(color) {\n        return [color.r, color.g, color.b, color.a];\n      }\n    }\n  }\n},\n{\n  litmus: Common.isObject,\n  conversions: {\n    RGBA_OBJ: {\n      read: function read(original) {\n        if (Common.isNumber(original.r) && Common.isNumber(original.g) && Common.isNumber(original.b) && Common.isNumber(original.a)) {\n          return {\n            space: 'RGB',\n            r: original.r,\n            g: original.g,\n            b: original.b,\n            a: original.a\n          };\n        }\n        return false;\n      },\n      write: function write(color) {\n        return {\n          r: color.r,\n          g: color.g,\n          b: color.b,\n          a: color.a\n        };\n      }\n    },\n    RGB_OBJ: {\n      read: function read(original) {\n        if (Common.isNumber(original.r) && Common.isNumber(original.g) && Common.isNumber(original.b)) {\n          return {\n            space: 'RGB',\n            r: original.r,\n            g: original.g,\n            b: original.b\n          };\n        }\n        return false;\n      },\n      write: function write(color) {\n        return {\n          r: color.r,\n          g: color.g,\n          b: color.b\n        };\n      }\n    },\n    HSVA_OBJ: {\n      read: function read(original) {\n        if (Common.isNumber(original.h) && Common.isNumber(original.s) && Common.isNumber(original.v) && Common.isNumber(original.a)) {\n          return {\n            space: 'HSV',\n            h: original.h,\n            s: original.s,\n            v: original.v,\n            a: original.a\n          };\n        }\n        return false;\n      },\n      write: function write(color) {\n        return {\n          h: color.h,\n          s: color.s,\n          v: color.v,\n          a: color.a\n        };\n      }\n    },\n    HSV_OBJ: {\n      read: function read(original) {\n        if (Common.isNumber(original.h) && Common.isNumber(original.s) && Common.isNumber(original.v)) {\n          return {\n            space: 'HSV',\n            h: original.h,\n            s: original.s,\n            v: original.v\n          };\n        }\n        return false;\n      },\n      write: function write(color) {\n        return {\n          h: color.h,\n          s: color.s,\n          v: color.v\n        };\n      }\n    }\n  }\n}];\nvar result = void 0;\nvar toReturn = void 0;\nvar interpret = function interpret() {\n  toReturn = false;\n  var original = arguments.length > 1 ? Common.toArray(arguments) : arguments[0];\n  Common.each(INTERPRETATIONS, function (family) {\n    if (family.litmus(original)) {\n      Common.each(family.conversions, function (conversion, conversionName) {\n        result = conversion.read(original);\n        if (toReturn === false && result !== false) {\n          toReturn = result;\n          result.conversionName = conversionName;\n          result.conversion = conversion;\n          return Common.BREAK;\n        }\n      });\n      return Common.BREAK;\n    }\n  });\n  return toReturn;\n};\n\nvar tmpComponent = void 0;\nvar ColorMath = {\n  hsv_to_rgb: function hsv_to_rgb(h, s, v) {\n    var hi = Math.floor(h / 60) % 6;\n    var f = h / 60 - Math.floor(h / 60);\n    var p = v * (1.0 - s);\n    var q = v * (1.0 - f * s);\n    var t = v * (1.0 - (1.0 - f) * s);\n    var c = [[v, t, p], [q, v, p], [p, v, t], [p, q, v], [t, p, v], [v, p, q]][hi];\n    return {\n      r: c[0] * 255,\n      g: c[1] * 255,\n      b: c[2] * 255\n    };\n  },\n  rgb_to_hsv: function rgb_to_hsv(r, g, b) {\n    var min = Math.min(r, g, b);\n    var max = Math.max(r, g, b);\n    var delta = max - min;\n    var h = void 0;\n    var s = void 0;\n    if (max !== 0) {\n      s = delta / max;\n    } else {\n      return {\n        h: NaN,\n        s: 0,\n        v: 0\n      };\n    }\n    if (r === max) {\n      h = (g - b) / delta;\n    } else if (g === max) {\n      h = 2 + (b - r) / delta;\n    } else {\n      h = 4 + (r - g) / delta;\n    }\n    h /= 6;\n    if (h < 0) {\n      h += 1;\n    }\n    return {\n      h: h * 360,\n      s: s,\n      v: max / 255\n    };\n  },\n  rgb_to_hex: function rgb_to_hex(r, g, b) {\n    var hex = this.hex_with_component(0, 2, r);\n    hex = this.hex_with_component(hex, 1, g);\n    hex = this.hex_with_component(hex, 0, b);\n    return hex;\n  },\n  component_from_hex: function component_from_hex(hex, componentIndex) {\n    return hex >> componentIndex * 8 & 0xFF;\n  },\n  hex_with_component: function hex_with_component(hex, componentIndex, value) {\n    return value << (tmpComponent = componentIndex * 8) | hex & ~(0xFF << tmpComponent);\n  }\n};\n\nvar _typeof = typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\" ? function (obj) {\n  return typeof obj;\n} : function (obj) {\n  return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj;\n};\n\n\n\n\n\n\n\n\n\n\n\nvar classCallCheck = function (instance, Constructor) {\n  if (!(instance instanceof Constructor)) {\n    throw new TypeError(\"Cannot call a class as a function\");\n  }\n};\n\nvar createClass = function () {\n  function defineProperties(target, props) {\n    for (var i = 0; i < props.length; i++) {\n      var descriptor = props[i];\n      descriptor.enumerable = descriptor.enumerable || false;\n      descriptor.configurable = true;\n      if (\"value\" in descriptor) descriptor.writable = true;\n      Object.defineProperty(target, descriptor.key, descriptor);\n    }\n  }\n\n  return function (Constructor, protoProps, staticProps) {\n    if (protoProps) defineProperties(Constructor.prototype, protoProps);\n    if (staticProps) defineProperties(Constructor, staticProps);\n    return Constructor;\n  };\n}();\n\n\n\n\n\n\n\nvar get = function get(object, property, receiver) {\n  if (object === null) object = Function.prototype;\n  var desc = Object.getOwnPropertyDescriptor(object, property);\n\n  if (desc === undefined) {\n    var parent = Object.getPrototypeOf(object);\n\n    if (parent === null) {\n      return undefined;\n    } else {\n      return get(parent, property, receiver);\n    }\n  } else if (\"value\" in desc) {\n    return desc.value;\n  } else {\n    var getter = desc.get;\n\n    if (getter === undefined) {\n      return undefined;\n    }\n\n    return getter.call(receiver);\n  }\n};\n\nvar inherits = function (subClass, superClass) {\n  if (typeof superClass !== \"function\" && superClass !== null) {\n    throw new TypeError(\"Super expression must either be null or a function, not \" + typeof superClass);\n  }\n\n  subClass.prototype = Object.create(superClass && superClass.prototype, {\n    constructor: {\n      value: subClass,\n      enumerable: false,\n      writable: true,\n      configurable: true\n    }\n  });\n  if (superClass) Object.setPrototypeOf ? Object.setPrototypeOf(subClass, superClass) : subClass.__proto__ = superClass;\n};\n\n\n\n\n\n\n\n\n\n\n\nvar possibleConstructorReturn = function (self, call) {\n  if (!self) {\n    throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");\n  }\n\n  return call && (typeof call === \"object\" || typeof call === \"function\") ? call : self;\n};\n\nvar Color = function () {\n  function Color() {\n    classCallCheck(this, Color);\n    this.__state = interpret.apply(this, arguments);\n    if (this.__state === false) {\n      throw new Error('Failed to interpret color arguments');\n    }\n    this.__state.a = this.__state.a || 1;\n  }\n  createClass(Color, [{\n    key: 'toString',\n    value: function toString() {\n      return colorToString(this);\n    }\n  }, {\n    key: 'toHexString',\n    value: function toHexString() {\n      return colorToString(this, true);\n    }\n  }, {\n    key: 'toOriginal',\n    value: function toOriginal() {\n      return this.__state.conversion.write(this);\n    }\n  }]);\n  return Color;\n}();\nfunction defineRGBComponent(target, component, componentHexIndex) {\n  Object.defineProperty(target, component, {\n    get: function get$$1() {\n      if (this.__state.space === 'RGB') {\n        return this.__state[component];\n      }\n      Color.recalculateRGB(this, component, componentHexIndex);\n      return this.__state[component];\n    },\n    set: function set$$1(v) {\n      if (this.__state.space !== 'RGB') {\n        Color.recalculateRGB(this, component, componentHexIndex);\n        this.__state.space = 'RGB';\n      }\n      this.__state[component] = v;\n    }\n  });\n}\nfunction defineHSVComponent(target, component) {\n  Object.defineProperty(target, component, {\n    get: function get$$1() {\n      if (this.__state.space === 'HSV') {\n        return this.__state[component];\n      }\n      Color.recalculateHSV(this);\n      return this.__state[component];\n    },\n    set: function set$$1(v) {\n      if (this.__state.space !== 'HSV') {\n        Color.recalculateHSV(this);\n        this.__state.space = 'HSV';\n      }\n      this.__state[component] = v;\n    }\n  });\n}\nColor.recalculateRGB = function (color, component, componentHexIndex) {\n  if (color.__state.space === 'HEX') {\n    color.__state[component] = ColorMath.component_from_hex(color.__state.hex, componentHexIndex);\n  } else if (color.__state.space === 'HSV') {\n    Common.extend(color.__state, ColorMath.hsv_to_rgb(color.__state.h, color.__state.s, color.__state.v));\n  } else {\n    throw new Error('Corrupted color state');\n  }\n};\nColor.recalculateHSV = function (color) {\n  var result = ColorMath.rgb_to_hsv(color.r, color.g, color.b);\n  Common.extend(color.__state, {\n    s: result.s,\n    v: result.v\n  });\n  if (!Common.isNaN(result.h)) {\n    color.__state.h = result.h;\n  } else if (Common.isUndefined(color.__state.h)) {\n    color.__state.h = 0;\n  }\n};\nColor.COMPONENTS = ['r', 'g', 'b', 'h', 's', 'v', 'hex', 'a'];\ndefineRGBComponent(Color.prototype, 'r', 2);\ndefineRGBComponent(Color.prototype, 'g', 1);\ndefineRGBComponent(Color.prototype, 'b', 0);\ndefineHSVComponent(Color.prototype, 'h');\ndefineHSVComponent(Color.prototype, 's');\ndefineHSVComponent(Color.prototype, 'v');\nObject.defineProperty(Color.prototype, 'a', {\n  get: function get$$1() {\n    return this.__state.a;\n  },\n  set: function set$$1(v) {\n    this.__state.a = v;\n  }\n});\nObject.defineProperty(Color.prototype, 'hex', {\n  get: function get$$1() {\n    if (!this.__state.space !== 'HEX') {\n      this.__state.hex = ColorMath.rgb_to_hex(this.r, this.g, this.b);\n    }\n    return this.__state.hex;\n  },\n  set: function set$$1(v) {\n    this.__state.space = 'HEX';\n    this.__state.hex = v;\n  }\n});\n\nvar Controller = function () {\n  function Controller(object, property) {\n    classCallCheck(this, Controller);\n    this.initialValue = object[property];\n    this.domElement = document.createElement('div');\n    this.object = object;\n    this.property = property;\n    this.__onChange = undefined;\n    this.__onFinishChange = undefined;\n  }\n  createClass(Controller, [{\n    key: 'onChange',\n    value: function onChange(fnc) {\n      this.__onChange = fnc;\n      return this;\n    }\n  }, {\n    key: 'onFinishChange',\n    value: function onFinishChange(fnc) {\n      this.__onFinishChange = fnc;\n      return this;\n    }\n  }, {\n    key: 'setValue',\n    value: function setValue(newValue) {\n      this.object[this.property] = newValue;\n      if (this.__onChange) {\n        this.__onChange.call(this, newValue);\n      }\n      this.updateDisplay();\n      return this;\n    }\n  }, {\n    key: 'getValue',\n    value: function getValue() {\n      return this.object[this.property];\n    }\n  }, {\n    key: 'updateDisplay',\n    value: function updateDisplay() {\n      return this;\n    }\n  }, {\n    key: 'isModified',\n    value: function isModified() {\n      return this.initialValue !== this.getValue();\n    }\n  }]);\n  return Controller;\n}();\n\nvar EVENT_MAP = {\n  HTMLEvents: ['change'],\n  MouseEvents: ['click', 'mousemove', 'mousedown', 'mouseup', 'mouseover'],\n  KeyboardEvents: ['keydown']\n};\nvar EVENT_MAP_INV = {};\nCommon.each(EVENT_MAP, function (v, k) {\n  Common.each(v, function (e) {\n    EVENT_MAP_INV[e] = k;\n  });\n});\nvar CSS_VALUE_PIXELS = /(\\d+(\\.\\d+)?)px/;\nfunction cssValueToPixels(val) {\n  if (val === '0' || Common.isUndefined(val)) {\n    return 0;\n  }\n  var match = val.match(CSS_VALUE_PIXELS);\n  if (!Common.isNull(match)) {\n    return parseFloat(match[1]);\n  }\n  return 0;\n}\nvar dom = {\n  makeSelectable: function makeSelectable(elem, selectable) {\n    if (elem === undefined || elem.style === undefined) return;\n    elem.onselectstart = selectable ? function () {\n      return false;\n    } : function () {};\n    elem.style.MozUserSelect = selectable ? 'auto' : 'none';\n    elem.style.KhtmlUserSelect = selectable ? 'auto' : 'none';\n    elem.unselectable = selectable ? 'on' : 'off';\n  },\n  makeFullscreen: function makeFullscreen(elem, hor, vert) {\n    var vertical = vert;\n    var horizontal = hor;\n    if (Common.isUndefined(horizontal)) {\n      horizontal = true;\n    }\n    if (Common.isUndefined(vertical)) {\n      vertical = true;\n    }\n    elem.style.position = 'absolute';\n    if (horizontal) {\n      elem.style.left = 0;\n      elem.style.right = 0;\n    }\n    if (vertical) {\n      elem.style.top = 0;\n      elem.style.bottom = 0;\n    }\n  },\n  fakeEvent: function fakeEvent(elem, eventType, pars, aux) {\n    var params = pars || {};\n    var className = EVENT_MAP_INV[eventType];\n    if (!className) {\n      throw new Error('Event type ' + eventType + ' not supported.');\n    }\n    var evt = document.createEvent(className);\n    switch (className) {\n      case 'MouseEvents':\n        {\n          var clientX = params.x || params.clientX || 0;\n          var clientY = params.y || params.clientY || 0;\n          evt.initMouseEvent(eventType, params.bubbles || false, params.cancelable || true, window, params.clickCount || 1, 0,\n          0,\n          clientX,\n          clientY,\n          false, false, false, false, 0, null);\n          break;\n        }\n      case 'KeyboardEvents':\n        {\n          var init = evt.initKeyboardEvent || evt.initKeyEvent;\n          Common.defaults(params, {\n            cancelable: true,\n            ctrlKey: false,\n            altKey: false,\n            shiftKey: false,\n            metaKey: false,\n            keyCode: undefined,\n            charCode: undefined\n          });\n          init(eventType, params.bubbles || false, params.cancelable, window, params.ctrlKey, params.altKey, params.shiftKey, params.metaKey, params.keyCode, params.charCode);\n          break;\n        }\n      default:\n        {\n          evt.initEvent(eventType, params.bubbles || false, params.cancelable || true);\n          break;\n        }\n    }\n    Common.defaults(evt, aux);\n    elem.dispatchEvent(evt);\n  },\n  bind: function bind(elem, event, func, newBool) {\n    var bool = newBool || false;\n    if (elem.addEventListener) {\n      elem.addEventListener(event, func, bool);\n    } else if (elem.attachEvent) {\n      elem.attachEvent('on' + event, func);\n    }\n    return dom;\n  },\n  unbind: function unbind(elem, event, func, newBool) {\n    var bool = newBool || false;\n    if (elem.removeEventListener) {\n      elem.removeEventListener(event, func, bool);\n    } else if (elem.detachEvent) {\n      elem.detachEvent('on' + event, func);\n    }\n    return dom;\n  },\n  addClass: function addClass(elem, className) {\n    if (elem.className === undefined) {\n      elem.className = className;\n    } else if (elem.className !== className) {\n      var classes = elem.className.split(/ +/);\n      if (classes.indexOf(className) === -1) {\n        classes.push(className);\n        elem.className = classes.join(' ').replace(/^\\s+/, '').replace(/\\s+$/, '');\n      }\n    }\n    return dom;\n  },\n  removeClass: function removeClass(elem, className) {\n    if (className) {\n      if (elem.className === className) {\n        elem.removeAttribute('class');\n      } else {\n        var classes = elem.className.split(/ +/);\n        var index = classes.indexOf(className);\n        if (index !== -1) {\n          classes.splice(index, 1);\n          elem.className = classes.join(' ');\n        }\n      }\n    } else {\n      elem.className = undefined;\n    }\n    return dom;\n  },\n  hasClass: function hasClass(elem, className) {\n    return new RegExp('(?:^|\\\\s+)' + className + '(?:\\\\s+|$)').test(elem.className) || false;\n  },\n  getWidth: function getWidth(elem) {\n    var style = getComputedStyle(elem);\n    return cssValueToPixels(style['border-left-width']) + cssValueToPixels(style['border-right-width']) + cssValueToPixels(style['padding-left']) + cssValueToPixels(style['padding-right']) + cssValueToPixels(style.width);\n  },\n  getHeight: function getHeight(elem) {\n    var style = getComputedStyle(elem);\n    return cssValueToPixels(style['border-top-width']) + cssValueToPixels(style['border-bottom-width']) + cssValueToPixels(style['padding-top']) + cssValueToPixels(style['padding-bottom']) + cssValueToPixels(style.height);\n  },\n  getOffset: function getOffset(el) {\n    var elem = el;\n    var offset = { left: 0, top: 0 };\n    if (elem.offsetParent) {\n      do {\n        offset.left += elem.offsetLeft;\n        offset.top += elem.offsetTop;\n        elem = elem.offsetParent;\n      } while (elem);\n    }\n    return offset;\n  },\n  isActive: function isActive(elem) {\n    return elem === document.activeElement && (elem.type || elem.href);\n  }\n};\n\nvar BooleanController = function (_Controller) {\n  inherits(BooleanController, _Controller);\n  function BooleanController(object, property) {\n    classCallCheck(this, BooleanController);\n    var _this2 = possibleConstructorReturn(this, (BooleanController.__proto__ || Object.getPrototypeOf(BooleanController)).call(this, object, property));\n    var _this = _this2;\n    _this2.__prev = _this2.getValue();\n    _this2.__checkbox = document.createElement('input');\n    _this2.__checkbox.setAttribute('type', 'checkbox');\n    function onChange() {\n      _this.setValue(!_this.__prev);\n    }\n    dom.bind(_this2.__checkbox, 'change', onChange, false);\n    _this2.domElement.appendChild(_this2.__checkbox);\n    _this2.updateDisplay();\n    return _this2;\n  }\n  createClass(BooleanController, [{\n    key: 'setValue',\n    value: function setValue(v) {\n      var toReturn = get(BooleanController.prototype.__proto__ || Object.getPrototypeOf(BooleanController.prototype), 'setValue', this).call(this, v);\n      if (this.__onFinishChange) {\n        this.__onFinishChange.call(this, this.getValue());\n      }\n      this.__prev = this.getValue();\n      return toReturn;\n    }\n  }, {\n    key: 'updateDisplay',\n    value: function updateDisplay() {\n      if (this.getValue() === true) {\n        this.__checkbox.setAttribute('checked', 'checked');\n        this.__checkbox.checked = true;\n        this.__prev = true;\n      } else {\n        this.__checkbox.checked = false;\n        this.__prev = false;\n      }\n      return get(BooleanController.prototype.__proto__ || Object.getPrototypeOf(BooleanController.prototype), 'updateDisplay', this).call(this);\n    }\n  }]);\n  return BooleanController;\n}(Controller);\n\nvar OptionController = function (_Controller) {\n  inherits(OptionController, _Controller);\n  function OptionController(object, property, opts) {\n    classCallCheck(this, OptionController);\n    var _this2 = possibleConstructorReturn(this, (OptionController.__proto__ || Object.getPrototypeOf(OptionController)).call(this, object, property));\n    var options = opts;\n    var _this = _this2;\n    _this2.__select = document.createElement('select');\n    if (Common.isArray(options)) {\n      var map = {};\n      Common.each(options, function (element) {\n        map[element] = element;\n      });\n      options = map;\n    }\n    Common.each(options, function (value, key) {\n      var opt = document.createElement('option');\n      opt.innerHTML = key;\n      opt.setAttribute('value', value);\n      _this.__select.appendChild(opt);\n    });\n    _this2.updateDisplay();\n    dom.bind(_this2.__select, 'change', function () {\n      var desiredValue = this.options[this.selectedIndex].value;\n      _this.setValue(desiredValue);\n    });\n    _this2.domElement.appendChild(_this2.__select);\n    return _this2;\n  }\n  createClass(OptionController, [{\n    key: 'setValue',\n    value: function setValue(v) {\n      var toReturn = get(OptionController.prototype.__proto__ || Object.getPrototypeOf(OptionController.prototype), 'setValue', this).call(this, v);\n      if (this.__onFinishChange) {\n        this.__onFinishChange.call(this, this.getValue());\n      }\n      return toReturn;\n    }\n  }, {\n    key: 'updateDisplay',\n    value: function updateDisplay() {\n      if (dom.isActive(this.__select)) return this;\n      this.__select.value = this.getValue();\n      return get(OptionController.prototype.__proto__ || Object.getPrototypeOf(OptionController.prototype), 'updateDisplay', this).call(this);\n    }\n  }]);\n  return OptionController;\n}(Controller);\n\nvar StringController = function (_Controller) {\n  inherits(StringController, _Controller);\n  function StringController(object, property) {\n    classCallCheck(this, StringController);\n    var _this2 = possibleConstructorReturn(this, (StringController.__proto__ || Object.getPrototypeOf(StringController)).call(this, object, property));\n    var _this = _this2;\n    function onChange() {\n      _this.setValue(_this.__input.value);\n    }\n    function onBlur() {\n      if (_this.__onFinishChange) {\n        _this.__onFinishChange.call(_this, _this.getValue());\n      }\n    }\n    _this2.__input = document.createElement('input');\n    _this2.__input.setAttribute('type', 'text');\n    dom.bind(_this2.__input, 'keyup', onChange);\n    dom.bind(_this2.__input, 'change', onChange);\n    dom.bind(_this2.__input, 'blur', onBlur);\n    dom.bind(_this2.__input, 'keydown', function (e) {\n      if (e.keyCode === 13) {\n        this.blur();\n      }\n    });\n    _this2.updateDisplay();\n    _this2.domElement.appendChild(_this2.__input);\n    return _this2;\n  }\n  createClass(StringController, [{\n    key: 'updateDisplay',\n    value: function updateDisplay() {\n      if (!dom.isActive(this.__input)) {\n        this.__input.value = this.getValue();\n      }\n      return get(StringController.prototype.__proto__ || Object.getPrototypeOf(StringController.prototype), 'updateDisplay', this).call(this);\n    }\n  }]);\n  return StringController;\n}(Controller);\n\nfunction numDecimals(x) {\n  var _x = x.toString();\n  if (_x.indexOf('.') > -1) {\n    return _x.length - _x.indexOf('.') - 1;\n  }\n  return 0;\n}\nvar NumberController = function (_Controller) {\n  inherits(NumberController, _Controller);\n  function NumberController(object, property, params) {\n    classCallCheck(this, NumberController);\n    var _this = possibleConstructorReturn(this, (NumberController.__proto__ || Object.getPrototypeOf(NumberController)).call(this, object, property));\n    var _params = params || {};\n    _this.__min = _params.min;\n    _this.__max = _params.max;\n    _this.__step = _params.step;\n    if (Common.isUndefined(_this.__step)) {\n      if (_this.initialValue === 0) {\n        _this.__impliedStep = 1;\n      } else {\n        _this.__impliedStep = Math.pow(10, Math.floor(Math.log(Math.abs(_this.initialValue)) / Math.LN10)) / 10;\n      }\n    } else {\n      _this.__impliedStep = _this.__step;\n    }\n    _this.__precision = numDecimals(_this.__impliedStep);\n    return _this;\n  }\n  createClass(NumberController, [{\n    key: 'setValue',\n    value: function setValue(v) {\n      var _v = v;\n      if (this.__min !== undefined && _v < this.__min) {\n        _v = this.__min;\n      } else if (this.__max !== undefined && _v > this.__max) {\n        _v = this.__max;\n      }\n      if (this.__step !== undefined && _v % this.__step !== 0) {\n        _v = Math.round(_v / this.__step) * this.__step;\n      }\n      return get(NumberController.prototype.__proto__ || Object.getPrototypeOf(NumberController.prototype), 'setValue', this).call(this, _v);\n    }\n  }, {\n    key: 'min',\n    value: function min(minValue) {\n      this.__min = minValue;\n      return this;\n    }\n  }, {\n    key: 'max',\n    value: function max(maxValue) {\n      this.__max = maxValue;\n      return this;\n    }\n  }, {\n    key: 'step',\n    value: function step(stepValue) {\n      this.__step = stepValue;\n      this.__impliedStep = stepValue;\n      this.__precision = numDecimals(stepValue);\n      return this;\n    }\n  }]);\n  return NumberController;\n}(Controller);\n\nfunction roundToDecimal(value, decimals) {\n  var tenTo = Math.pow(10, decimals);\n  return Math.round(value * tenTo) / tenTo;\n}\nvar NumberControllerBox = function (_NumberController) {\n  inherits(NumberControllerBox, _NumberController);\n  function NumberControllerBox(object, property, params) {\n    classCallCheck(this, NumberControllerBox);\n    var _this2 = possibleConstructorReturn(this, (NumberControllerBox.__proto__ || Object.getPrototypeOf(NumberControllerBox)).call(this, object, property, params));\n    _this2.__truncationSuspended = false;\n    var _this = _this2;\n    var prevY = void 0;\n    function onChange() {\n      var attempted = parseFloat(_this.__input.value);\n      if (!Common.isNaN(attempted)) {\n        _this.setValue(attempted);\n      }\n    }\n    function onFinish() {\n      if (_this.__onFinishChange) {\n        _this.__onFinishChange.call(_this, _this.getValue());\n      }\n    }\n    function onBlur() {\n      onFinish();\n    }\n    function onMouseDrag(e) {\n      var diff = prevY - e.clientY;\n      _this.setValue(_this.getValue() + diff * _this.__impliedStep);\n      prevY = e.clientY;\n    }\n    function onMouseUp() {\n      dom.unbind(window, 'mousemove', onMouseDrag);\n      dom.unbind(window, 'mouseup', onMouseUp);\n      onFinish();\n    }\n    function onMouseDown(e) {\n      dom.bind(window, 'mousemove', onMouseDrag);\n      dom.bind(window, 'mouseup', onMouseUp);\n      prevY = e.clientY;\n    }\n    _this2.__input = document.createElement('input');\n    _this2.__input.setAttribute('type', 'text');\n    dom.bind(_this2.__input, 'change', onChange);\n    dom.bind(_this2.__input, 'blur', onBlur);\n    dom.bind(_this2.__input, 'mousedown', onMouseDown);\n    dom.bind(_this2.__input, 'keydown', function (e) {\n      if (e.keyCode === 13) {\n        _this.__truncationSuspended = true;\n        this.blur();\n        _this.__truncationSuspended = false;\n        onFinish();\n      }\n    });\n    _this2.updateDisplay();\n    _this2.domElement.appendChild(_this2.__input);\n    return _this2;\n  }\n  createClass(NumberControllerBox, [{\n    key: 'updateDisplay',\n    value: function updateDisplay() {\n      this.__input.value = this.__truncationSuspended ? this.getValue() : roundToDecimal(this.getValue(), this.__precision);\n      return get(NumberControllerBox.prototype.__proto__ || Object.getPrototypeOf(NumberControllerBox.prototype), 'updateDisplay', this).call(this);\n    }\n  }]);\n  return NumberControllerBox;\n}(NumberController);\n\nfunction map(v, i1, i2, o1, o2) {\n  return o1 + (o2 - o1) * ((v - i1) / (i2 - i1));\n}\nvar NumberControllerSlider = function (_NumberController) {\n  inherits(NumberControllerSlider, _NumberController);\n  function NumberControllerSlider(object, property, min, max, step) {\n    classCallCheck(this, NumberControllerSlider);\n    var _this2 = possibleConstructorReturn(this, (NumberControllerSlider.__proto__ || Object.getPrototypeOf(NumberControllerSlider)).call(this, object, property, { min: min, max: max, step: step }));\n    var _this = _this2;\n    _this2.__background = document.createElement('div');\n    _this2.__foreground = document.createElement('div');\n    dom.bind(_this2.__background, 'mousedown', onMouseDown);\n    dom.bind(_this2.__background, 'touchstart', onTouchStart);\n    dom.addClass(_this2.__background, 'slider');\n    dom.addClass(_this2.__foreground, 'slider-fg');\n    function onMouseDown(e) {\n      document.activeElement.blur();\n      dom.bind(window, 'mousemove', onMouseDrag);\n      dom.bind(window, 'mouseup', onMouseUp);\n      onMouseDrag(e);\n    }\n    function onMouseDrag(e) {\n      e.preventDefault();\n      var bgRect = _this.__background.getBoundingClientRect();\n      _this.setValue(map(e.clientX, bgRect.left, bgRect.right, _this.__min, _this.__max));\n      return false;\n    }\n    function onMouseUp() {\n      dom.unbind(window, 'mousemove', onMouseDrag);\n      dom.unbind(window, 'mouseup', onMouseUp);\n      if (_this.__onFinishChange) {\n        _this.__onFinishChange.call(_this, _this.getValue());\n      }\n    }\n    function onTouchStart(e) {\n      if (e.touches.length !== 1) {\n        return;\n      }\n      dom.bind(window, 'touchmove', onTouchMove);\n      dom.bind(window, 'touchend', onTouchEnd);\n      onTouchMove(e);\n    }\n    function onTouchMove(e) {\n      var clientX = e.touches[0].clientX;\n      var bgRect = _this.__background.getBoundingClientRect();\n      _this.setValue(map(clientX, bgRect.left, bgRect.right, _this.__min, _this.__max));\n    }\n    function onTouchEnd() {\n      dom.unbind(window, 'touchmove', onTouchMove);\n      dom.unbind(window, 'touchend', onTouchEnd);\n      if (_this.__onFinishChange) {\n        _this.__onFinishChange.call(_this, _this.getValue());\n      }\n    }\n    _this2.updateDisplay();\n    _this2.__background.appendChild(_this2.__foreground);\n    _this2.domElement.appendChild(_this2.__background);\n    return _this2;\n  }\n  createClass(NumberControllerSlider, [{\n    key: 'updateDisplay',\n    value: function updateDisplay() {\n      var pct = (this.getValue() - this.__min) / (this.__max - this.__min);\n      this.__foreground.style.width = pct * 100 + '%';\n      return get(NumberControllerSlider.prototype.__proto__ || Object.getPrototypeOf(NumberControllerSlider.prototype), 'updateDisplay', this).call(this);\n    }\n  }]);\n  return NumberControllerSlider;\n}(NumberController);\n\nvar FunctionController = function (_Controller) {\n  inherits(FunctionController, _Controller);\n  function FunctionController(object, property, text) {\n    classCallCheck(this, FunctionController);\n    var _this2 = possibleConstructorReturn(this, (FunctionController.__proto__ || Object.getPrototypeOf(FunctionController)).call(this, object, property));\n    var _this = _this2;\n    _this2.__button = document.createElement('div');\n    _this2.__button.innerHTML = text === undefined ? 'Fire' : text;\n    dom.bind(_this2.__button, 'click', function (e) {\n      e.preventDefault();\n      _this.fire();\n      return false;\n    });\n    dom.addClass(_this2.__button, 'button');\n    _this2.domElement.appendChild(_this2.__button);\n    return _this2;\n  }\n  createClass(FunctionController, [{\n    key: 'fire',\n    value: function fire() {\n      if (this.__onChange) {\n        this.__onChange.call(this);\n      }\n      this.getValue().call(this.object);\n      if (this.__onFinishChange) {\n        this.__onFinishChange.call(this, this.getValue());\n      }\n    }\n  }]);\n  return FunctionController;\n}(Controller);\n\nvar ColorController = function (_Controller) {\n  inherits(ColorController, _Controller);\n  function ColorController(object, property) {\n    classCallCheck(this, ColorController);\n    var _this2 = possibleConstructorReturn(this, (ColorController.__proto__ || Object.getPrototypeOf(ColorController)).call(this, object, property));\n    _this2.__color = new Color(_this2.getValue());\n    _this2.__temp = new Color(0);\n    var _this = _this2;\n    _this2.domElement = document.createElement('div');\n    dom.makeSelectable(_this2.domElement, false);\n    _this2.__selector = document.createElement('div');\n    _this2.__selector.className = 'selector';\n    _this2.__saturation_field = document.createElement('div');\n    _this2.__saturation_field.className = 'saturation-field';\n    _this2.__field_knob = document.createElement('div');\n    _this2.__field_knob.className = 'field-knob';\n    _this2.__field_knob_border = '2px solid ';\n    _this2.__hue_knob = document.createElement('div');\n    _this2.__hue_knob.className = 'hue-knob';\n    _this2.__hue_field = document.createElement('div');\n    _this2.__hue_field.className = 'hue-field';\n    _this2.__input = document.createElement('input');\n    _this2.__input.type = 'text';\n    _this2.__input_textShadow = '0 1px 1px ';\n    dom.bind(_this2.__input, 'keydown', function (e) {\n      if (e.keyCode === 13) {\n        onBlur.call(this);\n      }\n    });\n    dom.bind(_this2.__input, 'blur', onBlur);\n    dom.bind(_this2.__selector, 'mousedown', function ()        {\n      dom.addClass(this, 'drag').bind(window, 'mouseup', function ()        {\n        dom.removeClass(_this.__selector, 'drag');\n      });\n    });\n    dom.bind(_this2.__selector, 'touchstart', function ()        {\n      dom.addClass(this, 'drag').bind(window, 'touchend', function ()        {\n        dom.removeClass(_this.__selector, 'drag');\n      });\n    });\n    var valueField = document.createElement('div');\n    Common.extend(_this2.__selector.style, {\n      width: '122px',\n      height: '102px',\n      padding: '3px',\n      backgroundColor: '#222',\n      boxShadow: '0px 1px 3px rgba(0,0,0,0.3)'\n    });\n    Common.extend(_this2.__field_knob.style, {\n      position: 'absolute',\n      width: '12px',\n      height: '12px',\n      border: _this2.__field_knob_border + (_this2.__color.v < 0.5 ? '#fff' : '#000'),\n      boxShadow: '0px 1px 3px rgba(0,0,0,0.5)',\n      borderRadius: '12px',\n      zIndex: 1\n    });\n    Common.extend(_this2.__hue_knob.style, {\n      position: 'absolute',\n      width: '15px',\n      height: '2px',\n      borderRight: '4px solid #fff',\n      zIndex: 1\n    });\n    Common.extend(_this2.__saturation_field.style, {\n      width: '100px',\n      height: '100px',\n      border: '1px solid #555',\n      marginRight: '3px',\n      display: 'inline-block',\n      cursor: 'pointer'\n    });\n    Common.extend(valueField.style, {\n      width: '100%',\n      height: '100%',\n      background: 'none'\n    });\n    linearGradient(valueField, 'top', 'rgba(0,0,0,0)', '#000');\n    Common.extend(_this2.__hue_field.style, {\n      width: '15px',\n      height: '100px',\n      border: '1px solid #555',\n      cursor: 'ns-resize',\n      position: 'absolute',\n      top: '3px',\n      right: '3px'\n    });\n    hueGradient(_this2.__hue_field);\n    Common.extend(_this2.__input.style, {\n      outline: 'none',\n      textAlign: 'center',\n      color: '#fff',\n      border: 0,\n      fontWeight: 'bold',\n      textShadow: _this2.__input_textShadow + 'rgba(0,0,0,0.7)'\n    });\n    dom.bind(_this2.__saturation_field, 'mousedown', fieldDown);\n    dom.bind(_this2.__saturation_field, 'touchstart', fieldDown);\n    dom.bind(_this2.__field_knob, 'mousedown', fieldDown);\n    dom.bind(_this2.__field_knob, 'touchstart', fieldDown);\n    dom.bind(_this2.__hue_field, 'mousedown', fieldDownH);\n    dom.bind(_this2.__hue_field, 'touchstart', fieldDownH);\n    function fieldDown(e) {\n      setSV(e);\n      dom.bind(window, 'mousemove', setSV);\n      dom.bind(window, 'touchmove', setSV);\n      dom.bind(window, 'mouseup', fieldUpSV);\n      dom.bind(window, 'touchend', fieldUpSV);\n    }\n    function fieldDownH(e) {\n      setH(e);\n      dom.bind(window, 'mousemove', setH);\n      dom.bind(window, 'touchmove', setH);\n      dom.bind(window, 'mouseup', fieldUpH);\n      dom.bind(window, 'touchend', fieldUpH);\n    }\n    function fieldUpSV() {\n      dom.unbind(window, 'mousemove', setSV);\n      dom.unbind(window, 'touchmove', setSV);\n      dom.unbind(window, 'mouseup', fieldUpSV);\n      dom.unbind(window, 'touchend', fieldUpSV);\n      onFinish();\n    }\n    function fieldUpH() {\n      dom.unbind(window, 'mousemove', setH);\n      dom.unbind(window, 'touchmove', setH);\n      dom.unbind(window, 'mouseup', fieldUpH);\n      dom.unbind(window, 'touchend', fieldUpH);\n      onFinish();\n    }\n    function onBlur() {\n      var i = interpret(this.value);\n      if (i !== false) {\n        _this.__color.__state = i;\n        _this.setValue(_this.__color.toOriginal());\n      } else {\n        this.value = _this.__color.toString();\n      }\n    }\n    function onFinish() {\n      if (_this.__onFinishChange) {\n        _this.__onFinishChange.call(_this, _this.__color.toOriginal());\n      }\n    }\n    _this2.__saturation_field.appendChild(valueField);\n    _this2.__selector.appendChild(_this2.__field_knob);\n    _this2.__selector.appendChild(_this2.__saturation_field);\n    _this2.__selector.appendChild(_this2.__hue_field);\n    _this2.__hue_field.appendChild(_this2.__hue_knob);\n    _this2.domElement.appendChild(_this2.__input);\n    _this2.domElement.appendChild(_this2.__selector);\n    _this2.updateDisplay();\n    function setSV(e) {\n      if (e.type.indexOf('touch') === -1) {\n        e.preventDefault();\n      }\n      var fieldRect = _this.__saturation_field.getBoundingClientRect();\n      var _ref = e.touches && e.touches[0] || e,\n          clientX = _ref.clientX,\n          clientY = _ref.clientY;\n      var s = (clientX - fieldRect.left) / (fieldRect.right - fieldRect.left);\n      var v = 1 - (clientY - fieldRect.top) / (fieldRect.bottom - fieldRect.top);\n      if (v > 1) {\n        v = 1;\n      } else if (v < 0) {\n        v = 0;\n      }\n      if (s > 1) {\n        s = 1;\n      } else if (s < 0) {\n        s = 0;\n      }\n      _this.__color.v = v;\n      _this.__color.s = s;\n      _this.setValue(_this.__color.toOriginal());\n      return false;\n    }\n    function setH(e) {\n      if (e.type.indexOf('touch') === -1) {\n        e.preventDefault();\n      }\n      var fieldRect = _this.__hue_field.getBoundingClientRect();\n      var _ref2 = e.touches && e.touches[0] || e,\n          clientY = _ref2.clientY;\n      var h = 1 - (clientY - fieldRect.top) / (fieldRect.bottom - fieldRect.top);\n      if (h > 1) {\n        h = 1;\n      } else if (h < 0) {\n        h = 0;\n      }\n      _this.__color.h = h * 360;\n      _this.setValue(_this.__color.toOriginal());\n      return false;\n    }\n    return _this2;\n  }\n  createClass(ColorController, [{\n    key: 'updateDisplay',\n    value: function updateDisplay() {\n      var i = interpret(this.getValue());\n      if (i !== false) {\n        var mismatch = false;\n        Common.each(Color.COMPONENTS, function (component) {\n          if (!Common.isUndefined(i[component]) && !Common.isUndefined(this.__color.__state[component]) && i[component] !== this.__color.__state[component]) {\n            mismatch = true;\n            return {};\n          }\n        }, this);\n        if (mismatch) {\n          Common.extend(this.__color.__state, i);\n        }\n      }\n      Common.extend(this.__temp.__state, this.__color.__state);\n      this.__temp.a = 1;\n      var flip = this.__color.v < 0.5 || this.__color.s > 0.5 ? 255 : 0;\n      var _flip = 255 - flip;\n      Common.extend(this.__field_knob.style, {\n        marginLeft: 100 * this.__color.s - 7 + 'px',\n        marginTop: 100 * (1 - this.__color.v) - 7 + 'px',\n        backgroundColor: this.__temp.toHexString(),\n        border: this.__field_knob_border + 'rgb(' + flip + ',' + flip + ',' + flip + ')'\n      });\n      this.__hue_knob.style.marginTop = (1 - this.__color.h / 360) * 100 + 'px';\n      this.__temp.s = 1;\n      this.__temp.v = 1;\n      linearGradient(this.__saturation_field, 'left', '#fff', this.__temp.toHexString());\n      this.__input.value = this.__color.toString();\n      Common.extend(this.__input.style, {\n        backgroundColor: this.__color.toHexString(),\n        color: 'rgb(' + flip + ',' + flip + ',' + flip + ')',\n        textShadow: this.__input_textShadow + 'rgba(' + _flip + ',' + _flip + ',' + _flip + ',.7)'\n      });\n    }\n  }]);\n  return ColorController;\n}(Controller);\nvar vendors = ['-moz-', '-o-', '-webkit-', '-ms-', ''];\nfunction linearGradient(elem, x, a, b) {\n  elem.style.background = '';\n  Common.each(vendors, function (vendor) {\n    elem.style.cssText += 'background: ' + vendor + 'linear-gradient(' + x + ', ' + a + ' 0%, ' + b + ' 100%); ';\n  });\n}\nfunction hueGradient(elem) {\n  elem.style.background = '';\n  elem.style.cssText += 'background: -moz-linear-gradient(top,  #ff0000 0%, #ff00ff 17%, #0000ff 34%, #00ffff 50%, #00ff00 67%, #ffff00 84%, #ff0000 100%);';\n  elem.style.cssText += 'background: -webkit-linear-gradient(top,  #ff0000 0%,#ff00ff 17%,#0000ff 34%,#00ffff 50%,#00ff00 67%,#ffff00 84%,#ff0000 100%);';\n  elem.style.cssText += 'background: -o-linear-gradient(top,  #ff0000 0%,#ff00ff 17%,#0000ff 34%,#00ffff 50%,#00ff00 67%,#ffff00 84%,#ff0000 100%);';\n  elem.style.cssText += 'background: -ms-linear-gradient(top,  #ff0000 0%,#ff00ff 17%,#0000ff 34%,#00ffff 50%,#00ff00 67%,#ffff00 84%,#ff0000 100%);';\n  elem.style.cssText += 'background: linear-gradient(top,  #ff0000 0%,#ff00ff 17%,#0000ff 34%,#00ffff 50%,#00ff00 67%,#ffff00 84%,#ff0000 100%);';\n}\n\nvar css = {\n  load: function load(url, indoc) {\n    var doc = indoc || document;\n    var link = doc.createElement('link');\n    link.type = 'text/css';\n    link.rel = 'stylesheet';\n    link.href = url;\n    doc.getElementsByTagName('head')[0].appendChild(link);\n  },\n  inject: function inject(cssContent, indoc) {\n    var doc = indoc || document;\n    var injected = document.createElement('style');\n    injected.type = 'text/css';\n    injected.innerHTML = cssContent;\n    var head = doc.getElementsByTagName('head')[0];\n    try {\n      head.appendChild(injected);\n    } catch (e) {\n    }\n  }\n};\n\nvar saveDialogContents = \"<div id=\\\"dg-save\\\" class=\\\"dg dialogue\\\">\\n\\n  Here's the new load parameter for your <code>GUI</code>'s constructor:\\n\\n  <textarea id=\\\"dg-new-constructor\\\"></textarea>\\n\\n  <div id=\\\"dg-save-locally\\\">\\n\\n    <input id=\\\"dg-local-storage\\\" type=\\\"checkbox\\\"/> Automatically save\\n    values to <code>localStorage</code> on exit.\\n\\n    <div id=\\\"dg-local-explain\\\">The values saved to <code>localStorage</code> will\\n      override those passed to <code>dat.GUI</code>'s constructor. This makes it\\n      easier to work incrementally, but <code>localStorage</code> is fragile,\\n      and your friends may not see the same values you do.\\n\\n    </div>\\n\\n  </div>\\n\\n</div>\";\n\nvar ControllerFactory = function ControllerFactory(object, property) {\n  var initialValue = object[property];\n  if (Common.isArray(arguments[2]) || Common.isObject(arguments[2])) {\n    return new OptionController(object, property, arguments[2]);\n  }\n  if (Common.isNumber(initialValue)) {\n    if (Common.isNumber(arguments[2]) && Common.isNumber(arguments[3])) {\n      if (Common.isNumber(arguments[4])) {\n        return new NumberControllerSlider(object, property, arguments[2], arguments[3], arguments[4]);\n      }\n      return new NumberControllerSlider(object, property, arguments[2], arguments[3]);\n    }\n    if (Common.isNumber(arguments[4])) {\n      return new NumberControllerBox(object, property, { min: arguments[2], max: arguments[3], step: arguments[4] });\n    }\n    return new NumberControllerBox(object, property, { min: arguments[2], max: arguments[3] });\n  }\n  if (Common.isString(initialValue)) {\n    return new StringController(object, property);\n  }\n  if (Common.isFunction(initialValue)) {\n    return new FunctionController(object, property, '');\n  }\n  if (Common.isBoolean(initialValue)) {\n    return new BooleanController(object, property);\n  }\n  return null;\n};\n\nfunction requestAnimationFrame(callback) {\n  setTimeout(callback, 1000 / 60);\n}\nvar requestAnimationFrame$1 = window.requestAnimationFrame || window.webkitRequestAnimationFrame || window.mozRequestAnimationFrame || window.oRequestAnimationFrame || window.msRequestAnimationFrame || requestAnimationFrame;\n\nvar CenteredDiv = function () {\n  function CenteredDiv() {\n    classCallCheck(this, CenteredDiv);\n    this.backgroundElement = document.createElement('div');\n    Common.extend(this.backgroundElement.style, {\n      backgroundColor: 'rgba(0,0,0,0.8)',\n      top: 0,\n      left: 0,\n      display: 'none',\n      zIndex: '1000',\n      opacity: 0,\n      WebkitTransition: 'opacity 0.2s linear',\n      transition: 'opacity 0.2s linear'\n    });\n    dom.makeFullscreen(this.backgroundElement);\n    this.backgroundElement.style.position = 'fixed';\n    this.domElement = document.createElement('div');\n    Common.extend(this.domElement.style, {\n      position: 'fixed',\n      display: 'none',\n      zIndex: '1001',\n      opacity: 0,\n      WebkitTransition: '-webkit-transform 0.2s ease-out, opacity 0.2s linear',\n      transition: 'transform 0.2s ease-out, opacity 0.2s linear'\n    });\n    document.body.appendChild(this.backgroundElement);\n    document.body.appendChild(this.domElement);\n    var _this = this;\n    dom.bind(this.backgroundElement, 'click', function () {\n      _this.hide();\n    });\n  }\n  createClass(CenteredDiv, [{\n    key: 'show',\n    value: function show() {\n      var _this = this;\n      this.backgroundElement.style.display = 'block';\n      this.domElement.style.display = 'block';\n      this.domElement.style.opacity = 0;\n      this.domElement.style.webkitTransform = 'scale(1.1)';\n      this.layout();\n      Common.defer(function () {\n        _this.backgroundElement.style.opacity = 1;\n        _this.domElement.style.opacity = 1;\n        _this.domElement.style.webkitTransform = 'scale(1)';\n      });\n    }\n  }, {\n    key: 'hide',\n    value: function hide() {\n      var _this = this;\n      var hide = function hide() {\n        _this.domElement.style.display = 'none';\n        _this.backgroundElement.style.display = 'none';\n        dom.unbind(_this.domElement, 'webkitTransitionEnd', hide);\n        dom.unbind(_this.domElement, 'transitionend', hide);\n        dom.unbind(_this.domElement, 'oTransitionEnd', hide);\n      };\n      dom.bind(this.domElement, 'webkitTransitionEnd', hide);\n      dom.bind(this.domElement, 'transitionend', hide);\n      dom.bind(this.domElement, 'oTransitionEnd', hide);\n      this.backgroundElement.style.opacity = 0;\n      this.domElement.style.opacity = 0;\n      this.domElement.style.webkitTransform = 'scale(1.1)';\n    }\n  }, {\n    key: 'layout',\n    value: function layout() {\n      this.domElement.style.left = window.innerWidth / 2 - dom.getWidth(this.domElement) / 2 + 'px';\n      this.domElement.style.top = window.innerHeight / 2 - dom.getHeight(this.domElement) / 2 + 'px';\n    }\n  }]);\n  return CenteredDiv;\n}();\n\nvar styleSheet = ___$insertStyle(\".dg ul{list-style:none;margin:0;padding:0;width:100%;clear:both}.dg.ac{position:fixed;top:0;left:0;right:0;height:0;z-index:0}.dg:not(.ac) .main{overflow:hidden}.dg.main{-webkit-transition:opacity .1s linear;-o-transition:opacity .1s linear;-moz-transition:opacity .1s linear;transition:opacity .1s linear}.dg.main.taller-than-window{overflow-y:auto}.dg.main.taller-than-window .close-button{opacity:1;margin-top:-1px;border-top:1px solid #2c2c2c}.dg.main ul.closed .close-button{opacity:1 !important}.dg.main:hover .close-button,.dg.main .close-button.drag{opacity:1}.dg.main .close-button{-webkit-transition:opacity .1s linear;-o-transition:opacity .1s linear;-moz-transition:opacity .1s linear;transition:opacity .1s linear;border:0;line-height:19px;height:20px;cursor:pointer;text-align:center;background-color:#000}.dg.main .close-button.close-top{position:relative}.dg.main .close-button.close-bottom{position:absolute}.dg.main .close-button:hover{background-color:#111}.dg.a{float:right;margin-right:15px;overflow-y:visible}.dg.a.has-save>ul.close-top{margin-top:0}.dg.a.has-save>ul.close-bottom{margin-top:27px}.dg.a.has-save>ul.closed{margin-top:0}.dg.a .save-row{top:0;z-index:1002}.dg.a .save-row.close-top{position:relative}.dg.a .save-row.close-bottom{position:fixed}.dg li{-webkit-transition:height .1s ease-out;-o-transition:height .1s ease-out;-moz-transition:height .1s ease-out;transition:height .1s ease-out;-webkit-transition:overflow .1s linear;-o-transition:overflow .1s linear;-moz-transition:overflow .1s linear;transition:overflow .1s linear}.dg li:not(.folder){cursor:auto;height:27px;line-height:27px;padding:0 4px 0 5px}.dg li.folder{padding:0;border-left:4px solid rgba(0,0,0,0)}.dg li.title{cursor:pointer;margin-left:-4px}.dg .closed li:not(.title),.dg .closed ul li,.dg .closed ul li>*{height:0;overflow:hidden;border:0}.dg .cr{clear:both;padding-left:3px;height:27px;overflow:hidden}.dg .property-name{cursor:default;float:left;clear:left;width:40%;overflow:hidden;text-overflow:ellipsis}.dg .c{float:left;width:60%;position:relative}.dg .c input[type=text]{border:0;margin-top:4px;padding:3px;width:100%;float:right}.dg .has-slider input[type=text]{width:30%;margin-left:0}.dg .slider{float:left;width:66%;margin-left:-5px;margin-right:0;height:19px;margin-top:4px}.dg .slider-fg{height:100%}.dg .c input[type=checkbox]{margin-top:7px}.dg .c select{margin-top:5px}.dg .cr.function,.dg .cr.function .property-name,.dg .cr.function *,.dg .cr.boolean,.dg .cr.boolean *{cursor:pointer}.dg .cr.color{overflow:visible}.dg .selector{display:none;position:absolute;margin-left:-9px;margin-top:23px;z-index:10}.dg .c:hover .selector,.dg .selector.drag{display:block}.dg li.save-row{padding:0}.dg li.save-row .button{display:inline-block;padding:0px 6px}.dg.dialogue{background-color:#222;width:460px;padding:15px;font-size:13px;line-height:15px}#dg-new-constructor{padding:10px;color:#222;font-family:Monaco, monospace;font-size:10px;border:0;resize:none;box-shadow:inset 1px 1px 1px #888;word-wrap:break-word;margin:12px 0;display:block;width:440px;overflow-y:scroll;height:100px;position:relative}#dg-local-explain{display:none;font-size:11px;line-height:17px;border-radius:3px;background-color:#333;padding:8px;margin-top:10px}#dg-local-explain code{font-size:10px}#dat-gui-save-locally{display:none}.dg{color:#eee;font:11px 'Lucida Grande', sans-serif;text-shadow:0 -1px 0 #111}.dg.main::-webkit-scrollbar{width:5px;background:#1a1a1a}.dg.main::-webkit-scrollbar-corner{height:0;display:none}.dg.main::-webkit-scrollbar-thumb{border-radius:5px;background:#676767}.dg li:not(.folder){background:#1a1a1a;border-bottom:1px solid #2c2c2c}.dg li.save-row{line-height:25px;background:#dad5cb;border:0}.dg li.save-row select{margin-left:5px;width:108px}.dg li.save-row .button{margin-left:5px;margin-top:1px;border-radius:2px;font-size:9px;line-height:7px;padding:4px 4px 5px 4px;background:#c5bdad;color:#fff;text-shadow:0 1px 0 #b0a58f;box-shadow:0 -1px 0 #b0a58f;cursor:pointer}.dg li.save-row .button.gears{background:#c5bdad url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAANCAYAAAB/9ZQ7AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAQJJREFUeNpiYKAU/P//PwGIC/ApCABiBSAW+I8AClAcgKxQ4T9hoMAEUrxx2QSGN6+egDX+/vWT4e7N82AMYoPAx/evwWoYoSYbACX2s7KxCxzcsezDh3evFoDEBYTEEqycggWAzA9AuUSQQgeYPa9fPv6/YWm/Acx5IPb7ty/fw+QZblw67vDs8R0YHyQhgObx+yAJkBqmG5dPPDh1aPOGR/eugW0G4vlIoTIfyFcA+QekhhHJhPdQxbiAIguMBTQZrPD7108M6roWYDFQiIAAv6Aow/1bFwXgis+f2LUAynwoIaNcz8XNx3Dl7MEJUDGQpx9gtQ8YCueB+D26OECAAQDadt7e46D42QAAAABJRU5ErkJggg==) 2px 1px no-repeat;height:7px;width:8px}.dg li.save-row .button:hover{background-color:#bab19e;box-shadow:0 -1px 0 #b0a58f}.dg li.folder{border-bottom:0}.dg li.title{padding-left:16px;background:#000 url(data:image/gif;base64,R0lGODlhBQAFAJEAAP////Pz8////////yH5BAEAAAIALAAAAAAFAAUAAAIIlI+hKgFxoCgAOw==) 6px 10px no-repeat;cursor:pointer;border-bottom:1px solid rgba(255,255,255,0.2)}.dg .closed li.title{background-image:url(data:image/gif;base64,R0lGODlhBQAFAJEAAP////Pz8////////yH5BAEAAAIALAAAAAAFAAUAAAIIlGIWqMCbWAEAOw==)}.dg .cr.boolean{border-left:3px solid #806787}.dg .cr.color{border-left:3px solid}.dg .cr.function{border-left:3px solid #e61d5f}.dg .cr.number{border-left:3px solid #2FA1D6}.dg .cr.number input[type=text]{color:#2FA1D6}.dg .cr.string{border-left:3px solid #1ed36f}.dg .cr.string input[type=text]{color:#1ed36f}.dg .cr.function:hover,.dg .cr.boolean:hover{background:#111}.dg .c input[type=text]{background:#303030;outline:none}.dg .c input[type=text]:hover{background:#3c3c3c}.dg .c input[type=text]:focus{background:#494949;color:#fff}.dg .c .slider{background:#303030;cursor:ew-resize}.dg .c .slider-fg{background:#2FA1D6;max-width:100%}.dg .c .slider:hover{background:#3c3c3c}.dg .c .slider:hover .slider-fg{background:#44abda}\\n\");\n\ncss.inject(styleSheet);\nvar CSS_NAMESPACE = 'dg';\nvar HIDE_KEY_CODE = 72;\nvar CLOSE_BUTTON_HEIGHT = 20;\nvar DEFAULT_DEFAULT_PRESET_NAME = 'Default';\nvar SUPPORTS_LOCAL_STORAGE = function () {\n  try {\n    return !!window.localStorage;\n  } catch (e) {\n    return false;\n  }\n}();\nvar SAVE_DIALOGUE = void 0;\nvar autoPlaceVirgin = true;\nvar autoPlaceContainer = void 0;\nvar hide = false;\nvar hideableGuis = [];\nvar GUI = function GUI(pars) {\n  var _this = this;\n  var params = pars || {};\n  this.domElement = document.createElement('div');\n  this.__ul = document.createElement('ul');\n  this.domElement.appendChild(this.__ul);\n  dom.addClass(this.domElement, CSS_NAMESPACE);\n  this.__folders = {};\n  this.__controllers = [];\n  this.__rememberedObjects = [];\n  this.__rememberedObjectIndecesToControllers = [];\n  this.__listening = [];\n  params = Common.defaults(params, {\n    closeOnTop: false,\n    autoPlace: true,\n    width: GUI.DEFAULT_WIDTH\n  });\n  params = Common.defaults(params, {\n    resizable: params.autoPlace,\n    hideable: params.autoPlace\n  });\n  if (!Common.isUndefined(params.load)) {\n    if (params.preset) {\n      params.load.preset = params.preset;\n    }\n  } else {\n    params.load = { preset: DEFAULT_DEFAULT_PRESET_NAME };\n  }\n  if (Common.isUndefined(params.parent) && params.hideable) {\n    hideableGuis.push(this);\n  }\n  params.resizable = Common.isUndefined(params.parent) && params.resizable;\n  if (params.autoPlace && Common.isUndefined(params.scrollable)) {\n    params.scrollable = true;\n  }\n  var useLocalStorage = SUPPORTS_LOCAL_STORAGE && localStorage.getItem(getLocalStorageHash(this, 'isLocal')) === 'true';\n  var saveToLocalStorage = void 0;\n  var titleRow = void 0;\n  Object.defineProperties(this,\n  {\n    parent: {\n      get: function get$$1() {\n        return params.parent;\n      }\n    },\n    scrollable: {\n      get: function get$$1() {\n        return params.scrollable;\n      }\n    },\n    autoPlace: {\n      get: function get$$1() {\n        return params.autoPlace;\n      }\n    },\n    closeOnTop: {\n      get: function get$$1() {\n        return params.closeOnTop;\n      }\n    },\n    preset: {\n      get: function get$$1() {\n        if (_this.parent) {\n          return _this.getRoot().preset;\n        }\n        return params.load.preset;\n      },\n      set: function set$$1(v) {\n        if (_this.parent) {\n          _this.getRoot().preset = v;\n        } else {\n          params.load.preset = v;\n        }\n        setPresetSelectIndex(this);\n        _this.revert();\n      }\n    },\n    width: {\n      get: function get$$1() {\n        return params.width;\n      },\n      set: function set$$1(v) {\n        params.width = v;\n        setWidth(_this, v);\n      }\n    },\n    name: {\n      get: function get$$1() {\n        return params.name;\n      },\n      set: function set$$1(v) {\n        params.name = v;\n        if (titleRow) {\n          titleRow.innerHTML = params.name;\n        }\n      }\n    },\n    closed: {\n      get: function get$$1() {\n        return params.closed;\n      },\n      set: function set$$1(v) {\n        params.closed = v;\n        if (params.closed) {\n          dom.addClass(_this.__ul, GUI.CLASS_CLOSED);\n        } else {\n          dom.removeClass(_this.__ul, GUI.CLASS_CLOSED);\n        }\n        this.onResize();\n        if (_this.__closeButton) {\n          _this.__closeButton.innerHTML = v ? GUI.TEXT_OPEN : GUI.TEXT_CLOSED;\n        }\n      }\n    },\n    load: {\n      get: function get$$1() {\n        return params.load;\n      }\n    },\n    useLocalStorage: {\n      get: function get$$1() {\n        return useLocalStorage;\n      },\n      set: function set$$1(bool) {\n        if (SUPPORTS_LOCAL_STORAGE) {\n          useLocalStorage = bool;\n          if (bool) {\n            dom.bind(window, 'unload', saveToLocalStorage);\n          } else {\n            dom.unbind(window, 'unload', saveToLocalStorage);\n          }\n          localStorage.setItem(getLocalStorageHash(_this, 'isLocal'), bool);\n        }\n      }\n    }\n  });\n  if (Common.isUndefined(params.parent)) {\n    this.closed = params.closed || false;\n    dom.addClass(this.domElement, GUI.CLASS_MAIN);\n    dom.makeSelectable(this.domElement, false);\n    if (SUPPORTS_LOCAL_STORAGE) {\n      if (useLocalStorage) {\n        _this.useLocalStorage = true;\n        var savedGui = localStorage.getItem(getLocalStorageHash(this, 'gui'));\n        if (savedGui) {\n          params.load = JSON.parse(savedGui);\n        }\n      }\n    }\n    this.__closeButton = document.createElement('div');\n    this.__closeButton.innerHTML = GUI.TEXT_CLOSED;\n    dom.addClass(this.__closeButton, GUI.CLASS_CLOSE_BUTTON);\n    if (params.closeOnTop) {\n      dom.addClass(this.__closeButton, GUI.CLASS_CLOSE_TOP);\n      this.domElement.insertBefore(this.__closeButton, this.domElement.childNodes[0]);\n    } else {\n      dom.addClass(this.__closeButton, GUI.CLASS_CLOSE_BOTTOM);\n      this.domElement.appendChild(this.__closeButton);\n    }\n    dom.bind(this.__closeButton, 'click', function () {\n      _this.closed = !_this.closed;\n    });\n  } else {\n    if (params.closed === undefined) {\n      params.closed = true;\n    }\n    var titleRowName = document.createTextNode(params.name);\n    dom.addClass(titleRowName, 'controller-name');\n    titleRow = addRow(_this, titleRowName);\n    var onClickTitle = function onClickTitle(e) {\n      e.preventDefault();\n      _this.closed = !_this.closed;\n      return false;\n    };\n    dom.addClass(this.__ul, GUI.CLASS_CLOSED);\n    dom.addClass(titleRow, 'title');\n    dom.bind(titleRow, 'click', onClickTitle);\n    if (!params.closed) {\n      this.closed = false;\n    }\n  }\n  if (params.autoPlace) {\n    if (Common.isUndefined(params.parent)) {\n      if (autoPlaceVirgin) {\n        autoPlaceContainer = document.createElement('div');\n        dom.addClass(autoPlaceContainer, CSS_NAMESPACE);\n        dom.addClass(autoPlaceContainer, GUI.CLASS_AUTO_PLACE_CONTAINER);\n        document.body.appendChild(autoPlaceContainer);\n        autoPlaceVirgin = false;\n      }\n      autoPlaceContainer.appendChild(this.domElement);\n      dom.addClass(this.domElement, GUI.CLASS_AUTO_PLACE);\n    }\n    if (!this.parent) {\n      setWidth(_this, params.width);\n    }\n  }\n  this.__resizeHandler = function () {\n    _this.onResizeDebounced();\n  };\n  dom.bind(window, 'resize', this.__resizeHandler);\n  dom.bind(this.__ul, 'webkitTransitionEnd', this.__resizeHandler);\n  dom.bind(this.__ul, 'transitionend', this.__resizeHandler);\n  dom.bind(this.__ul, 'oTransitionEnd', this.__resizeHandler);\n  this.onResize();\n  if (params.resizable) {\n    addResizeHandle(this);\n  }\n  saveToLocalStorage = function saveToLocalStorage() {\n    if (SUPPORTS_LOCAL_STORAGE && localStorage.getItem(getLocalStorageHash(_this, 'isLocal')) === 'true') {\n      localStorage.setItem(getLocalStorageHash(_this, 'gui'), JSON.stringify(_this.getSaveObject()));\n    }\n  };\n  this.saveToLocalStorageIfPossible = saveToLocalStorage;\n  function resetWidth() {\n    var root = _this.getRoot();\n    root.width += 1;\n    Common.defer(function () {\n      root.width -= 1;\n    });\n  }\n  if (!params.parent) {\n    resetWidth();\n  }\n};\nGUI.toggleHide = function () {\n  hide = !hide;\n  Common.each(hideableGuis, function (gui) {\n    gui.domElement.style.display = hide ? 'none' : '';\n  });\n};\nGUI.CLASS_AUTO_PLACE = 'a';\nGUI.CLASS_AUTO_PLACE_CONTAINER = 'ac';\nGUI.CLASS_MAIN = 'main';\nGUI.CLASS_CONTROLLER_ROW = 'cr';\nGUI.CLASS_TOO_TALL = 'taller-than-window';\nGUI.CLASS_CLOSED = 'closed';\nGUI.CLASS_CLOSE_BUTTON = 'close-button';\nGUI.CLASS_CLOSE_TOP = 'close-top';\nGUI.CLASS_CLOSE_BOTTOM = 'close-bottom';\nGUI.CLASS_DRAG = 'drag';\nGUI.DEFAULT_WIDTH = 245;\nGUI.TEXT_CLOSED = 'Close Controls';\nGUI.TEXT_OPEN = 'Open Controls';\nGUI._keydownHandler = function (e) {\n  if (document.activeElement.type !== 'text' && (e.which === HIDE_KEY_CODE || e.keyCode === HIDE_KEY_CODE)) {\n    GUI.toggleHide();\n  }\n};\ndom.bind(window, 'keydown', GUI._keydownHandler, false);\nCommon.extend(GUI.prototype,\n{\n  add: function add(object, property) {\n    return _add(this, object, property, {\n      factoryArgs: Array.prototype.slice.call(arguments, 2)\n    });\n  },\n  addColor: function addColor(object, property) {\n    return _add(this, object, property, {\n      color: true\n    });\n  },\n  remove: function remove(controller) {\n    this.__ul.removeChild(controller.__li);\n    this.__controllers.splice(this.__controllers.indexOf(controller), 1);\n    var _this = this;\n    Common.defer(function () {\n      _this.onResize();\n    });\n  },\n  destroy: function destroy() {\n    if (this.parent) {\n      throw new Error('Only the root GUI should be removed with .destroy(). ' + 'For subfolders, use gui.removeFolder(folder) instead.');\n    }\n    if (this.autoPlace) {\n      autoPlaceContainer.removeChild(this.domElement);\n    }\n    var _this = this;\n    Common.each(this.__folders, function (subfolder) {\n      _this.removeFolder(subfolder);\n    });\n    dom.unbind(window, 'keydown', GUI._keydownHandler, false);\n    removeListeners(this);\n  },\n  addFolder: function addFolder(name) {\n    if (this.__folders[name] !== undefined) {\n      throw new Error('You already have a folder in this GUI by the' + ' name \"' + name + '\"');\n    }\n    var newGuiParams = { name: name, parent: this };\n    newGuiParams.autoPlace = this.autoPlace;\n    if (this.load &&\n    this.load.folders &&\n    this.load.folders[name]) {\n      newGuiParams.closed = this.load.folders[name].closed;\n      newGuiParams.load = this.load.folders[name];\n    }\n    var gui = new GUI(newGuiParams);\n    this.__folders[name] = gui;\n    var li = addRow(this, gui.domElement);\n    dom.addClass(li, 'folder');\n    return gui;\n  },\n  removeFolder: function removeFolder(folder) {\n    this.__ul.removeChild(folder.domElement.parentElement);\n    delete this.__folders[folder.name];\n    if (this.load &&\n    this.load.folders &&\n    this.load.folders[folder.name]) {\n      delete this.load.folders[folder.name];\n    }\n    removeListeners(folder);\n    var _this = this;\n    Common.each(folder.__folders, function (subfolder) {\n      folder.removeFolder(subfolder);\n    });\n    Common.defer(function () {\n      _this.onResize();\n    });\n  },\n  open: function open() {\n    this.closed = false;\n  },\n  close: function close() {\n    this.closed = true;\n  },\n  hide: function hide() {\n    this.domElement.style.display = 'none';\n  },\n  show: function show() {\n    this.domElement.style.display = '';\n  },\n  onResize: function onResize() {\n    var root = this.getRoot();\n    if (root.scrollable) {\n      var top = dom.getOffset(root.__ul).top;\n      var h = 0;\n      Common.each(root.__ul.childNodes, function (node) {\n        if (!(root.autoPlace && node === root.__save_row)) {\n          h += dom.getHeight(node);\n        }\n      });\n      if (window.innerHeight - top - CLOSE_BUTTON_HEIGHT < h) {\n        dom.addClass(root.domElement, GUI.CLASS_TOO_TALL);\n        root.__ul.style.height = window.innerHeight - top - CLOSE_BUTTON_HEIGHT + 'px';\n      } else {\n        dom.removeClass(root.domElement, GUI.CLASS_TOO_TALL);\n        root.__ul.style.height = 'auto';\n      }\n    }\n    if (root.__resize_handle) {\n      Common.defer(function () {\n        root.__resize_handle.style.height = root.__ul.offsetHeight + 'px';\n      });\n    }\n    if (root.__closeButton) {\n      root.__closeButton.style.width = root.width + 'px';\n    }\n  },\n  onResizeDebounced: Common.debounce(function () {\n    this.onResize();\n  }, 50),\n  remember: function remember() {\n    if (Common.isUndefined(SAVE_DIALOGUE)) {\n      SAVE_DIALOGUE = new CenteredDiv();\n      SAVE_DIALOGUE.domElement.innerHTML = saveDialogContents;\n    }\n    if (this.parent) {\n      throw new Error('You can only call remember on a top level GUI.');\n    }\n    var _this = this;\n    Common.each(Array.prototype.slice.call(arguments), function (object) {\n      if (_this.__rememberedObjects.length === 0) {\n        addSaveMenu(_this);\n      }\n      if (_this.__rememberedObjects.indexOf(object) === -1) {\n        _this.__rememberedObjects.push(object);\n      }\n    });\n    if (this.autoPlace) {\n      setWidth(this, this.width);\n    }\n  },\n  getRoot: function getRoot() {\n    var gui = this;\n    while (gui.parent) {\n      gui = gui.parent;\n    }\n    return gui;\n  },\n  getSaveObject: function getSaveObject() {\n    var toReturn = this.load;\n    toReturn.closed = this.closed;\n    if (this.__rememberedObjects.length > 0) {\n      toReturn.preset = this.preset;\n      if (!toReturn.remembered) {\n        toReturn.remembered = {};\n      }\n      toReturn.remembered[this.preset] = getCurrentPreset(this);\n    }\n    toReturn.folders = {};\n    Common.each(this.__folders, function (element, key) {\n      toReturn.folders[key] = element.getSaveObject();\n    });\n    return toReturn;\n  },\n  save: function save() {\n    if (!this.load.remembered) {\n      this.load.remembered = {};\n    }\n    this.load.remembered[this.preset] = getCurrentPreset(this);\n    markPresetModified(this, false);\n    this.saveToLocalStorageIfPossible();\n  },\n  saveAs: function saveAs(presetName) {\n    if (!this.load.remembered) {\n      this.load.remembered = {};\n      this.load.remembered[DEFAULT_DEFAULT_PRESET_NAME] = getCurrentPreset(this, true);\n    }\n    this.load.remembered[presetName] = getCurrentPreset(this);\n    this.preset = presetName;\n    addPresetOption(this, presetName, true);\n    this.saveToLocalStorageIfPossible();\n  },\n  revert: function revert(gui) {\n    Common.each(this.__controllers, function (controller) {\n      if (!this.getRoot().load.remembered) {\n        controller.setValue(controller.initialValue);\n      } else {\n        recallSavedValue(gui || this.getRoot(), controller);\n      }\n      if (controller.__onFinishChange) {\n        controller.__onFinishChange.call(controller, controller.getValue());\n      }\n    }, this);\n    Common.each(this.__folders, function (folder) {\n      folder.revert(folder);\n    });\n    if (!gui) {\n      markPresetModified(this.getRoot(), false);\n    }\n  },\n  listen: function listen(controller) {\n    var init = this.__listening.length === 0;\n    this.__listening.push(controller);\n    if (init) {\n      updateDisplays(this.__listening);\n    }\n  },\n  updateDisplay: function updateDisplay() {\n    Common.each(this.__controllers, function (controller) {\n      controller.updateDisplay();\n    });\n    Common.each(this.__folders, function (folder) {\n      folder.updateDisplay();\n    });\n  }\n});\nfunction addRow(gui, newDom, liBefore) {\n  var li = document.createElement('li');\n  if (newDom) {\n    li.appendChild(newDom);\n  }\n  if (liBefore) {\n    gui.__ul.insertBefore(li, liBefore);\n  } else {\n    gui.__ul.appendChild(li);\n  }\n  gui.onResize();\n  return li;\n}\nfunction removeListeners(gui) {\n  dom.unbind(window, 'resize', gui.__resizeHandler);\n  if (gui.saveToLocalStorageIfPossible) {\n    dom.unbind(window, 'unload', gui.saveToLocalStorageIfPossible);\n  }\n}\nfunction markPresetModified(gui, modified) {\n  var opt = gui.__preset_select[gui.__preset_select.selectedIndex];\n  if (modified) {\n    opt.innerHTML = opt.value + '*';\n  } else {\n    opt.innerHTML = opt.value;\n  }\n}\nfunction augmentController(gui, li, controller) {\n  controller.__li = li;\n  controller.__gui = gui;\n  Common.extend(controller,                                   {\n    options: function options(_options) {\n      if (arguments.length > 1) {\n        var nextSibling = controller.__li.nextElementSibling;\n        controller.remove();\n        return _add(gui, controller.object, controller.property, {\n          before: nextSibling,\n          factoryArgs: [Common.toArray(arguments)]\n        });\n      }\n      if (Common.isArray(_options) || Common.isObject(_options)) {\n        var _nextSibling = controller.__li.nextElementSibling;\n        controller.remove();\n        return _add(gui, controller.object, controller.property, {\n          before: _nextSibling,\n          factoryArgs: [_options]\n        });\n      }\n    },\n    name: function name(_name) {\n      controller.__li.firstElementChild.firstElementChild.innerHTML = _name;\n      return controller;\n    },\n    listen: function listen() {\n      controller.__gui.listen(controller);\n      return controller;\n    },\n    remove: function remove() {\n      controller.__gui.remove(controller);\n      return controller;\n    }\n  });\n  if (controller instanceof NumberControllerSlider) {\n    var box = new NumberControllerBox(controller.object, controller.property, { min: controller.__min, max: controller.__max, step: controller.__step });\n    Common.each(['updateDisplay', 'onChange', 'onFinishChange', 'step', 'min', 'max'], function (method) {\n      var pc = controller[method];\n      var pb = box[method];\n      controller[method] = box[method] = function () {\n        var args = Array.prototype.slice.call(arguments);\n        pb.apply(box, args);\n        return pc.apply(controller, args);\n      };\n    });\n    dom.addClass(li, 'has-slider');\n    controller.domElement.insertBefore(box.domElement, controller.domElement.firstElementChild);\n  } else if (controller instanceof NumberControllerBox) {\n    var r = function r(returned) {\n      if (Common.isNumber(controller.__min) && Common.isNumber(controller.__max)) {\n        var oldName = controller.__li.firstElementChild.firstElementChild.innerHTML;\n        var wasListening = controller.__gui.__listening.indexOf(controller) > -1;\n        controller.remove();\n        var newController = _add(gui, controller.object, controller.property, {\n          before: controller.__li.nextElementSibling,\n          factoryArgs: [controller.__min, controller.__max, controller.__step]\n        });\n        newController.name(oldName);\n        if (wasListening) newController.listen();\n        return newController;\n      }\n      return returned;\n    };\n    controller.min = Common.compose(r, controller.min);\n    controller.max = Common.compose(r, controller.max);\n  } else if (controller instanceof BooleanController) {\n    dom.bind(li, 'click', function () {\n      dom.fakeEvent(controller.__checkbox, 'click');\n    });\n    dom.bind(controller.__checkbox, 'click', function (e) {\n      e.stopPropagation();\n    });\n  } else if (controller instanceof FunctionController) {\n    dom.bind(li, 'click', function () {\n      dom.fakeEvent(controller.__button, 'click');\n    });\n    dom.bind(li, 'mouseover', function () {\n      dom.addClass(controller.__button, 'hover');\n    });\n    dom.bind(li, 'mouseout', function () {\n      dom.removeClass(controller.__button, 'hover');\n    });\n  } else if (controller instanceof ColorController) {\n    dom.addClass(li, 'color');\n    controller.updateDisplay = Common.compose(function (val) {\n      li.style.borderLeftColor = controller.__color.toString();\n      return val;\n    }, controller.updateDisplay);\n    controller.updateDisplay();\n  }\n  controller.setValue = Common.compose(function (val) {\n    if (gui.getRoot().__preset_select && controller.isModified()) {\n      markPresetModified(gui.getRoot(), true);\n    }\n    return val;\n  }, controller.setValue);\n}\nfunction recallSavedValue(gui, controller) {\n  var root = gui.getRoot();\n  var matchedIndex = root.__rememberedObjects.indexOf(controller.object);\n  if (matchedIndex !== -1) {\n    var controllerMap = root.__rememberedObjectIndecesToControllers[matchedIndex];\n    if (controllerMap === undefined) {\n      controllerMap = {};\n      root.__rememberedObjectIndecesToControllers[matchedIndex] = controllerMap;\n    }\n    controllerMap[controller.property] = controller;\n    if (root.load && root.load.remembered) {\n      var presetMap = root.load.remembered;\n      var preset = void 0;\n      if (presetMap[gui.preset]) {\n        preset = presetMap[gui.preset];\n      } else if (presetMap[DEFAULT_DEFAULT_PRESET_NAME]) {\n        preset = presetMap[DEFAULT_DEFAULT_PRESET_NAME];\n      } else {\n        return;\n      }\n      if (preset[matchedIndex] && preset[matchedIndex][controller.property] !== undefined) {\n        var value = preset[matchedIndex][controller.property];\n        controller.initialValue = value;\n        controller.setValue(value);\n      }\n    }\n  }\n}\nfunction _add(gui, object, property, params) {\n  if (object[property] === undefined) {\n    throw new Error('Object \"' + object + '\" has no property \"' + property + '\"');\n  }\n  var controller = void 0;\n  if (params.color) {\n    controller = new ColorController(object, property);\n  } else {\n    var factoryArgs = [object, property].concat(params.factoryArgs);\n    controller = ControllerFactory.apply(gui, factoryArgs);\n  }\n  if (params.before instanceof Controller) {\n    params.before = params.before.__li;\n  }\n  recallSavedValue(gui, controller);\n  dom.addClass(controller.domElement, 'c');\n  var name = document.createElement('span');\n  dom.addClass(name, 'property-name');\n  name.innerHTML = controller.property;\n  var container = document.createElement('div');\n  container.appendChild(name);\n  container.appendChild(controller.domElement);\n  var li = addRow(gui, container, params.before);\n  dom.addClass(li, GUI.CLASS_CONTROLLER_ROW);\n  if (controller instanceof ColorController) {\n    dom.addClass(li, 'color');\n  } else {\n    dom.addClass(li, _typeof(controller.getValue()));\n  }\n  augmentController(gui, li, controller);\n  gui.__controllers.push(controller);\n  return controller;\n}\nfunction getLocalStorageHash(gui, key) {\n  return document.location.href + '.' + key;\n}\nfunction addPresetOption(gui, name, setSelected) {\n  var opt = document.createElement('option');\n  opt.innerHTML = name;\n  opt.value = name;\n  gui.__preset_select.appendChild(opt);\n  if (setSelected) {\n    gui.__preset_select.selectedIndex = gui.__preset_select.length - 1;\n  }\n}\nfunction showHideExplain(gui, explain) {\n  explain.style.display = gui.useLocalStorage ? 'block' : 'none';\n}\nfunction addSaveMenu(gui) {\n  var div = gui.__save_row = document.createElement('li');\n  dom.addClass(gui.domElement, 'has-save');\n  gui.__ul.insertBefore(div, gui.__ul.firstChild);\n  dom.addClass(div, 'save-row');\n  var gears = document.createElement('span');\n  gears.innerHTML = '&nbsp;';\n  dom.addClass(gears, 'button gears');\n  var button = document.createElement('span');\n  button.innerHTML = 'Save';\n  dom.addClass(button, 'button');\n  dom.addClass(button, 'save');\n  var button2 = document.createElement('span');\n  button2.innerHTML = 'New';\n  dom.addClass(button2, 'button');\n  dom.addClass(button2, 'save-as');\n  var button3 = document.createElement('span');\n  button3.innerHTML = 'Revert';\n  dom.addClass(button3, 'button');\n  dom.addClass(button3, 'revert');\n  var select = gui.__preset_select = document.createElement('select');\n  if (gui.load && gui.load.remembered) {\n    Common.each(gui.load.remembered, function (value, key) {\n      addPresetOption(gui, key, key === gui.preset);\n    });\n  } else {\n    addPresetOption(gui, DEFAULT_DEFAULT_PRESET_NAME, false);\n  }\n  dom.bind(select, 'change', function () {\n    for (var index = 0; index < gui.__preset_select.length; index++) {\n      gui.__preset_select[index].innerHTML = gui.__preset_select[index].value;\n    }\n    gui.preset = this.value;\n  });\n  div.appendChild(select);\n  div.appendChild(gears);\n  div.appendChild(button);\n  div.appendChild(button2);\n  div.appendChild(button3);\n  if (SUPPORTS_LOCAL_STORAGE) {\n    var explain = document.getElementById('dg-local-explain');\n    var localStorageCheckBox = document.getElementById('dg-local-storage');\n    var saveLocally = document.getElementById('dg-save-locally');\n    saveLocally.style.display = 'block';\n    if (localStorage.getItem(getLocalStorageHash(gui, 'isLocal')) === 'true') {\n      localStorageCheckBox.setAttribute('checked', 'checked');\n    }\n    showHideExplain(gui, explain);\n    dom.bind(localStorageCheckBox, 'change', function () {\n      gui.useLocalStorage = !gui.useLocalStorage;\n      showHideExplain(gui, explain);\n    });\n  }\n  var newConstructorTextArea = document.getElementById('dg-new-constructor');\n  dom.bind(newConstructorTextArea, 'keydown', function (e) {\n    if (e.metaKey && (e.which === 67 || e.keyCode === 67)) {\n      SAVE_DIALOGUE.hide();\n    }\n  });\n  dom.bind(gears, 'click', function () {\n    newConstructorTextArea.innerHTML = JSON.stringify(gui.getSaveObject(), undefined, 2);\n    SAVE_DIALOGUE.show();\n    newConstructorTextArea.focus();\n    newConstructorTextArea.select();\n  });\n  dom.bind(button, 'click', function () {\n    gui.save();\n  });\n  dom.bind(button2, 'click', function () {\n    var presetName = prompt('Enter a new preset name.');\n    if (presetName) {\n      gui.saveAs(presetName);\n    }\n  });\n  dom.bind(button3, 'click', function () {\n    gui.revert();\n  });\n}\nfunction addResizeHandle(gui) {\n  var pmouseX = void 0;\n  gui.__resize_handle = document.createElement('div');\n  Common.extend(gui.__resize_handle.style, {\n    width: '6px',\n    marginLeft: '-3px',\n    height: '200px',\n    cursor: 'ew-resize',\n    position: 'absolute'\n  });\n  function drag(e) {\n    e.preventDefault();\n    gui.width += pmouseX - e.clientX;\n    gui.onResize();\n    pmouseX = e.clientX;\n    return false;\n  }\n  function dragStop() {\n    dom.removeClass(gui.__closeButton, GUI.CLASS_DRAG);\n    dom.unbind(window, 'mousemove', drag);\n    dom.unbind(window, 'mouseup', dragStop);\n  }\n  function dragStart(e) {\n    e.preventDefault();\n    pmouseX = e.clientX;\n    dom.addClass(gui.__closeButton, GUI.CLASS_DRAG);\n    dom.bind(window, 'mousemove', drag);\n    dom.bind(window, 'mouseup', dragStop);\n    return false;\n  }\n  dom.bind(gui.__resize_handle, 'mousedown', dragStart);\n  dom.bind(gui.__closeButton, 'mousedown', dragStart);\n  gui.domElement.insertBefore(gui.__resize_handle, gui.domElement.firstElementChild);\n}\nfunction setWidth(gui, w) {\n  gui.domElement.style.width = w + 'px';\n  if (gui.__save_row && gui.autoPlace) {\n    gui.__save_row.style.width = w + 'px';\n  }\n  if (gui.__closeButton) {\n    gui.__closeButton.style.width = w + 'px';\n  }\n}\nfunction getCurrentPreset(gui, useInitialValues) {\n  var toReturn = {};\n  Common.each(gui.__rememberedObjects, function (val, index) {\n    var savedValues = {};\n    var controllerMap = gui.__rememberedObjectIndecesToControllers[index];\n    Common.each(controllerMap, function (controller, property) {\n      savedValues[property] = useInitialValues ? controller.initialValue : controller.getValue();\n    });\n    toReturn[index] = savedValues;\n  });\n  return toReturn;\n}\nfunction setPresetSelectIndex(gui) {\n  for (var index = 0; index < gui.__preset_select.length; index++) {\n    if (gui.__preset_select[index].value === gui.preset) {\n      gui.__preset_select.selectedIndex = index;\n    }\n  }\n}\nfunction updateDisplays(controllerArray) {\n  if (controllerArray.length !== 0) {\n    requestAnimationFrame$1.call(window, function () {\n      updateDisplays(controllerArray);\n    });\n  }\n  Common.each(controllerArray, function (c) {\n    c.updateDisplay();\n  });\n}\n\nvar color = {\n  Color: Color,\n  math: ColorMath,\n  interpret: interpret\n};\nvar controllers = {\n  Controller: Controller,\n  BooleanController: BooleanController,\n  OptionController: OptionController,\n  StringController: StringController,\n  NumberController: NumberController,\n  NumberControllerBox: NumberControllerBox,\n  NumberControllerSlider: NumberControllerSlider,\n  FunctionController: FunctionController,\n  ColorController: ColorController\n};\nvar dom$1 = { dom: dom };\nvar gui = { GUI: GUI };\nvar GUI$1 = GUI;\nvar index = {\n  color: color,\n  controllers: controllers,\n  dom: dom$1,\n  gui: gui,\n  GUI: GUI$1\n};\n\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (index);\n//# sourceMappingURL=dat.gui.module.js.map\n\n\n//# sourceURL=webpack:///./node_modules/dat.gui/build/dat.gui.module.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/ageGenderNet/AgeGenderNet.js":
/*!*************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/ageGenderNet/AgeGenderNet.js ***!
  \*************************************************************************/
/*! exports provided: AgeGenderNet */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AgeGenderNet\", function() { return AgeGenderNet; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _common_fullyConnectedLayer__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common/fullyConnectedLayer */ \"./node_modules/face-api.js/build/es6/common/fullyConnectedLayer.js\");\n/* harmony import */ var _faceProcessor_util__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../faceProcessor/util */ \"./node_modules/face-api.js/build/es6/faceProcessor/util.js\");\n/* harmony import */ var _xception_TinyXception__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../xception/TinyXception */ \"./node_modules/face-api.js/build/es6/xception/TinyXception.js\");\n/* harmony import */ var _extractParams__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./extractParams */ \"./node_modules/face-api.js/build/es6/ageGenderNet/extractParams.js\");\n/* harmony import */ var _extractParamsFromWeigthMap__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./extractParamsFromWeigthMap */ \"./node_modules/face-api.js/build/es6/ageGenderNet/extractParamsFromWeigthMap.js\");\n/* harmony import */ var _types__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./types */ \"./node_modules/face-api.js/build/es6/ageGenderNet/types.js\");\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nvar AgeGenderNet = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(AgeGenderNet, _super);\r\n    function AgeGenderNet(faceFeatureExtractor) {\r\n        if (faceFeatureExtractor === void 0) { faceFeatureExtractor = new _xception_TinyXception__WEBPACK_IMPORTED_MODULE_5__[\"TinyXception\"](2); }\r\n        var _this = _super.call(this, 'AgeGenderNet') || this;\r\n        _this._faceFeatureExtractor = faceFeatureExtractor;\r\n        return _this;\r\n    }\r\n    Object.defineProperty(AgeGenderNet.prototype, \"faceFeatureExtractor\", {\r\n        get: function () {\r\n            return this._faceFeatureExtractor;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    AgeGenderNet.prototype.runNet = function (input) {\r\n        var _this = this;\r\n        var params = this.params;\r\n        if (!params) {\r\n            throw new Error(this._name + \" - load model before inference\");\r\n        }\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tidy\"](function () {\r\n            var bottleneckFeatures = input instanceof tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"NetInput\"]\r\n                ? _this.faceFeatureExtractor.forwardInput(input)\r\n                : input;\r\n            var pooled = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"avgPool\"](bottleneckFeatures, [7, 7], [2, 2], 'valid').as2D(bottleneckFeatures.shape[0], -1);\r\n            var age = Object(_common_fullyConnectedLayer__WEBPACK_IMPORTED_MODULE_3__[\"fullyConnectedLayer\"])(pooled, params.fc.age).as1D();\r\n            var gender = Object(_common_fullyConnectedLayer__WEBPACK_IMPORTED_MODULE_3__[\"fullyConnectedLayer\"])(pooled, params.fc.gender);\r\n            return { age: age, gender: gender };\r\n        });\r\n    };\r\n    AgeGenderNet.prototype.forwardInput = function (input) {\r\n        var _this = this;\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tidy\"](function () {\r\n            var _a = _this.runNet(input), age = _a.age, gender = _a.gender;\r\n            return { age: age, gender: _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"softmax\"](gender) };\r\n        });\r\n    };\r\n    AgeGenderNet.prototype.forward = function (input) {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var _a;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this.forwardInput;\r\n                        return [4 /*yield*/, Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"toNetInput\"])(input)];\r\n                    case 1: return [2 /*return*/, _a.apply(this, [_b.sent()])];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    AgeGenderNet.prototype.predictAgeAndGender = function (input) {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var netInput, out, ages, genders, ageAndGenderTensors, predictionsByBatch;\r\n            var _this = this;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"toNetInput\"])(input)];\r\n                    case 1:\r\n                        netInput = _a.sent();\r\n                        return [4 /*yield*/, this.forwardInput(netInput)];\r\n                    case 2:\r\n                        out = _a.sent();\r\n                        ages = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"unstack\"](out.age);\r\n                        genders = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"unstack\"](out.gender);\r\n                        ageAndGenderTensors = ages.map(function (ageTensor, i) { return ({\r\n                            ageTensor: ageTensor,\r\n                            genderTensor: genders[i]\r\n                        }); });\r\n                        return [4 /*yield*/, Promise.all(ageAndGenderTensors.map(function (_a) {\r\n                                var ageTensor = _a.ageTensor, genderTensor = _a.genderTensor;\r\n                                return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(_this, void 0, void 0, function () {\r\n                                    var age, probMale, isMale, gender, genderProbability;\r\n                                    return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n                                        switch (_b.label) {\r\n                                            case 0: return [4 /*yield*/, ageTensor.data()];\r\n                                            case 1:\r\n                                                age = (_b.sent())[0];\r\n                                                return [4 /*yield*/, genderTensor.data()];\r\n                                            case 2:\r\n                                                probMale = (_b.sent())[0];\r\n                                                isMale = probMale > 0.5;\r\n                                                gender = isMale ? _types__WEBPACK_IMPORTED_MODULE_8__[\"Gender\"].MALE : _types__WEBPACK_IMPORTED_MODULE_8__[\"Gender\"].FEMALE;\r\n                                                genderProbability = isMale ? probMale : (1 - probMale);\r\n                                                ageTensor.dispose();\r\n                                                genderTensor.dispose();\r\n                                                return [2 /*return*/, { age: age, gender: gender, genderProbability: genderProbability }];\r\n                                        }\r\n                                    });\r\n                                });\r\n                            }))];\r\n                    case 3:\r\n                        predictionsByBatch = _a.sent();\r\n                        out.age.dispose();\r\n                        out.gender.dispose();\r\n                        return [2 /*return*/, netInput.isBatchInput\r\n                                ? predictionsByBatch\r\n                                : predictionsByBatch[0]];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    AgeGenderNet.prototype.getDefaultModelName = function () {\r\n        return 'age_gender_model';\r\n    };\r\n    AgeGenderNet.prototype.dispose = function (throwOnRedispose) {\r\n        if (throwOnRedispose === void 0) { throwOnRedispose = true; }\r\n        this.faceFeatureExtractor.dispose(throwOnRedispose);\r\n        _super.prototype.dispose.call(this, throwOnRedispose);\r\n    };\r\n    AgeGenderNet.prototype.loadClassifierParams = function (weights) {\r\n        var _a = this.extractClassifierParams(weights), params = _a.params, paramMappings = _a.paramMappings;\r\n        this._params = params;\r\n        this._paramMappings = paramMappings;\r\n    };\r\n    AgeGenderNet.prototype.extractClassifierParams = function (weights) {\r\n        return Object(_extractParams__WEBPACK_IMPORTED_MODULE_6__[\"extractParams\"])(weights);\r\n    };\r\n    AgeGenderNet.prototype.extractParamsFromWeigthMap = function (weightMap) {\r\n        var _a = Object(_faceProcessor_util__WEBPACK_IMPORTED_MODULE_4__[\"seperateWeightMaps\"])(weightMap), featureExtractorMap = _a.featureExtractorMap, classifierMap = _a.classifierMap;\r\n        this.faceFeatureExtractor.loadFromWeightMap(featureExtractorMap);\r\n        return Object(_extractParamsFromWeigthMap__WEBPACK_IMPORTED_MODULE_7__[\"extractParamsFromWeigthMap\"])(classifierMap);\r\n    };\r\n    AgeGenderNet.prototype.extractParams = function (weights) {\r\n        var classifierWeightSize = (512 * 1 + 1) + (512 * 2 + 2);\r\n        var featureExtractorWeights = weights.slice(0, weights.length - classifierWeightSize);\r\n        var classifierWeights = weights.slice(weights.length - classifierWeightSize);\r\n        this.faceFeatureExtractor.extractWeights(featureExtractorWeights);\r\n        return this.extractClassifierParams(classifierWeights);\r\n    };\r\n    return AgeGenderNet;\r\n}(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"NeuralNetwork\"]));\r\n\r\n//# sourceMappingURL=AgeGenderNet.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/ageGenderNet/AgeGenderNet.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/ageGenderNet/extractParams.js":
/*!**************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/ageGenderNet/extractParams.js ***!
  \**************************************************************************/
/*! exports provided: extractParams */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractParams\", function() { return extractParams; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n\r\nfunction extractParams(weights) {\r\n    var paramMappings = [];\r\n    var _a = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].extractWeightsFactory(weights), extractWeights = _a.extractWeights, getRemainingWeights = _a.getRemainingWeights;\r\n    var extractFCParams = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].extractFCParamsFactory(extractWeights, paramMappings);\r\n    var age = extractFCParams(512, 1, 'fc/age');\r\n    var gender = extractFCParams(512, 2, 'fc/gender');\r\n    if (getRemainingWeights().length !== 0) {\r\n        throw new Error(\"weights remaing after extract: \" + getRemainingWeights().length);\r\n    }\r\n    return {\r\n        paramMappings: paramMappings,\r\n        params: { fc: { age: age, gender: gender } }\r\n    };\r\n}\r\n//# sourceMappingURL=extractParams.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/ageGenderNet/extractParams.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/ageGenderNet/extractParamsFromWeigthMap.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/ageGenderNet/extractParamsFromWeigthMap.js ***!
  \***************************************************************************************/
/*! exports provided: extractParamsFromWeigthMap */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractParamsFromWeigthMap\", function() { return extractParamsFromWeigthMap; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n\r\nfunction extractParamsFromWeigthMap(weightMap) {\r\n    var paramMappings = [];\r\n    var extractWeightEntry = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].extractWeightEntryFactory(weightMap, paramMappings);\r\n    function extractFcParams(prefix) {\r\n        var weights = extractWeightEntry(prefix + \"/weights\", 2);\r\n        var bias = extractWeightEntry(prefix + \"/bias\", 1);\r\n        return { weights: weights, bias: bias };\r\n    }\r\n    var params = {\r\n        fc: {\r\n            age: extractFcParams('fc/age'),\r\n            gender: extractFcParams('fc/gender')\r\n        }\r\n    };\r\n    tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].disposeUnusedWeightTensors(weightMap, paramMappings);\r\n    return { params: params, paramMappings: paramMappings };\r\n}\r\n//# sourceMappingURL=extractParamsFromWeigthMap.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/ageGenderNet/extractParamsFromWeigthMap.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/ageGenderNet/index.js":
/*!******************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/ageGenderNet/index.js ***!
  \******************************************************************/
/*! exports provided: AgeGenderNet, Gender */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _AgeGenderNet__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AgeGenderNet */ \"./node_modules/face-api.js/build/es6/ageGenderNet/AgeGenderNet.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AgeGenderNet\", function() { return _AgeGenderNet__WEBPACK_IMPORTED_MODULE_0__[\"AgeGenderNet\"]; });\n\n/* harmony import */ var _types__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./types */ \"./node_modules/face-api.js/build/es6/ageGenderNet/types.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Gender\", function() { return _types__WEBPACK_IMPORTED_MODULE_1__[\"Gender\"]; });\n\n\r\n\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/ageGenderNet/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/ageGenderNet/types.js":
/*!******************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/ageGenderNet/types.js ***!
  \******************************************************************/
/*! exports provided: Gender */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Gender\", function() { return Gender; });\nvar Gender;\r\n(function (Gender) {\r\n    Gender[\"FEMALE\"] = \"female\";\r\n    Gender[\"MALE\"] = \"male\";\r\n})(Gender || (Gender = {}));\r\n//# sourceMappingURL=types.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/ageGenderNet/types.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/classes/FaceDetection.js":
/*!*********************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/classes/FaceDetection.js ***!
  \*********************************************************************/
/*! exports provided: FaceDetection */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"FaceDetection\", function() { return FaceDetection; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n\r\n\r\nvar FaceDetection = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(FaceDetection, _super);\r\n    function FaceDetection(score, relativeBox, imageDims) {\r\n        return _super.call(this, score, score, '', relativeBox, imageDims) || this;\r\n    }\r\n    FaceDetection.prototype.forSize = function (width, height) {\r\n        var _a = _super.prototype.forSize.call(this, width, height), score = _a.score, relativeBox = _a.relativeBox, imageDims = _a.imageDims;\r\n        return new FaceDetection(score, relativeBox, imageDims);\r\n    };\r\n    return FaceDetection;\r\n}(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"ObjectDetection\"]));\r\n\r\n//# sourceMappingURL=FaceDetection.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/classes/FaceDetection.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/classes/FaceLandmarks.js":
/*!*********************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/classes/FaceLandmarks.js ***!
  \*********************************************************************/
/*! exports provided: FaceLandmarks */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"FaceLandmarks\", function() { return FaceLandmarks; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _minBbox__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../minBbox */ \"./node_modules/face-api.js/build/es6/minBbox.js\");\n/* harmony import */ var _FaceDetection__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./FaceDetection */ \"./node_modules/face-api.js/build/es6/classes/FaceDetection.js\");\n\r\n\r\n\r\n// face alignment constants\r\nvar relX = 0.5;\r\nvar relY = 0.43;\r\nvar relScale = 0.45;\r\nvar FaceLandmarks = /** @class */ (function () {\r\n    function FaceLandmarks(relativeFaceLandmarkPositions, imgDims, shift) {\r\n        if (shift === void 0) { shift = new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Point\"](0, 0); }\r\n        var width = imgDims.width, height = imgDims.height;\r\n        this._imgDims = new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Dimensions\"](width, height);\r\n        this._shift = shift;\r\n        this._positions = relativeFaceLandmarkPositions.map(function (pt) { return pt.mul(new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Point\"](width, height)).add(shift); });\r\n    }\r\n    Object.defineProperty(FaceLandmarks.prototype, \"shift\", {\r\n        get: function () { return new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Point\"](this._shift.x, this._shift.y); },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(FaceLandmarks.prototype, \"imageWidth\", {\r\n        get: function () { return this._imgDims.width; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(FaceLandmarks.prototype, \"imageHeight\", {\r\n        get: function () { return this._imgDims.height; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(FaceLandmarks.prototype, \"positions\", {\r\n        get: function () { return this._positions; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(FaceLandmarks.prototype, \"relativePositions\", {\r\n        get: function () {\r\n            var _this = this;\r\n            return this._positions.map(function (pt) { return pt.sub(_this._shift).div(new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Point\"](_this.imageWidth, _this.imageHeight)); });\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    FaceLandmarks.prototype.forSize = function (width, height) {\r\n        return new this.constructor(this.relativePositions, { width: width, height: height });\r\n    };\r\n    FaceLandmarks.prototype.shiftBy = function (x, y) {\r\n        return new this.constructor(this.relativePositions, this._imgDims, new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Point\"](x, y));\r\n    };\r\n    FaceLandmarks.prototype.shiftByPoint = function (pt) {\r\n        return this.shiftBy(pt.x, pt.y);\r\n    };\r\n    /**\r\n     * Aligns the face landmarks after face detection from the relative positions of the faces\r\n     * bounding box, or it's current shift. This function should be used to align the face images\r\n     * after face detection has been performed, before they are passed to the face recognition net.\r\n     * This will make the computed face descriptor more accurate.\r\n     *\r\n     * @param detection (optional) The bounding box of the face or the face detection result. If\r\n     * no argument was passed the position of the face landmarks are assumed to be relative to\r\n     * it's current shift.\r\n     * @returns The bounding box of the aligned face.\r\n     */\r\n    FaceLandmarks.prototype.align = function (detection, options) {\r\n        if (options === void 0) { options = {}; }\r\n        if (detection) {\r\n            var box = detection instanceof _FaceDetection__WEBPACK_IMPORTED_MODULE_2__[\"FaceDetection\"]\r\n                ? detection.box.floor()\r\n                : new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Box\"](detection);\r\n            return this.shiftBy(box.x, box.y).align(null, options);\r\n        }\r\n        var _a = Object.assign({}, { useDlibAlignment: false, minBoxPadding: 0.2 }, options), useDlibAlignment = _a.useDlibAlignment, minBoxPadding = _a.minBoxPadding;\r\n        if (useDlibAlignment) {\r\n            return this.alignDlib();\r\n        }\r\n        return this.alignMinBbox(minBoxPadding);\r\n    };\r\n    FaceLandmarks.prototype.alignDlib = function () {\r\n        var centers = this.getRefPointsForAlignment();\r\n        var leftEyeCenter = centers[0], rightEyeCenter = centers[1], mouthCenter = centers[2];\r\n        var distToMouth = function (pt) { return mouthCenter.sub(pt).magnitude(); };\r\n        var eyeToMouthDist = (distToMouth(leftEyeCenter) + distToMouth(rightEyeCenter)) / 2;\r\n        var size = Math.floor(eyeToMouthDist / relScale);\r\n        var refPoint = Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"getCenterPoint\"])(centers);\r\n        // TODO: pad in case rectangle is out of image bounds\r\n        var x = Math.floor(Math.max(0, refPoint.x - (relX * size)));\r\n        var y = Math.floor(Math.max(0, refPoint.y - (relY * size)));\r\n        return new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Rect\"](x, y, Math.min(size, this.imageWidth + x), Math.min(size, this.imageHeight + y));\r\n    };\r\n    FaceLandmarks.prototype.alignMinBbox = function (padding) {\r\n        var box = Object(_minBbox__WEBPACK_IMPORTED_MODULE_1__[\"minBbox\"])(this.positions);\r\n        return box.pad(box.width * padding, box.height * padding);\r\n    };\r\n    FaceLandmarks.prototype.getRefPointsForAlignment = function () {\r\n        throw new Error('getRefPointsForAlignment not implemented by base class');\r\n    };\r\n    return FaceLandmarks;\r\n}());\r\n\r\n//# sourceMappingURL=FaceLandmarks.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/classes/FaceLandmarks.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/classes/FaceLandmarks5.js":
/*!**********************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/classes/FaceLandmarks5.js ***!
  \**********************************************************************/
/*! exports provided: FaceLandmarks5 */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"FaceLandmarks5\", function() { return FaceLandmarks5; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _FaceLandmarks__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./FaceLandmarks */ \"./node_modules/face-api.js/build/es6/classes/FaceLandmarks.js\");\n\r\n\r\n\r\nvar FaceLandmarks5 = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(FaceLandmarks5, _super);\r\n    function FaceLandmarks5() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    FaceLandmarks5.prototype.getRefPointsForAlignment = function () {\r\n        var pts = this.positions;\r\n        return [\r\n            pts[0],\r\n            pts[1],\r\n            Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"getCenterPoint\"])([pts[3], pts[4]])\r\n        ];\r\n    };\r\n    return FaceLandmarks5;\r\n}(_FaceLandmarks__WEBPACK_IMPORTED_MODULE_2__[\"FaceLandmarks\"]));\r\n\r\n//# sourceMappingURL=FaceLandmarks5.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/classes/FaceLandmarks5.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/classes/FaceLandmarks68.js":
/*!***********************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/classes/FaceLandmarks68.js ***!
  \***********************************************************************/
/*! exports provided: FaceLandmarks68 */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"FaceLandmarks68\", function() { return FaceLandmarks68; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _classes_FaceLandmarks__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../classes/FaceLandmarks */ \"./node_modules/face-api.js/build/es6/classes/FaceLandmarks.js\");\n\r\n\r\n\r\nvar FaceLandmarks68 = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(FaceLandmarks68, _super);\r\n    function FaceLandmarks68() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    FaceLandmarks68.prototype.getJawOutline = function () {\r\n        return this.positions.slice(0, 17);\r\n    };\r\n    FaceLandmarks68.prototype.getLeftEyeBrow = function () {\r\n        return this.positions.slice(17, 22);\r\n    };\r\n    FaceLandmarks68.prototype.getRightEyeBrow = function () {\r\n        return this.positions.slice(22, 27);\r\n    };\r\n    FaceLandmarks68.prototype.getNose = function () {\r\n        return this.positions.slice(27, 36);\r\n    };\r\n    FaceLandmarks68.prototype.getLeftEye = function () {\r\n        return this.positions.slice(36, 42);\r\n    };\r\n    FaceLandmarks68.prototype.getRightEye = function () {\r\n        return this.positions.slice(42, 48);\r\n    };\r\n    FaceLandmarks68.prototype.getMouth = function () {\r\n        return this.positions.slice(48, 68);\r\n    };\r\n    FaceLandmarks68.prototype.getRefPointsForAlignment = function () {\r\n        return [\r\n            this.getLeftEye(),\r\n            this.getRightEye(),\r\n            this.getMouth()\r\n        ].map(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"getCenterPoint\"]);\r\n    };\r\n    return FaceLandmarks68;\r\n}(_classes_FaceLandmarks__WEBPACK_IMPORTED_MODULE_2__[\"FaceLandmarks\"]));\r\n\r\n//# sourceMappingURL=FaceLandmarks68.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/classes/FaceLandmarks68.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/classes/FaceMatch.js":
/*!*****************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/classes/FaceMatch.js ***!
  \*****************************************************************/
/*! exports provided: FaceMatch */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"FaceMatch\", function() { return FaceMatch; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n\r\nvar FaceMatch = /** @class */ (function () {\r\n    function FaceMatch(label, distance) {\r\n        this._label = label;\r\n        this._distance = distance;\r\n    }\r\n    Object.defineProperty(FaceMatch.prototype, \"label\", {\r\n        get: function () { return this._label; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(FaceMatch.prototype, \"distance\", {\r\n        get: function () { return this._distance; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    FaceMatch.prototype.toString = function (withDistance) {\r\n        if (withDistance === void 0) { withDistance = true; }\r\n        return \"\" + this.label + (withDistance ? \" (\" + Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"round\"])(this.distance) + \")\" : '');\r\n    };\r\n    return FaceMatch;\r\n}());\r\n\r\n//# sourceMappingURL=FaceMatch.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/classes/FaceMatch.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/classes/LabeledFaceDescriptors.js":
/*!******************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/classes/LabeledFaceDescriptors.js ***!
  \******************************************************************************/
/*! exports provided: LabeledFaceDescriptors */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"LabeledFaceDescriptors\", function() { return LabeledFaceDescriptors; });\nvar LabeledFaceDescriptors = /** @class */ (function () {\r\n    function LabeledFaceDescriptors(label, descriptors) {\r\n        if (!(typeof label === 'string')) {\r\n            throw new Error('LabeledFaceDescriptors - constructor expected label to be a string');\r\n        }\r\n        if (!Array.isArray(descriptors) || descriptors.some(function (desc) { return !(desc instanceof Float32Array); })) {\r\n            throw new Error('LabeledFaceDescriptors - constructor expected descriptors to be an array of Float32Array');\r\n        }\r\n        this._label = label;\r\n        this._descriptors = descriptors;\r\n    }\r\n    Object.defineProperty(LabeledFaceDescriptors.prototype, \"label\", {\r\n        get: function () { return this._label; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(LabeledFaceDescriptors.prototype, \"descriptors\", {\r\n        get: function () { return this._descriptors; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    LabeledFaceDescriptors.prototype.toJSON = function () {\r\n        return {\r\n            label: this.label,\r\n            descriptors: this.descriptors.map(function (d) { return Array.from(d); })\r\n        };\r\n    };\r\n    LabeledFaceDescriptors.fromJSON = function (json) {\r\n        var descriptors = json.descriptors.map(function (d) {\r\n            return new Float32Array(d);\r\n        });\r\n        return new LabeledFaceDescriptors(json.label, descriptors);\r\n    };\r\n    return LabeledFaceDescriptors;\r\n}());\r\n\r\n//# sourceMappingURL=LabeledFaceDescriptors.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/classes/LabeledFaceDescriptors.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/classes/index.js":
/*!*************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/classes/index.js ***!
  \*************************************************************/
/*! exports provided: FaceDetection, FaceLandmarks, FaceLandmarks5, FaceLandmarks68, FaceMatch, LabeledFaceDescriptors */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _FaceDetection__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./FaceDetection */ \"./node_modules/face-api.js/build/es6/classes/FaceDetection.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceDetection\", function() { return _FaceDetection__WEBPACK_IMPORTED_MODULE_0__[\"FaceDetection\"]; });\n\n/* harmony import */ var _FaceLandmarks__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./FaceLandmarks */ \"./node_modules/face-api.js/build/es6/classes/FaceLandmarks.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceLandmarks\", function() { return _FaceLandmarks__WEBPACK_IMPORTED_MODULE_1__[\"FaceLandmarks\"]; });\n\n/* harmony import */ var _FaceLandmarks5__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./FaceLandmarks5 */ \"./node_modules/face-api.js/build/es6/classes/FaceLandmarks5.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceLandmarks5\", function() { return _FaceLandmarks5__WEBPACK_IMPORTED_MODULE_2__[\"FaceLandmarks5\"]; });\n\n/* harmony import */ var _FaceLandmarks68__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./FaceLandmarks68 */ \"./node_modules/face-api.js/build/es6/classes/FaceLandmarks68.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceLandmarks68\", function() { return _FaceLandmarks68__WEBPACK_IMPORTED_MODULE_3__[\"FaceLandmarks68\"]; });\n\n/* harmony import */ var _FaceMatch__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./FaceMatch */ \"./node_modules/face-api.js/build/es6/classes/FaceMatch.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceMatch\", function() { return _FaceMatch__WEBPACK_IMPORTED_MODULE_4__[\"FaceMatch\"]; });\n\n/* harmony import */ var _LabeledFaceDescriptors__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./LabeledFaceDescriptors */ \"./node_modules/face-api.js/build/es6/classes/LabeledFaceDescriptors.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"LabeledFaceDescriptors\", function() { return _LabeledFaceDescriptors__WEBPACK_IMPORTED_MODULE_5__[\"LabeledFaceDescriptors\"]; });\n\n\r\n\r\n\r\n\r\n\r\n\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/classes/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/common/depthwiseSeparableConv.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/common/depthwiseSeparableConv.js ***!
  \*****************************************************************************/
/*! exports provided: depthwiseSeparableConv */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"depthwiseSeparableConv\", function() { return depthwiseSeparableConv; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n\r\nfunction depthwiseSeparableConv(x, params, stride) {\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () {\r\n        var out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"separableConv2d\"](x, params.depthwise_filter, params.pointwise_filter, stride, 'same');\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](out, params.bias);\r\n        return out;\r\n    });\r\n}\r\n//# sourceMappingURL=depthwiseSeparableConv.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/common/depthwiseSeparableConv.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/common/fullyConnectedLayer.js":
/*!**************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/common/fullyConnectedLayer.js ***!
  \**************************************************************************/
/*! exports provided: fullyConnectedLayer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"fullyConnectedLayer\", function() { return fullyConnectedLayer; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n\r\nfunction fullyConnectedLayer(x, params) {\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () {\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"matMul\"](x, params.weights), params.bias);\r\n    });\r\n}\r\n//# sourceMappingURL=fullyConnectedLayer.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/common/fullyConnectedLayer.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/common/loadConvParamsFactory.js":
/*!****************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/common/loadConvParamsFactory.js ***!
  \****************************************************************************/
/*! exports provided: loadConvParamsFactory */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"loadConvParamsFactory\", function() { return loadConvParamsFactory; });\nfunction loadConvParamsFactory(extractWeightEntry) {\r\n    return function (prefix) {\r\n        var filters = extractWeightEntry(prefix + \"/filters\", 4);\r\n        var bias = extractWeightEntry(prefix + \"/bias\", 1);\r\n        return { filters: filters, bias: bias };\r\n    };\r\n}\r\n//# sourceMappingURL=loadConvParamsFactory.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/common/loadConvParamsFactory.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/dom/extractFaceTensors.js":
/*!**********************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/dom/extractFaceTensors.js ***!
  \**********************************************************************/
/*! exports provided: extractFaceTensors */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractFaceTensors\", function() { return extractFaceTensors; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _classes_FaceDetection__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../classes/FaceDetection */ \"./node_modules/face-api.js/build/es6/classes/FaceDetection.js\");\n\r\n\r\n\r\n\r\n/**\r\n * Extracts the tensors of the image regions containing the detected faces.\r\n * Useful if you want to compute the face descriptors for the face images.\r\n * Using this method is faster then extracting a canvas for each face and\r\n * converting them to tensors individually.\r\n *\r\n * @param imageTensor The image tensor that face detection has been performed on.\r\n * @param detections The face detection results or face bounding boxes for that image.\r\n * @returns Tensors of the corresponding image region for each detected face.\r\n */\r\nfunction extractFaceTensors(imageTensor, detections) {\r\n    return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n            if (!Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"isTensor3D\"])(imageTensor) && !Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"isTensor4D\"])(imageTensor)) {\r\n                throw new Error('extractFaceTensors - expected image tensor to be 3D or 4D');\r\n            }\r\n            if (Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"isTensor4D\"])(imageTensor) && imageTensor.shape[0] > 1) {\r\n                throw new Error('extractFaceTensors - batchSize > 1 not supported');\r\n            }\r\n            return [2 /*return*/, _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tidy\"](function () {\r\n                    var _a = imageTensor.shape.slice(Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"isTensor4D\"])(imageTensor) ? 1 : 0), imgHeight = _a[0], imgWidth = _a[1], numChannels = _a[2];\r\n                    var boxes = detections.map(function (det) { return det instanceof _classes_FaceDetection__WEBPACK_IMPORTED_MODULE_3__[\"FaceDetection\"]\r\n                        ? det.forSize(imgWidth, imgHeight).box\r\n                        : det; })\r\n                        .map(function (box) { return box.clipAtImageBorders(imgWidth, imgHeight); });\r\n                    var faceTensors = boxes.map(function (_a) {\r\n                        var x = _a.x, y = _a.y, width = _a.width, height = _a.height;\r\n                        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"slice3d\"](imageTensor.as3D(imgHeight, imgWidth, numChannels), [y, x, 0], [height, width, numChannels]);\r\n                    });\r\n                    return faceTensors;\r\n                })];\r\n        });\r\n    });\r\n}\r\n//# sourceMappingURL=extractFaceTensors.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/dom/extractFaceTensors.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/dom/extractFaces.js":
/*!****************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/dom/extractFaces.js ***!
  \****************************************************************/
/*! exports provided: extractFaces */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractFaces\", function() { return extractFaces; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _classes_FaceDetection__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../classes/FaceDetection */ \"./node_modules/face-api.js/build/es6/classes/FaceDetection.js\");\n\r\n\r\n\r\n/**\r\n * Extracts the image regions containing the detected faces.\r\n *\r\n * @param input The image that face detection has been performed on.\r\n * @param detections The face detection results or face bounding boxes for that image.\r\n * @returns The Canvases of the corresponding image region for each detected face.\r\n */\r\nfunction extractFaces(input, detections) {\r\n    return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n        var Canvas, canvas, netInput, tensorOrCanvas, _a, ctx, boxes;\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n            switch (_b.label) {\r\n                case 0:\r\n                    Canvas = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"env\"].getEnv().Canvas;\r\n                    canvas = input;\r\n                    if (!!(input instanceof Canvas)) return [3 /*break*/, 5];\r\n                    return [4 /*yield*/, Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"toNetInput\"])(input)];\r\n                case 1:\r\n                    netInput = _b.sent();\r\n                    if (netInput.batchSize > 1) {\r\n                        throw new Error('extractFaces - batchSize > 1 not supported');\r\n                    }\r\n                    tensorOrCanvas = netInput.getInput(0);\r\n                    if (!(tensorOrCanvas instanceof Canvas)) return [3 /*break*/, 2];\r\n                    _a = tensorOrCanvas;\r\n                    return [3 /*break*/, 4];\r\n                case 2: return [4 /*yield*/, Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"imageTensorToCanvas\"])(tensorOrCanvas)];\r\n                case 3:\r\n                    _a = _b.sent();\r\n                    _b.label = 4;\r\n                case 4:\r\n                    canvas = _a;\r\n                    _b.label = 5;\r\n                case 5:\r\n                    ctx = Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"getContext2dOrThrow\"])(canvas);\r\n                    boxes = detections.map(function (det) { return det instanceof _classes_FaceDetection__WEBPACK_IMPORTED_MODULE_2__[\"FaceDetection\"]\r\n                        ? det.forSize(canvas.width, canvas.height).box.floor()\r\n                        : det; })\r\n                        .map(function (box) { return box.clipAtImageBorders(canvas.width, canvas.height); });\r\n                    return [2 /*return*/, boxes.map(function (_a) {\r\n                            var x = _a.x, y = _a.y, width = _a.width, height = _a.height;\r\n                            var faceImg = Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"createCanvas\"])({ width: width, height: height });\r\n                            Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"getContext2dOrThrow\"])(faceImg)\r\n                                .putImageData(ctx.getImageData(x, y, width, height), 0, 0);\r\n                            return faceImg;\r\n                        })];\r\n            }\r\n        });\r\n    });\r\n}\r\n//# sourceMappingURL=extractFaces.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/dom/extractFaces.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/dom/index.js":
/*!*********************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/dom/index.js ***!
  \*********************************************************/
/*! exports provided: extractFaces, extractFaceTensors */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _extractFaces__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./extractFaces */ \"./node_modules/face-api.js/build/es6/dom/extractFaces.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extractFaces\", function() { return _extractFaces__WEBPACK_IMPORTED_MODULE_0__[\"extractFaces\"]; });\n\n/* harmony import */ var _extractFaceTensors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./extractFaceTensors */ \"./node_modules/face-api.js/build/es6/dom/extractFaceTensors.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extractFaceTensors\", function() { return _extractFaceTensors__WEBPACK_IMPORTED_MODULE_1__[\"extractFaceTensors\"]; });\n\n\r\n\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/dom/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/draw/DrawFaceLandmarks.js":
/*!**********************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/draw/DrawFaceLandmarks.js ***!
  \**********************************************************************/
/*! exports provided: DrawFaceLandmarksOptions, DrawFaceLandmarks, drawFaceLandmarks */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DrawFaceLandmarksOptions\", function() { return DrawFaceLandmarksOptions; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DrawFaceLandmarks\", function() { return DrawFaceLandmarks; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"drawFaceLandmarks\", function() { return drawFaceLandmarks; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _classes_FaceLandmarks__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../classes/FaceLandmarks */ \"./node_modules/face-api.js/build/es6/classes/FaceLandmarks.js\");\n/* harmony import */ var _classes_FaceLandmarks68__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../classes/FaceLandmarks68 */ \"./node_modules/face-api.js/build/es6/classes/FaceLandmarks68.js\");\n/* harmony import */ var _factories_WithFaceLandmarks__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../factories/WithFaceLandmarks */ \"./node_modules/face-api.js/build/es6/factories/WithFaceLandmarks.js\");\n/* harmony import */ var _drawContour__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./drawContour */ \"./node_modules/face-api.js/build/es6/draw/drawContour.js\");\n\r\n\r\n\r\n\r\n\r\nvar DrawFaceLandmarksOptions = /** @class */ (function () {\r\n    function DrawFaceLandmarksOptions(options) {\r\n        if (options === void 0) { options = {}; }\r\n        var _a = options.drawLines, drawLines = _a === void 0 ? true : _a, _b = options.drawPoints, drawPoints = _b === void 0 ? true : _b, lineWidth = options.lineWidth, lineColor = options.lineColor, pointSize = options.pointSize, pointColor = options.pointColor;\r\n        this.drawLines = drawLines;\r\n        this.drawPoints = drawPoints;\r\n        this.lineWidth = lineWidth || 1;\r\n        this.pointSize = pointSize || 2;\r\n        this.lineColor = lineColor || 'rgba(0, 255, 255, 1)';\r\n        this.pointColor = pointColor || 'rgba(255, 0, 255, 1)';\r\n    }\r\n    return DrawFaceLandmarksOptions;\r\n}());\r\n\r\nvar DrawFaceLandmarks = /** @class */ (function () {\r\n    function DrawFaceLandmarks(faceLandmarks, options) {\r\n        if (options === void 0) { options = {}; }\r\n        this.faceLandmarks = faceLandmarks;\r\n        this.options = new DrawFaceLandmarksOptions(options);\r\n    }\r\n    DrawFaceLandmarks.prototype.draw = function (canvasArg) {\r\n        var ctx = Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"getContext2dOrThrow\"])(canvasArg);\r\n        var _a = this.options, drawLines = _a.drawLines, drawPoints = _a.drawPoints, lineWidth = _a.lineWidth, lineColor = _a.lineColor, pointSize = _a.pointSize, pointColor = _a.pointColor;\r\n        if (drawLines && this.faceLandmarks instanceof _classes_FaceLandmarks68__WEBPACK_IMPORTED_MODULE_2__[\"FaceLandmarks68\"]) {\r\n            ctx.strokeStyle = lineColor;\r\n            ctx.lineWidth = lineWidth;\r\n            Object(_drawContour__WEBPACK_IMPORTED_MODULE_4__[\"drawContour\"])(ctx, this.faceLandmarks.getJawOutline());\r\n            Object(_drawContour__WEBPACK_IMPORTED_MODULE_4__[\"drawContour\"])(ctx, this.faceLandmarks.getLeftEyeBrow());\r\n            Object(_drawContour__WEBPACK_IMPORTED_MODULE_4__[\"drawContour\"])(ctx, this.faceLandmarks.getRightEyeBrow());\r\n            Object(_drawContour__WEBPACK_IMPORTED_MODULE_4__[\"drawContour\"])(ctx, this.faceLandmarks.getNose());\r\n            Object(_drawContour__WEBPACK_IMPORTED_MODULE_4__[\"drawContour\"])(ctx, this.faceLandmarks.getLeftEye(), true);\r\n            Object(_drawContour__WEBPACK_IMPORTED_MODULE_4__[\"drawContour\"])(ctx, this.faceLandmarks.getRightEye(), true);\r\n            Object(_drawContour__WEBPACK_IMPORTED_MODULE_4__[\"drawContour\"])(ctx, this.faceLandmarks.getMouth(), true);\r\n        }\r\n        if (drawPoints) {\r\n            ctx.strokeStyle = pointColor;\r\n            ctx.fillStyle = pointColor;\r\n            var drawPoint = function (pt) {\r\n                ctx.beginPath();\r\n                ctx.arc(pt.x, pt.y, pointSize, 0, 2 * Math.PI);\r\n                ctx.fill();\r\n            };\r\n            this.faceLandmarks.positions.forEach(drawPoint);\r\n        }\r\n    };\r\n    return DrawFaceLandmarks;\r\n}());\r\n\r\nfunction drawFaceLandmarks(canvasArg, faceLandmarks) {\r\n    var faceLandmarksArray = Array.isArray(faceLandmarks) ? faceLandmarks : [faceLandmarks];\r\n    faceLandmarksArray.forEach(function (f) {\r\n        var landmarks = f instanceof _classes_FaceLandmarks__WEBPACK_IMPORTED_MODULE_1__[\"FaceLandmarks\"]\r\n            ? f\r\n            : (Object(_factories_WithFaceLandmarks__WEBPACK_IMPORTED_MODULE_3__[\"isWithFaceLandmarks\"])(f) ? f.landmarks : undefined);\r\n        if (!landmarks) {\r\n            throw new Error('drawFaceLandmarks - expected faceExpressions to be FaceLandmarks | WithFaceLandmarks<WithFaceDetection<{}>> or array thereof');\r\n        }\r\n        new DrawFaceLandmarks(landmarks).draw(canvasArg);\r\n    });\r\n}\r\n//# sourceMappingURL=DrawFaceLandmarks.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/draw/DrawFaceLandmarks.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/draw/drawContour.js":
/*!****************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/draw/drawContour.js ***!
  \****************************************************************/
/*! exports provided: drawContour */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"drawContour\", function() { return drawContour; });\nfunction drawContour(ctx, points, isClosed) {\r\n    if (isClosed === void 0) { isClosed = false; }\r\n    ctx.beginPath();\r\n    points.slice(1).forEach(function (_a, prevIdx) {\r\n        var x = _a.x, y = _a.y;\r\n        var from = points[prevIdx];\r\n        ctx.moveTo(from.x, from.y);\r\n        ctx.lineTo(x, y);\r\n    });\r\n    if (isClosed) {\r\n        var from = points[points.length - 1];\r\n        var to = points[0];\r\n        if (!from || !to) {\r\n            return;\r\n        }\r\n        ctx.moveTo(from.x, from.y);\r\n        ctx.lineTo(to.x, to.y);\r\n    }\r\n    ctx.stroke();\r\n}\r\n//# sourceMappingURL=drawContour.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/draw/drawContour.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/draw/drawDetections.js":
/*!*******************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/draw/drawDetections.js ***!
  \*******************************************************************/
/*! exports provided: drawDetections */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"drawDetections\", function() { return drawDetections; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _classes_FaceDetection__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../classes/FaceDetection */ \"./node_modules/face-api.js/build/es6/classes/FaceDetection.js\");\n/* harmony import */ var _factories_WithFaceDetection__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../factories/WithFaceDetection */ \"./node_modules/face-api.js/build/es6/factories/WithFaceDetection.js\");\n\r\n\r\n\r\nfunction drawDetections(canvasArg, detections) {\r\n    var detectionsArray = Array.isArray(detections) ? detections : [detections];\r\n    detectionsArray.forEach(function (det) {\r\n        var score = det instanceof _classes_FaceDetection__WEBPACK_IMPORTED_MODULE_1__[\"FaceDetection\"]\r\n            ? det.score\r\n            : (Object(_factories_WithFaceDetection__WEBPACK_IMPORTED_MODULE_2__[\"isWithFaceDetection\"])(det) ? det.detection.score : undefined);\r\n        var box = det instanceof _classes_FaceDetection__WEBPACK_IMPORTED_MODULE_1__[\"FaceDetection\"]\r\n            ? det.box\r\n            : (Object(_factories_WithFaceDetection__WEBPACK_IMPORTED_MODULE_2__[\"isWithFaceDetection\"])(det) ? det.detection.box : new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Box\"](det));\r\n        var label = score ? \"\" + Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"round\"])(score) : undefined;\r\n        new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"draw\"].DrawBox(box, { label: label }).draw(canvasArg);\r\n    });\r\n}\r\n//# sourceMappingURL=drawDetections.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/draw/drawDetections.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/draw/drawFaceExpressions.js":
/*!************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/draw/drawFaceExpressions.js ***!
  \************************************************************************/
/*! exports provided: drawFaceExpressions */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"drawFaceExpressions\", function() { return drawFaceExpressions; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _faceExpressionNet__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../faceExpressionNet */ \"./node_modules/face-api.js/build/es6/faceExpressionNet/index.js\");\n/* harmony import */ var _factories_WithFaceDetection__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../factories/WithFaceDetection */ \"./node_modules/face-api.js/build/es6/factories/WithFaceDetection.js\");\n/* harmony import */ var _factories_WithFaceExpressions__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../factories/WithFaceExpressions */ \"./node_modules/face-api.js/build/es6/factories/WithFaceExpressions.js\");\n\r\n\r\n\r\n\r\nfunction drawFaceExpressions(canvasArg, faceExpressions, minConfidence, textFieldAnchor) {\r\n    if (minConfidence === void 0) { minConfidence = 0.1; }\r\n    var faceExpressionsArray = Array.isArray(faceExpressions) ? faceExpressions : [faceExpressions];\r\n    faceExpressionsArray.forEach(function (e) {\r\n        var expr = e instanceof _faceExpressionNet__WEBPACK_IMPORTED_MODULE_1__[\"FaceExpressions\"]\r\n            ? e\r\n            : (Object(_factories_WithFaceExpressions__WEBPACK_IMPORTED_MODULE_3__[\"isWithFaceExpressions\"])(e) ? e.expressions : undefined);\r\n        if (!expr) {\r\n            throw new Error('drawFaceExpressions - expected faceExpressions to be FaceExpressions | WithFaceExpressions<{}> or array thereof');\r\n        }\r\n        var sorted = expr.asSortedArray();\r\n        var resultsToDisplay = sorted.filter(function (expr) { return expr.probability > minConfidence; });\r\n        var anchor = Object(_factories_WithFaceDetection__WEBPACK_IMPORTED_MODULE_2__[\"isWithFaceDetection\"])(e)\r\n            ? e.detection.box.bottomLeft\r\n            : (textFieldAnchor || new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Point\"](0, 0));\r\n        var drawTextField = new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"draw\"].DrawTextField(resultsToDisplay.map(function (expr) { return expr.expression + \" (\" + Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"round\"])(expr.probability) + \")\"; }), anchor);\r\n        drawTextField.draw(canvasArg);\r\n    });\r\n}\r\n//# sourceMappingURL=drawFaceExpressions.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/draw/drawFaceExpressions.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/draw/index.js":
/*!**********************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/draw/index.js ***!
  \**********************************************************/
/*! exports provided: drawContour, drawDetections, drawFaceExpressions, DrawFaceLandmarksOptions, DrawFaceLandmarks, drawFaceLandmarks */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _drawContour__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./drawContour */ \"./node_modules/face-api.js/build/es6/draw/drawContour.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"drawContour\", function() { return _drawContour__WEBPACK_IMPORTED_MODULE_0__[\"drawContour\"]; });\n\n/* harmony import */ var _drawDetections__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./drawDetections */ \"./node_modules/face-api.js/build/es6/draw/drawDetections.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"drawDetections\", function() { return _drawDetections__WEBPACK_IMPORTED_MODULE_1__[\"drawDetections\"]; });\n\n/* harmony import */ var _drawFaceExpressions__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./drawFaceExpressions */ \"./node_modules/face-api.js/build/es6/draw/drawFaceExpressions.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"drawFaceExpressions\", function() { return _drawFaceExpressions__WEBPACK_IMPORTED_MODULE_2__[\"drawFaceExpressions\"]; });\n\n/* harmony import */ var _DrawFaceLandmarks__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./DrawFaceLandmarks */ \"./node_modules/face-api.js/build/es6/draw/DrawFaceLandmarks.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DrawFaceLandmarksOptions\", function() { return _DrawFaceLandmarks__WEBPACK_IMPORTED_MODULE_3__[\"DrawFaceLandmarksOptions\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DrawFaceLandmarks\", function() { return _DrawFaceLandmarks__WEBPACK_IMPORTED_MODULE_3__[\"DrawFaceLandmarks\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"drawFaceLandmarks\", function() { return _DrawFaceLandmarks__WEBPACK_IMPORTED_MODULE_3__[\"drawFaceLandmarks\"]; });\n\n\r\n\r\n\r\n\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/draw/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/euclideanDistance.js":
/*!*****************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/euclideanDistance.js ***!
  \*****************************************************************/
/*! exports provided: euclideanDistance */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"euclideanDistance\", function() { return euclideanDistance; });\nfunction euclideanDistance(arr1, arr2) {\r\n    if (arr1.length !== arr2.length)\r\n        throw new Error('euclideanDistance: arr1.length !== arr2.length');\r\n    var desc1 = Array.from(arr1);\r\n    var desc2 = Array.from(arr2);\r\n    return Math.sqrt(desc1\r\n        .map(function (val, i) { return val - desc2[i]; })\r\n        .reduce(function (res, diff) { return res + Math.pow(diff, 2); }, 0));\r\n}\r\n//# sourceMappingURL=euclideanDistance.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/euclideanDistance.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceExpressionNet/FaceExpressionNet.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceExpressionNet/FaceExpressionNet.js ***!
  \***********************************************************************************/
/*! exports provided: FaceExpressionNet */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"FaceExpressionNet\", function() { return FaceExpressionNet; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _faceFeatureExtractor_FaceFeatureExtractor__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../faceFeatureExtractor/FaceFeatureExtractor */ \"./node_modules/face-api.js/build/es6/faceFeatureExtractor/FaceFeatureExtractor.js\");\n/* harmony import */ var _faceProcessor_FaceProcessor__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../faceProcessor/FaceProcessor */ \"./node_modules/face-api.js/build/es6/faceProcessor/FaceProcessor.js\");\n/* harmony import */ var _FaceExpressions__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./FaceExpressions */ \"./node_modules/face-api.js/build/es6/faceExpressionNet/FaceExpressions.js\");\n\r\n\r\n\r\n\r\n\r\n\r\nvar FaceExpressionNet = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(FaceExpressionNet, _super);\r\n    function FaceExpressionNet(faceFeatureExtractor) {\r\n        if (faceFeatureExtractor === void 0) { faceFeatureExtractor = new _faceFeatureExtractor_FaceFeatureExtractor__WEBPACK_IMPORTED_MODULE_3__[\"FaceFeatureExtractor\"](); }\r\n        return _super.call(this, 'FaceExpressionNet', faceFeatureExtractor) || this;\r\n    }\r\n    FaceExpressionNet.prototype.forwardInput = function (input) {\r\n        var _this = this;\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tidy\"](function () { return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"softmax\"](_this.runNet(input)); });\r\n    };\r\n    FaceExpressionNet.prototype.forward = function (input) {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var _a;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this.forwardInput;\r\n                        return [4 /*yield*/, Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"toNetInput\"])(input)];\r\n                    case 1: return [2 /*return*/, _a.apply(this, [_b.sent()])];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    FaceExpressionNet.prototype.predictExpressions = function (input) {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var netInput, out, probabilitesByBatch, predictionsByBatch;\r\n            var _this = this;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"toNetInput\"])(input)];\r\n                    case 1:\r\n                        netInput = _a.sent();\r\n                        return [4 /*yield*/, this.forwardInput(netInput)];\r\n                    case 2:\r\n                        out = _a.sent();\r\n                        return [4 /*yield*/, Promise.all(_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"unstack\"](out).map(function (t) { return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(_this, void 0, void 0, function () {\r\n                                var data;\r\n                                return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n                                    switch (_a.label) {\r\n                                        case 0: return [4 /*yield*/, t.data()];\r\n                                        case 1:\r\n                                            data = _a.sent();\r\n                                            t.dispose();\r\n                                            return [2 /*return*/, data];\r\n                                    }\r\n                                });\r\n                            }); }))];\r\n                    case 3:\r\n                        probabilitesByBatch = _a.sent();\r\n                        out.dispose();\r\n                        predictionsByBatch = probabilitesByBatch\r\n                            .map(function (probabilites) { return new _FaceExpressions__WEBPACK_IMPORTED_MODULE_5__[\"FaceExpressions\"](probabilites); });\r\n                        return [2 /*return*/, netInput.isBatchInput\r\n                                ? predictionsByBatch\r\n                                : predictionsByBatch[0]];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    FaceExpressionNet.prototype.getDefaultModelName = function () {\r\n        return 'face_expression_model';\r\n    };\r\n    FaceExpressionNet.prototype.getClassifierChannelsIn = function () {\r\n        return 256;\r\n    };\r\n    FaceExpressionNet.prototype.getClassifierChannelsOut = function () {\r\n        return 7;\r\n    };\r\n    return FaceExpressionNet;\r\n}(_faceProcessor_FaceProcessor__WEBPACK_IMPORTED_MODULE_4__[\"FaceProcessor\"]));\r\n\r\n//# sourceMappingURL=FaceExpressionNet.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceExpressionNet/FaceExpressionNet.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceExpressionNet/FaceExpressions.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceExpressionNet/FaceExpressions.js ***!
  \*********************************************************************************/
/*! exports provided: FACE_EXPRESSION_LABELS, FaceExpressions */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"FACE_EXPRESSION_LABELS\", function() { return FACE_EXPRESSION_LABELS; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"FaceExpressions\", function() { return FaceExpressions; });\nvar FACE_EXPRESSION_LABELS = ['neutral', 'happy', 'sad', 'angry', 'fearful', 'disgusted', 'surprised'];\r\nvar FaceExpressions = /** @class */ (function () {\r\n    function FaceExpressions(probabilities) {\r\n        var _this = this;\r\n        if (probabilities.length !== 7) {\r\n            throw new Error(\"FaceExpressions.constructor - expected probabilities.length to be 7, have: \" + probabilities.length);\r\n        }\r\n        FACE_EXPRESSION_LABELS.forEach(function (expression, idx) {\r\n            _this[expression] = probabilities[idx];\r\n        });\r\n    }\r\n    FaceExpressions.prototype.asSortedArray = function () {\r\n        var _this = this;\r\n        return FACE_EXPRESSION_LABELS\r\n            .map(function (expression) { return ({ expression: expression, probability: _this[expression] }); })\r\n            .sort(function (e0, e1) { return e1.probability - e0.probability; });\r\n    };\r\n    return FaceExpressions;\r\n}());\r\n\r\n//# sourceMappingURL=FaceExpressions.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceExpressionNet/FaceExpressions.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceExpressionNet/index.js":
/*!***********************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceExpressionNet/index.js ***!
  \***********************************************************************/
/*! exports provided: FaceExpressionNet, FACE_EXPRESSION_LABELS, FaceExpressions */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _FaceExpressionNet__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./FaceExpressionNet */ \"./node_modules/face-api.js/build/es6/faceExpressionNet/FaceExpressionNet.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceExpressionNet\", function() { return _FaceExpressionNet__WEBPACK_IMPORTED_MODULE_0__[\"FaceExpressionNet\"]; });\n\n/* harmony import */ var _FaceExpressions__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./FaceExpressions */ \"./node_modules/face-api.js/build/es6/faceExpressionNet/FaceExpressions.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FACE_EXPRESSION_LABELS\", function() { return _FaceExpressions__WEBPACK_IMPORTED_MODULE_1__[\"FACE_EXPRESSION_LABELS\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceExpressions\", function() { return _FaceExpressions__WEBPACK_IMPORTED_MODULE_1__[\"FaceExpressions\"]; });\n\n\r\n\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceExpressionNet/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceFeatureExtractor/FaceFeatureExtractor.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceFeatureExtractor/FaceFeatureExtractor.js ***!
  \*****************************************************************************************/
/*! exports provided: FaceFeatureExtractor */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"FaceFeatureExtractor\", function() { return FaceFeatureExtractor; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _denseBlock__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./denseBlock */ \"./node_modules/face-api.js/build/es6/faceFeatureExtractor/denseBlock.js\");\n/* harmony import */ var _extractParams__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./extractParams */ \"./node_modules/face-api.js/build/es6/faceFeatureExtractor/extractParams.js\");\n/* harmony import */ var _extractParamsFromWeigthMap__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./extractParamsFromWeigthMap */ \"./node_modules/face-api.js/build/es6/faceFeatureExtractor/extractParamsFromWeigthMap.js\");\n\r\n\r\n\r\n\r\n\r\n\r\nvar FaceFeatureExtractor = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(FaceFeatureExtractor, _super);\r\n    function FaceFeatureExtractor() {\r\n        return _super.call(this, 'FaceFeatureExtractor') || this;\r\n    }\r\n    FaceFeatureExtractor.prototype.forwardInput = function (input) {\r\n        var params = this.params;\r\n        if (!params) {\r\n            throw new Error('FaceFeatureExtractor - load model before inference');\r\n        }\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tidy\"](function () {\r\n            var batchTensor = input.toBatchTensor(112, true);\r\n            var meanRgb = [122.782, 117.001, 104.298];\r\n            var normalized = Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"normalize\"])(batchTensor, meanRgb).div(_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"scalar\"](255));\r\n            var out = Object(_denseBlock__WEBPACK_IMPORTED_MODULE_3__[\"denseBlock4\"])(normalized, params.dense0, true);\r\n            out = Object(_denseBlock__WEBPACK_IMPORTED_MODULE_3__[\"denseBlock4\"])(out, params.dense1);\r\n            out = Object(_denseBlock__WEBPACK_IMPORTED_MODULE_3__[\"denseBlock4\"])(out, params.dense2);\r\n            out = Object(_denseBlock__WEBPACK_IMPORTED_MODULE_3__[\"denseBlock4\"])(out, params.dense3);\r\n            out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"avgPool\"](out, [7, 7], [2, 2], 'valid');\r\n            return out;\r\n        });\r\n    };\r\n    FaceFeatureExtractor.prototype.forward = function (input) {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var _a;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this.forwardInput;\r\n                        return [4 /*yield*/, Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"toNetInput\"])(input)];\r\n                    case 1: return [2 /*return*/, _a.apply(this, [_b.sent()])];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    FaceFeatureExtractor.prototype.getDefaultModelName = function () {\r\n        return 'face_feature_extractor_model';\r\n    };\r\n    FaceFeatureExtractor.prototype.extractParamsFromWeigthMap = function (weightMap) {\r\n        return Object(_extractParamsFromWeigthMap__WEBPACK_IMPORTED_MODULE_5__[\"extractParamsFromWeigthMap\"])(weightMap);\r\n    };\r\n    FaceFeatureExtractor.prototype.extractParams = function (weights) {\r\n        return Object(_extractParams__WEBPACK_IMPORTED_MODULE_4__[\"extractParams\"])(weights);\r\n    };\r\n    return FaceFeatureExtractor;\r\n}(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"NeuralNetwork\"]));\r\n\r\n//# sourceMappingURL=FaceFeatureExtractor.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceFeatureExtractor/FaceFeatureExtractor.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceFeatureExtractor/TinyFaceFeatureExtractor.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceFeatureExtractor/TinyFaceFeatureExtractor.js ***!
  \*********************************************************************************************/
/*! exports provided: TinyFaceFeatureExtractor */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TinyFaceFeatureExtractor\", function() { return TinyFaceFeatureExtractor; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _denseBlock__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./denseBlock */ \"./node_modules/face-api.js/build/es6/faceFeatureExtractor/denseBlock.js\");\n/* harmony import */ var _extractParamsFromWeigthMapTiny__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./extractParamsFromWeigthMapTiny */ \"./node_modules/face-api.js/build/es6/faceFeatureExtractor/extractParamsFromWeigthMapTiny.js\");\n/* harmony import */ var _extractParamsTiny__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./extractParamsTiny */ \"./node_modules/face-api.js/build/es6/faceFeatureExtractor/extractParamsTiny.js\");\n\r\n\r\n\r\n\r\n\r\n\r\nvar TinyFaceFeatureExtractor = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(TinyFaceFeatureExtractor, _super);\r\n    function TinyFaceFeatureExtractor() {\r\n        return _super.call(this, 'TinyFaceFeatureExtractor') || this;\r\n    }\r\n    TinyFaceFeatureExtractor.prototype.forwardInput = function (input) {\r\n        var params = this.params;\r\n        if (!params) {\r\n            throw new Error('TinyFaceFeatureExtractor - load model before inference');\r\n        }\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tidy\"](function () {\r\n            var batchTensor = input.toBatchTensor(112, true);\r\n            var meanRgb = [122.782, 117.001, 104.298];\r\n            var normalized = Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"normalize\"])(batchTensor, meanRgb).div(_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"scalar\"](255));\r\n            var out = Object(_denseBlock__WEBPACK_IMPORTED_MODULE_3__[\"denseBlock3\"])(normalized, params.dense0, true);\r\n            out = Object(_denseBlock__WEBPACK_IMPORTED_MODULE_3__[\"denseBlock3\"])(out, params.dense1);\r\n            out = Object(_denseBlock__WEBPACK_IMPORTED_MODULE_3__[\"denseBlock3\"])(out, params.dense2);\r\n            out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"avgPool\"](out, [14, 14], [2, 2], 'valid');\r\n            return out;\r\n        });\r\n    };\r\n    TinyFaceFeatureExtractor.prototype.forward = function (input) {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var _a;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this.forwardInput;\r\n                        return [4 /*yield*/, Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"toNetInput\"])(input)];\r\n                    case 1: return [2 /*return*/, _a.apply(this, [_b.sent()])];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    TinyFaceFeatureExtractor.prototype.getDefaultModelName = function () {\r\n        return 'face_feature_extractor_tiny_model';\r\n    };\r\n    TinyFaceFeatureExtractor.prototype.extractParamsFromWeigthMap = function (weightMap) {\r\n        return Object(_extractParamsFromWeigthMapTiny__WEBPACK_IMPORTED_MODULE_4__[\"extractParamsFromWeigthMapTiny\"])(weightMap);\r\n    };\r\n    TinyFaceFeatureExtractor.prototype.extractParams = function (weights) {\r\n        return Object(_extractParamsTiny__WEBPACK_IMPORTED_MODULE_5__[\"extractParamsTiny\"])(weights);\r\n    };\r\n    return TinyFaceFeatureExtractor;\r\n}(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"NeuralNetwork\"]));\r\n\r\n//# sourceMappingURL=TinyFaceFeatureExtractor.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceFeatureExtractor/TinyFaceFeatureExtractor.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceFeatureExtractor/denseBlock.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceFeatureExtractor/denseBlock.js ***!
  \*******************************************************************************/
/*! exports provided: denseBlock3, denseBlock4 */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"denseBlock3\", function() { return denseBlock3; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"denseBlock4\", function() { return denseBlock4; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var _common_depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/depthwiseSeparableConv */ \"./node_modules/face-api.js/build/es6/common/depthwiseSeparableConv.js\");\n\r\n\r\nfunction denseBlock3(x, denseBlockParams, isFirstLayer) {\r\n    if (isFirstLayer === void 0) { isFirstLayer = false; }\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () {\r\n        var out1 = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"relu\"](isFirstLayer\r\n            ? _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"conv2d\"](x, denseBlockParams.conv0.filters, [2, 2], 'same'), denseBlockParams.conv0.bias)\r\n            : Object(_common_depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_1__[\"depthwiseSeparableConv\"])(x, denseBlockParams.conv0, [2, 2]));\r\n        var out2 = Object(_common_depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_1__[\"depthwiseSeparableConv\"])(out1, denseBlockParams.conv1, [1, 1]);\r\n        var in3 = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"relu\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](out1, out2));\r\n        var out3 = Object(_common_depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_1__[\"depthwiseSeparableConv\"])(in3, denseBlockParams.conv2, [1, 1]);\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"relu\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](out1, _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](out2, out3)));\r\n    });\r\n}\r\nfunction denseBlock4(x, denseBlockParams, isFirstLayer, isScaleDown) {\r\n    if (isFirstLayer === void 0) { isFirstLayer = false; }\r\n    if (isScaleDown === void 0) { isScaleDown = true; }\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () {\r\n        var out1 = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"relu\"](isFirstLayer\r\n            ? _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"conv2d\"](x, denseBlockParams.conv0.filters, isScaleDown ? [2, 2] : [1, 1], 'same'), denseBlockParams.conv0.bias)\r\n            : Object(_common_depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_1__[\"depthwiseSeparableConv\"])(x, denseBlockParams.conv0, isScaleDown ? [2, 2] : [1, 1]));\r\n        var out2 = Object(_common_depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_1__[\"depthwiseSeparableConv\"])(out1, denseBlockParams.conv1, [1, 1]);\r\n        var in3 = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"relu\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](out1, out2));\r\n        var out3 = Object(_common_depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_1__[\"depthwiseSeparableConv\"])(in3, denseBlockParams.conv2, [1, 1]);\r\n        var in4 = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"relu\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](out1, _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](out2, out3)));\r\n        var out4 = Object(_common_depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_1__[\"depthwiseSeparableConv\"])(in4, denseBlockParams.conv3, [1, 1]);\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"relu\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](out1, _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](out2, _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](out3, out4))));\r\n    });\r\n}\r\n//# sourceMappingURL=denseBlock.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceFeatureExtractor/denseBlock.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceFeatureExtractor/extractParams.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceFeatureExtractor/extractParams.js ***!
  \**********************************************************************************/
/*! exports provided: extractParams */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractParams\", function() { return extractParams; });\n/* harmony import */ var _extractorsFactory__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./extractorsFactory */ \"./node_modules/face-api.js/build/es6/faceFeatureExtractor/extractorsFactory.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n\r\n\r\nfunction extractParams(weights) {\r\n    var paramMappings = [];\r\n    var _a = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"TfjsImageRecognitionBase\"].extractWeightsFactory(weights), extractWeights = _a.extractWeights, getRemainingWeights = _a.getRemainingWeights;\r\n    var extractDenseBlock4Params = Object(_extractorsFactory__WEBPACK_IMPORTED_MODULE_0__[\"extractorsFactory\"])(extractWeights, paramMappings).extractDenseBlock4Params;\r\n    var dense0 = extractDenseBlock4Params(3, 32, 'dense0', true);\r\n    var dense1 = extractDenseBlock4Params(32, 64, 'dense1');\r\n    var dense2 = extractDenseBlock4Params(64, 128, 'dense2');\r\n    var dense3 = extractDenseBlock4Params(128, 256, 'dense3');\r\n    if (getRemainingWeights().length !== 0) {\r\n        throw new Error(\"weights remaing after extract: \" + getRemainingWeights().length);\r\n    }\r\n    return {\r\n        paramMappings: paramMappings,\r\n        params: { dense0: dense0, dense1: dense1, dense2: dense2, dense3: dense3 }\r\n    };\r\n}\r\n//# sourceMappingURL=extractParams.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceFeatureExtractor/extractParams.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceFeatureExtractor/extractParamsFromWeigthMap.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceFeatureExtractor/extractParamsFromWeigthMap.js ***!
  \***********************************************************************************************/
/*! exports provided: extractParamsFromWeigthMap */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractParamsFromWeigthMap\", function() { return extractParamsFromWeigthMap; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _loadParamsFactory__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./loadParamsFactory */ \"./node_modules/face-api.js/build/es6/faceFeatureExtractor/loadParamsFactory.js\");\n\r\n\r\nfunction extractParamsFromWeigthMap(weightMap) {\r\n    var paramMappings = [];\r\n    var extractDenseBlock4Params = Object(_loadParamsFactory__WEBPACK_IMPORTED_MODULE_1__[\"loadParamsFactory\"])(weightMap, paramMappings).extractDenseBlock4Params;\r\n    var params = {\r\n        dense0: extractDenseBlock4Params('dense0', true),\r\n        dense1: extractDenseBlock4Params('dense1'),\r\n        dense2: extractDenseBlock4Params('dense2'),\r\n        dense3: extractDenseBlock4Params('dense3')\r\n    };\r\n    tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].disposeUnusedWeightTensors(weightMap, paramMappings);\r\n    return { params: params, paramMappings: paramMappings };\r\n}\r\n//# sourceMappingURL=extractParamsFromWeigthMap.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceFeatureExtractor/extractParamsFromWeigthMap.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceFeatureExtractor/extractParamsFromWeigthMapTiny.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceFeatureExtractor/extractParamsFromWeigthMapTiny.js ***!
  \***************************************************************************************************/
/*! exports provided: extractParamsFromWeigthMapTiny */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractParamsFromWeigthMapTiny\", function() { return extractParamsFromWeigthMapTiny; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _loadParamsFactory__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./loadParamsFactory */ \"./node_modules/face-api.js/build/es6/faceFeatureExtractor/loadParamsFactory.js\");\n\r\n\r\nfunction extractParamsFromWeigthMapTiny(weightMap) {\r\n    var paramMappings = [];\r\n    var extractDenseBlock3Params = Object(_loadParamsFactory__WEBPACK_IMPORTED_MODULE_1__[\"loadParamsFactory\"])(weightMap, paramMappings).extractDenseBlock3Params;\r\n    var params = {\r\n        dense0: extractDenseBlock3Params('dense0', true),\r\n        dense1: extractDenseBlock3Params('dense1'),\r\n        dense2: extractDenseBlock3Params('dense2')\r\n    };\r\n    tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].disposeUnusedWeightTensors(weightMap, paramMappings);\r\n    return { params: params, paramMappings: paramMappings };\r\n}\r\n//# sourceMappingURL=extractParamsFromWeigthMapTiny.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceFeatureExtractor/extractParamsFromWeigthMapTiny.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceFeatureExtractor/extractParamsTiny.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceFeatureExtractor/extractParamsTiny.js ***!
  \**************************************************************************************/
/*! exports provided: extractParamsTiny */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractParamsTiny\", function() { return extractParamsTiny; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _extractorsFactory__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./extractorsFactory */ \"./node_modules/face-api.js/build/es6/faceFeatureExtractor/extractorsFactory.js\");\n\r\n\r\nfunction extractParamsTiny(weights) {\r\n    var paramMappings = [];\r\n    var _a = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].extractWeightsFactory(weights), extractWeights = _a.extractWeights, getRemainingWeights = _a.getRemainingWeights;\r\n    var extractDenseBlock3Params = Object(_extractorsFactory__WEBPACK_IMPORTED_MODULE_1__[\"extractorsFactory\"])(extractWeights, paramMappings).extractDenseBlock3Params;\r\n    var dense0 = extractDenseBlock3Params(3, 32, 'dense0', true);\r\n    var dense1 = extractDenseBlock3Params(32, 64, 'dense1');\r\n    var dense2 = extractDenseBlock3Params(64, 128, 'dense2');\r\n    if (getRemainingWeights().length !== 0) {\r\n        throw new Error(\"weights remaing after extract: \" + getRemainingWeights().length);\r\n    }\r\n    return {\r\n        paramMappings: paramMappings,\r\n        params: { dense0: dense0, dense1: dense1, dense2: dense2 }\r\n    };\r\n}\r\n//# sourceMappingURL=extractParamsTiny.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceFeatureExtractor/extractParamsTiny.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceFeatureExtractor/extractorsFactory.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceFeatureExtractor/extractorsFactory.js ***!
  \**************************************************************************************/
/*! exports provided: extractorsFactory */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractorsFactory\", function() { return extractorsFactory; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n\r\nfunction extractorsFactory(extractWeights, paramMappings) {\r\n    var extractConvParams = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].extractConvParamsFactory(extractWeights, paramMappings);\r\n    var extractSeparableConvParams = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].extractSeparableConvParamsFactory(extractWeights, paramMappings);\r\n    function extractDenseBlock3Params(channelsIn, channelsOut, mappedPrefix, isFirstLayer) {\r\n        if (isFirstLayer === void 0) { isFirstLayer = false; }\r\n        var conv0 = isFirstLayer\r\n            ? extractConvParams(channelsIn, channelsOut, 3, mappedPrefix + \"/conv0\")\r\n            : extractSeparableConvParams(channelsIn, channelsOut, mappedPrefix + \"/conv0\");\r\n        var conv1 = extractSeparableConvParams(channelsOut, channelsOut, mappedPrefix + \"/conv1\");\r\n        var conv2 = extractSeparableConvParams(channelsOut, channelsOut, mappedPrefix + \"/conv2\");\r\n        return { conv0: conv0, conv1: conv1, conv2: conv2 };\r\n    }\r\n    function extractDenseBlock4Params(channelsIn, channelsOut, mappedPrefix, isFirstLayer) {\r\n        if (isFirstLayer === void 0) { isFirstLayer = false; }\r\n        var _a = extractDenseBlock3Params(channelsIn, channelsOut, mappedPrefix, isFirstLayer), conv0 = _a.conv0, conv1 = _a.conv1, conv2 = _a.conv2;\r\n        var conv3 = extractSeparableConvParams(channelsOut, channelsOut, mappedPrefix + \"/conv3\");\r\n        return { conv0: conv0, conv1: conv1, conv2: conv2, conv3: conv3 };\r\n    }\r\n    return {\r\n        extractDenseBlock3Params: extractDenseBlock3Params,\r\n        extractDenseBlock4Params: extractDenseBlock4Params\r\n    };\r\n}\r\n//# sourceMappingURL=extractorsFactory.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceFeatureExtractor/extractorsFactory.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceFeatureExtractor/loadParamsFactory.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceFeatureExtractor/loadParamsFactory.js ***!
  \**************************************************************************************/
/*! exports provided: loadParamsFactory */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"loadParamsFactory\", function() { return loadParamsFactory; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _common_loadConvParamsFactory__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/loadConvParamsFactory */ \"./node_modules/face-api.js/build/es6/common/loadConvParamsFactory.js\");\n\r\n\r\nfunction loadParamsFactory(weightMap, paramMappings) {\r\n    var extractWeightEntry = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].extractWeightEntryFactory(weightMap, paramMappings);\r\n    var extractConvParams = Object(_common_loadConvParamsFactory__WEBPACK_IMPORTED_MODULE_1__[\"loadConvParamsFactory\"])(extractWeightEntry);\r\n    var extractSeparableConvParams = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].loadSeparableConvParamsFactory(extractWeightEntry);\r\n    function extractDenseBlock3Params(prefix, isFirstLayer) {\r\n        if (isFirstLayer === void 0) { isFirstLayer = false; }\r\n        var conv0 = isFirstLayer\r\n            ? extractConvParams(prefix + \"/conv0\")\r\n            : extractSeparableConvParams(prefix + \"/conv0\");\r\n        var conv1 = extractSeparableConvParams(prefix + \"/conv1\");\r\n        var conv2 = extractSeparableConvParams(prefix + \"/conv2\");\r\n        return { conv0: conv0, conv1: conv1, conv2: conv2 };\r\n    }\r\n    function extractDenseBlock4Params(prefix, isFirstLayer) {\r\n        if (isFirstLayer === void 0) { isFirstLayer = false; }\r\n        var conv0 = isFirstLayer\r\n            ? extractConvParams(prefix + \"/conv0\")\r\n            : extractSeparableConvParams(prefix + \"/conv0\");\r\n        var conv1 = extractSeparableConvParams(prefix + \"/conv1\");\r\n        var conv2 = extractSeparableConvParams(prefix + \"/conv2\");\r\n        var conv3 = extractSeparableConvParams(prefix + \"/conv3\");\r\n        return { conv0: conv0, conv1: conv1, conv2: conv2, conv3: conv3 };\r\n    }\r\n    return {\r\n        extractDenseBlock3Params: extractDenseBlock3Params,\r\n        extractDenseBlock4Params: extractDenseBlock4Params\r\n    };\r\n}\r\n//# sourceMappingURL=loadParamsFactory.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceFeatureExtractor/loadParamsFactory.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceLandmarkNet/FaceLandmark68Net.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceLandmarkNet/FaceLandmark68Net.js ***!
  \*********************************************************************************/
/*! exports provided: FaceLandmark68Net */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"FaceLandmark68Net\", function() { return FaceLandmark68Net; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _faceFeatureExtractor_FaceFeatureExtractor__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../faceFeatureExtractor/FaceFeatureExtractor */ \"./node_modules/face-api.js/build/es6/faceFeatureExtractor/FaceFeatureExtractor.js\");\n/* harmony import */ var _FaceLandmark68NetBase__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./FaceLandmark68NetBase */ \"./node_modules/face-api.js/build/es6/faceLandmarkNet/FaceLandmark68NetBase.js\");\n\r\n\r\n\r\nvar FaceLandmark68Net = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(FaceLandmark68Net, _super);\r\n    function FaceLandmark68Net(faceFeatureExtractor) {\r\n        if (faceFeatureExtractor === void 0) { faceFeatureExtractor = new _faceFeatureExtractor_FaceFeatureExtractor__WEBPACK_IMPORTED_MODULE_1__[\"FaceFeatureExtractor\"](); }\r\n        return _super.call(this, 'FaceLandmark68Net', faceFeatureExtractor) || this;\r\n    }\r\n    FaceLandmark68Net.prototype.getDefaultModelName = function () {\r\n        return 'face_landmark_68_model';\r\n    };\r\n    FaceLandmark68Net.prototype.getClassifierChannelsIn = function () {\r\n        return 256;\r\n    };\r\n    return FaceLandmark68Net;\r\n}(_FaceLandmark68NetBase__WEBPACK_IMPORTED_MODULE_2__[\"FaceLandmark68NetBase\"]));\r\n\r\n//# sourceMappingURL=FaceLandmark68Net.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceLandmarkNet/FaceLandmark68Net.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceLandmarkNet/FaceLandmark68NetBase.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceLandmarkNet/FaceLandmark68NetBase.js ***!
  \*************************************************************************************/
/*! exports provided: FaceLandmark68NetBase */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"FaceLandmark68NetBase\", function() { return FaceLandmark68NetBase; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _classes_FaceLandmarks68__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../classes/FaceLandmarks68 */ \"./node_modules/face-api.js/build/es6/classes/FaceLandmarks68.js\");\n/* harmony import */ var _faceProcessor_FaceProcessor__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../faceProcessor/FaceProcessor */ \"./node_modules/face-api.js/build/es6/faceProcessor/FaceProcessor.js\");\n\r\n\r\n\r\n\r\n\r\nvar FaceLandmark68NetBase = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(FaceLandmark68NetBase, _super);\r\n    function FaceLandmark68NetBase() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    FaceLandmark68NetBase.prototype.postProcess = function (output, inputSize, originalDimensions) {\r\n        var inputDimensions = originalDimensions.map(function (_a) {\r\n            var width = _a.width, height = _a.height;\r\n            var scale = inputSize / Math.max(height, width);\r\n            return {\r\n                width: width * scale,\r\n                height: height * scale\r\n            };\r\n        });\r\n        var batchSize = inputDimensions.length;\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tidy\"](function () {\r\n            var createInterleavedTensor = function (fillX, fillY) {\r\n                return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"stack\"]([\r\n                    _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"fill\"]([68], fillX),\r\n                    _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"fill\"]([68], fillY)\r\n                ], 1).as2D(1, 136).as1D();\r\n            };\r\n            var getPadding = function (batchIdx, cond) {\r\n                var _a = inputDimensions[batchIdx], width = _a.width, height = _a.height;\r\n                return cond(width, height) ? Math.abs(width - height) / 2 : 0;\r\n            };\r\n            var getPaddingX = function (batchIdx) { return getPadding(batchIdx, function (w, h) { return w < h; }); };\r\n            var getPaddingY = function (batchIdx) { return getPadding(batchIdx, function (w, h) { return h < w; }); };\r\n            var landmarkTensors = output\r\n                .mul(_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"fill\"]([batchSize, 136], inputSize))\r\n                .sub(_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"stack\"](Array.from(Array(batchSize), function (_, batchIdx) {\r\n                return createInterleavedTensor(getPaddingX(batchIdx), getPaddingY(batchIdx));\r\n            })))\r\n                .div(_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"stack\"](Array.from(Array(batchSize), function (_, batchIdx) {\r\n                return createInterleavedTensor(inputDimensions[batchIdx].width, inputDimensions[batchIdx].height);\r\n            })));\r\n            return landmarkTensors;\r\n        });\r\n    };\r\n    FaceLandmark68NetBase.prototype.forwardInput = function (input) {\r\n        var _this = this;\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tidy\"](function () {\r\n            var out = _this.runNet(input);\r\n            return _this.postProcess(out, input.inputSize, input.inputDimensions.map(function (_a) {\r\n                var height = _a[0], width = _a[1];\r\n                return ({ height: height, width: width });\r\n            }));\r\n        });\r\n    };\r\n    FaceLandmark68NetBase.prototype.forward = function (input) {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var _a;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this.forwardInput;\r\n                        return [4 /*yield*/, Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"toNetInput\"])(input)];\r\n                    case 1: return [2 /*return*/, _a.apply(this, [_b.sent()])];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    FaceLandmark68NetBase.prototype.detectLandmarks = function (input) {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var netInput, landmarkTensors, landmarksForBatch;\r\n            var _this = this;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"toNetInput\"])(input)];\r\n                    case 1:\r\n                        netInput = _a.sent();\r\n                        landmarkTensors = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tidy\"](function () { return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"unstack\"](_this.forwardInput(netInput)); });\r\n                        return [4 /*yield*/, Promise.all(landmarkTensors.map(function (landmarkTensor, batchIdx) { return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(_this, void 0, void 0, function () {\r\n                                var landmarksArray, _a, _b, xCoords, yCoords;\r\n                                return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_c) {\r\n                                    switch (_c.label) {\r\n                                        case 0:\r\n                                            _b = (_a = Array).from;\r\n                                            return [4 /*yield*/, landmarkTensor.data()];\r\n                                        case 1:\r\n                                            landmarksArray = _b.apply(_a, [_c.sent()]);\r\n                                            xCoords = landmarksArray.filter(function (_, i) { return Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"isEven\"])(i); });\r\n                                            yCoords = landmarksArray.filter(function (_, i) { return !Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"isEven\"])(i); });\r\n                                            return [2 /*return*/, new _classes_FaceLandmarks68__WEBPACK_IMPORTED_MODULE_3__[\"FaceLandmarks68\"](Array(68).fill(0).map(function (_, i) { return new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"Point\"](xCoords[i], yCoords[i]); }), {\r\n                                                    height: netInput.getInputHeight(batchIdx),\r\n                                                    width: netInput.getInputWidth(batchIdx),\r\n                                                })];\r\n                                    }\r\n                                });\r\n                            }); }))];\r\n                    case 2:\r\n                        landmarksForBatch = _a.sent();\r\n                        landmarkTensors.forEach(function (t) { return t.dispose(); });\r\n                        return [2 /*return*/, netInput.isBatchInput\r\n                                ? landmarksForBatch\r\n                                : landmarksForBatch[0]];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    FaceLandmark68NetBase.prototype.getClassifierChannelsOut = function () {\r\n        return 136;\r\n    };\r\n    return FaceLandmark68NetBase;\r\n}(_faceProcessor_FaceProcessor__WEBPACK_IMPORTED_MODULE_4__[\"FaceProcessor\"]));\r\n\r\n//# sourceMappingURL=FaceLandmark68NetBase.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceLandmarkNet/FaceLandmark68NetBase.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceLandmarkNet/FaceLandmark68TinyNet.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceLandmarkNet/FaceLandmark68TinyNet.js ***!
  \*************************************************************************************/
/*! exports provided: FaceLandmark68TinyNet */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"FaceLandmark68TinyNet\", function() { return FaceLandmark68TinyNet; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _faceFeatureExtractor_TinyFaceFeatureExtractor__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../faceFeatureExtractor/TinyFaceFeatureExtractor */ \"./node_modules/face-api.js/build/es6/faceFeatureExtractor/TinyFaceFeatureExtractor.js\");\n/* harmony import */ var _FaceLandmark68NetBase__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./FaceLandmark68NetBase */ \"./node_modules/face-api.js/build/es6/faceLandmarkNet/FaceLandmark68NetBase.js\");\n\r\n\r\n\r\nvar FaceLandmark68TinyNet = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(FaceLandmark68TinyNet, _super);\r\n    function FaceLandmark68TinyNet(faceFeatureExtractor) {\r\n        if (faceFeatureExtractor === void 0) { faceFeatureExtractor = new _faceFeatureExtractor_TinyFaceFeatureExtractor__WEBPACK_IMPORTED_MODULE_1__[\"TinyFaceFeatureExtractor\"](); }\r\n        return _super.call(this, 'FaceLandmark68TinyNet', faceFeatureExtractor) || this;\r\n    }\r\n    FaceLandmark68TinyNet.prototype.getDefaultModelName = function () {\r\n        return 'face_landmark_68_tiny_model';\r\n    };\r\n    FaceLandmark68TinyNet.prototype.getClassifierChannelsIn = function () {\r\n        return 128;\r\n    };\r\n    return FaceLandmark68TinyNet;\r\n}(_FaceLandmark68NetBase__WEBPACK_IMPORTED_MODULE_2__[\"FaceLandmark68NetBase\"]));\r\n\r\n//# sourceMappingURL=FaceLandmark68TinyNet.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceLandmarkNet/FaceLandmark68TinyNet.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceLandmarkNet/index.js":
/*!*********************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceLandmarkNet/index.js ***!
  \*********************************************************************/
/*! exports provided: FaceLandmark68Net, FaceLandmark68TinyNet, FaceLandmarkNet */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"FaceLandmarkNet\", function() { return FaceLandmarkNet; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _FaceLandmark68Net__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./FaceLandmark68Net */ \"./node_modules/face-api.js/build/es6/faceLandmarkNet/FaceLandmark68Net.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceLandmark68Net\", function() { return _FaceLandmark68Net__WEBPACK_IMPORTED_MODULE_1__[\"FaceLandmark68Net\"]; });\n\n/* harmony import */ var _FaceLandmark68TinyNet__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./FaceLandmark68TinyNet */ \"./node_modules/face-api.js/build/es6/faceLandmarkNet/FaceLandmark68TinyNet.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceLandmark68TinyNet\", function() { return _FaceLandmark68TinyNet__WEBPACK_IMPORTED_MODULE_2__[\"FaceLandmark68TinyNet\"]; });\n\n\r\n\r\n\r\n\r\nvar FaceLandmarkNet = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(FaceLandmarkNet, _super);\r\n    function FaceLandmarkNet() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    return FaceLandmarkNet;\r\n}(_FaceLandmark68Net__WEBPACK_IMPORTED_MODULE_1__[\"FaceLandmark68Net\"]));\r\n\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceLandmarkNet/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceProcessor/FaceProcessor.js":
/*!***************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceProcessor/FaceProcessor.js ***!
  \***************************************************************************/
/*! exports provided: FaceProcessor */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"FaceProcessor\", function() { return FaceProcessor; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _common_fullyConnectedLayer__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common/fullyConnectedLayer */ \"./node_modules/face-api.js/build/es6/common/fullyConnectedLayer.js\");\n/* harmony import */ var _extractParams__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./extractParams */ \"./node_modules/face-api.js/build/es6/faceProcessor/extractParams.js\");\n/* harmony import */ var _extractParamsFromWeigthMap__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./extractParamsFromWeigthMap */ \"./node_modules/face-api.js/build/es6/faceProcessor/extractParamsFromWeigthMap.js\");\n/* harmony import */ var _util__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./util */ \"./node_modules/face-api.js/build/es6/faceProcessor/util.js\");\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nvar FaceProcessor = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(FaceProcessor, _super);\r\n    function FaceProcessor(_name, faceFeatureExtractor) {\r\n        var _this = _super.call(this, _name) || this;\r\n        _this._faceFeatureExtractor = faceFeatureExtractor;\r\n        return _this;\r\n    }\r\n    Object.defineProperty(FaceProcessor.prototype, \"faceFeatureExtractor\", {\r\n        get: function () {\r\n            return this._faceFeatureExtractor;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    FaceProcessor.prototype.runNet = function (input) {\r\n        var _this = this;\r\n        var params = this.params;\r\n        if (!params) {\r\n            throw new Error(this._name + \" - load model before inference\");\r\n        }\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tidy\"](function () {\r\n            var bottleneckFeatures = input instanceof tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"NetInput\"]\r\n                ? _this.faceFeatureExtractor.forwardInput(input)\r\n                : input;\r\n            return Object(_common_fullyConnectedLayer__WEBPACK_IMPORTED_MODULE_3__[\"fullyConnectedLayer\"])(bottleneckFeatures.as2D(bottleneckFeatures.shape[0], -1), params.fc);\r\n        });\r\n    };\r\n    FaceProcessor.prototype.dispose = function (throwOnRedispose) {\r\n        if (throwOnRedispose === void 0) { throwOnRedispose = true; }\r\n        this.faceFeatureExtractor.dispose(throwOnRedispose);\r\n        _super.prototype.dispose.call(this, throwOnRedispose);\r\n    };\r\n    FaceProcessor.prototype.loadClassifierParams = function (weights) {\r\n        var _a = this.extractClassifierParams(weights), params = _a.params, paramMappings = _a.paramMappings;\r\n        this._params = params;\r\n        this._paramMappings = paramMappings;\r\n    };\r\n    FaceProcessor.prototype.extractClassifierParams = function (weights) {\r\n        return Object(_extractParams__WEBPACK_IMPORTED_MODULE_4__[\"extractParams\"])(weights, this.getClassifierChannelsIn(), this.getClassifierChannelsOut());\r\n    };\r\n    FaceProcessor.prototype.extractParamsFromWeigthMap = function (weightMap) {\r\n        var _a = Object(_util__WEBPACK_IMPORTED_MODULE_6__[\"seperateWeightMaps\"])(weightMap), featureExtractorMap = _a.featureExtractorMap, classifierMap = _a.classifierMap;\r\n        this.faceFeatureExtractor.loadFromWeightMap(featureExtractorMap);\r\n        return Object(_extractParamsFromWeigthMap__WEBPACK_IMPORTED_MODULE_5__[\"extractParamsFromWeigthMap\"])(classifierMap);\r\n    };\r\n    FaceProcessor.prototype.extractParams = function (weights) {\r\n        var cIn = this.getClassifierChannelsIn();\r\n        var cOut = this.getClassifierChannelsOut();\r\n        var classifierWeightSize = (cOut * cIn) + cOut;\r\n        var featureExtractorWeights = weights.slice(0, weights.length - classifierWeightSize);\r\n        var classifierWeights = weights.slice(weights.length - classifierWeightSize);\r\n        this.faceFeatureExtractor.extractWeights(featureExtractorWeights);\r\n        return this.extractClassifierParams(classifierWeights);\r\n    };\r\n    return FaceProcessor;\r\n}(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"NeuralNetwork\"]));\r\n\r\n//# sourceMappingURL=FaceProcessor.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceProcessor/FaceProcessor.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceProcessor/extractParams.js":
/*!***************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceProcessor/extractParams.js ***!
  \***************************************************************************/
/*! exports provided: extractParams */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractParams\", function() { return extractParams; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n\r\nfunction extractParams(weights, channelsIn, channelsOut) {\r\n    var paramMappings = [];\r\n    var _a = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].extractWeightsFactory(weights), extractWeights = _a.extractWeights, getRemainingWeights = _a.getRemainingWeights;\r\n    var extractFCParams = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].extractFCParamsFactory(extractWeights, paramMappings);\r\n    var fc = extractFCParams(channelsIn, channelsOut, 'fc');\r\n    if (getRemainingWeights().length !== 0) {\r\n        throw new Error(\"weights remaing after extract: \" + getRemainingWeights().length);\r\n    }\r\n    return {\r\n        paramMappings: paramMappings,\r\n        params: { fc: fc }\r\n    };\r\n}\r\n//# sourceMappingURL=extractParams.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceProcessor/extractParams.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceProcessor/extractParamsFromWeigthMap.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceProcessor/extractParamsFromWeigthMap.js ***!
  \****************************************************************************************/
/*! exports provided: extractParamsFromWeigthMap */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractParamsFromWeigthMap\", function() { return extractParamsFromWeigthMap; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n\r\nfunction extractParamsFromWeigthMap(weightMap) {\r\n    var paramMappings = [];\r\n    var extractWeightEntry = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].extractWeightEntryFactory(weightMap, paramMappings);\r\n    function extractFcParams(prefix) {\r\n        var weights = extractWeightEntry(prefix + \"/weights\", 2);\r\n        var bias = extractWeightEntry(prefix + \"/bias\", 1);\r\n        return { weights: weights, bias: bias };\r\n    }\r\n    var params = {\r\n        fc: extractFcParams('fc')\r\n    };\r\n    tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].disposeUnusedWeightTensors(weightMap, paramMappings);\r\n    return { params: params, paramMappings: paramMappings };\r\n}\r\n//# sourceMappingURL=extractParamsFromWeigthMap.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceProcessor/extractParamsFromWeigthMap.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceProcessor/util.js":
/*!******************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceProcessor/util.js ***!
  \******************************************************************/
/*! exports provided: seperateWeightMaps */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"seperateWeightMaps\", function() { return seperateWeightMaps; });\nfunction seperateWeightMaps(weightMap) {\r\n    var featureExtractorMap = {};\r\n    var classifierMap = {};\r\n    Object.keys(weightMap).forEach(function (key) {\r\n        var map = key.startsWith('fc') ? classifierMap : featureExtractorMap;\r\n        map[key] = weightMap[key];\r\n    });\r\n    return { featureExtractorMap: featureExtractorMap, classifierMap: classifierMap };\r\n}\r\n//# sourceMappingURL=util.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceProcessor/util.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceRecognitionNet/FaceRecognitionNet.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceRecognitionNet/FaceRecognitionNet.js ***!
  \*************************************************************************************/
/*! exports provided: FaceRecognitionNet */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"FaceRecognitionNet\", function() { return FaceRecognitionNet; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _convLayer__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./convLayer */ \"./node_modules/face-api.js/build/es6/faceRecognitionNet/convLayer.js\");\n/* harmony import */ var _extractParams__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./extractParams */ \"./node_modules/face-api.js/build/es6/faceRecognitionNet/extractParams.js\");\n/* harmony import */ var _extractParamsFromWeigthMap__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./extractParamsFromWeigthMap */ \"./node_modules/face-api.js/build/es6/faceRecognitionNet/extractParamsFromWeigthMap.js\");\n/* harmony import */ var _residualLayer__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./residualLayer */ \"./node_modules/face-api.js/build/es6/faceRecognitionNet/residualLayer.js\");\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nvar FaceRecognitionNet = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(FaceRecognitionNet, _super);\r\n    function FaceRecognitionNet() {\r\n        return _super.call(this, 'FaceRecognitionNet') || this;\r\n    }\r\n    FaceRecognitionNet.prototype.forwardInput = function (input) {\r\n        var params = this.params;\r\n        if (!params) {\r\n            throw new Error('FaceRecognitionNet - load model before inference');\r\n        }\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tidy\"](function () {\r\n            var batchTensor = input.toBatchTensor(150, true).toFloat();\r\n            var meanRgb = [122.782, 117.001, 104.298];\r\n            var normalized = Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"normalize\"])(batchTensor, meanRgb).div(_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"scalar\"](256));\r\n            var out = Object(_convLayer__WEBPACK_IMPORTED_MODULE_3__[\"convDown\"])(normalized, params.conv32_down);\r\n            out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"maxPool\"](out, 3, 2, 'valid');\r\n            out = Object(_residualLayer__WEBPACK_IMPORTED_MODULE_6__[\"residual\"])(out, params.conv32_1);\r\n            out = Object(_residualLayer__WEBPACK_IMPORTED_MODULE_6__[\"residual\"])(out, params.conv32_2);\r\n            out = Object(_residualLayer__WEBPACK_IMPORTED_MODULE_6__[\"residual\"])(out, params.conv32_3);\r\n            out = Object(_residualLayer__WEBPACK_IMPORTED_MODULE_6__[\"residualDown\"])(out, params.conv64_down);\r\n            out = Object(_residualLayer__WEBPACK_IMPORTED_MODULE_6__[\"residual\"])(out, params.conv64_1);\r\n            out = Object(_residualLayer__WEBPACK_IMPORTED_MODULE_6__[\"residual\"])(out, params.conv64_2);\r\n            out = Object(_residualLayer__WEBPACK_IMPORTED_MODULE_6__[\"residual\"])(out, params.conv64_3);\r\n            out = Object(_residualLayer__WEBPACK_IMPORTED_MODULE_6__[\"residualDown\"])(out, params.conv128_down);\r\n            out = Object(_residualLayer__WEBPACK_IMPORTED_MODULE_6__[\"residual\"])(out, params.conv128_1);\r\n            out = Object(_residualLayer__WEBPACK_IMPORTED_MODULE_6__[\"residual\"])(out, params.conv128_2);\r\n            out = Object(_residualLayer__WEBPACK_IMPORTED_MODULE_6__[\"residualDown\"])(out, params.conv256_down);\r\n            out = Object(_residualLayer__WEBPACK_IMPORTED_MODULE_6__[\"residual\"])(out, params.conv256_1);\r\n            out = Object(_residualLayer__WEBPACK_IMPORTED_MODULE_6__[\"residual\"])(out, params.conv256_2);\r\n            out = Object(_residualLayer__WEBPACK_IMPORTED_MODULE_6__[\"residualDown\"])(out, params.conv256_down_out);\r\n            var globalAvg = out.mean([1, 2]);\r\n            var fullyConnected = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"matMul\"](globalAvg, params.fc);\r\n            return fullyConnected;\r\n        });\r\n    };\r\n    FaceRecognitionNet.prototype.forward = function (input) {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var _a;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this.forwardInput;\r\n                        return [4 /*yield*/, Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"toNetInput\"])(input)];\r\n                    case 1: return [2 /*return*/, _a.apply(this, [_b.sent()])];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    FaceRecognitionNet.prototype.computeFaceDescriptor = function (input) {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var netInput, faceDescriptorTensors, faceDescriptorsForBatch;\r\n            var _this = this;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"toNetInput\"])(input)];\r\n                    case 1:\r\n                        netInput = _a.sent();\r\n                        faceDescriptorTensors = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tidy\"](function () { return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"unstack\"](_this.forwardInput(netInput)); });\r\n                        return [4 /*yield*/, Promise.all(faceDescriptorTensors.map(function (t) { return t.data(); }))];\r\n                    case 2:\r\n                        faceDescriptorsForBatch = _a.sent();\r\n                        faceDescriptorTensors.forEach(function (t) { return t.dispose(); });\r\n                        return [2 /*return*/, netInput.isBatchInput\r\n                                ? faceDescriptorsForBatch\r\n                                : faceDescriptorsForBatch[0]];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    FaceRecognitionNet.prototype.getDefaultModelName = function () {\r\n        return 'face_recognition_model';\r\n    };\r\n    FaceRecognitionNet.prototype.extractParamsFromWeigthMap = function (weightMap) {\r\n        return Object(_extractParamsFromWeigthMap__WEBPACK_IMPORTED_MODULE_5__[\"extractParamsFromWeigthMap\"])(weightMap);\r\n    };\r\n    FaceRecognitionNet.prototype.extractParams = function (weights) {\r\n        return Object(_extractParams__WEBPACK_IMPORTED_MODULE_4__[\"extractParams\"])(weights);\r\n    };\r\n    return FaceRecognitionNet;\r\n}(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"NeuralNetwork\"]));\r\n\r\n//# sourceMappingURL=FaceRecognitionNet.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceRecognitionNet/FaceRecognitionNet.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceRecognitionNet/convLayer.js":
/*!****************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceRecognitionNet/convLayer.js ***!
  \****************************************************************************/
/*! exports provided: conv, convNoRelu, convDown */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"conv\", function() { return conv; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"convNoRelu\", function() { return convNoRelu; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"convDown\", function() { return convDown; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var _scaleLayer__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./scaleLayer */ \"./node_modules/face-api.js/build/es6/faceRecognitionNet/scaleLayer.js\");\n\r\n\r\nfunction convLayer(x, params, strides, withRelu, padding) {\r\n    if (padding === void 0) { padding = 'same'; }\r\n    var _a = params.conv, filters = _a.filters, bias = _a.bias;\r\n    var out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"conv2d\"](x, filters, strides, padding);\r\n    out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](out, bias);\r\n    out = Object(_scaleLayer__WEBPACK_IMPORTED_MODULE_1__[\"scale\"])(out, params.scale);\r\n    return withRelu ? _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"relu\"](out) : out;\r\n}\r\nfunction conv(x, params) {\r\n    return convLayer(x, params, [1, 1], true);\r\n}\r\nfunction convNoRelu(x, params) {\r\n    return convLayer(x, params, [1, 1], false);\r\n}\r\nfunction convDown(x, params) {\r\n    return convLayer(x, params, [2, 2], true, 'valid');\r\n}\r\n//# sourceMappingURL=convLayer.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceRecognitionNet/convLayer.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceRecognitionNet/extractParams.js":
/*!********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceRecognitionNet/extractParams.js ***!
  \********************************************************************************/
/*! exports provided: extractParams */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractParams\", function() { return extractParams; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n\r\n\r\nfunction extractorsFactory(extractWeights, paramMappings) {\r\n    function extractFilterValues(numFilterValues, numFilters, filterSize) {\r\n        var weights = extractWeights(numFilterValues);\r\n        var depth = weights.length / (numFilters * filterSize * filterSize);\r\n        if (Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"isFloat\"])(depth)) {\r\n            throw new Error(\"depth has to be an integer: \" + depth + \", weights.length: \" + weights.length + \", numFilters: \" + numFilters + \", filterSize: \" + filterSize);\r\n        }\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () { return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"transpose\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tensor4d\"](weights, [numFilters, depth, filterSize, filterSize]), [2, 3, 1, 0]); });\r\n    }\r\n    function extractConvParams(numFilterValues, numFilters, filterSize, mappedPrefix) {\r\n        var filters = extractFilterValues(numFilterValues, numFilters, filterSize);\r\n        var bias = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tensor1d\"](extractWeights(numFilters));\r\n        paramMappings.push({ paramPath: mappedPrefix + \"/filters\" }, { paramPath: mappedPrefix + \"/bias\" });\r\n        return { filters: filters, bias: bias };\r\n    }\r\n    function extractScaleLayerParams(numWeights, mappedPrefix) {\r\n        var weights = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tensor1d\"](extractWeights(numWeights));\r\n        var biases = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tensor1d\"](extractWeights(numWeights));\r\n        paramMappings.push({ paramPath: mappedPrefix + \"/weights\" }, { paramPath: mappedPrefix + \"/biases\" });\r\n        return {\r\n            weights: weights,\r\n            biases: biases\r\n        };\r\n    }\r\n    function extractConvLayerParams(numFilterValues, numFilters, filterSize, mappedPrefix) {\r\n        var conv = extractConvParams(numFilterValues, numFilters, filterSize, mappedPrefix + \"/conv\");\r\n        var scale = extractScaleLayerParams(numFilters, mappedPrefix + \"/scale\");\r\n        return { conv: conv, scale: scale };\r\n    }\r\n    function extractResidualLayerParams(numFilterValues, numFilters, filterSize, mappedPrefix, isDown) {\r\n        if (isDown === void 0) { isDown = false; }\r\n        var conv1 = extractConvLayerParams((isDown ? 0.5 : 1) * numFilterValues, numFilters, filterSize, mappedPrefix + \"/conv1\");\r\n        var conv2 = extractConvLayerParams(numFilterValues, numFilters, filterSize, mappedPrefix + \"/conv2\");\r\n        return { conv1: conv1, conv2: conv2 };\r\n    }\r\n    return {\r\n        extractConvLayerParams: extractConvLayerParams,\r\n        extractResidualLayerParams: extractResidualLayerParams\r\n    };\r\n}\r\nfunction extractParams(weights) {\r\n    var _a = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"TfjsImageRecognitionBase\"].extractWeightsFactory(weights), extractWeights = _a.extractWeights, getRemainingWeights = _a.getRemainingWeights;\r\n    var paramMappings = [];\r\n    var _b = extractorsFactory(extractWeights, paramMappings), extractConvLayerParams = _b.extractConvLayerParams, extractResidualLayerParams = _b.extractResidualLayerParams;\r\n    var conv32_down = extractConvLayerParams(4704, 32, 7, 'conv32_down');\r\n    var conv32_1 = extractResidualLayerParams(9216, 32, 3, 'conv32_1');\r\n    var conv32_2 = extractResidualLayerParams(9216, 32, 3, 'conv32_2');\r\n    var conv32_3 = extractResidualLayerParams(9216, 32, 3, 'conv32_3');\r\n    var conv64_down = extractResidualLayerParams(36864, 64, 3, 'conv64_down', true);\r\n    var conv64_1 = extractResidualLayerParams(36864, 64, 3, 'conv64_1');\r\n    var conv64_2 = extractResidualLayerParams(36864, 64, 3, 'conv64_2');\r\n    var conv64_3 = extractResidualLayerParams(36864, 64, 3, 'conv64_3');\r\n    var conv128_down = extractResidualLayerParams(147456, 128, 3, 'conv128_down', true);\r\n    var conv128_1 = extractResidualLayerParams(147456, 128, 3, 'conv128_1');\r\n    var conv128_2 = extractResidualLayerParams(147456, 128, 3, 'conv128_2');\r\n    var conv256_down = extractResidualLayerParams(589824, 256, 3, 'conv256_down', true);\r\n    var conv256_1 = extractResidualLayerParams(589824, 256, 3, 'conv256_1');\r\n    var conv256_2 = extractResidualLayerParams(589824, 256, 3, 'conv256_2');\r\n    var conv256_down_out = extractResidualLayerParams(589824, 256, 3, 'conv256_down_out');\r\n    var fc = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () { return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"transpose\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tensor2d\"](extractWeights(256 * 128), [128, 256]), [1, 0]); });\r\n    paramMappings.push({ paramPath: \"fc\" });\r\n    if (getRemainingWeights().length !== 0) {\r\n        throw new Error(\"weights remaing after extract: \" + getRemainingWeights().length);\r\n    }\r\n    var params = {\r\n        conv32_down: conv32_down,\r\n        conv32_1: conv32_1,\r\n        conv32_2: conv32_2,\r\n        conv32_3: conv32_3,\r\n        conv64_down: conv64_down,\r\n        conv64_1: conv64_1,\r\n        conv64_2: conv64_2,\r\n        conv64_3: conv64_3,\r\n        conv128_down: conv128_down,\r\n        conv128_1: conv128_1,\r\n        conv128_2: conv128_2,\r\n        conv256_down: conv256_down,\r\n        conv256_1: conv256_1,\r\n        conv256_2: conv256_2,\r\n        conv256_down_out: conv256_down_out,\r\n        fc: fc\r\n    };\r\n    return { params: params, paramMappings: paramMappings };\r\n}\r\n//# sourceMappingURL=extractParams.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceRecognitionNet/extractParams.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceRecognitionNet/extractParamsFromWeigthMap.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceRecognitionNet/extractParamsFromWeigthMap.js ***!
  \*********************************************************************************************/
/*! exports provided: extractParamsFromWeigthMap */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractParamsFromWeigthMap\", function() { return extractParamsFromWeigthMap; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n\r\nfunction extractorsFactory(weightMap, paramMappings) {\r\n    var extractWeightEntry = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].extractWeightEntryFactory(weightMap, paramMappings);\r\n    function extractScaleLayerParams(prefix) {\r\n        var weights = extractWeightEntry(prefix + \"/scale/weights\", 1);\r\n        var biases = extractWeightEntry(prefix + \"/scale/biases\", 1);\r\n        return { weights: weights, biases: biases };\r\n    }\r\n    function extractConvLayerParams(prefix) {\r\n        var filters = extractWeightEntry(prefix + \"/conv/filters\", 4);\r\n        var bias = extractWeightEntry(prefix + \"/conv/bias\", 1);\r\n        var scale = extractScaleLayerParams(prefix);\r\n        return { conv: { filters: filters, bias: bias }, scale: scale };\r\n    }\r\n    function extractResidualLayerParams(prefix) {\r\n        return {\r\n            conv1: extractConvLayerParams(prefix + \"/conv1\"),\r\n            conv2: extractConvLayerParams(prefix + \"/conv2\")\r\n        };\r\n    }\r\n    return {\r\n        extractConvLayerParams: extractConvLayerParams,\r\n        extractResidualLayerParams: extractResidualLayerParams\r\n    };\r\n}\r\nfunction extractParamsFromWeigthMap(weightMap) {\r\n    var paramMappings = [];\r\n    var _a = extractorsFactory(weightMap, paramMappings), extractConvLayerParams = _a.extractConvLayerParams, extractResidualLayerParams = _a.extractResidualLayerParams;\r\n    var conv32_down = extractConvLayerParams('conv32_down');\r\n    var conv32_1 = extractResidualLayerParams('conv32_1');\r\n    var conv32_2 = extractResidualLayerParams('conv32_2');\r\n    var conv32_3 = extractResidualLayerParams('conv32_3');\r\n    var conv64_down = extractResidualLayerParams('conv64_down');\r\n    var conv64_1 = extractResidualLayerParams('conv64_1');\r\n    var conv64_2 = extractResidualLayerParams('conv64_2');\r\n    var conv64_3 = extractResidualLayerParams('conv64_3');\r\n    var conv128_down = extractResidualLayerParams('conv128_down');\r\n    var conv128_1 = extractResidualLayerParams('conv128_1');\r\n    var conv128_2 = extractResidualLayerParams('conv128_2');\r\n    var conv256_down = extractResidualLayerParams('conv256_down');\r\n    var conv256_1 = extractResidualLayerParams('conv256_1');\r\n    var conv256_2 = extractResidualLayerParams('conv256_2');\r\n    var conv256_down_out = extractResidualLayerParams('conv256_down_out');\r\n    var fc = weightMap['fc'];\r\n    paramMappings.push({ originalPath: 'fc', paramPath: 'fc' });\r\n    if (!Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"isTensor2D\"])(fc)) {\r\n        throw new Error(\"expected weightMap[fc] to be a Tensor2D, instead have \" + fc);\r\n    }\r\n    var params = {\r\n        conv32_down: conv32_down,\r\n        conv32_1: conv32_1,\r\n        conv32_2: conv32_2,\r\n        conv32_3: conv32_3,\r\n        conv64_down: conv64_down,\r\n        conv64_1: conv64_1,\r\n        conv64_2: conv64_2,\r\n        conv64_3: conv64_3,\r\n        conv128_down: conv128_down,\r\n        conv128_1: conv128_1,\r\n        conv128_2: conv128_2,\r\n        conv256_down: conv256_down,\r\n        conv256_1: conv256_1,\r\n        conv256_2: conv256_2,\r\n        conv256_down_out: conv256_down_out,\r\n        fc: fc\r\n    };\r\n    tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].disposeUnusedWeightTensors(weightMap, paramMappings);\r\n    return { params: params, paramMappings: paramMappings };\r\n}\r\n//# sourceMappingURL=extractParamsFromWeigthMap.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceRecognitionNet/extractParamsFromWeigthMap.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceRecognitionNet/index.js":
/*!************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceRecognitionNet/index.js ***!
  \************************************************************************/
/*! exports provided: FaceRecognitionNet, createFaceRecognitionNet */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"createFaceRecognitionNet\", function() { return createFaceRecognitionNet; });\n/* harmony import */ var _FaceRecognitionNet__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./FaceRecognitionNet */ \"./node_modules/face-api.js/build/es6/faceRecognitionNet/FaceRecognitionNet.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceRecognitionNet\", function() { return _FaceRecognitionNet__WEBPACK_IMPORTED_MODULE_0__[\"FaceRecognitionNet\"]; });\n\n\r\n\r\nfunction createFaceRecognitionNet(weights) {\r\n    var net = new _FaceRecognitionNet__WEBPACK_IMPORTED_MODULE_0__[\"FaceRecognitionNet\"]();\r\n    net.extractWeights(weights);\r\n    return net;\r\n}\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceRecognitionNet/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceRecognitionNet/residualLayer.js":
/*!********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceRecognitionNet/residualLayer.js ***!
  \********************************************************************************/
/*! exports provided: residual, residualDown */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"residual\", function() { return residual; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"residualDown\", function() { return residualDown; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var _convLayer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./convLayer */ \"./node_modules/face-api.js/build/es6/faceRecognitionNet/convLayer.js\");\n\r\n\r\n\r\nfunction residual(x, params) {\r\n    var out = Object(_convLayer__WEBPACK_IMPORTED_MODULE_2__[\"conv\"])(x, params.conv1);\r\n    out = Object(_convLayer__WEBPACK_IMPORTED_MODULE_2__[\"convNoRelu\"])(out, params.conv2);\r\n    out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"add\"](out, x);\r\n    out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"relu\"](out);\r\n    return out;\r\n}\r\nfunction residualDown(x, params) {\r\n    var out = Object(_convLayer__WEBPACK_IMPORTED_MODULE_2__[\"convDown\"])(x, params.conv1);\r\n    out = Object(_convLayer__WEBPACK_IMPORTED_MODULE_2__[\"convNoRelu\"])(out, params.conv2);\r\n    var pooled = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"avgPool\"](x, 2, 2, 'valid');\r\n    var zeros = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"zeros\"](pooled.shape);\r\n    var isPad = pooled.shape[3] !== out.shape[3];\r\n    var isAdjustShape = pooled.shape[1] !== out.shape[1] || pooled.shape[2] !== out.shape[2];\r\n    if (isAdjustShape) {\r\n        var padShapeX = Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__spreadArrays\"])(out.shape);\r\n        padShapeX[1] = 1;\r\n        var zerosW = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"zeros\"](padShapeX);\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"concat\"]([out, zerosW], 1);\r\n        var padShapeY = Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__spreadArrays\"])(out.shape);\r\n        padShapeY[2] = 1;\r\n        var zerosH = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"zeros\"](padShapeY);\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"concat\"]([out, zerosH], 2);\r\n    }\r\n    pooled = isPad ? _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"concat\"]([pooled, zeros], 3) : pooled;\r\n    out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"add\"](pooled, out);\r\n    out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"relu\"](out);\r\n    return out;\r\n}\r\n//# sourceMappingURL=residualLayer.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceRecognitionNet/residualLayer.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/faceRecognitionNet/scaleLayer.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/faceRecognitionNet/scaleLayer.js ***!
  \*****************************************************************************/
/*! exports provided: scale */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"scale\", function() { return scale; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n\r\nfunction scale(x, params) {\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"mul\"](x, params.weights), params.biases);\r\n}\r\n//# sourceMappingURL=scaleLayer.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/faceRecognitionNet/scaleLayer.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/factories/WithAge.js":
/*!*****************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/factories/WithAge.js ***!
  \*****************************************************************/
/*! exports provided: isWithAge, extendWithAge */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isWithAge\", function() { return isWithAge; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extendWithAge\", function() { return extendWithAge; });\nfunction isWithAge(obj) {\r\n    return typeof obj['age'] === 'number';\r\n}\r\nfunction extendWithAge(sourceObj, age) {\r\n    var extension = { age: age };\r\n    return Object.assign({}, sourceObj, extension);\r\n}\r\n//# sourceMappingURL=WithAge.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/factories/WithAge.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/factories/WithFaceDescriptor.js":
/*!****************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/factories/WithFaceDescriptor.js ***!
  \****************************************************************************/
/*! exports provided: extendWithFaceDescriptor */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extendWithFaceDescriptor\", function() { return extendWithFaceDescriptor; });\nfunction extendWithFaceDescriptor(sourceObj, descriptor) {\r\n    var extension = { descriptor: descriptor };\r\n    return Object.assign({}, sourceObj, extension);\r\n}\r\n//# sourceMappingURL=WithFaceDescriptor.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/factories/WithFaceDescriptor.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/factories/WithFaceDetection.js":
/*!***************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/factories/WithFaceDetection.js ***!
  \***************************************************************************/
/*! exports provided: isWithFaceDetection, extendWithFaceDetection */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isWithFaceDetection\", function() { return isWithFaceDetection; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extendWithFaceDetection\", function() { return extendWithFaceDetection; });\n/* harmony import */ var _classes_FaceDetection__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../classes/FaceDetection */ \"./node_modules/face-api.js/build/es6/classes/FaceDetection.js\");\n\r\nfunction isWithFaceDetection(obj) {\r\n    return obj['detection'] instanceof _classes_FaceDetection__WEBPACK_IMPORTED_MODULE_0__[\"FaceDetection\"];\r\n}\r\nfunction extendWithFaceDetection(sourceObj, detection) {\r\n    var extension = { detection: detection };\r\n    return Object.assign({}, sourceObj, extension);\r\n}\r\n//# sourceMappingURL=WithFaceDetection.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/factories/WithFaceDetection.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/factories/WithFaceExpressions.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/factories/WithFaceExpressions.js ***!
  \*****************************************************************************/
/*! exports provided: isWithFaceExpressions, extendWithFaceExpressions */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isWithFaceExpressions\", function() { return isWithFaceExpressions; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extendWithFaceExpressions\", function() { return extendWithFaceExpressions; });\n/* harmony import */ var _faceExpressionNet_FaceExpressions__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../faceExpressionNet/FaceExpressions */ \"./node_modules/face-api.js/build/es6/faceExpressionNet/FaceExpressions.js\");\n\r\nfunction isWithFaceExpressions(obj) {\r\n    return obj['expressions'] instanceof _faceExpressionNet_FaceExpressions__WEBPACK_IMPORTED_MODULE_0__[\"FaceExpressions\"];\r\n}\r\nfunction extendWithFaceExpressions(sourceObj, expressions) {\r\n    var extension = { expressions: expressions };\r\n    return Object.assign({}, sourceObj, extension);\r\n}\r\n//# sourceMappingURL=WithFaceExpressions.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/factories/WithFaceExpressions.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/factories/WithFaceLandmarks.js":
/*!***************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/factories/WithFaceLandmarks.js ***!
  \***************************************************************************/
/*! exports provided: isWithFaceLandmarks, extendWithFaceLandmarks */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isWithFaceLandmarks\", function() { return isWithFaceLandmarks; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extendWithFaceLandmarks\", function() { return extendWithFaceLandmarks; });\n/* harmony import */ var _classes_FaceDetection__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../classes/FaceDetection */ \"./node_modules/face-api.js/build/es6/classes/FaceDetection.js\");\n/* harmony import */ var _classes_FaceLandmarks__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../classes/FaceLandmarks */ \"./node_modules/face-api.js/build/es6/classes/FaceLandmarks.js\");\n/* harmony import */ var _WithFaceDetection__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./WithFaceDetection */ \"./node_modules/face-api.js/build/es6/factories/WithFaceDetection.js\");\n\r\n\r\n\r\nfunction isWithFaceLandmarks(obj) {\r\n    return Object(_WithFaceDetection__WEBPACK_IMPORTED_MODULE_2__[\"isWithFaceDetection\"])(obj)\r\n        && obj['landmarks'] instanceof _classes_FaceLandmarks__WEBPACK_IMPORTED_MODULE_1__[\"FaceLandmarks\"]\r\n        && obj['unshiftedLandmarks'] instanceof _classes_FaceLandmarks__WEBPACK_IMPORTED_MODULE_1__[\"FaceLandmarks\"]\r\n        && obj['alignedRect'] instanceof _classes_FaceDetection__WEBPACK_IMPORTED_MODULE_0__[\"FaceDetection\"];\r\n}\r\nfunction extendWithFaceLandmarks(sourceObj, unshiftedLandmarks) {\r\n    var shift = sourceObj.detection.box;\r\n    var landmarks = unshiftedLandmarks.shiftBy(shift.x, shift.y);\r\n    var rect = landmarks.align();\r\n    var imageDims = sourceObj.detection.imageDims;\r\n    var alignedRect = new _classes_FaceDetection__WEBPACK_IMPORTED_MODULE_0__[\"FaceDetection\"](sourceObj.detection.score, rect.rescale(imageDims.reverse()), imageDims);\r\n    var extension = {\r\n        landmarks: landmarks,\r\n        unshiftedLandmarks: unshiftedLandmarks,\r\n        alignedRect: alignedRect\r\n    };\r\n    return Object.assign({}, sourceObj, extension);\r\n}\r\n//# sourceMappingURL=WithFaceLandmarks.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/factories/WithFaceLandmarks.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/factories/WithGender.js":
/*!********************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/factories/WithGender.js ***!
  \********************************************************************/
/*! exports provided: isWithGender, extendWithGender */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isWithGender\", function() { return isWithGender; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extendWithGender\", function() { return extendWithGender; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _ageGenderNet_types__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../ageGenderNet/types */ \"./node_modules/face-api.js/build/es6/ageGenderNet/types.js\");\n\r\n\r\nfunction isWithGender(obj) {\r\n    return (obj['gender'] === _ageGenderNet_types__WEBPACK_IMPORTED_MODULE_1__[\"Gender\"].MALE || obj['gender'] === _ageGenderNet_types__WEBPACK_IMPORTED_MODULE_1__[\"Gender\"].FEMALE)\r\n        && Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"isValidProbablitiy\"])(obj['genderProbability']);\r\n}\r\nfunction extendWithGender(sourceObj, gender, genderProbability) {\r\n    var extension = { gender: gender, genderProbability: genderProbability };\r\n    return Object.assign({}, sourceObj, extension);\r\n}\r\n//# sourceMappingURL=WithGender.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/factories/WithGender.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/factories/index.js":
/*!***************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/factories/index.js ***!
  \***************************************************************/
/*! exports provided: extendWithFaceDescriptor, isWithFaceDetection, extendWithFaceDetection, isWithFaceExpressions, extendWithFaceExpressions, isWithFaceLandmarks, extendWithFaceLandmarks, isWithAge, extendWithAge, isWithGender, extendWithGender */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _WithFaceDescriptor__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./WithFaceDescriptor */ \"./node_modules/face-api.js/build/es6/factories/WithFaceDescriptor.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extendWithFaceDescriptor\", function() { return _WithFaceDescriptor__WEBPACK_IMPORTED_MODULE_0__[\"extendWithFaceDescriptor\"]; });\n\n/* harmony import */ var _WithFaceDetection__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./WithFaceDetection */ \"./node_modules/face-api.js/build/es6/factories/WithFaceDetection.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isWithFaceDetection\", function() { return _WithFaceDetection__WEBPACK_IMPORTED_MODULE_1__[\"isWithFaceDetection\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extendWithFaceDetection\", function() { return _WithFaceDetection__WEBPACK_IMPORTED_MODULE_1__[\"extendWithFaceDetection\"]; });\n\n/* harmony import */ var _WithFaceExpressions__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./WithFaceExpressions */ \"./node_modules/face-api.js/build/es6/factories/WithFaceExpressions.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isWithFaceExpressions\", function() { return _WithFaceExpressions__WEBPACK_IMPORTED_MODULE_2__[\"isWithFaceExpressions\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extendWithFaceExpressions\", function() { return _WithFaceExpressions__WEBPACK_IMPORTED_MODULE_2__[\"extendWithFaceExpressions\"]; });\n\n/* harmony import */ var _WithFaceLandmarks__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./WithFaceLandmarks */ \"./node_modules/face-api.js/build/es6/factories/WithFaceLandmarks.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isWithFaceLandmarks\", function() { return _WithFaceLandmarks__WEBPACK_IMPORTED_MODULE_3__[\"isWithFaceLandmarks\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extendWithFaceLandmarks\", function() { return _WithFaceLandmarks__WEBPACK_IMPORTED_MODULE_3__[\"extendWithFaceLandmarks\"]; });\n\n/* harmony import */ var _WithAge__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./WithAge */ \"./node_modules/face-api.js/build/es6/factories/WithAge.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isWithAge\", function() { return _WithAge__WEBPACK_IMPORTED_MODULE_4__[\"isWithAge\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extendWithAge\", function() { return _WithAge__WEBPACK_IMPORTED_MODULE_4__[\"extendWithAge\"]; });\n\n/* harmony import */ var _WithGender__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./WithGender */ \"./node_modules/face-api.js/build/es6/factories/WithGender.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isWithGender\", function() { return _WithGender__WEBPACK_IMPORTED_MODULE_5__[\"isWithGender\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extendWithGender\", function() { return _WithGender__WEBPACK_IMPORTED_MODULE_5__[\"extendWithGender\"]; });\n\n\r\n\r\n\r\n\r\n\r\n\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/factories/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/globalApi/ComposableTask.js":
/*!************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/globalApi/ComposableTask.js ***!
  \************************************************************************/
/*! exports provided: ComposableTask */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ComposableTask\", function() { return ComposableTask; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n\r\nvar ComposableTask = /** @class */ (function () {\r\n    function ComposableTask() {\r\n    }\r\n    ComposableTask.prototype.then = function (onfulfilled) {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var _a;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = onfulfilled;\r\n                        return [4 /*yield*/, this.run()];\r\n                    case 1: return [2 /*return*/, _a.apply(void 0, [_b.sent()])];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    ComposableTask.prototype.run = function () {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n                throw new Error('ComposableTask - run is not implemented');\r\n            });\r\n        });\r\n    };\r\n    return ComposableTask;\r\n}());\r\n\r\n//# sourceMappingURL=ComposableTask.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/globalApi/ComposableTask.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/globalApi/ComputeFaceDescriptorsTasks.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/globalApi/ComputeFaceDescriptorsTasks.js ***!
  \*************************************************************************************/
/*! exports provided: ComputeFaceDescriptorsTaskBase, ComputeAllFaceDescriptorsTask, ComputeSingleFaceDescriptorTask */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ComputeFaceDescriptorsTaskBase\", function() { return ComputeFaceDescriptorsTaskBase; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ComputeAllFaceDescriptorsTask\", function() { return ComputeAllFaceDescriptorsTask; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ComputeSingleFaceDescriptorTask\", function() { return ComputeSingleFaceDescriptorTask; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _factories_WithFaceDescriptor__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../factories/WithFaceDescriptor */ \"./node_modules/face-api.js/build/es6/factories/WithFaceDescriptor.js\");\n/* harmony import */ var _ComposableTask__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ComposableTask */ \"./node_modules/face-api.js/build/es6/globalApi/ComposableTask.js\");\n/* harmony import */ var _extractFacesAndComputeResults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./extractFacesAndComputeResults */ \"./node_modules/face-api.js/build/es6/globalApi/extractFacesAndComputeResults.js\");\n/* harmony import */ var _nets__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./nets */ \"./node_modules/face-api.js/build/es6/globalApi/nets.js\");\n/* harmony import */ var _PredictAgeAndGenderTask__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./PredictAgeAndGenderTask */ \"./node_modules/face-api.js/build/es6/globalApi/PredictAgeAndGenderTask.js\");\n/* harmony import */ var _PredictFaceExpressionsTask__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./PredictFaceExpressionsTask */ \"./node_modules/face-api.js/build/es6/globalApi/PredictFaceExpressionsTask.js\");\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nvar ComputeFaceDescriptorsTaskBase = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(ComputeFaceDescriptorsTaskBase, _super);\r\n    function ComputeFaceDescriptorsTaskBase(parentTask, input) {\r\n        var _this = _super.call(this) || this;\r\n        _this.parentTask = parentTask;\r\n        _this.input = input;\r\n        return _this;\r\n    }\r\n    return ComputeFaceDescriptorsTaskBase;\r\n}(_ComposableTask__WEBPACK_IMPORTED_MODULE_2__[\"ComposableTask\"]));\r\n\r\nvar ComputeAllFaceDescriptorsTask = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(ComputeAllFaceDescriptorsTask, _super);\r\n    function ComputeAllFaceDescriptorsTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    ComputeAllFaceDescriptorsTask.prototype.run = function () {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var parentResults, descriptors;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, this.parentTask];\r\n                    case 1:\r\n                        parentResults = _a.sent();\r\n                        return [4 /*yield*/, Object(_extractFacesAndComputeResults__WEBPACK_IMPORTED_MODULE_3__[\"extractAllFacesAndComputeResults\"])(parentResults, this.input, function (faces) { return Promise.all(faces.map(function (face) {\r\n                                return _nets__WEBPACK_IMPORTED_MODULE_4__[\"nets\"].faceRecognitionNet.computeFaceDescriptor(face);\r\n                            })); }, null, function (parentResult) { return parentResult.landmarks.align(null, { useDlibAlignment: true }); })];\r\n                    case 2:\r\n                        descriptors = _a.sent();\r\n                        return [2 /*return*/, descriptors.map(function (descriptor, i) { return Object(_factories_WithFaceDescriptor__WEBPACK_IMPORTED_MODULE_1__[\"extendWithFaceDescriptor\"])(parentResults[i], descriptor); })];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    ComputeAllFaceDescriptorsTask.prototype.withFaceExpressions = function () {\r\n        return new _PredictFaceExpressionsTask__WEBPACK_IMPORTED_MODULE_6__[\"PredictAllFaceExpressionsWithFaceAlignmentTask\"](this, this.input);\r\n    };\r\n    ComputeAllFaceDescriptorsTask.prototype.withAgeAndGender = function () {\r\n        return new _PredictAgeAndGenderTask__WEBPACK_IMPORTED_MODULE_5__[\"PredictAllAgeAndGenderWithFaceAlignmentTask\"](this, this.input);\r\n    };\r\n    return ComputeAllFaceDescriptorsTask;\r\n}(ComputeFaceDescriptorsTaskBase));\r\n\r\nvar ComputeSingleFaceDescriptorTask = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(ComputeSingleFaceDescriptorTask, _super);\r\n    function ComputeSingleFaceDescriptorTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    ComputeSingleFaceDescriptorTask.prototype.run = function () {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var parentResult, descriptor;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, this.parentTask];\r\n                    case 1:\r\n                        parentResult = _a.sent();\r\n                        if (!parentResult) {\r\n                            return [2 /*return*/];\r\n                        }\r\n                        return [4 /*yield*/, Object(_extractFacesAndComputeResults__WEBPACK_IMPORTED_MODULE_3__[\"extractSingleFaceAndComputeResult\"])(parentResult, this.input, function (face) { return _nets__WEBPACK_IMPORTED_MODULE_4__[\"nets\"].faceRecognitionNet.computeFaceDescriptor(face); }, null, function (parentResult) { return parentResult.landmarks.align(null, { useDlibAlignment: true }); })];\r\n                    case 2:\r\n                        descriptor = _a.sent();\r\n                        return [2 /*return*/, Object(_factories_WithFaceDescriptor__WEBPACK_IMPORTED_MODULE_1__[\"extendWithFaceDescriptor\"])(parentResult, descriptor)];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    ComputeSingleFaceDescriptorTask.prototype.withFaceExpressions = function () {\r\n        return new _PredictFaceExpressionsTask__WEBPACK_IMPORTED_MODULE_6__[\"PredictSingleFaceExpressionsWithFaceAlignmentTask\"](this, this.input);\r\n    };\r\n    ComputeSingleFaceDescriptorTask.prototype.withAgeAndGender = function () {\r\n        return new _PredictAgeAndGenderTask__WEBPACK_IMPORTED_MODULE_5__[\"PredictSingleAgeAndGenderWithFaceAlignmentTask\"](this, this.input);\r\n    };\r\n    return ComputeSingleFaceDescriptorTask;\r\n}(ComputeFaceDescriptorsTaskBase));\r\n\r\n//# sourceMappingURL=ComputeFaceDescriptorsTasks.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/globalApi/ComputeFaceDescriptorsTasks.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/globalApi/DetectFaceLandmarksTasks.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/globalApi/DetectFaceLandmarksTasks.js ***!
  \**********************************************************************************/
/*! exports provided: DetectFaceLandmarksTaskBase, DetectAllFaceLandmarksTask, DetectSingleFaceLandmarksTask */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DetectFaceLandmarksTaskBase\", function() { return DetectFaceLandmarksTaskBase; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DetectAllFaceLandmarksTask\", function() { return DetectAllFaceLandmarksTask; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DetectSingleFaceLandmarksTask\", function() { return DetectSingleFaceLandmarksTask; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var _dom__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../dom */ \"./node_modules/face-api.js/build/es6/dom/index.js\");\n/* harmony import */ var _factories_WithFaceLandmarks__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../factories/WithFaceLandmarks */ \"./node_modules/face-api.js/build/es6/factories/WithFaceLandmarks.js\");\n/* harmony import */ var _ComposableTask__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ComposableTask */ \"./node_modules/face-api.js/build/es6/globalApi/ComposableTask.js\");\n/* harmony import */ var _ComputeFaceDescriptorsTasks__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ComputeFaceDescriptorsTasks */ \"./node_modules/face-api.js/build/es6/globalApi/ComputeFaceDescriptorsTasks.js\");\n/* harmony import */ var _nets__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./nets */ \"./node_modules/face-api.js/build/es6/globalApi/nets.js\");\n/* harmony import */ var _PredictAgeAndGenderTask__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./PredictAgeAndGenderTask */ \"./node_modules/face-api.js/build/es6/globalApi/PredictAgeAndGenderTask.js\");\n/* harmony import */ var _PredictFaceExpressionsTask__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./PredictFaceExpressionsTask */ \"./node_modules/face-api.js/build/es6/globalApi/PredictFaceExpressionsTask.js\");\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nvar DetectFaceLandmarksTaskBase = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(DetectFaceLandmarksTaskBase, _super);\r\n    function DetectFaceLandmarksTaskBase(parentTask, input, useTinyLandmarkNet) {\r\n        var _this = _super.call(this) || this;\r\n        _this.parentTask = parentTask;\r\n        _this.input = input;\r\n        _this.useTinyLandmarkNet = useTinyLandmarkNet;\r\n        return _this;\r\n    }\r\n    Object.defineProperty(DetectFaceLandmarksTaskBase.prototype, \"landmarkNet\", {\r\n        get: function () {\r\n            return this.useTinyLandmarkNet\r\n                ? _nets__WEBPACK_IMPORTED_MODULE_6__[\"nets\"].faceLandmark68TinyNet\r\n                : _nets__WEBPACK_IMPORTED_MODULE_6__[\"nets\"].faceLandmark68Net;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    return DetectFaceLandmarksTaskBase;\r\n}(_ComposableTask__WEBPACK_IMPORTED_MODULE_4__[\"ComposableTask\"]));\r\n\r\nvar DetectAllFaceLandmarksTask = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(DetectAllFaceLandmarksTask, _super);\r\n    function DetectAllFaceLandmarksTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    DetectAllFaceLandmarksTask.prototype.run = function () {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var parentResults, detections, faces, _a, faceLandmarksByFace;\r\n            var _this = this;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0: return [4 /*yield*/, this.parentTask];\r\n                    case 1:\r\n                        parentResults = _b.sent();\r\n                        detections = parentResults.map(function (res) { return res.detection; });\r\n                        if (!(this.input instanceof _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"Tensor\"])) return [3 /*break*/, 3];\r\n                        return [4 /*yield*/, Object(_dom__WEBPACK_IMPORTED_MODULE_2__[\"extractFaceTensors\"])(this.input, detections)];\r\n                    case 2:\r\n                        _a = _b.sent();\r\n                        return [3 /*break*/, 5];\r\n                    case 3: return [4 /*yield*/, Object(_dom__WEBPACK_IMPORTED_MODULE_2__[\"extractFaces\"])(this.input, detections)];\r\n                    case 4:\r\n                        _a = _b.sent();\r\n                        _b.label = 5;\r\n                    case 5:\r\n                        faces = _a;\r\n                        return [4 /*yield*/, Promise.all(faces.map(function (face) { return _this.landmarkNet.detectLandmarks(face); }))];\r\n                    case 6:\r\n                        faceLandmarksByFace = _b.sent();\r\n                        faces.forEach(function (f) { return f instanceof _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"Tensor\"] && f.dispose(); });\r\n                        return [2 /*return*/, parentResults.map(function (parentResult, i) {\r\n                                return Object(_factories_WithFaceLandmarks__WEBPACK_IMPORTED_MODULE_3__[\"extendWithFaceLandmarks\"])(parentResult, faceLandmarksByFace[i]);\r\n                            })];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    DetectAllFaceLandmarksTask.prototype.withFaceExpressions = function () {\r\n        return new _PredictFaceExpressionsTask__WEBPACK_IMPORTED_MODULE_8__[\"PredictAllFaceExpressionsWithFaceAlignmentTask\"](this, this.input);\r\n    };\r\n    DetectAllFaceLandmarksTask.prototype.withAgeAndGender = function () {\r\n        return new _PredictAgeAndGenderTask__WEBPACK_IMPORTED_MODULE_7__[\"PredictAllAgeAndGenderWithFaceAlignmentTask\"](this, this.input);\r\n    };\r\n    DetectAllFaceLandmarksTask.prototype.withFaceDescriptors = function () {\r\n        return new _ComputeFaceDescriptorsTasks__WEBPACK_IMPORTED_MODULE_5__[\"ComputeAllFaceDescriptorsTask\"](this, this.input);\r\n    };\r\n    return DetectAllFaceLandmarksTask;\r\n}(DetectFaceLandmarksTaskBase));\r\n\r\nvar DetectSingleFaceLandmarksTask = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(DetectSingleFaceLandmarksTask, _super);\r\n    function DetectSingleFaceLandmarksTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    DetectSingleFaceLandmarksTask.prototype.run = function () {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var parentResult, detection, faces, _a, landmarks;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0: return [4 /*yield*/, this.parentTask];\r\n                    case 1:\r\n                        parentResult = _b.sent();\r\n                        if (!parentResult) {\r\n                            return [2 /*return*/];\r\n                        }\r\n                        detection = parentResult.detection;\r\n                        if (!(this.input instanceof _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"Tensor\"])) return [3 /*break*/, 3];\r\n                        return [4 /*yield*/, Object(_dom__WEBPACK_IMPORTED_MODULE_2__[\"extractFaceTensors\"])(this.input, [detection])];\r\n                    case 2:\r\n                        _a = _b.sent();\r\n                        return [3 /*break*/, 5];\r\n                    case 3: return [4 /*yield*/, Object(_dom__WEBPACK_IMPORTED_MODULE_2__[\"extractFaces\"])(this.input, [detection])];\r\n                    case 4:\r\n                        _a = _b.sent();\r\n                        _b.label = 5;\r\n                    case 5:\r\n                        faces = _a;\r\n                        return [4 /*yield*/, this.landmarkNet.detectLandmarks(faces[0])];\r\n                    case 6:\r\n                        landmarks = _b.sent();\r\n                        faces.forEach(function (f) { return f instanceof _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"Tensor\"] && f.dispose(); });\r\n                        return [2 /*return*/, Object(_factories_WithFaceLandmarks__WEBPACK_IMPORTED_MODULE_3__[\"extendWithFaceLandmarks\"])(parentResult, landmarks)];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    DetectSingleFaceLandmarksTask.prototype.withFaceExpressions = function () {\r\n        return new _PredictFaceExpressionsTask__WEBPACK_IMPORTED_MODULE_8__[\"PredictSingleFaceExpressionsWithFaceAlignmentTask\"](this, this.input);\r\n    };\r\n    DetectSingleFaceLandmarksTask.prototype.withAgeAndGender = function () {\r\n        return new _PredictAgeAndGenderTask__WEBPACK_IMPORTED_MODULE_7__[\"PredictSingleAgeAndGenderWithFaceAlignmentTask\"](this, this.input);\r\n    };\r\n    DetectSingleFaceLandmarksTask.prototype.withFaceDescriptor = function () {\r\n        return new _ComputeFaceDescriptorsTasks__WEBPACK_IMPORTED_MODULE_5__[\"ComputeSingleFaceDescriptorTask\"](this, this.input);\r\n    };\r\n    return DetectSingleFaceLandmarksTask;\r\n}(DetectFaceLandmarksTaskBase));\r\n\r\n//# sourceMappingURL=DetectFaceLandmarksTasks.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/globalApi/DetectFaceLandmarksTasks.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/globalApi/DetectFacesTasks.js":
/*!**************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/globalApi/DetectFacesTasks.js ***!
  \**************************************************************************/
/*! exports provided: DetectFacesTaskBase, DetectAllFacesTask, DetectSingleFaceTask */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DetectFacesTaskBase\", function() { return DetectFacesTaskBase; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DetectAllFacesTask\", function() { return DetectAllFacesTask; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DetectSingleFaceTask\", function() { return DetectSingleFaceTask; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _factories_WithFaceDetection__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../factories/WithFaceDetection */ \"./node_modules/face-api.js/build/es6/factories/WithFaceDetection.js\");\n/* harmony import */ var _mtcnn_MtcnnOptions__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../mtcnn/MtcnnOptions */ \"./node_modules/face-api.js/build/es6/mtcnn/MtcnnOptions.js\");\n/* harmony import */ var _ssdMobilenetv1_SsdMobilenetv1Options__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../ssdMobilenetv1/SsdMobilenetv1Options */ \"./node_modules/face-api.js/build/es6/ssdMobilenetv1/SsdMobilenetv1Options.js\");\n/* harmony import */ var _tinyFaceDetector_TinyFaceDetectorOptions__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../tinyFaceDetector/TinyFaceDetectorOptions */ \"./node_modules/face-api.js/build/es6/tinyFaceDetector/TinyFaceDetectorOptions.js\");\n/* harmony import */ var _ComposableTask__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./ComposableTask */ \"./node_modules/face-api.js/build/es6/globalApi/ComposableTask.js\");\n/* harmony import */ var _DetectFaceLandmarksTasks__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./DetectFaceLandmarksTasks */ \"./node_modules/face-api.js/build/es6/globalApi/DetectFaceLandmarksTasks.js\");\n/* harmony import */ var _nets__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./nets */ \"./node_modules/face-api.js/build/es6/globalApi/nets.js\");\n/* harmony import */ var _PredictAgeAndGenderTask__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./PredictAgeAndGenderTask */ \"./node_modules/face-api.js/build/es6/globalApi/PredictAgeAndGenderTask.js\");\n/* harmony import */ var _PredictFaceExpressionsTask__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./PredictFaceExpressionsTask */ \"./node_modules/face-api.js/build/es6/globalApi/PredictFaceExpressionsTask.js\");\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nvar DetectFacesTaskBase = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(DetectFacesTaskBase, _super);\r\n    function DetectFacesTaskBase(input, options) {\r\n        if (options === void 0) { options = new _ssdMobilenetv1_SsdMobilenetv1Options__WEBPACK_IMPORTED_MODULE_4__[\"SsdMobilenetv1Options\"](); }\r\n        var _this = _super.call(this) || this;\r\n        _this.input = input;\r\n        _this.options = options;\r\n        return _this;\r\n    }\r\n    return DetectFacesTaskBase;\r\n}(_ComposableTask__WEBPACK_IMPORTED_MODULE_6__[\"ComposableTask\"]));\r\n\r\nvar DetectAllFacesTask = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(DetectAllFacesTask, _super);\r\n    function DetectAllFacesTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    DetectAllFacesTask.prototype.run = function () {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var _a, input, options, faceDetectionFunction;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this, input = _a.input, options = _a.options;\r\n                        if (!(options instanceof _mtcnn_MtcnnOptions__WEBPACK_IMPORTED_MODULE_3__[\"MtcnnOptions\"])) return [3 /*break*/, 2];\r\n                        return [4 /*yield*/, _nets__WEBPACK_IMPORTED_MODULE_8__[\"nets\"].mtcnn.forward(input, options)];\r\n                    case 1: return [2 /*return*/, (_b.sent())\r\n                            .map(function (result) { return result.detection; })];\r\n                    case 2:\r\n                        faceDetectionFunction = options instanceof _tinyFaceDetector_TinyFaceDetectorOptions__WEBPACK_IMPORTED_MODULE_5__[\"TinyFaceDetectorOptions\"]\r\n                            ? function (input) { return _nets__WEBPACK_IMPORTED_MODULE_8__[\"nets\"].tinyFaceDetector.locateFaces(input, options); }\r\n                            : (options instanceof _ssdMobilenetv1_SsdMobilenetv1Options__WEBPACK_IMPORTED_MODULE_4__[\"SsdMobilenetv1Options\"]\r\n                                ? function (input) { return _nets__WEBPACK_IMPORTED_MODULE_8__[\"nets\"].ssdMobilenetv1.locateFaces(input, options); }\r\n                                : (options instanceof tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"TfjsImageRecognitionBase\"].TinyYolov2Options\r\n                                    ? function (input) { return _nets__WEBPACK_IMPORTED_MODULE_8__[\"nets\"].tinyYolov2.locateFaces(input, options); }\r\n                                    : null));\r\n                        if (!faceDetectionFunction) {\r\n                            throw new Error('detectFaces - expected options to be instance of TinyFaceDetectorOptions | SsdMobilenetv1Options | MtcnnOptions | TinyYolov2Options');\r\n                        }\r\n                        return [2 /*return*/, faceDetectionFunction(input)];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    DetectAllFacesTask.prototype.runAndExtendWithFaceDetections = function () {\r\n        var _this = this;\r\n        return new Promise(function (res) { return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(_this, void 0, void 0, function () {\r\n            var detections;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, this.run()];\r\n                    case 1:\r\n                        detections = _a.sent();\r\n                        return [2 /*return*/, res(detections.map(function (detection) { return Object(_factories_WithFaceDetection__WEBPACK_IMPORTED_MODULE_2__[\"extendWithFaceDetection\"])({}, detection); }))];\r\n                }\r\n            });\r\n        }); });\r\n    };\r\n    DetectAllFacesTask.prototype.withFaceLandmarks = function (useTinyLandmarkNet) {\r\n        if (useTinyLandmarkNet === void 0) { useTinyLandmarkNet = false; }\r\n        return new _DetectFaceLandmarksTasks__WEBPACK_IMPORTED_MODULE_7__[\"DetectAllFaceLandmarksTask\"](this.runAndExtendWithFaceDetections(), this.input, useTinyLandmarkNet);\r\n    };\r\n    DetectAllFacesTask.prototype.withFaceExpressions = function () {\r\n        return new _PredictFaceExpressionsTask__WEBPACK_IMPORTED_MODULE_10__[\"PredictAllFaceExpressionsTask\"](this.runAndExtendWithFaceDetections(), this.input);\r\n    };\r\n    DetectAllFacesTask.prototype.withAgeAndGender = function () {\r\n        return new _PredictAgeAndGenderTask__WEBPACK_IMPORTED_MODULE_9__[\"PredictAllAgeAndGenderTask\"](this.runAndExtendWithFaceDetections(), this.input);\r\n    };\r\n    return DetectAllFacesTask;\r\n}(DetectFacesTaskBase));\r\n\r\nvar DetectSingleFaceTask = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(DetectSingleFaceTask, _super);\r\n    function DetectSingleFaceTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    DetectSingleFaceTask.prototype.run = function () {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var faceDetections, faceDetectionWithHighestScore;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, new DetectAllFacesTask(this.input, this.options)];\r\n                    case 1:\r\n                        faceDetections = _a.sent();\r\n                        faceDetectionWithHighestScore = faceDetections[0];\r\n                        faceDetections.forEach(function (faceDetection) {\r\n                            if (faceDetection.score > faceDetectionWithHighestScore.score) {\r\n                                faceDetectionWithHighestScore = faceDetection;\r\n                            }\r\n                        });\r\n                        return [2 /*return*/, faceDetectionWithHighestScore];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    DetectSingleFaceTask.prototype.runAndExtendWithFaceDetection = function () {\r\n        var _this = this;\r\n        return new Promise(function (res) { return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(_this, void 0, void 0, function () {\r\n            var detection;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, this.run()];\r\n                    case 1:\r\n                        detection = _a.sent();\r\n                        return [2 /*return*/, res(detection ? Object(_factories_WithFaceDetection__WEBPACK_IMPORTED_MODULE_2__[\"extendWithFaceDetection\"])({}, detection) : undefined)];\r\n                }\r\n            });\r\n        }); });\r\n    };\r\n    DetectSingleFaceTask.prototype.withFaceLandmarks = function (useTinyLandmarkNet) {\r\n        if (useTinyLandmarkNet === void 0) { useTinyLandmarkNet = false; }\r\n        return new _DetectFaceLandmarksTasks__WEBPACK_IMPORTED_MODULE_7__[\"DetectSingleFaceLandmarksTask\"](this.runAndExtendWithFaceDetection(), this.input, useTinyLandmarkNet);\r\n    };\r\n    DetectSingleFaceTask.prototype.withFaceExpressions = function () {\r\n        return new _PredictFaceExpressionsTask__WEBPACK_IMPORTED_MODULE_10__[\"PredictSingleFaceExpressionsTask\"](this.runAndExtendWithFaceDetection(), this.input);\r\n    };\r\n    DetectSingleFaceTask.prototype.withAgeAndGender = function () {\r\n        return new _PredictAgeAndGenderTask__WEBPACK_IMPORTED_MODULE_9__[\"PredictSingleAgeAndGenderTask\"](this.runAndExtendWithFaceDetection(), this.input);\r\n    };\r\n    return DetectSingleFaceTask;\r\n}(DetectFacesTaskBase));\r\n\r\n//# sourceMappingURL=DetectFacesTasks.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/globalApi/DetectFacesTasks.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/globalApi/FaceMatcher.js":
/*!*********************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/globalApi/FaceMatcher.js ***!
  \*********************************************************************/
/*! exports provided: FaceMatcher */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"FaceMatcher\", function() { return FaceMatcher; });\n/* harmony import */ var _classes_FaceMatch__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../classes/FaceMatch */ \"./node_modules/face-api.js/build/es6/classes/FaceMatch.js\");\n/* harmony import */ var _classes_LabeledFaceDescriptors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../classes/LabeledFaceDescriptors */ \"./node_modules/face-api.js/build/es6/classes/LabeledFaceDescriptors.js\");\n/* harmony import */ var _euclideanDistance__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../euclideanDistance */ \"./node_modules/face-api.js/build/es6/euclideanDistance.js\");\n\r\n\r\n\r\nvar FaceMatcher = /** @class */ (function () {\r\n    function FaceMatcher(inputs, distanceThreshold) {\r\n        if (distanceThreshold === void 0) { distanceThreshold = 0.6; }\r\n        this._distanceThreshold = distanceThreshold;\r\n        var inputArray = Array.isArray(inputs) ? inputs : [inputs];\r\n        if (!inputArray.length) {\r\n            throw new Error(\"FaceRecognizer.constructor - expected atleast one input\");\r\n        }\r\n        var count = 1;\r\n        var createUniqueLabel = function () { return \"person \" + count++; };\r\n        this._labeledDescriptors = inputArray.map(function (desc) {\r\n            if (desc instanceof _classes_LabeledFaceDescriptors__WEBPACK_IMPORTED_MODULE_1__[\"LabeledFaceDescriptors\"]) {\r\n                return desc;\r\n            }\r\n            if (desc instanceof Float32Array) {\r\n                return new _classes_LabeledFaceDescriptors__WEBPACK_IMPORTED_MODULE_1__[\"LabeledFaceDescriptors\"](createUniqueLabel(), [desc]);\r\n            }\r\n            if (desc.descriptor && desc.descriptor instanceof Float32Array) {\r\n                return new _classes_LabeledFaceDescriptors__WEBPACK_IMPORTED_MODULE_1__[\"LabeledFaceDescriptors\"](createUniqueLabel(), [desc.descriptor]);\r\n            }\r\n            throw new Error(\"FaceRecognizer.constructor - expected inputs to be of type LabeledFaceDescriptors | WithFaceDescriptor<any> | Float32Array | Array<LabeledFaceDescriptors | WithFaceDescriptor<any> | Float32Array>\");\r\n        });\r\n    }\r\n    Object.defineProperty(FaceMatcher.prototype, \"labeledDescriptors\", {\r\n        get: function () { return this._labeledDescriptors; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(FaceMatcher.prototype, \"distanceThreshold\", {\r\n        get: function () { return this._distanceThreshold; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    FaceMatcher.prototype.computeMeanDistance = function (queryDescriptor, descriptors) {\r\n        return descriptors\r\n            .map(function (d) { return Object(_euclideanDistance__WEBPACK_IMPORTED_MODULE_2__[\"euclideanDistance\"])(d, queryDescriptor); })\r\n            .reduce(function (d1, d2) { return d1 + d2; }, 0)\r\n            / (descriptors.length || 1);\r\n    };\r\n    FaceMatcher.prototype.matchDescriptor = function (queryDescriptor) {\r\n        var _this = this;\r\n        return this.labeledDescriptors\r\n            .map(function (_a) {\r\n            var descriptors = _a.descriptors, label = _a.label;\r\n            return new _classes_FaceMatch__WEBPACK_IMPORTED_MODULE_0__[\"FaceMatch\"](label, _this.computeMeanDistance(queryDescriptor, descriptors));\r\n        })\r\n            .reduce(function (best, curr) { return best.distance < curr.distance ? best : curr; });\r\n    };\r\n    FaceMatcher.prototype.findBestMatch = function (queryDescriptor) {\r\n        var bestMatch = this.matchDescriptor(queryDescriptor);\r\n        return bestMatch.distance < this.distanceThreshold\r\n            ? bestMatch\r\n            : new _classes_FaceMatch__WEBPACK_IMPORTED_MODULE_0__[\"FaceMatch\"]('unknown', bestMatch.distance);\r\n    };\r\n    FaceMatcher.prototype.toJSON = function () {\r\n        return {\r\n            distanceThreshold: this.distanceThreshold,\r\n            labeledDescriptors: this.labeledDescriptors.map(function (ld) { return ld.toJSON(); })\r\n        };\r\n    };\r\n    FaceMatcher.fromJSON = function (json) {\r\n        var labeledDescriptors = json.labeledDescriptors\r\n            .map(function (ld) { return _classes_LabeledFaceDescriptors__WEBPACK_IMPORTED_MODULE_1__[\"LabeledFaceDescriptors\"].fromJSON(ld); });\r\n        return new FaceMatcher(labeledDescriptors, json.distanceThreshold);\r\n    };\r\n    return FaceMatcher;\r\n}());\r\n\r\n//# sourceMappingURL=FaceMatcher.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/globalApi/FaceMatcher.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/globalApi/PredictAgeAndGenderTask.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/globalApi/PredictAgeAndGenderTask.js ***!
  \*********************************************************************************/
/*! exports provided: PredictAgeAndGenderTaskBase, PredictAllAgeAndGenderTask, PredictSingleAgeAndGenderTask, PredictAllAgeAndGenderWithFaceAlignmentTask, PredictSingleAgeAndGenderWithFaceAlignmentTask */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PredictAgeAndGenderTaskBase\", function() { return PredictAgeAndGenderTaskBase; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PredictAllAgeAndGenderTask\", function() { return PredictAllAgeAndGenderTask; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PredictSingleAgeAndGenderTask\", function() { return PredictSingleAgeAndGenderTask; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PredictAllAgeAndGenderWithFaceAlignmentTask\", function() { return PredictAllAgeAndGenderWithFaceAlignmentTask; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PredictSingleAgeAndGenderWithFaceAlignmentTask\", function() { return PredictSingleAgeAndGenderWithFaceAlignmentTask; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _factories_WithAge__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../factories/WithAge */ \"./node_modules/face-api.js/build/es6/factories/WithAge.js\");\n/* harmony import */ var _factories_WithGender__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../factories/WithGender */ \"./node_modules/face-api.js/build/es6/factories/WithGender.js\");\n/* harmony import */ var _ComposableTask__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ComposableTask */ \"./node_modules/face-api.js/build/es6/globalApi/ComposableTask.js\");\n/* harmony import */ var _ComputeFaceDescriptorsTasks__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ComputeFaceDescriptorsTasks */ \"./node_modules/face-api.js/build/es6/globalApi/ComputeFaceDescriptorsTasks.js\");\n/* harmony import */ var _extractFacesAndComputeResults__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./extractFacesAndComputeResults */ \"./node_modules/face-api.js/build/es6/globalApi/extractFacesAndComputeResults.js\");\n/* harmony import */ var _nets__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./nets */ \"./node_modules/face-api.js/build/es6/globalApi/nets.js\");\n/* harmony import */ var _PredictFaceExpressionsTask__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./PredictFaceExpressionsTask */ \"./node_modules/face-api.js/build/es6/globalApi/PredictFaceExpressionsTask.js\");\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nvar PredictAgeAndGenderTaskBase = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(PredictAgeAndGenderTaskBase, _super);\r\n    function PredictAgeAndGenderTaskBase(parentTask, input, extractedFaces) {\r\n        var _this = _super.call(this) || this;\r\n        _this.parentTask = parentTask;\r\n        _this.input = input;\r\n        _this.extractedFaces = extractedFaces;\r\n        return _this;\r\n    }\r\n    return PredictAgeAndGenderTaskBase;\r\n}(_ComposableTask__WEBPACK_IMPORTED_MODULE_3__[\"ComposableTask\"]));\r\n\r\nvar PredictAllAgeAndGenderTask = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(PredictAllAgeAndGenderTask, _super);\r\n    function PredictAllAgeAndGenderTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    PredictAllAgeAndGenderTask.prototype.run = function () {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var parentResults, ageAndGenderByFace;\r\n            var _this = this;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, this.parentTask];\r\n                    case 1:\r\n                        parentResults = _a.sent();\r\n                        return [4 /*yield*/, Object(_extractFacesAndComputeResults__WEBPACK_IMPORTED_MODULE_5__[\"extractAllFacesAndComputeResults\"])(parentResults, this.input, function (faces) { return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(_this, void 0, void 0, function () {\r\n                                return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n                                    switch (_a.label) {\r\n                                        case 0: return [4 /*yield*/, Promise.all(faces.map(function (face) { return _nets__WEBPACK_IMPORTED_MODULE_6__[\"nets\"].ageGenderNet.predictAgeAndGender(face); }))];\r\n                                        case 1: return [2 /*return*/, _a.sent()];\r\n                                    }\r\n                                });\r\n                            }); }, this.extractedFaces)];\r\n                    case 2:\r\n                        ageAndGenderByFace = _a.sent();\r\n                        return [2 /*return*/, parentResults.map(function (parentResult, i) {\r\n                                var _a = ageAndGenderByFace[i], age = _a.age, gender = _a.gender, genderProbability = _a.genderProbability;\r\n                                return Object(_factories_WithAge__WEBPACK_IMPORTED_MODULE_1__[\"extendWithAge\"])(Object(_factories_WithGender__WEBPACK_IMPORTED_MODULE_2__[\"extendWithGender\"])(parentResult, gender, genderProbability), age);\r\n                            })];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    PredictAllAgeAndGenderTask.prototype.withFaceExpressions = function () {\r\n        return new _PredictFaceExpressionsTask__WEBPACK_IMPORTED_MODULE_7__[\"PredictAllFaceExpressionsTask\"](this, this.input);\r\n    };\r\n    return PredictAllAgeAndGenderTask;\r\n}(PredictAgeAndGenderTaskBase));\r\n\r\nvar PredictSingleAgeAndGenderTask = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(PredictSingleAgeAndGenderTask, _super);\r\n    function PredictSingleAgeAndGenderTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    PredictSingleAgeAndGenderTask.prototype.run = function () {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var parentResult, _a, age, gender, genderProbability;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0: return [4 /*yield*/, this.parentTask];\r\n                    case 1:\r\n                        parentResult = _b.sent();\r\n                        if (!parentResult) {\r\n                            return [2 /*return*/];\r\n                        }\r\n                        return [4 /*yield*/, Object(_extractFacesAndComputeResults__WEBPACK_IMPORTED_MODULE_5__[\"extractSingleFaceAndComputeResult\"])(parentResult, this.input, function (face) { return _nets__WEBPACK_IMPORTED_MODULE_6__[\"nets\"].ageGenderNet.predictAgeAndGender(face); }, this.extractedFaces)];\r\n                    case 2:\r\n                        _a = _b.sent(), age = _a.age, gender = _a.gender, genderProbability = _a.genderProbability;\r\n                        return [2 /*return*/, Object(_factories_WithAge__WEBPACK_IMPORTED_MODULE_1__[\"extendWithAge\"])(Object(_factories_WithGender__WEBPACK_IMPORTED_MODULE_2__[\"extendWithGender\"])(parentResult, gender, genderProbability), age)];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    PredictSingleAgeAndGenderTask.prototype.withFaceExpressions = function () {\r\n        return new _PredictFaceExpressionsTask__WEBPACK_IMPORTED_MODULE_7__[\"PredictSingleFaceExpressionsTask\"](this, this.input);\r\n    };\r\n    return PredictSingleAgeAndGenderTask;\r\n}(PredictAgeAndGenderTaskBase));\r\n\r\nvar PredictAllAgeAndGenderWithFaceAlignmentTask = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(PredictAllAgeAndGenderWithFaceAlignmentTask, _super);\r\n    function PredictAllAgeAndGenderWithFaceAlignmentTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    PredictAllAgeAndGenderWithFaceAlignmentTask.prototype.withFaceExpressions = function () {\r\n        return new _PredictFaceExpressionsTask__WEBPACK_IMPORTED_MODULE_7__[\"PredictAllFaceExpressionsWithFaceAlignmentTask\"](this, this.input);\r\n    };\r\n    PredictAllAgeAndGenderWithFaceAlignmentTask.prototype.withFaceDescriptors = function () {\r\n        return new _ComputeFaceDescriptorsTasks__WEBPACK_IMPORTED_MODULE_4__[\"ComputeAllFaceDescriptorsTask\"](this, this.input);\r\n    };\r\n    return PredictAllAgeAndGenderWithFaceAlignmentTask;\r\n}(PredictAllAgeAndGenderTask));\r\n\r\nvar PredictSingleAgeAndGenderWithFaceAlignmentTask = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(PredictSingleAgeAndGenderWithFaceAlignmentTask, _super);\r\n    function PredictSingleAgeAndGenderWithFaceAlignmentTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    PredictSingleAgeAndGenderWithFaceAlignmentTask.prototype.withFaceExpressions = function () {\r\n        return new _PredictFaceExpressionsTask__WEBPACK_IMPORTED_MODULE_7__[\"PredictSingleFaceExpressionsWithFaceAlignmentTask\"](this, this.input);\r\n    };\r\n    PredictSingleAgeAndGenderWithFaceAlignmentTask.prototype.withFaceDescriptor = function () {\r\n        return new _ComputeFaceDescriptorsTasks__WEBPACK_IMPORTED_MODULE_4__[\"ComputeSingleFaceDescriptorTask\"](this, this.input);\r\n    };\r\n    return PredictSingleAgeAndGenderWithFaceAlignmentTask;\r\n}(PredictSingleAgeAndGenderTask));\r\n\r\n//# sourceMappingURL=PredictAgeAndGenderTask.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/globalApi/PredictAgeAndGenderTask.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/globalApi/PredictFaceExpressionsTask.js":
/*!************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/globalApi/PredictFaceExpressionsTask.js ***!
  \************************************************************************************/
/*! exports provided: PredictFaceExpressionsTaskBase, PredictAllFaceExpressionsTask, PredictSingleFaceExpressionsTask, PredictAllFaceExpressionsWithFaceAlignmentTask, PredictSingleFaceExpressionsWithFaceAlignmentTask */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PredictFaceExpressionsTaskBase\", function() { return PredictFaceExpressionsTaskBase; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PredictAllFaceExpressionsTask\", function() { return PredictAllFaceExpressionsTask; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PredictSingleFaceExpressionsTask\", function() { return PredictSingleFaceExpressionsTask; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PredictAllFaceExpressionsWithFaceAlignmentTask\", function() { return PredictAllFaceExpressionsWithFaceAlignmentTask; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PredictSingleFaceExpressionsWithFaceAlignmentTask\", function() { return PredictSingleFaceExpressionsWithFaceAlignmentTask; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _factories_WithFaceExpressions__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../factories/WithFaceExpressions */ \"./node_modules/face-api.js/build/es6/factories/WithFaceExpressions.js\");\n/* harmony import */ var _ComposableTask__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ComposableTask */ \"./node_modules/face-api.js/build/es6/globalApi/ComposableTask.js\");\n/* harmony import */ var _ComputeFaceDescriptorsTasks__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ComputeFaceDescriptorsTasks */ \"./node_modules/face-api.js/build/es6/globalApi/ComputeFaceDescriptorsTasks.js\");\n/* harmony import */ var _extractFacesAndComputeResults__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./extractFacesAndComputeResults */ \"./node_modules/face-api.js/build/es6/globalApi/extractFacesAndComputeResults.js\");\n/* harmony import */ var _nets__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./nets */ \"./node_modules/face-api.js/build/es6/globalApi/nets.js\");\n/* harmony import */ var _PredictAgeAndGenderTask__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./PredictAgeAndGenderTask */ \"./node_modules/face-api.js/build/es6/globalApi/PredictAgeAndGenderTask.js\");\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nvar PredictFaceExpressionsTaskBase = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(PredictFaceExpressionsTaskBase, _super);\r\n    function PredictFaceExpressionsTaskBase(parentTask, input, extractedFaces) {\r\n        var _this = _super.call(this) || this;\r\n        _this.parentTask = parentTask;\r\n        _this.input = input;\r\n        _this.extractedFaces = extractedFaces;\r\n        return _this;\r\n    }\r\n    return PredictFaceExpressionsTaskBase;\r\n}(_ComposableTask__WEBPACK_IMPORTED_MODULE_2__[\"ComposableTask\"]));\r\n\r\nvar PredictAllFaceExpressionsTask = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(PredictAllFaceExpressionsTask, _super);\r\n    function PredictAllFaceExpressionsTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    PredictAllFaceExpressionsTask.prototype.run = function () {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var parentResults, faceExpressionsByFace;\r\n            var _this = this;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, this.parentTask];\r\n                    case 1:\r\n                        parentResults = _a.sent();\r\n                        return [4 /*yield*/, Object(_extractFacesAndComputeResults__WEBPACK_IMPORTED_MODULE_4__[\"extractAllFacesAndComputeResults\"])(parentResults, this.input, function (faces) { return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(_this, void 0, void 0, function () {\r\n                                return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n                                    switch (_a.label) {\r\n                                        case 0: return [4 /*yield*/, Promise.all(faces.map(function (face) { return _nets__WEBPACK_IMPORTED_MODULE_5__[\"nets\"].faceExpressionNet.predictExpressions(face); }))];\r\n                                        case 1: return [2 /*return*/, _a.sent()];\r\n                                    }\r\n                                });\r\n                            }); }, this.extractedFaces)];\r\n                    case 2:\r\n                        faceExpressionsByFace = _a.sent();\r\n                        return [2 /*return*/, parentResults.map(function (parentResult, i) { return Object(_factories_WithFaceExpressions__WEBPACK_IMPORTED_MODULE_1__[\"extendWithFaceExpressions\"])(parentResult, faceExpressionsByFace[i]); })];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    PredictAllFaceExpressionsTask.prototype.withAgeAndGender = function () {\r\n        return new _PredictAgeAndGenderTask__WEBPACK_IMPORTED_MODULE_6__[\"PredictAllAgeAndGenderTask\"](this, this.input);\r\n    };\r\n    return PredictAllFaceExpressionsTask;\r\n}(PredictFaceExpressionsTaskBase));\r\n\r\nvar PredictSingleFaceExpressionsTask = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(PredictSingleFaceExpressionsTask, _super);\r\n    function PredictSingleFaceExpressionsTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    PredictSingleFaceExpressionsTask.prototype.run = function () {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var parentResult, faceExpressions;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, this.parentTask];\r\n                    case 1:\r\n                        parentResult = _a.sent();\r\n                        if (!parentResult) {\r\n                            return [2 /*return*/];\r\n                        }\r\n                        return [4 /*yield*/, Object(_extractFacesAndComputeResults__WEBPACK_IMPORTED_MODULE_4__[\"extractSingleFaceAndComputeResult\"])(parentResult, this.input, function (face) { return _nets__WEBPACK_IMPORTED_MODULE_5__[\"nets\"].faceExpressionNet.predictExpressions(face); }, this.extractedFaces)];\r\n                    case 2:\r\n                        faceExpressions = _a.sent();\r\n                        return [2 /*return*/, Object(_factories_WithFaceExpressions__WEBPACK_IMPORTED_MODULE_1__[\"extendWithFaceExpressions\"])(parentResult, faceExpressions)];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    PredictSingleFaceExpressionsTask.prototype.withAgeAndGender = function () {\r\n        return new _PredictAgeAndGenderTask__WEBPACK_IMPORTED_MODULE_6__[\"PredictSingleAgeAndGenderTask\"](this, this.input);\r\n    };\r\n    return PredictSingleFaceExpressionsTask;\r\n}(PredictFaceExpressionsTaskBase));\r\n\r\nvar PredictAllFaceExpressionsWithFaceAlignmentTask = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(PredictAllFaceExpressionsWithFaceAlignmentTask, _super);\r\n    function PredictAllFaceExpressionsWithFaceAlignmentTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    PredictAllFaceExpressionsWithFaceAlignmentTask.prototype.withAgeAndGender = function () {\r\n        return new _PredictAgeAndGenderTask__WEBPACK_IMPORTED_MODULE_6__[\"PredictAllAgeAndGenderWithFaceAlignmentTask\"](this, this.input);\r\n    };\r\n    PredictAllFaceExpressionsWithFaceAlignmentTask.prototype.withFaceDescriptors = function () {\r\n        return new _ComputeFaceDescriptorsTasks__WEBPACK_IMPORTED_MODULE_3__[\"ComputeAllFaceDescriptorsTask\"](this, this.input);\r\n    };\r\n    return PredictAllFaceExpressionsWithFaceAlignmentTask;\r\n}(PredictAllFaceExpressionsTask));\r\n\r\nvar PredictSingleFaceExpressionsWithFaceAlignmentTask = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(PredictSingleFaceExpressionsWithFaceAlignmentTask, _super);\r\n    function PredictSingleFaceExpressionsWithFaceAlignmentTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    PredictSingleFaceExpressionsWithFaceAlignmentTask.prototype.withAgeAndGender = function () {\r\n        return new _PredictAgeAndGenderTask__WEBPACK_IMPORTED_MODULE_6__[\"PredictSingleAgeAndGenderWithFaceAlignmentTask\"](this, this.input);\r\n    };\r\n    PredictSingleFaceExpressionsWithFaceAlignmentTask.prototype.withFaceDescriptor = function () {\r\n        return new _ComputeFaceDescriptorsTasks__WEBPACK_IMPORTED_MODULE_3__[\"ComputeSingleFaceDescriptorTask\"](this, this.input);\r\n    };\r\n    return PredictSingleFaceExpressionsWithFaceAlignmentTask;\r\n}(PredictSingleFaceExpressionsTask));\r\n\r\n//# sourceMappingURL=PredictFaceExpressionsTask.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/globalApi/PredictFaceExpressionsTask.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/globalApi/allFaces.js":
/*!******************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/globalApi/allFaces.js ***!
  \******************************************************************/
/*! exports provided: allFacesSsdMobilenetv1, allFacesTinyYolov2, allFacesMtcnn, allFaces */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"allFacesSsdMobilenetv1\", function() { return allFacesSsdMobilenetv1; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"allFacesTinyYolov2\", function() { return allFacesTinyYolov2; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"allFacesMtcnn\", function() { return allFacesMtcnn; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"allFaces\", function() { return allFaces; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _mtcnn_MtcnnOptions__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../mtcnn/MtcnnOptions */ \"./node_modules/face-api.js/build/es6/mtcnn/MtcnnOptions.js\");\n/* harmony import */ var _ssdMobilenetv1__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../ssdMobilenetv1 */ \"./node_modules/face-api.js/build/es6/ssdMobilenetv1/index.js\");\n/* harmony import */ var _detectFaces__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./detectFaces */ \"./node_modules/face-api.js/build/es6/globalApi/detectFaces.js\");\n\r\n\r\n\r\n\r\n\r\n// export allFaces API for backward compatibility\r\nfunction allFacesSsdMobilenetv1(input, minConfidence) {\r\n    return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n            switch (_a.label) {\r\n                case 0: return [4 /*yield*/, Object(_detectFaces__WEBPACK_IMPORTED_MODULE_4__[\"detectAllFaces\"])(input, new _ssdMobilenetv1__WEBPACK_IMPORTED_MODULE_3__[\"SsdMobilenetv1Options\"](minConfidence ? { minConfidence: minConfidence } : {}))\r\n                        .withFaceLandmarks()\r\n                        .withFaceDescriptors()];\r\n                case 1: return [2 /*return*/, _a.sent()];\r\n            }\r\n        });\r\n    });\r\n}\r\nfunction allFacesTinyYolov2(input, forwardParams) {\r\n    if (forwardParams === void 0) { forwardParams = {}; }\r\n    return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n            switch (_a.label) {\r\n                case 0: return [4 /*yield*/, Object(_detectFaces__WEBPACK_IMPORTED_MODULE_4__[\"detectAllFaces\"])(input, new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"TfjsImageRecognitionBase\"].TinyYolov2Options(forwardParams))\r\n                        .withFaceLandmarks()\r\n                        .withFaceDescriptors()];\r\n                case 1: return [2 /*return*/, _a.sent()];\r\n            }\r\n        });\r\n    });\r\n}\r\nfunction allFacesMtcnn(input, forwardParams) {\r\n    if (forwardParams === void 0) { forwardParams = {}; }\r\n    return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n            switch (_a.label) {\r\n                case 0: return [4 /*yield*/, Object(_detectFaces__WEBPACK_IMPORTED_MODULE_4__[\"detectAllFaces\"])(input, new _mtcnn_MtcnnOptions__WEBPACK_IMPORTED_MODULE_2__[\"MtcnnOptions\"](forwardParams))\r\n                        .withFaceLandmarks()\r\n                        .withFaceDescriptors()];\r\n                case 1: return [2 /*return*/, _a.sent()];\r\n            }\r\n        });\r\n    });\r\n}\r\nvar allFaces = allFacesSsdMobilenetv1;\r\n//# sourceMappingURL=allFaces.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/globalApi/allFaces.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/globalApi/detectFaces.js":
/*!*********************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/globalApi/detectFaces.js ***!
  \*********************************************************************/
/*! exports provided: detectSingleFace, detectAllFaces */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"detectSingleFace\", function() { return detectSingleFace; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"detectAllFaces\", function() { return detectAllFaces; });\n/* harmony import */ var _ssdMobilenetv1_SsdMobilenetv1Options__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../ssdMobilenetv1/SsdMobilenetv1Options */ \"./node_modules/face-api.js/build/es6/ssdMobilenetv1/SsdMobilenetv1Options.js\");\n/* harmony import */ var _DetectFacesTasks__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./DetectFacesTasks */ \"./node_modules/face-api.js/build/es6/globalApi/DetectFacesTasks.js\");\n\r\n\r\nfunction detectSingleFace(input, options) {\r\n    if (options === void 0) { options = new _ssdMobilenetv1_SsdMobilenetv1Options__WEBPACK_IMPORTED_MODULE_0__[\"SsdMobilenetv1Options\"](); }\r\n    return new _DetectFacesTasks__WEBPACK_IMPORTED_MODULE_1__[\"DetectSingleFaceTask\"](input, options);\r\n}\r\nfunction detectAllFaces(input, options) {\r\n    if (options === void 0) { options = new _ssdMobilenetv1_SsdMobilenetv1Options__WEBPACK_IMPORTED_MODULE_0__[\"SsdMobilenetv1Options\"](); }\r\n    return new _DetectFacesTasks__WEBPACK_IMPORTED_MODULE_1__[\"DetectAllFacesTask\"](input, options);\r\n}\r\n//# sourceMappingURL=detectFaces.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/globalApi/detectFaces.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/globalApi/extractFacesAndComputeResults.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/globalApi/extractFacesAndComputeResults.js ***!
  \***************************************************************************************/
/*! exports provided: extractAllFacesAndComputeResults, extractSingleFaceAndComputeResult */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractAllFacesAndComputeResults\", function() { return extractAllFacesAndComputeResults; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractSingleFaceAndComputeResult\", function() { return extractSingleFaceAndComputeResult; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var _dom__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../dom */ \"./node_modules/face-api.js/build/es6/dom/index.js\");\n/* harmony import */ var _factories_WithFaceLandmarks__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../factories/WithFaceLandmarks */ \"./node_modules/face-api.js/build/es6/factories/WithFaceLandmarks.js\");\n\r\n\r\n\r\n\r\nfunction extractAllFacesAndComputeResults(parentResults, input, computeResults, extractedFaces, getRectForAlignment) {\r\n    if (getRectForAlignment === void 0) { getRectForAlignment = function (_a) {\r\n        var alignedRect = _a.alignedRect;\r\n        return alignedRect;\r\n    }; }\r\n    return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n        var faceBoxes, faces, _a, _b, results;\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_c) {\r\n            switch (_c.label) {\r\n                case 0:\r\n                    faceBoxes = parentResults.map(function (parentResult) {\r\n                        return Object(_factories_WithFaceLandmarks__WEBPACK_IMPORTED_MODULE_3__[\"isWithFaceLandmarks\"])(parentResult)\r\n                            ? getRectForAlignment(parentResult)\r\n                            : parentResult.detection;\r\n                    });\r\n                    _a = extractedFaces;\r\n                    if (_a) return [3 /*break*/, 5];\r\n                    if (!(input instanceof _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"Tensor\"])) return [3 /*break*/, 2];\r\n                    return [4 /*yield*/, Object(_dom__WEBPACK_IMPORTED_MODULE_2__[\"extractFaceTensors\"])(input, faceBoxes)];\r\n                case 1:\r\n                    _b = _c.sent();\r\n                    return [3 /*break*/, 4];\r\n                case 2: return [4 /*yield*/, Object(_dom__WEBPACK_IMPORTED_MODULE_2__[\"extractFaces\"])(input, faceBoxes)];\r\n                case 3:\r\n                    _b = _c.sent();\r\n                    _c.label = 4;\r\n                case 4:\r\n                    _a = (_b);\r\n                    _c.label = 5;\r\n                case 5:\r\n                    faces = _a;\r\n                    return [4 /*yield*/, computeResults(faces)];\r\n                case 6:\r\n                    results = _c.sent();\r\n                    faces.forEach(function (f) { return f instanceof _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"Tensor\"] && f.dispose(); });\r\n                    return [2 /*return*/, results];\r\n            }\r\n        });\r\n    });\r\n}\r\nfunction extractSingleFaceAndComputeResult(parentResult, input, computeResult, extractedFaces, getRectForAlignment) {\r\n    return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n        var _this = this;\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n            return [2 /*return*/, extractAllFacesAndComputeResults([parentResult], input, function (faces) { return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(_this, void 0, void 0, function () { return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n                    return [2 /*return*/, computeResult(faces[0])];\r\n                }); }); }, extractedFaces, getRectForAlignment)];\r\n        });\r\n    });\r\n}\r\n//# sourceMappingURL=extractFacesAndComputeResults.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/globalApi/extractFacesAndComputeResults.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/globalApi/index.js":
/*!***************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/globalApi/index.js ***!
  \***************************************************************/
/*! exports provided: allFacesSsdMobilenetv1, allFacesTinyYolov2, allFacesMtcnn, allFaces, ComposableTask, ComputeFaceDescriptorsTaskBase, ComputeAllFaceDescriptorsTask, ComputeSingleFaceDescriptorTask, detectSingleFace, detectAllFaces, DetectFacesTaskBase, DetectAllFacesTask, DetectSingleFaceTask, DetectFaceLandmarksTaskBase, DetectAllFaceLandmarksTask, DetectSingleFaceLandmarksTask, FaceMatcher, nets, ssdMobilenetv1, tinyFaceDetector, tinyYolov2, mtcnn, detectFaceLandmarks, detectFaceLandmarksTiny, computeFaceDescriptor, recognizeFaceExpressions, predictAgeAndGender, loadSsdMobilenetv1Model, loadTinyFaceDetectorModel, loadMtcnnModel, loadTinyYolov2Model, loadFaceLandmarkModel, loadFaceLandmarkTinyModel, loadFaceRecognitionModel, loadFaceExpressionModel, loadAgeGenderModel, loadFaceDetectionModel, locateFaces, detectLandmarks */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _allFaces__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./allFaces */ \"./node_modules/face-api.js/build/es6/globalApi/allFaces.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"allFacesSsdMobilenetv1\", function() { return _allFaces__WEBPACK_IMPORTED_MODULE_0__[\"allFacesSsdMobilenetv1\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"allFacesTinyYolov2\", function() { return _allFaces__WEBPACK_IMPORTED_MODULE_0__[\"allFacesTinyYolov2\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"allFacesMtcnn\", function() { return _allFaces__WEBPACK_IMPORTED_MODULE_0__[\"allFacesMtcnn\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"allFaces\", function() { return _allFaces__WEBPACK_IMPORTED_MODULE_0__[\"allFaces\"]; });\n\n/* harmony import */ var _ComposableTask__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ComposableTask */ \"./node_modules/face-api.js/build/es6/globalApi/ComposableTask.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ComposableTask\", function() { return _ComposableTask__WEBPACK_IMPORTED_MODULE_1__[\"ComposableTask\"]; });\n\n/* harmony import */ var _ComputeFaceDescriptorsTasks__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ComputeFaceDescriptorsTasks */ \"./node_modules/face-api.js/build/es6/globalApi/ComputeFaceDescriptorsTasks.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ComputeFaceDescriptorsTaskBase\", function() { return _ComputeFaceDescriptorsTasks__WEBPACK_IMPORTED_MODULE_2__[\"ComputeFaceDescriptorsTaskBase\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ComputeAllFaceDescriptorsTask\", function() { return _ComputeFaceDescriptorsTasks__WEBPACK_IMPORTED_MODULE_2__[\"ComputeAllFaceDescriptorsTask\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ComputeSingleFaceDescriptorTask\", function() { return _ComputeFaceDescriptorsTasks__WEBPACK_IMPORTED_MODULE_2__[\"ComputeSingleFaceDescriptorTask\"]; });\n\n/* harmony import */ var _detectFaces__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./detectFaces */ \"./node_modules/face-api.js/build/es6/globalApi/detectFaces.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"detectSingleFace\", function() { return _detectFaces__WEBPACK_IMPORTED_MODULE_3__[\"detectSingleFace\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"detectAllFaces\", function() { return _detectFaces__WEBPACK_IMPORTED_MODULE_3__[\"detectAllFaces\"]; });\n\n/* harmony import */ var _DetectFacesTasks__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./DetectFacesTasks */ \"./node_modules/face-api.js/build/es6/globalApi/DetectFacesTasks.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DetectFacesTaskBase\", function() { return _DetectFacesTasks__WEBPACK_IMPORTED_MODULE_4__[\"DetectFacesTaskBase\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DetectAllFacesTask\", function() { return _DetectFacesTasks__WEBPACK_IMPORTED_MODULE_4__[\"DetectAllFacesTask\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DetectSingleFaceTask\", function() { return _DetectFacesTasks__WEBPACK_IMPORTED_MODULE_4__[\"DetectSingleFaceTask\"]; });\n\n/* harmony import */ var _DetectFaceLandmarksTasks__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./DetectFaceLandmarksTasks */ \"./node_modules/face-api.js/build/es6/globalApi/DetectFaceLandmarksTasks.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DetectFaceLandmarksTaskBase\", function() { return _DetectFaceLandmarksTasks__WEBPACK_IMPORTED_MODULE_5__[\"DetectFaceLandmarksTaskBase\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DetectAllFaceLandmarksTask\", function() { return _DetectFaceLandmarksTasks__WEBPACK_IMPORTED_MODULE_5__[\"DetectAllFaceLandmarksTask\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DetectSingleFaceLandmarksTask\", function() { return _DetectFaceLandmarksTasks__WEBPACK_IMPORTED_MODULE_5__[\"DetectSingleFaceLandmarksTask\"]; });\n\n/* harmony import */ var _FaceMatcher__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./FaceMatcher */ \"./node_modules/face-api.js/build/es6/globalApi/FaceMatcher.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceMatcher\", function() { return _FaceMatcher__WEBPACK_IMPORTED_MODULE_6__[\"FaceMatcher\"]; });\n\n/* harmony import */ var _nets__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./nets */ \"./node_modules/face-api.js/build/es6/globalApi/nets.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"nets\", function() { return _nets__WEBPACK_IMPORTED_MODULE_7__[\"nets\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ssdMobilenetv1\", function() { return _nets__WEBPACK_IMPORTED_MODULE_7__[\"ssdMobilenetv1\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"tinyFaceDetector\", function() { return _nets__WEBPACK_IMPORTED_MODULE_7__[\"tinyFaceDetector\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"tinyYolov2\", function() { return _nets__WEBPACK_IMPORTED_MODULE_7__[\"tinyYolov2\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"mtcnn\", function() { return _nets__WEBPACK_IMPORTED_MODULE_7__[\"mtcnn\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"detectFaceLandmarks\", function() { return _nets__WEBPACK_IMPORTED_MODULE_7__[\"detectFaceLandmarks\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"detectFaceLandmarksTiny\", function() { return _nets__WEBPACK_IMPORTED_MODULE_7__[\"detectFaceLandmarksTiny\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"computeFaceDescriptor\", function() { return _nets__WEBPACK_IMPORTED_MODULE_7__[\"computeFaceDescriptor\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"recognizeFaceExpressions\", function() { return _nets__WEBPACK_IMPORTED_MODULE_7__[\"recognizeFaceExpressions\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"predictAgeAndGender\", function() { return _nets__WEBPACK_IMPORTED_MODULE_7__[\"predictAgeAndGender\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadSsdMobilenetv1Model\", function() { return _nets__WEBPACK_IMPORTED_MODULE_7__[\"loadSsdMobilenetv1Model\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadTinyFaceDetectorModel\", function() { return _nets__WEBPACK_IMPORTED_MODULE_7__[\"loadTinyFaceDetectorModel\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadMtcnnModel\", function() { return _nets__WEBPACK_IMPORTED_MODULE_7__[\"loadMtcnnModel\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadTinyYolov2Model\", function() { return _nets__WEBPACK_IMPORTED_MODULE_7__[\"loadTinyYolov2Model\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadFaceLandmarkModel\", function() { return _nets__WEBPACK_IMPORTED_MODULE_7__[\"loadFaceLandmarkModel\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadFaceLandmarkTinyModel\", function() { return _nets__WEBPACK_IMPORTED_MODULE_7__[\"loadFaceLandmarkTinyModel\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadFaceRecognitionModel\", function() { return _nets__WEBPACK_IMPORTED_MODULE_7__[\"loadFaceRecognitionModel\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadFaceExpressionModel\", function() { return _nets__WEBPACK_IMPORTED_MODULE_7__[\"loadFaceExpressionModel\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadAgeGenderModel\", function() { return _nets__WEBPACK_IMPORTED_MODULE_7__[\"loadAgeGenderModel\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadFaceDetectionModel\", function() { return _nets__WEBPACK_IMPORTED_MODULE_7__[\"loadFaceDetectionModel\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"locateFaces\", function() { return _nets__WEBPACK_IMPORTED_MODULE_7__[\"locateFaces\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"detectLandmarks\", function() { return _nets__WEBPACK_IMPORTED_MODULE_7__[\"detectLandmarks\"]; });\n\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/globalApi/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/globalApi/nets.js":
/*!**************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/globalApi/nets.js ***!
  \**************************************************************/
/*! exports provided: nets, ssdMobilenetv1, tinyFaceDetector, tinyYolov2, mtcnn, detectFaceLandmarks, detectFaceLandmarksTiny, computeFaceDescriptor, recognizeFaceExpressions, predictAgeAndGender, loadSsdMobilenetv1Model, loadTinyFaceDetectorModel, loadMtcnnModel, loadTinyYolov2Model, loadFaceLandmarkModel, loadFaceLandmarkTinyModel, loadFaceRecognitionModel, loadFaceExpressionModel, loadAgeGenderModel, loadFaceDetectionModel, locateFaces, detectLandmarks */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"nets\", function() { return nets; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ssdMobilenetv1\", function() { return ssdMobilenetv1; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"tinyFaceDetector\", function() { return tinyFaceDetector; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"tinyYolov2\", function() { return tinyYolov2; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"mtcnn\", function() { return mtcnn; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"detectFaceLandmarks\", function() { return detectFaceLandmarks; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"detectFaceLandmarksTiny\", function() { return detectFaceLandmarksTiny; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"computeFaceDescriptor\", function() { return computeFaceDescriptor; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"recognizeFaceExpressions\", function() { return recognizeFaceExpressions; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"predictAgeAndGender\", function() { return predictAgeAndGender; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"loadSsdMobilenetv1Model\", function() { return loadSsdMobilenetv1Model; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"loadTinyFaceDetectorModel\", function() { return loadTinyFaceDetectorModel; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"loadMtcnnModel\", function() { return loadMtcnnModel; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"loadTinyYolov2Model\", function() { return loadTinyYolov2Model; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"loadFaceLandmarkModel\", function() { return loadFaceLandmarkModel; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"loadFaceLandmarkTinyModel\", function() { return loadFaceLandmarkTinyModel; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"loadFaceRecognitionModel\", function() { return loadFaceRecognitionModel; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"loadFaceExpressionModel\", function() { return loadFaceExpressionModel; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"loadAgeGenderModel\", function() { return loadAgeGenderModel; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"loadFaceDetectionModel\", function() { return loadFaceDetectionModel; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"locateFaces\", function() { return locateFaces; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"detectLandmarks\", function() { return detectLandmarks; });\n/* harmony import */ var _ageGenderNet_AgeGenderNet__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../ageGenderNet/AgeGenderNet */ \"./node_modules/face-api.js/build/es6/ageGenderNet/AgeGenderNet.js\");\n/* harmony import */ var _faceExpressionNet_FaceExpressionNet__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../faceExpressionNet/FaceExpressionNet */ \"./node_modules/face-api.js/build/es6/faceExpressionNet/FaceExpressionNet.js\");\n/* harmony import */ var _faceLandmarkNet_FaceLandmark68Net__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../faceLandmarkNet/FaceLandmark68Net */ \"./node_modules/face-api.js/build/es6/faceLandmarkNet/FaceLandmark68Net.js\");\n/* harmony import */ var _faceLandmarkNet_FaceLandmark68TinyNet__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../faceLandmarkNet/FaceLandmark68TinyNet */ \"./node_modules/face-api.js/build/es6/faceLandmarkNet/FaceLandmark68TinyNet.js\");\n/* harmony import */ var _faceRecognitionNet_FaceRecognitionNet__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../faceRecognitionNet/FaceRecognitionNet */ \"./node_modules/face-api.js/build/es6/faceRecognitionNet/FaceRecognitionNet.js\");\n/* harmony import */ var _mtcnn_Mtcnn__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../mtcnn/Mtcnn */ \"./node_modules/face-api.js/build/es6/mtcnn/Mtcnn.js\");\n/* harmony import */ var _ssdMobilenetv1_SsdMobilenetv1__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../ssdMobilenetv1/SsdMobilenetv1 */ \"./node_modules/face-api.js/build/es6/ssdMobilenetv1/SsdMobilenetv1.js\");\n/* harmony import */ var _tinyFaceDetector_TinyFaceDetector__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../tinyFaceDetector/TinyFaceDetector */ \"./node_modules/face-api.js/build/es6/tinyFaceDetector/TinyFaceDetector.js\");\n/* harmony import */ var _tinyYolov2__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../tinyYolov2 */ \"./node_modules/face-api.js/build/es6/tinyYolov2/index.js\");\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nvar nets = {\r\n    ssdMobilenetv1: new _ssdMobilenetv1_SsdMobilenetv1__WEBPACK_IMPORTED_MODULE_6__[\"SsdMobilenetv1\"](),\r\n    tinyFaceDetector: new _tinyFaceDetector_TinyFaceDetector__WEBPACK_IMPORTED_MODULE_7__[\"TinyFaceDetector\"](),\r\n    tinyYolov2: new _tinyYolov2__WEBPACK_IMPORTED_MODULE_8__[\"TinyYolov2\"](),\r\n    mtcnn: new _mtcnn_Mtcnn__WEBPACK_IMPORTED_MODULE_5__[\"Mtcnn\"](),\r\n    faceLandmark68Net: new _faceLandmarkNet_FaceLandmark68Net__WEBPACK_IMPORTED_MODULE_2__[\"FaceLandmark68Net\"](),\r\n    faceLandmark68TinyNet: new _faceLandmarkNet_FaceLandmark68TinyNet__WEBPACK_IMPORTED_MODULE_3__[\"FaceLandmark68TinyNet\"](),\r\n    faceRecognitionNet: new _faceRecognitionNet_FaceRecognitionNet__WEBPACK_IMPORTED_MODULE_4__[\"FaceRecognitionNet\"](),\r\n    faceExpressionNet: new _faceExpressionNet_FaceExpressionNet__WEBPACK_IMPORTED_MODULE_1__[\"FaceExpressionNet\"](),\r\n    ageGenderNet: new _ageGenderNet_AgeGenderNet__WEBPACK_IMPORTED_MODULE_0__[\"AgeGenderNet\"]()\r\n};\r\n/**\r\n * Attempts to detect all faces in an image using SSD Mobilenetv1 Network.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see SsdMobilenetv1Options constructor for default parameters).\r\n * @returns Bounding box of each face with score.\r\n */\r\nvar ssdMobilenetv1 = function (input, options) {\r\n    return nets.ssdMobilenetv1.locateFaces(input, options);\r\n};\r\n/**\r\n * Attempts to detect all faces in an image using the Tiny Face Detector.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see TinyFaceDetectorOptions constructor for default parameters).\r\n * @returns Bounding box of each face with score.\r\n */\r\nvar tinyFaceDetector = function (input, options) {\r\n    return nets.tinyFaceDetector.locateFaces(input, options);\r\n};\r\n/**\r\n * Attempts to detect all faces in an image using the Tiny Yolov2 Network.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see TinyYolov2Options constructor for default parameters).\r\n * @returns Bounding box of each face with score.\r\n */\r\nvar tinyYolov2 = function (input, options) {\r\n    return nets.tinyYolov2.locateFaces(input, options);\r\n};\r\n/**\r\n * Attempts to detect all faces in an image and the 5 point face landmarks\r\n * of each detected face using the MTCNN Network.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see MtcnnOptions constructor for default parameters).\r\n * @returns Bounding box of each face with score and 5 point face landmarks.\r\n */\r\nvar mtcnn = function (input, options) {\r\n    return nets.mtcnn.forward(input, options);\r\n};\r\n/**\r\n * Detects the 68 point face landmark positions of the face shown in an image.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns 68 point face landmarks or array thereof in case of batch input.\r\n */\r\nvar detectFaceLandmarks = function (input) {\r\n    return nets.faceLandmark68Net.detectLandmarks(input);\r\n};\r\n/**\r\n * Detects the 68 point face landmark positions of the face shown in an image\r\n * using a tinier version of the 68 point face landmark model, which is slightly\r\n * faster at inference, but also slightly less accurate.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns 68 point face landmarks or array thereof in case of batch input.\r\n */\r\nvar detectFaceLandmarksTiny = function (input) {\r\n    return nets.faceLandmark68TinyNet.detectLandmarks(input);\r\n};\r\n/**\r\n * Computes a 128 entry vector (face descriptor / face embeddings) from the face shown in an image,\r\n * which uniquely represents the features of that persons face. The computed face descriptor can\r\n * be used to measure the similarity between faces, by computing the euclidean distance of two\r\n * face descriptors.\r\n *\r\n * @param inputs The face image extracted from the aligned bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns Face descriptor with 128 entries or array thereof in case of batch input.\r\n */\r\nvar computeFaceDescriptor = function (input) {\r\n    return nets.faceRecognitionNet.computeFaceDescriptor(input);\r\n};\r\n/**\r\n * Recognizes the facial expressions from a face image.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns Facial expressions with corresponding probabilities or array thereof in case of batch input.\r\n */\r\nvar recognizeFaceExpressions = function (input) {\r\n    return nets.faceExpressionNet.predictExpressions(input);\r\n};\r\n/**\r\n * Predicts age and gender from a face image.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns Predictions with age, gender and gender probability or array thereof in case of batch input.\r\n */\r\nvar predictAgeAndGender = function (input) {\r\n    return nets.ageGenderNet.predictAgeAndGender(input);\r\n};\r\nvar loadSsdMobilenetv1Model = function (url) { return nets.ssdMobilenetv1.load(url); };\r\nvar loadTinyFaceDetectorModel = function (url) { return nets.tinyFaceDetector.load(url); };\r\nvar loadMtcnnModel = function (url) { return nets.mtcnn.load(url); };\r\nvar loadTinyYolov2Model = function (url) { return nets.tinyYolov2.load(url); };\r\nvar loadFaceLandmarkModel = function (url) { return nets.faceLandmark68Net.load(url); };\r\nvar loadFaceLandmarkTinyModel = function (url) { return nets.faceLandmark68TinyNet.load(url); };\r\nvar loadFaceRecognitionModel = function (url) { return nets.faceRecognitionNet.load(url); };\r\nvar loadFaceExpressionModel = function (url) { return nets.faceExpressionNet.load(url); };\r\nvar loadAgeGenderModel = function (url) { return nets.ageGenderNet.load(url); };\r\n// backward compatibility\r\nvar loadFaceDetectionModel = loadSsdMobilenetv1Model;\r\nvar locateFaces = ssdMobilenetv1;\r\nvar detectLandmarks = detectFaceLandmarks;\r\n//# sourceMappingURL=nets.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/globalApi/nets.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/index.js":
/*!*****************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/index.js ***!
  \*****************************************************/
/*! exports provided: tf, draw, TinyYolov2, createTinyYolov2, euclideanDistance, resizeResults, env, isTensor, isTensor1D, isTensor2D, isTensor3D, isTensor4D, isFloat, isEven, round, isDimensions, computeReshapedDimensions, getCenterPoint, range, isValidNumber, isValidProbablitiy, NeuralNetwork, TfjsImageRecognitionBase, AgeGenderNet, Gender, FaceDetection, FaceLandmarks, FaceLandmarks5, FaceLandmarks68, FaceMatch, LabeledFaceDescriptors, extractFaces, extractFaceTensors, FaceExpressionNet, FACE_EXPRESSION_LABELS, FaceExpressions, FaceLandmark68Net, FaceLandmark68TinyNet, FaceLandmarkNet, FaceRecognitionNet, createFaceRecognitionNet, extendWithFaceDescriptor, isWithFaceDetection, extendWithFaceDetection, isWithFaceExpressions, extendWithFaceExpressions, isWithFaceLandmarks, extendWithFaceLandmarks, isWithAge, extendWithAge, isWithGender, extendWithGender, allFacesSsdMobilenetv1, allFacesTinyYolov2, allFacesMtcnn, allFaces, ComposableTask, ComputeFaceDescriptorsTaskBase, ComputeAllFaceDescriptorsTask, ComputeSingleFaceDescriptorTask, detectSingleFace, detectAllFaces, DetectFacesTaskBase, DetectAllFacesTask, DetectSingleFaceTask, DetectFaceLandmarksTaskBase, DetectAllFaceLandmarksTask, DetectSingleFaceLandmarksTask, FaceMatcher, nets, ssdMobilenetv1, tinyFaceDetector, tinyYolov2, mtcnn, detectFaceLandmarks, detectFaceLandmarksTiny, computeFaceDescriptor, recognizeFaceExpressions, predictAgeAndGender, loadSsdMobilenetv1Model, loadTinyFaceDetectorModel, loadMtcnnModel, loadTinyYolov2Model, loadFaceLandmarkModel, loadFaceLandmarkTinyModel, loadFaceRecognitionModel, loadFaceExpressionModel, loadAgeGenderModel, loadFaceDetectionModel, locateFaces, detectLandmarks, Mtcnn, MtcnnOptions, createMtcnn, SsdMobilenetv1, SsdMobilenetv1Options, createSsdMobilenetv1, createFaceDetectionNet, FaceDetectionNet, TinyFaceDetector, TinyFaceDetectorOptions, createTinyFaceDetector, BoundingBox, Box, Dimensions, LabeledBox, ObjectDetection, Point, PredictedBox, Rect, awaitMediaLoaded, bufferToImage, createCanvas, createCanvasFromMedia, fetchImage, fetchJson, fetchNetWeights, fetchOrThrow, getContext2dOrThrow, getMediaDimensions, imageTensorToCanvas, imageToSquare, isMediaElement, isMediaLoaded, loadWeightMap, matchDimensions, NetInput, resolveInput, toNetInput, iou, minBbox, nonMaxSuppression, normalize, padToSquare, shuffleArray, sigmoid, inverseSigmoid */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"draw\", function() { return draw; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony reexport (module object) */ __webpack_require__.d(__webpack_exports__, \"tf\", function() { return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _draw__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./draw */ \"./node_modules/face-api.js/build/es6/draw/index.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"env\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"env\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isTensor\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"isTensor\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isTensor1D\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"isTensor1D\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isTensor2D\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"isTensor2D\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isTensor3D\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"isTensor3D\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isTensor4D\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"isTensor4D\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isFloat\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"isFloat\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isEven\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"isEven\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"round\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"round\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isDimensions\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"isDimensions\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"computeReshapedDimensions\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"computeReshapedDimensions\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"getCenterPoint\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"getCenterPoint\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"range\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"range\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isValidNumber\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"isValidNumber\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isValidProbablitiy\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"isValidProbablitiy\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"NeuralNetwork\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"NeuralNetwork\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TfjsImageRecognitionBase\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"TfjsImageRecognitionBase\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"BoundingBox\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"BoundingBox\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Box\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"Box\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Dimensions\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"Dimensions\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"LabeledBox\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"LabeledBox\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ObjectDetection\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"ObjectDetection\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Point\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"Point\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PredictedBox\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"PredictedBox\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Rect\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"Rect\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"awaitMediaLoaded\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"awaitMediaLoaded\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"bufferToImage\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"bufferToImage\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"createCanvas\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"createCanvas\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"createCanvasFromMedia\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"createCanvasFromMedia\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"fetchImage\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"fetchImage\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"fetchJson\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"fetchJson\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"fetchNetWeights\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"fetchNetWeights\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"fetchOrThrow\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"fetchOrThrow\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"getContext2dOrThrow\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"getContext2dOrThrow\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"getMediaDimensions\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"getMediaDimensions\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"imageTensorToCanvas\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"imageTensorToCanvas\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"imageToSquare\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"imageToSquare\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isMediaElement\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"isMediaElement\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isMediaLoaded\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"isMediaLoaded\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadWeightMap\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"loadWeightMap\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"matchDimensions\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"matchDimensions\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"NetInput\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"NetInput\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"resolveInput\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"resolveInput\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"toNetInput\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"toNetInput\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"iou\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"iou\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"minBbox\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"minBbox\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"nonMaxSuppression\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"nonMaxSuppression\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"normalize\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"normalize\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"padToSquare\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"padToSquare\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"shuffleArray\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"shuffleArray\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"sigmoid\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"sigmoid\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"inverseSigmoid\", function() { return tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"inverseSigmoid\"]; });\n\n/* harmony import */ var _ageGenderNet_index__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ageGenderNet/index */ \"./node_modules/face-api.js/build/es6/ageGenderNet/index.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AgeGenderNet\", function() { return _ageGenderNet_index__WEBPACK_IMPORTED_MODULE_4__[\"AgeGenderNet\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Gender\", function() { return _ageGenderNet_index__WEBPACK_IMPORTED_MODULE_4__[\"Gender\"]; });\n\n/* harmony import */ var _classes_index__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./classes/index */ \"./node_modules/face-api.js/build/es6/classes/index.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceDetection\", function() { return _classes_index__WEBPACK_IMPORTED_MODULE_5__[\"FaceDetection\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceLandmarks\", function() { return _classes_index__WEBPACK_IMPORTED_MODULE_5__[\"FaceLandmarks\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceLandmarks5\", function() { return _classes_index__WEBPACK_IMPORTED_MODULE_5__[\"FaceLandmarks5\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceLandmarks68\", function() { return _classes_index__WEBPACK_IMPORTED_MODULE_5__[\"FaceLandmarks68\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceMatch\", function() { return _classes_index__WEBPACK_IMPORTED_MODULE_5__[\"FaceMatch\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"LabeledFaceDescriptors\", function() { return _classes_index__WEBPACK_IMPORTED_MODULE_5__[\"LabeledFaceDescriptors\"]; });\n\n/* harmony import */ var _dom_index__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./dom/index */ \"./node_modules/face-api.js/build/es6/dom/index.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extractFaces\", function() { return _dom_index__WEBPACK_IMPORTED_MODULE_6__[\"extractFaces\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extractFaceTensors\", function() { return _dom_index__WEBPACK_IMPORTED_MODULE_6__[\"extractFaceTensors\"]; });\n\n/* harmony import */ var _faceExpressionNet_index__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./faceExpressionNet/index */ \"./node_modules/face-api.js/build/es6/faceExpressionNet/index.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceExpressionNet\", function() { return _faceExpressionNet_index__WEBPACK_IMPORTED_MODULE_7__[\"FaceExpressionNet\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FACE_EXPRESSION_LABELS\", function() { return _faceExpressionNet_index__WEBPACK_IMPORTED_MODULE_7__[\"FACE_EXPRESSION_LABELS\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceExpressions\", function() { return _faceExpressionNet_index__WEBPACK_IMPORTED_MODULE_7__[\"FaceExpressions\"]; });\n\n/* harmony import */ var _faceLandmarkNet_index__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./faceLandmarkNet/index */ \"./node_modules/face-api.js/build/es6/faceLandmarkNet/index.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceLandmark68Net\", function() { return _faceLandmarkNet_index__WEBPACK_IMPORTED_MODULE_8__[\"FaceLandmark68Net\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceLandmark68TinyNet\", function() { return _faceLandmarkNet_index__WEBPACK_IMPORTED_MODULE_8__[\"FaceLandmark68TinyNet\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceLandmarkNet\", function() { return _faceLandmarkNet_index__WEBPACK_IMPORTED_MODULE_8__[\"FaceLandmarkNet\"]; });\n\n/* harmony import */ var _faceRecognitionNet_index__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./faceRecognitionNet/index */ \"./node_modules/face-api.js/build/es6/faceRecognitionNet/index.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceRecognitionNet\", function() { return _faceRecognitionNet_index__WEBPACK_IMPORTED_MODULE_9__[\"FaceRecognitionNet\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"createFaceRecognitionNet\", function() { return _faceRecognitionNet_index__WEBPACK_IMPORTED_MODULE_9__[\"createFaceRecognitionNet\"]; });\n\n/* harmony import */ var _factories_index__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./factories/index */ \"./node_modules/face-api.js/build/es6/factories/index.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extendWithFaceDescriptor\", function() { return _factories_index__WEBPACK_IMPORTED_MODULE_10__[\"extendWithFaceDescriptor\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isWithFaceDetection\", function() { return _factories_index__WEBPACK_IMPORTED_MODULE_10__[\"isWithFaceDetection\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extendWithFaceDetection\", function() { return _factories_index__WEBPACK_IMPORTED_MODULE_10__[\"extendWithFaceDetection\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isWithFaceExpressions\", function() { return _factories_index__WEBPACK_IMPORTED_MODULE_10__[\"isWithFaceExpressions\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extendWithFaceExpressions\", function() { return _factories_index__WEBPACK_IMPORTED_MODULE_10__[\"extendWithFaceExpressions\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isWithFaceLandmarks\", function() { return _factories_index__WEBPACK_IMPORTED_MODULE_10__[\"isWithFaceLandmarks\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extendWithFaceLandmarks\", function() { return _factories_index__WEBPACK_IMPORTED_MODULE_10__[\"extendWithFaceLandmarks\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isWithAge\", function() { return _factories_index__WEBPACK_IMPORTED_MODULE_10__[\"isWithAge\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extendWithAge\", function() { return _factories_index__WEBPACK_IMPORTED_MODULE_10__[\"extendWithAge\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isWithGender\", function() { return _factories_index__WEBPACK_IMPORTED_MODULE_10__[\"isWithGender\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extendWithGender\", function() { return _factories_index__WEBPACK_IMPORTED_MODULE_10__[\"extendWithGender\"]; });\n\n/* harmony import */ var _globalApi_index__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./globalApi/index */ \"./node_modules/face-api.js/build/es6/globalApi/index.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"allFacesSsdMobilenetv1\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"allFacesSsdMobilenetv1\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"allFacesTinyYolov2\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"allFacesTinyYolov2\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"allFacesMtcnn\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"allFacesMtcnn\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"allFaces\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"allFaces\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ComposableTask\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"ComposableTask\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ComputeFaceDescriptorsTaskBase\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"ComputeFaceDescriptorsTaskBase\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ComputeAllFaceDescriptorsTask\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"ComputeAllFaceDescriptorsTask\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ComputeSingleFaceDescriptorTask\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"ComputeSingleFaceDescriptorTask\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"detectSingleFace\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"detectSingleFace\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"detectAllFaces\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"detectAllFaces\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DetectFacesTaskBase\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"DetectFacesTaskBase\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DetectAllFacesTask\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"DetectAllFacesTask\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DetectSingleFaceTask\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"DetectSingleFaceTask\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DetectFaceLandmarksTaskBase\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"DetectFaceLandmarksTaskBase\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DetectAllFaceLandmarksTask\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"DetectAllFaceLandmarksTask\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DetectSingleFaceLandmarksTask\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"DetectSingleFaceLandmarksTask\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceMatcher\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"FaceMatcher\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"nets\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"nets\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ssdMobilenetv1\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"ssdMobilenetv1\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"tinyFaceDetector\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"tinyFaceDetector\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"tinyYolov2\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"tinyYolov2\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"mtcnn\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"mtcnn\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"detectFaceLandmarks\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"detectFaceLandmarks\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"detectFaceLandmarksTiny\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"detectFaceLandmarksTiny\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"computeFaceDescriptor\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"computeFaceDescriptor\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"recognizeFaceExpressions\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"recognizeFaceExpressions\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"predictAgeAndGender\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"predictAgeAndGender\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadSsdMobilenetv1Model\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"loadSsdMobilenetv1Model\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadTinyFaceDetectorModel\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"loadTinyFaceDetectorModel\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadMtcnnModel\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"loadMtcnnModel\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadTinyYolov2Model\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"loadTinyYolov2Model\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadFaceLandmarkModel\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"loadFaceLandmarkModel\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadFaceLandmarkTinyModel\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"loadFaceLandmarkTinyModel\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadFaceRecognitionModel\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"loadFaceRecognitionModel\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadFaceExpressionModel\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"loadFaceExpressionModel\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadAgeGenderModel\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"loadAgeGenderModel\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadFaceDetectionModel\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"loadFaceDetectionModel\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"locateFaces\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"locateFaces\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"detectLandmarks\", function() { return _globalApi_index__WEBPACK_IMPORTED_MODULE_11__[\"detectLandmarks\"]; });\n\n/* harmony import */ var _mtcnn_index__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./mtcnn/index */ \"./node_modules/face-api.js/build/es6/mtcnn/index.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Mtcnn\", function() { return _mtcnn_index__WEBPACK_IMPORTED_MODULE_12__[\"Mtcnn\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"MtcnnOptions\", function() { return _mtcnn_index__WEBPACK_IMPORTED_MODULE_12__[\"MtcnnOptions\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"createMtcnn\", function() { return _mtcnn_index__WEBPACK_IMPORTED_MODULE_12__[\"createMtcnn\"]; });\n\n/* harmony import */ var _ssdMobilenetv1_index__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./ssdMobilenetv1/index */ \"./node_modules/face-api.js/build/es6/ssdMobilenetv1/index.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SsdMobilenetv1\", function() { return _ssdMobilenetv1_index__WEBPACK_IMPORTED_MODULE_13__[\"SsdMobilenetv1\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SsdMobilenetv1Options\", function() { return _ssdMobilenetv1_index__WEBPACK_IMPORTED_MODULE_13__[\"SsdMobilenetv1Options\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"createSsdMobilenetv1\", function() { return _ssdMobilenetv1_index__WEBPACK_IMPORTED_MODULE_13__[\"createSsdMobilenetv1\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"createFaceDetectionNet\", function() { return _ssdMobilenetv1_index__WEBPACK_IMPORTED_MODULE_13__[\"createFaceDetectionNet\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"FaceDetectionNet\", function() { return _ssdMobilenetv1_index__WEBPACK_IMPORTED_MODULE_13__[\"FaceDetectionNet\"]; });\n\n/* harmony import */ var _tinyFaceDetector_index__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./tinyFaceDetector/index */ \"./node_modules/face-api.js/build/es6/tinyFaceDetector/index.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TinyFaceDetector\", function() { return _tinyFaceDetector_index__WEBPACK_IMPORTED_MODULE_14__[\"TinyFaceDetector\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TinyFaceDetectorOptions\", function() { return _tinyFaceDetector_index__WEBPACK_IMPORTED_MODULE_14__[\"TinyFaceDetectorOptions\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"createTinyFaceDetector\", function() { return _tinyFaceDetector_index__WEBPACK_IMPORTED_MODULE_14__[\"createTinyFaceDetector\"]; });\n\n/* harmony import */ var _tinyYolov2_index__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./tinyYolov2/index */ \"./node_modules/face-api.js/build/es6/tinyYolov2/index.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TinyYolov2\", function() { return _tinyYolov2_index__WEBPACK_IMPORTED_MODULE_15__[\"TinyYolov2\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"createTinyYolov2\", function() { return _tinyYolov2_index__WEBPACK_IMPORTED_MODULE_15__[\"createTinyYolov2\"]; });\n\n/* harmony import */ var _euclideanDistance__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./euclideanDistance */ \"./node_modules/face-api.js/build/es6/euclideanDistance.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"euclideanDistance\", function() { return _euclideanDistance__WEBPACK_IMPORTED_MODULE_16__[\"euclideanDistance\"]; });\n\n/* harmony import */ var _resizeResults__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./resizeResults */ \"./node_modules/face-api.js/build/es6/resizeResults.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"resizeResults\", function() { return _resizeResults__WEBPACK_IMPORTED_MODULE_17__[\"resizeResults\"]; });\n\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nvar draw = Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__assign\"])(Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__assign\"])({}, tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"draw\"]), _draw__WEBPACK_IMPORTED_MODULE_3__);\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/minBbox.js":
/*!*******************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/minBbox.js ***!
  \*******************************************************/
/*! exports provided: minBbox */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"minBbox\", function() { return minBbox; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n\r\nfunction minBbox(pts) {\r\n    var xs = pts.map(function (pt) { return pt.x; });\r\n    var ys = pts.map(function (pt) { return pt.y; });\r\n    var minX = xs.reduce(function (min, x) { return x < min ? x : min; }, Infinity);\r\n    var minY = ys.reduce(function (min, y) { return y < min ? y : min; }, Infinity);\r\n    var maxX = xs.reduce(function (max, x) { return max < x ? x : max; }, 0);\r\n    var maxY = ys.reduce(function (max, y) { return max < y ? y : max; }, 0);\r\n    return new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"BoundingBox\"](minX, minY, maxX, maxY);\r\n}\r\n//# sourceMappingURL=minBbox.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/minBbox.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/mtcnn/Mtcnn.js":
/*!***********************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/mtcnn/Mtcnn.js ***!
  \***********************************************************/
/*! exports provided: Mtcnn */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Mtcnn\", function() { return Mtcnn; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _classes_FaceDetection__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../classes/FaceDetection */ \"./node_modules/face-api.js/build/es6/classes/FaceDetection.js\");\n/* harmony import */ var _classes_FaceLandmarks5__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../classes/FaceLandmarks5 */ \"./node_modules/face-api.js/build/es6/classes/FaceLandmarks5.js\");\n/* harmony import */ var _factories__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../factories */ \"./node_modules/face-api.js/build/es6/factories/index.js\");\n/* harmony import */ var _bgrToRgbTensor__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./bgrToRgbTensor */ \"./node_modules/face-api.js/build/es6/mtcnn/bgrToRgbTensor.js\");\n/* harmony import */ var _config__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./config */ \"./node_modules/face-api.js/build/es6/mtcnn/config.js\");\n/* harmony import */ var _extractParams__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./extractParams */ \"./node_modules/face-api.js/build/es6/mtcnn/extractParams.js\");\n/* harmony import */ var _extractParamsFromWeigthMap__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./extractParamsFromWeigthMap */ \"./node_modules/face-api.js/build/es6/mtcnn/extractParamsFromWeigthMap.js\");\n/* harmony import */ var _getSizesForScale__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./getSizesForScale */ \"./node_modules/face-api.js/build/es6/mtcnn/getSizesForScale.js\");\n/* harmony import */ var _MtcnnOptions__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./MtcnnOptions */ \"./node_modules/face-api.js/build/es6/mtcnn/MtcnnOptions.js\");\n/* harmony import */ var _pyramidDown__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./pyramidDown */ \"./node_modules/face-api.js/build/es6/mtcnn/pyramidDown.js\");\n/* harmony import */ var _stage1__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./stage1 */ \"./node_modules/face-api.js/build/es6/mtcnn/stage1.js\");\n/* harmony import */ var _stage2__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./stage2 */ \"./node_modules/face-api.js/build/es6/mtcnn/stage2.js\");\n/* harmony import */ var _stage3__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./stage3 */ \"./node_modules/face-api.js/build/es6/mtcnn/stage3.js\");\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nvar Mtcnn = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(Mtcnn, _super);\r\n    function Mtcnn() {\r\n        return _super.call(this, 'Mtcnn') || this;\r\n    }\r\n    Mtcnn.prototype.forwardInput = function (input, forwardParams) {\r\n        if (forwardParams === void 0) { forwardParams = {}; }\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var params, inputCanvas, stats, tsTotal, imgTensor, onReturn, _a, height, width, _b, minFaceSize, scaleFactor, maxNumScales, scoreThresholds, scaleSteps, scales, ts, out1, out2, out3, results;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_c) {\r\n                switch (_c.label) {\r\n                    case 0:\r\n                        params = this.params;\r\n                        if (!params) {\r\n                            throw new Error('Mtcnn - load model before inference');\r\n                        }\r\n                        inputCanvas = input.canvases[0];\r\n                        if (!inputCanvas) {\r\n                            throw new Error('Mtcnn - inputCanvas is not defined, note that passing tensors into Mtcnn.forwardInput is not supported yet.');\r\n                        }\r\n                        stats = {};\r\n                        tsTotal = Date.now();\r\n                        imgTensor = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tidy\"](function () {\r\n                            return Object(_bgrToRgbTensor__WEBPACK_IMPORTED_MODULE_6__[\"bgrToRgbTensor\"])(_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"expandDims\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"browser\"].fromPixels(inputCanvas)).toFloat());\r\n                        });\r\n                        onReturn = function (results) {\r\n                            // dispose tensors on return\r\n                            imgTensor.dispose();\r\n                            stats.total = Date.now() - tsTotal;\r\n                            return results;\r\n                        };\r\n                        _a = imgTensor.shape.slice(1), height = _a[0], width = _a[1];\r\n                        _b = new _MtcnnOptions__WEBPACK_IMPORTED_MODULE_11__[\"MtcnnOptions\"](forwardParams), minFaceSize = _b.minFaceSize, scaleFactor = _b.scaleFactor, maxNumScales = _b.maxNumScales, scoreThresholds = _b.scoreThresholds, scaleSteps = _b.scaleSteps;\r\n                        scales = (scaleSteps || Object(_pyramidDown__WEBPACK_IMPORTED_MODULE_12__[\"pyramidDown\"])(minFaceSize, scaleFactor, [height, width]))\r\n                            .filter(function (scale) {\r\n                            var sizes = Object(_getSizesForScale__WEBPACK_IMPORTED_MODULE_10__[\"getSizesForScale\"])(scale, [height, width]);\r\n                            return Math.min(sizes.width, sizes.height) > _config__WEBPACK_IMPORTED_MODULE_7__[\"CELL_SIZE\"];\r\n                        })\r\n                            .slice(0, maxNumScales);\r\n                        stats.scales = scales;\r\n                        stats.pyramid = scales.map(function (scale) { return Object(_getSizesForScale__WEBPACK_IMPORTED_MODULE_10__[\"getSizesForScale\"])(scale, [height, width]); });\r\n                        ts = Date.now();\r\n                        return [4 /*yield*/, Object(_stage1__WEBPACK_IMPORTED_MODULE_13__[\"stage1\"])(imgTensor, scales, scoreThresholds[0], params.pnet, stats)];\r\n                    case 1:\r\n                        out1 = _c.sent();\r\n                        stats.total_stage1 = Date.now() - ts;\r\n                        if (!out1.boxes.length) {\r\n                            return [2 /*return*/, onReturn({ results: [], stats: stats })];\r\n                        }\r\n                        stats.stage2_numInputBoxes = out1.boxes.length;\r\n                        // using the inputCanvas to extract and resize the image patches, since it is faster\r\n                        // than doing this on the gpu\r\n                        ts = Date.now();\r\n                        return [4 /*yield*/, Object(_stage2__WEBPACK_IMPORTED_MODULE_14__[\"stage2\"])(inputCanvas, out1.boxes, scoreThresholds[1], params.rnet, stats)];\r\n                    case 2:\r\n                        out2 = _c.sent();\r\n                        stats.total_stage2 = Date.now() - ts;\r\n                        if (!out2.boxes.length) {\r\n                            return [2 /*return*/, onReturn({ results: [], stats: stats })];\r\n                        }\r\n                        stats.stage3_numInputBoxes = out2.boxes.length;\r\n                        ts = Date.now();\r\n                        return [4 /*yield*/, Object(_stage3__WEBPACK_IMPORTED_MODULE_15__[\"stage3\"])(inputCanvas, out2.boxes, scoreThresholds[2], params.onet, stats)];\r\n                    case 3:\r\n                        out3 = _c.sent();\r\n                        stats.total_stage3 = Date.now() - ts;\r\n                        results = out3.boxes.map(function (box, idx) { return Object(_factories__WEBPACK_IMPORTED_MODULE_5__[\"extendWithFaceLandmarks\"])(Object(_factories__WEBPACK_IMPORTED_MODULE_5__[\"extendWithFaceDetection\"])({}, new _classes_FaceDetection__WEBPACK_IMPORTED_MODULE_3__[\"FaceDetection\"](out3.scores[idx], new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"Rect\"](box.left / width, box.top / height, box.width / width, box.height / height), {\r\n                            height: height,\r\n                            width: width\r\n                        })), new _classes_FaceLandmarks5__WEBPACK_IMPORTED_MODULE_4__[\"FaceLandmarks5\"](out3.points[idx].map(function (pt) { return pt.sub(new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"Point\"](box.left, box.top)).div(new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"Point\"](box.width, box.height)); }), { width: box.width, height: box.height })); });\r\n                        return [2 /*return*/, onReturn({ results: results, stats: stats })];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    Mtcnn.prototype.forward = function (input, forwardParams) {\r\n        if (forwardParams === void 0) { forwardParams = {}; }\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var _a;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this.forwardInput;\r\n                        return [4 /*yield*/, Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"toNetInput\"])(input)];\r\n                    case 1: return [4 /*yield*/, _a.apply(this, [_b.sent(),\r\n                            forwardParams])];\r\n                    case 2: return [2 /*return*/, (_b.sent()).results];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    Mtcnn.prototype.forwardWithStats = function (input, forwardParams) {\r\n        if (forwardParams === void 0) { forwardParams = {}; }\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var _a;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this.forwardInput;\r\n                        return [4 /*yield*/, Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"toNetInput\"])(input)];\r\n                    case 1: return [2 /*return*/, _a.apply(this, [_b.sent(),\r\n                            forwardParams])];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    Mtcnn.prototype.getDefaultModelName = function () {\r\n        return 'mtcnn_model';\r\n    };\r\n    Mtcnn.prototype.extractParamsFromWeigthMap = function (weightMap) {\r\n        return Object(_extractParamsFromWeigthMap__WEBPACK_IMPORTED_MODULE_9__[\"extractParamsFromWeigthMap\"])(weightMap);\r\n    };\r\n    Mtcnn.prototype.extractParams = function (weights) {\r\n        return Object(_extractParams__WEBPACK_IMPORTED_MODULE_8__[\"extractParams\"])(weights);\r\n    };\r\n    return Mtcnn;\r\n}(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"NeuralNetwork\"]));\r\n\r\n//# sourceMappingURL=Mtcnn.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/mtcnn/Mtcnn.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/mtcnn/MtcnnBox.js":
/*!**************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/mtcnn/MtcnnBox.js ***!
  \**************************************************************/
/*! exports provided: MtcnnBox */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"MtcnnBox\", function() { return MtcnnBox; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n\r\n\r\nvar MtcnnBox = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(MtcnnBox, _super);\r\n    function MtcnnBox(left, top, right, bottom) {\r\n        return _super.call(this, { left: left, top: top, right: right, bottom: bottom }, true) || this;\r\n    }\r\n    return MtcnnBox;\r\n}(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"Box\"]));\r\n\r\n//# sourceMappingURL=MtcnnBox.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/mtcnn/MtcnnBox.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/mtcnn/MtcnnOptions.js":
/*!******************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/mtcnn/MtcnnOptions.js ***!
  \******************************************************************/
/*! exports provided: MtcnnOptions */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"MtcnnOptions\", function() { return MtcnnOptions; });\nvar MtcnnOptions = /** @class */ (function () {\r\n    function MtcnnOptions(_a) {\r\n        var _b = _a === void 0 ? {} : _a, minFaceSize = _b.minFaceSize, scaleFactor = _b.scaleFactor, maxNumScales = _b.maxNumScales, scoreThresholds = _b.scoreThresholds, scaleSteps = _b.scaleSteps;\r\n        this._name = 'MtcnnOptions';\r\n        this._minFaceSize = minFaceSize || 20;\r\n        this._scaleFactor = scaleFactor || 0.709;\r\n        this._maxNumScales = maxNumScales || 10;\r\n        this._scoreThresholds = scoreThresholds || [0.6, 0.7, 0.7];\r\n        this._scaleSteps = scaleSteps;\r\n        if (typeof this._minFaceSize !== 'number' || this._minFaceSize < 0) {\r\n            throw new Error(this._name + \" - expected minFaceSize to be a number > 0\");\r\n        }\r\n        if (typeof this._scaleFactor !== 'number' || this._scaleFactor <= 0 || this._scaleFactor >= 1) {\r\n            throw new Error(this._name + \" - expected scaleFactor to be a number between 0 and 1\");\r\n        }\r\n        if (typeof this._maxNumScales !== 'number' || this._maxNumScales < 0) {\r\n            throw new Error(this._name + \" - expected maxNumScales to be a number > 0\");\r\n        }\r\n        if (!Array.isArray(this._scoreThresholds)\r\n            || this._scoreThresholds.length !== 3\r\n            || this._scoreThresholds.some(function (th) { return typeof th !== 'number'; })) {\r\n            throw new Error(this._name + \" - expected scoreThresholds to be an array of numbers of length 3\");\r\n        }\r\n        if (this._scaleSteps\r\n            && (!Array.isArray(this._scaleSteps) || this._scaleSteps.some(function (th) { return typeof th !== 'number'; }))) {\r\n            throw new Error(this._name + \" - expected scaleSteps to be an array of numbers\");\r\n        }\r\n    }\r\n    Object.defineProperty(MtcnnOptions.prototype, \"minFaceSize\", {\r\n        get: function () { return this._minFaceSize; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(MtcnnOptions.prototype, \"scaleFactor\", {\r\n        get: function () { return this._scaleFactor; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(MtcnnOptions.prototype, \"maxNumScales\", {\r\n        get: function () { return this._maxNumScales; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(MtcnnOptions.prototype, \"scoreThresholds\", {\r\n        get: function () { return this._scoreThresholds; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(MtcnnOptions.prototype, \"scaleSteps\", {\r\n        get: function () { return this._scaleSteps; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    return MtcnnOptions;\r\n}());\r\n\r\n//# sourceMappingURL=MtcnnOptions.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/mtcnn/MtcnnOptions.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/mtcnn/ONet.js":
/*!**********************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/mtcnn/ONet.js ***!
  \**********************************************************/
/*! exports provided: ONet */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ONet\", function() { return ONet; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _common_fullyConnectedLayer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/fullyConnectedLayer */ \"./node_modules/face-api.js/build/es6/common/fullyConnectedLayer.js\");\n/* harmony import */ var _prelu__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./prelu */ \"./node_modules/face-api.js/build/es6/mtcnn/prelu.js\");\n/* harmony import */ var _sharedLayers__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./sharedLayers */ \"./node_modules/face-api.js/build/es6/mtcnn/sharedLayers.js\");\n\r\n\r\n\r\n\r\n\r\nfunction ONet(x, params) {\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () {\r\n        var out = Object(_sharedLayers__WEBPACK_IMPORTED_MODULE_4__[\"sharedLayer\"])(x, params);\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"maxPool\"](out, [2, 2], [2, 2], 'same');\r\n        out = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"TfjsImageRecognitionBase\"].convLayer(out, params.conv4, 'valid');\r\n        out = Object(_prelu__WEBPACK_IMPORTED_MODULE_3__[\"prelu\"])(out, params.prelu4_alpha);\r\n        var vectorized = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"reshape\"](out, [out.shape[0], params.fc1.weights.shape[0]]);\r\n        var fc1 = Object(_common_fullyConnectedLayer__WEBPACK_IMPORTED_MODULE_2__[\"fullyConnectedLayer\"])(vectorized, params.fc1);\r\n        var prelu5 = Object(_prelu__WEBPACK_IMPORTED_MODULE_3__[\"prelu\"])(fc1, params.prelu5_alpha);\r\n        var fc2_1 = Object(_common_fullyConnectedLayer__WEBPACK_IMPORTED_MODULE_2__[\"fullyConnectedLayer\"])(prelu5, params.fc2_1);\r\n        var max = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"expandDims\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"max\"](fc2_1, 1), 1);\r\n        var prob = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"softmax\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"sub\"](fc2_1, max), 1);\r\n        var regions = Object(_common_fullyConnectedLayer__WEBPACK_IMPORTED_MODULE_2__[\"fullyConnectedLayer\"])(prelu5, params.fc2_2);\r\n        var points = Object(_common_fullyConnectedLayer__WEBPACK_IMPORTED_MODULE_2__[\"fullyConnectedLayer\"])(prelu5, params.fc2_3);\r\n        var scores = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"unstack\"](prob, 1)[1];\r\n        return { scores: scores, regions: regions, points: points };\r\n    });\r\n}\r\n//# sourceMappingURL=ONet.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/mtcnn/ONet.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/mtcnn/PNet.js":
/*!**********************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/mtcnn/PNet.js ***!
  \**********************************************************/
/*! exports provided: PNet */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PNet\", function() { return PNet; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _sharedLayers__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./sharedLayers */ \"./node_modules/face-api.js/build/es6/mtcnn/sharedLayers.js\");\n\r\n\r\n\r\nfunction PNet(x, params) {\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () {\r\n        var out = Object(_sharedLayers__WEBPACK_IMPORTED_MODULE_2__[\"sharedLayer\"])(x, params, true);\r\n        var conv = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"TfjsImageRecognitionBase\"].convLayer(out, params.conv4_1, 'valid');\r\n        var max = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"expandDims\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"max\"](conv, 3), 3);\r\n        var prob = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"softmax\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"sub\"](conv, max), 3);\r\n        var regions = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"TfjsImageRecognitionBase\"].convLayer(out, params.conv4_2, 'valid');\r\n        return { prob: prob, regions: regions };\r\n    });\r\n}\r\n//# sourceMappingURL=PNet.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/mtcnn/PNet.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/mtcnn/RNet.js":
/*!**********************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/mtcnn/RNet.js ***!
  \**********************************************************/
/*! exports provided: RNet */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"RNet\", function() { return RNet; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var _common_fullyConnectedLayer__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/fullyConnectedLayer */ \"./node_modules/face-api.js/build/es6/common/fullyConnectedLayer.js\");\n/* harmony import */ var _prelu__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./prelu */ \"./node_modules/face-api.js/build/es6/mtcnn/prelu.js\");\n/* harmony import */ var _sharedLayers__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./sharedLayers */ \"./node_modules/face-api.js/build/es6/mtcnn/sharedLayers.js\");\n\r\n\r\n\r\n\r\nfunction RNet(x, params) {\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () {\r\n        var convOut = Object(_sharedLayers__WEBPACK_IMPORTED_MODULE_3__[\"sharedLayer\"])(x, params);\r\n        var vectorized = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"reshape\"](convOut, [convOut.shape[0], params.fc1.weights.shape[0]]);\r\n        var fc1 = Object(_common_fullyConnectedLayer__WEBPACK_IMPORTED_MODULE_1__[\"fullyConnectedLayer\"])(vectorized, params.fc1);\r\n        var prelu4 = Object(_prelu__WEBPACK_IMPORTED_MODULE_2__[\"prelu\"])(fc1, params.prelu4_alpha);\r\n        var fc2_1 = Object(_common_fullyConnectedLayer__WEBPACK_IMPORTED_MODULE_1__[\"fullyConnectedLayer\"])(prelu4, params.fc2_1);\r\n        var max = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"expandDims\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"max\"](fc2_1, 1), 1);\r\n        var prob = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"softmax\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"sub\"](fc2_1, max), 1);\r\n        var regions = Object(_common_fullyConnectedLayer__WEBPACK_IMPORTED_MODULE_1__[\"fullyConnectedLayer\"])(prelu4, params.fc2_2);\r\n        var scores = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"unstack\"](prob, 1)[1];\r\n        return { scores: scores, regions: regions };\r\n    });\r\n}\r\n//# sourceMappingURL=RNet.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/mtcnn/RNet.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/mtcnn/bgrToRgbTensor.js":
/*!********************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/mtcnn/bgrToRgbTensor.js ***!
  \********************************************************************/
/*! exports provided: bgrToRgbTensor */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"bgrToRgbTensor\", function() { return bgrToRgbTensor; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n\r\nfunction bgrToRgbTensor(tensor) {\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () { return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"stack\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"unstack\"](tensor, 3).reverse(), 3); });\r\n}\r\n//# sourceMappingURL=bgrToRgbTensor.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/mtcnn/bgrToRgbTensor.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/mtcnn/config.js":
/*!************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/mtcnn/config.js ***!
  \************************************************************/
/*! exports provided: CELL_STRIDE, CELL_SIZE */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"CELL_STRIDE\", function() { return CELL_STRIDE; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"CELL_SIZE\", function() { return CELL_SIZE; });\nvar CELL_STRIDE = 2;\r\nvar CELL_SIZE = 12;\r\n//# sourceMappingURL=config.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/mtcnn/config.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/mtcnn/extractImagePatches.js":
/*!*************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/mtcnn/extractImagePatches.js ***!
  \*************************************************************************/
/*! exports provided: extractImagePatches */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractImagePatches\", function() { return extractImagePatches; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _normalize__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./normalize */ \"./node_modules/face-api.js/build/es6/mtcnn/normalize.js\");\n\r\n\r\n\r\n\r\nfunction extractImagePatches(img, boxes, _a) {\r\n    var width = _a.width, height = _a.height;\r\n    return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n        var imgCtx, bitmaps, imagePatchesDatas;\r\n        var _this = this;\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n            switch (_b.label) {\r\n                case 0:\r\n                    imgCtx = Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"getContext2dOrThrow\"])(img);\r\n                    return [4 /*yield*/, Promise.all(boxes.map(function (box) { return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(_this, void 0, void 0, function () {\r\n                            var _a, y, ey, x, ex, fromX, fromY, imgData;\r\n                            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n                                _a = box.padAtBorders(img.height, img.width), y = _a.y, ey = _a.ey, x = _a.x, ex = _a.ex;\r\n                                fromX = x - 1;\r\n                                fromY = y - 1;\r\n                                imgData = imgCtx.getImageData(fromX, fromY, (ex - fromX), (ey - fromY));\r\n                                return [2 /*return*/, tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"env\"].isNodejs() ? Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"createCanvasFromMedia\"])(imgData) : createImageBitmap(imgData)];\r\n                            });\r\n                        }); }))];\r\n                case 1:\r\n                    bitmaps = _b.sent();\r\n                    imagePatchesDatas = [];\r\n                    bitmaps.forEach(function (bmp) {\r\n                        var patch = Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"createCanvas\"])({ width: width, height: height });\r\n                        var patchCtx = Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"getContext2dOrThrow\"])(patch);\r\n                        patchCtx.drawImage(bmp, 0, 0, width, height);\r\n                        var data = patchCtx.getImageData(0, 0, width, height).data;\r\n                        var currData = [];\r\n                        // RGBA -> BGR\r\n                        for (var i = 0; i < data.length; i += 4) {\r\n                            currData.push(data[i + 2]);\r\n                            currData.push(data[i + 1]);\r\n                            currData.push(data[i]);\r\n                        }\r\n                        imagePatchesDatas.push(currData);\r\n                    });\r\n                    return [2 /*return*/, imagePatchesDatas.map(function (data) {\r\n                            var t = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tidy\"](function () {\r\n                                var imagePatchTensor = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"transpose\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tensor4d\"](data, [1, width, height, 3]), [0, 2, 1, 3]).toFloat();\r\n                                return Object(_normalize__WEBPACK_IMPORTED_MODULE_3__[\"normalize\"])(imagePatchTensor);\r\n                            });\r\n                            return t;\r\n                        })];\r\n            }\r\n        });\r\n    });\r\n}\r\n//# sourceMappingURL=extractImagePatches.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/mtcnn/extractImagePatches.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/mtcnn/extractParams.js":
/*!*******************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/mtcnn/extractParams.js ***!
  \*******************************************************************/
/*! exports provided: extractParams */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractParams\", function() { return extractParams; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n\r\n\r\n\r\nfunction extractorsFactory(extractWeights, paramMappings) {\r\n    var extractConvParams = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"TfjsImageRecognitionBase\"].extractConvParamsFactory(extractWeights, paramMappings);\r\n    var extractFCParams = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"TfjsImageRecognitionBase\"].extractFCParamsFactory(extractWeights, paramMappings);\r\n    function extractPReluParams(size, paramPath) {\r\n        var alpha = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tensor1d\"](extractWeights(size));\r\n        paramMappings.push({ paramPath: paramPath });\r\n        return alpha;\r\n    }\r\n    function extractSharedParams(numFilters, mappedPrefix, isRnet) {\r\n        if (isRnet === void 0) { isRnet = false; }\r\n        var conv1 = extractConvParams(numFilters[0], numFilters[1], 3, mappedPrefix + \"/conv1\");\r\n        var prelu1_alpha = extractPReluParams(numFilters[1], mappedPrefix + \"/prelu1_alpha\");\r\n        var conv2 = extractConvParams(numFilters[1], numFilters[2], 3, mappedPrefix + \"/conv2\");\r\n        var prelu2_alpha = extractPReluParams(numFilters[2], mappedPrefix + \"/prelu2_alpha\");\r\n        var conv3 = extractConvParams(numFilters[2], numFilters[3], isRnet ? 2 : 3, mappedPrefix + \"/conv3\");\r\n        var prelu3_alpha = extractPReluParams(numFilters[3], mappedPrefix + \"/prelu3_alpha\");\r\n        return { conv1: conv1, prelu1_alpha: prelu1_alpha, conv2: conv2, prelu2_alpha: prelu2_alpha, conv3: conv3, prelu3_alpha: prelu3_alpha };\r\n    }\r\n    function extractPNetParams() {\r\n        var sharedParams = extractSharedParams([3, 10, 16, 32], 'pnet');\r\n        var conv4_1 = extractConvParams(32, 2, 1, 'pnet/conv4_1');\r\n        var conv4_2 = extractConvParams(32, 4, 1, 'pnet/conv4_2');\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__assign\"])(Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__assign\"])({}, sharedParams), { conv4_1: conv4_1, conv4_2: conv4_2 });\r\n    }\r\n    function extractRNetParams() {\r\n        var sharedParams = extractSharedParams([3, 28, 48, 64], 'rnet', true);\r\n        var fc1 = extractFCParams(576, 128, 'rnet/fc1');\r\n        var prelu4_alpha = extractPReluParams(128, 'rnet/prelu4_alpha');\r\n        var fc2_1 = extractFCParams(128, 2, 'rnet/fc2_1');\r\n        var fc2_2 = extractFCParams(128, 4, 'rnet/fc2_2');\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__assign\"])(Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__assign\"])({}, sharedParams), { fc1: fc1, prelu4_alpha: prelu4_alpha, fc2_1: fc2_1, fc2_2: fc2_2 });\r\n    }\r\n    function extractONetParams() {\r\n        var sharedParams = extractSharedParams([3, 32, 64, 64], 'onet');\r\n        var conv4 = extractConvParams(64, 128, 2, 'onet/conv4');\r\n        var prelu4_alpha = extractPReluParams(128, 'onet/prelu4_alpha');\r\n        var fc1 = extractFCParams(1152, 256, 'onet/fc1');\r\n        var prelu5_alpha = extractPReluParams(256, 'onet/prelu5_alpha');\r\n        var fc2_1 = extractFCParams(256, 2, 'onet/fc2_1');\r\n        var fc2_2 = extractFCParams(256, 4, 'onet/fc2_2');\r\n        var fc2_3 = extractFCParams(256, 10, 'onet/fc2_3');\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__assign\"])(Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__assign\"])({}, sharedParams), { conv4: conv4, prelu4_alpha: prelu4_alpha, fc1: fc1, prelu5_alpha: prelu5_alpha, fc2_1: fc2_1, fc2_2: fc2_2, fc2_3: fc2_3 });\r\n    }\r\n    return {\r\n        extractPNetParams: extractPNetParams,\r\n        extractRNetParams: extractRNetParams,\r\n        extractONetParams: extractONetParams\r\n    };\r\n}\r\nfunction extractParams(weights) {\r\n    var _a = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"TfjsImageRecognitionBase\"].extractWeightsFactory(weights), extractWeights = _a.extractWeights, getRemainingWeights = _a.getRemainingWeights;\r\n    var paramMappings = [];\r\n    var _b = extractorsFactory(extractWeights, paramMappings), extractPNetParams = _b.extractPNetParams, extractRNetParams = _b.extractRNetParams, extractONetParams = _b.extractONetParams;\r\n    var pnet = extractPNetParams();\r\n    var rnet = extractRNetParams();\r\n    var onet = extractONetParams();\r\n    if (getRemainingWeights().length !== 0) {\r\n        throw new Error(\"weights remaing after extract: \" + getRemainingWeights().length);\r\n    }\r\n    return { params: { pnet: pnet, rnet: rnet, onet: onet }, paramMappings: paramMappings };\r\n}\r\n//# sourceMappingURL=extractParams.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/mtcnn/extractParams.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/mtcnn/extractParamsFromWeigthMap.js":
/*!********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/mtcnn/extractParamsFromWeigthMap.js ***!
  \********************************************************************************/
/*! exports provided: extractParamsFromWeigthMap */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractParamsFromWeigthMap\", function() { return extractParamsFromWeigthMap; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n\r\n\r\nfunction extractorsFactory(weightMap, paramMappings) {\r\n    var extractWeightEntry = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"TfjsImageRecognitionBase\"].extractWeightEntryFactory(weightMap, paramMappings);\r\n    function extractConvParams(prefix) {\r\n        var filters = extractWeightEntry(prefix + \"/weights\", 4, prefix + \"/filters\");\r\n        var bias = extractWeightEntry(prefix + \"/bias\", 1);\r\n        return { filters: filters, bias: bias };\r\n    }\r\n    function extractFCParams(prefix) {\r\n        var weights = extractWeightEntry(prefix + \"/weights\", 2);\r\n        var bias = extractWeightEntry(prefix + \"/bias\", 1);\r\n        return { weights: weights, bias: bias };\r\n    }\r\n    function extractPReluParams(paramPath) {\r\n        return extractWeightEntry(paramPath, 1);\r\n    }\r\n    function extractSharedParams(prefix) {\r\n        var conv1 = extractConvParams(prefix + \"/conv1\");\r\n        var prelu1_alpha = extractPReluParams(prefix + \"/prelu1_alpha\");\r\n        var conv2 = extractConvParams(prefix + \"/conv2\");\r\n        var prelu2_alpha = extractPReluParams(prefix + \"/prelu2_alpha\");\r\n        var conv3 = extractConvParams(prefix + \"/conv3\");\r\n        var prelu3_alpha = extractPReluParams(prefix + \"/prelu3_alpha\");\r\n        return { conv1: conv1, prelu1_alpha: prelu1_alpha, conv2: conv2, prelu2_alpha: prelu2_alpha, conv3: conv3, prelu3_alpha: prelu3_alpha };\r\n    }\r\n    function extractPNetParams() {\r\n        var sharedParams = extractSharedParams('pnet');\r\n        var conv4_1 = extractConvParams('pnet/conv4_1');\r\n        var conv4_2 = extractConvParams('pnet/conv4_2');\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__assign\"])(Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__assign\"])({}, sharedParams), { conv4_1: conv4_1, conv4_2: conv4_2 });\r\n    }\r\n    function extractRNetParams() {\r\n        var sharedParams = extractSharedParams('rnet');\r\n        var fc1 = extractFCParams('rnet/fc1');\r\n        var prelu4_alpha = extractPReluParams('rnet/prelu4_alpha');\r\n        var fc2_1 = extractFCParams('rnet/fc2_1');\r\n        var fc2_2 = extractFCParams('rnet/fc2_2');\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__assign\"])(Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__assign\"])({}, sharedParams), { fc1: fc1, prelu4_alpha: prelu4_alpha, fc2_1: fc2_1, fc2_2: fc2_2 });\r\n    }\r\n    function extractONetParams() {\r\n        var sharedParams = extractSharedParams('onet');\r\n        var conv4 = extractConvParams('onet/conv4');\r\n        var prelu4_alpha = extractPReluParams('onet/prelu4_alpha');\r\n        var fc1 = extractFCParams('onet/fc1');\r\n        var prelu5_alpha = extractPReluParams('onet/prelu5_alpha');\r\n        var fc2_1 = extractFCParams('onet/fc2_1');\r\n        var fc2_2 = extractFCParams('onet/fc2_2');\r\n        var fc2_3 = extractFCParams('onet/fc2_3');\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__assign\"])(Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__assign\"])({}, sharedParams), { conv4: conv4, prelu4_alpha: prelu4_alpha, fc1: fc1, prelu5_alpha: prelu5_alpha, fc2_1: fc2_1, fc2_2: fc2_2, fc2_3: fc2_3 });\r\n    }\r\n    return {\r\n        extractPNetParams: extractPNetParams,\r\n        extractRNetParams: extractRNetParams,\r\n        extractONetParams: extractONetParams\r\n    };\r\n}\r\nfunction extractParamsFromWeigthMap(weightMap) {\r\n    var paramMappings = [];\r\n    var _a = extractorsFactory(weightMap, paramMappings), extractPNetParams = _a.extractPNetParams, extractRNetParams = _a.extractRNetParams, extractONetParams = _a.extractONetParams;\r\n    var pnet = extractPNetParams();\r\n    var rnet = extractRNetParams();\r\n    var onet = extractONetParams();\r\n    tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"TfjsImageRecognitionBase\"].disposeUnusedWeightTensors(weightMap, paramMappings);\r\n    return { params: { pnet: pnet, rnet: rnet, onet: onet }, paramMappings: paramMappings };\r\n}\r\n//# sourceMappingURL=extractParamsFromWeigthMap.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/mtcnn/extractParamsFromWeigthMap.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/mtcnn/getSizesForScale.js":
/*!**********************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/mtcnn/getSizesForScale.js ***!
  \**********************************************************************/
/*! exports provided: getSizesForScale */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getSizesForScale\", function() { return getSizesForScale; });\nfunction getSizesForScale(scale, _a) {\r\n    var height = _a[0], width = _a[1];\r\n    return {\r\n        height: Math.floor(height * scale),\r\n        width: Math.floor(width * scale)\r\n    };\r\n}\r\n//# sourceMappingURL=getSizesForScale.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/mtcnn/getSizesForScale.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/mtcnn/index.js":
/*!***********************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/mtcnn/index.js ***!
  \***********************************************************/
/*! exports provided: Mtcnn, MtcnnOptions, createMtcnn */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"createMtcnn\", function() { return createMtcnn; });\n/* harmony import */ var _Mtcnn__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Mtcnn */ \"./node_modules/face-api.js/build/es6/mtcnn/Mtcnn.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Mtcnn\", function() { return _Mtcnn__WEBPACK_IMPORTED_MODULE_0__[\"Mtcnn\"]; });\n\n/* harmony import */ var _MtcnnOptions__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./MtcnnOptions */ \"./node_modules/face-api.js/build/es6/mtcnn/MtcnnOptions.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"MtcnnOptions\", function() { return _MtcnnOptions__WEBPACK_IMPORTED_MODULE_1__[\"MtcnnOptions\"]; });\n\n\r\n\r\n\r\nfunction createMtcnn(weights) {\r\n    var net = new _Mtcnn__WEBPACK_IMPORTED_MODULE_0__[\"Mtcnn\"]();\r\n    net.extractWeights(weights);\r\n    return net;\r\n}\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/mtcnn/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/mtcnn/normalize.js":
/*!***************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/mtcnn/normalize.js ***!
  \***************************************************************/
/*! exports provided: normalize */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"normalize\", function() { return normalize; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n\r\nfunction normalize(x) {\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () { return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"mul\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"sub\"](x, _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"scalar\"](127.5)), _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"scalar\"](0.0078125)); });\r\n}\r\n//# sourceMappingURL=normalize.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/mtcnn/normalize.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/mtcnn/prelu.js":
/*!***********************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/mtcnn/prelu.js ***!
  \***********************************************************/
/*! exports provided: prelu */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"prelu\", function() { return prelu; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n\r\nfunction prelu(x, alpha) {\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () {\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"relu\"](x), _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"mul\"](alpha, _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"neg\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"relu\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"neg\"](x)))));\r\n    });\r\n}\r\n//# sourceMappingURL=prelu.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/mtcnn/prelu.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/mtcnn/pyramidDown.js":
/*!*****************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/mtcnn/pyramidDown.js ***!
  \*****************************************************************/
/*! exports provided: pyramidDown */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"pyramidDown\", function() { return pyramidDown; });\n/* harmony import */ var _config__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./config */ \"./node_modules/face-api.js/build/es6/mtcnn/config.js\");\n\r\nfunction pyramidDown(minFaceSize, scaleFactor, dims) {\r\n    var height = dims[0], width = dims[1];\r\n    var m = _config__WEBPACK_IMPORTED_MODULE_0__[\"CELL_SIZE\"] / minFaceSize;\r\n    var scales = [];\r\n    var minLayer = Math.min(height, width) * m;\r\n    var exp = 0;\r\n    while (minLayer >= 12) {\r\n        scales.push(m * Math.pow(scaleFactor, exp));\r\n        minLayer = minLayer * scaleFactor;\r\n        exp += 1;\r\n    }\r\n    return scales;\r\n}\r\n//# sourceMappingURL=pyramidDown.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/mtcnn/pyramidDown.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/mtcnn/sharedLayers.js":
/*!******************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/mtcnn/sharedLayers.js ***!
  \******************************************************************/
/*! exports provided: sharedLayer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"sharedLayer\", function() { return sharedLayer; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _prelu__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./prelu */ \"./node_modules/face-api.js/build/es6/mtcnn/prelu.js\");\n\r\n\r\n\r\nfunction sharedLayer(x, params, isPnet) {\r\n    if (isPnet === void 0) { isPnet = false; }\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () {\r\n        var out = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"TfjsImageRecognitionBase\"].convLayer(x, params.conv1, 'valid');\r\n        out = Object(_prelu__WEBPACK_IMPORTED_MODULE_2__[\"prelu\"])(out, params.prelu1_alpha);\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"maxPool\"](out, isPnet ? [2, 2] : [3, 3], [2, 2], 'same');\r\n        out = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"TfjsImageRecognitionBase\"].convLayer(out, params.conv2, 'valid');\r\n        out = Object(_prelu__WEBPACK_IMPORTED_MODULE_2__[\"prelu\"])(out, params.prelu2_alpha);\r\n        out = isPnet ? out : _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"maxPool\"](out, [3, 3], [2, 2], 'valid');\r\n        out = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"TfjsImageRecognitionBase\"].convLayer(out, params.conv3, 'valid');\r\n        out = Object(_prelu__WEBPACK_IMPORTED_MODULE_2__[\"prelu\"])(out, params.prelu3_alpha);\r\n        return out;\r\n    });\r\n}\r\n//# sourceMappingURL=sharedLayers.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/mtcnn/sharedLayers.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/mtcnn/stage1.js":
/*!************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/mtcnn/stage1.js ***!
  \************************************************************/
/*! exports provided: stage1 */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"stage1\", function() { return stage1; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _config__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./config */ \"./node_modules/face-api.js/build/es6/mtcnn/config.js\");\n/* harmony import */ var _getSizesForScale__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./getSizesForScale */ \"./node_modules/face-api.js/build/es6/mtcnn/getSizesForScale.js\");\n/* harmony import */ var _MtcnnBox__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./MtcnnBox */ \"./node_modules/face-api.js/build/es6/mtcnn/MtcnnBox.js\");\n/* harmony import */ var _normalize__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./normalize */ \"./node_modules/face-api.js/build/es6/mtcnn/normalize.js\");\n/* harmony import */ var _PNet__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./PNet */ \"./node_modules/face-api.js/build/es6/mtcnn/PNet.js\");\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nfunction rescaleAndNormalize(x, scale) {\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () {\r\n        var _a = Object(_getSizesForScale__WEBPACK_IMPORTED_MODULE_3__[\"getSizesForScale\"])(scale, x.shape.slice(1)), height = _a.height, width = _a.width;\r\n        var resized = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"image\"].resizeBilinear(x, [height, width]);\r\n        var normalized = Object(_normalize__WEBPACK_IMPORTED_MODULE_5__[\"normalize\"])(resized);\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"transpose\"](normalized, [0, 2, 1, 3]);\r\n    });\r\n}\r\nfunction extractBoundingBoxes(scoresTensor, regionsTensor, scale, scoreThreshold) {\r\n    // TODO: fix this!, maybe better to use tf.gather here\r\n    var indices = [];\r\n    var scoresData = scoresTensor.arraySync();\r\n    for (var y = 0; y < scoresTensor.shape[0]; y++) {\r\n        for (var x = 0; x < scoresTensor.shape[1]; x++) {\r\n            if (scoresData[y][x] >= scoreThreshold) {\r\n                indices.push(new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"Point\"](x, y));\r\n            }\r\n        }\r\n    }\r\n    var boundingBoxes = indices.map(function (idx) {\r\n        var cell = new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"BoundingBox\"](Math.round((idx.y * _config__WEBPACK_IMPORTED_MODULE_2__[\"CELL_STRIDE\"] + 1) / scale), Math.round((idx.x * _config__WEBPACK_IMPORTED_MODULE_2__[\"CELL_STRIDE\"] + 1) / scale), Math.round((idx.y * _config__WEBPACK_IMPORTED_MODULE_2__[\"CELL_STRIDE\"] + _config__WEBPACK_IMPORTED_MODULE_2__[\"CELL_SIZE\"]) / scale), Math.round((idx.x * _config__WEBPACK_IMPORTED_MODULE_2__[\"CELL_STRIDE\"] + _config__WEBPACK_IMPORTED_MODULE_2__[\"CELL_SIZE\"]) / scale));\r\n        var score = scoresData[idx.y][idx.x];\r\n        var regionsData = regionsTensor.arraySync();\r\n        var region = new _MtcnnBox__WEBPACK_IMPORTED_MODULE_4__[\"MtcnnBox\"](regionsData[idx.y][idx.x][0], regionsData[idx.y][idx.x][1], regionsData[idx.y][idx.x][2], regionsData[idx.y][idx.x][3]);\r\n        return {\r\n            cell: cell,\r\n            score: score,\r\n            region: region\r\n        };\r\n    });\r\n    return boundingBoxes;\r\n}\r\nfunction stage1(imgTensor, scales, scoreThreshold, params, stats) {\r\n    stats.stage1 = [];\r\n    var pnetOutputs = scales.map(function (scale) { return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () {\r\n        var statsForScale = { scale: scale };\r\n        var resized = rescaleAndNormalize(imgTensor, scale);\r\n        var ts = Date.now();\r\n        var _a = Object(_PNet__WEBPACK_IMPORTED_MODULE_6__[\"PNet\"])(resized, params), prob = _a.prob, regions = _a.regions;\r\n        statsForScale.pnet = Date.now() - ts;\r\n        var scoresTensor = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"unstack\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"unstack\"](prob, 3)[1])[0];\r\n        var regionsTensor = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"unstack\"](regions)[0];\r\n        return {\r\n            scoresTensor: scoresTensor,\r\n            regionsTensor: regionsTensor,\r\n            scale: scale,\r\n            statsForScale: statsForScale\r\n        };\r\n    }); });\r\n    var boxesForScale = pnetOutputs.map(function (_a) {\r\n        var scoresTensor = _a.scoresTensor, regionsTensor = _a.regionsTensor, scale = _a.scale, statsForScale = _a.statsForScale;\r\n        var boundingBoxes = extractBoundingBoxes(scoresTensor, regionsTensor, scale, scoreThreshold);\r\n        scoresTensor.dispose();\r\n        regionsTensor.dispose();\r\n        if (!boundingBoxes.length) {\r\n            stats.stage1.push(statsForScale);\r\n            return [];\r\n        }\r\n        var ts = Date.now();\r\n        var indices = Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"nonMaxSuppression\"])(boundingBoxes.map(function (bbox) { return bbox.cell; }), boundingBoxes.map(function (bbox) { return bbox.score; }), 0.5);\r\n        statsForScale.nms = Date.now() - ts;\r\n        statsForScale.numBoxes = indices.length;\r\n        stats.stage1.push(statsForScale);\r\n        return indices.map(function (boxIdx) { return boundingBoxes[boxIdx]; });\r\n    });\r\n    var allBoxes = boxesForScale.reduce(function (all, boxes) { return all.concat(boxes); }, []);\r\n    var finalBoxes = [];\r\n    var finalScores = [];\r\n    if (allBoxes.length > 0) {\r\n        var ts = Date.now();\r\n        var indices = Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"nonMaxSuppression\"])(allBoxes.map(function (bbox) { return bbox.cell; }), allBoxes.map(function (bbox) { return bbox.score; }), 0.7);\r\n        stats.stage1_nms = Date.now() - ts;\r\n        finalScores = indices.map(function (idx) { return allBoxes[idx].score; });\r\n        finalBoxes = indices\r\n            .map(function (idx) { return allBoxes[idx]; })\r\n            .map(function (_a) {\r\n            var cell = _a.cell, region = _a.region;\r\n            return new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"BoundingBox\"](cell.left + (region.left * cell.width), cell.top + (region.top * cell.height), cell.right + (region.right * cell.width), cell.bottom + (region.bottom * cell.height)).toSquare().round();\r\n        });\r\n    }\r\n    return {\r\n        boxes: finalBoxes,\r\n        scores: finalScores\r\n    };\r\n}\r\n//# sourceMappingURL=stage1.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/mtcnn/stage1.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/mtcnn/stage2.js":
/*!************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/mtcnn/stage2.js ***!
  \************************************************************/
/*! exports provided: stage2 */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"stage2\", function() { return stage2; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _extractImagePatches__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./extractImagePatches */ \"./node_modules/face-api.js/build/es6/mtcnn/extractImagePatches.js\");\n/* harmony import */ var _MtcnnBox__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./MtcnnBox */ \"./node_modules/face-api.js/build/es6/mtcnn/MtcnnBox.js\");\n/* harmony import */ var _RNet__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./RNet */ \"./node_modules/face-api.js/build/es6/mtcnn/RNet.js\");\n\r\n\r\n\r\n\r\n\r\n\r\nfunction stage2(img, inputBoxes, scoreThreshold, params, stats) {\r\n    return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n        var ts, rnetInputs, rnetOuts, scoresTensor, scores, _a, _b, indices, filteredBoxes, filteredScores, finalBoxes, finalScores, indicesNms, regions_1;\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_c) {\r\n            switch (_c.label) {\r\n                case 0:\r\n                    ts = Date.now();\r\n                    return [4 /*yield*/, Object(_extractImagePatches__WEBPACK_IMPORTED_MODULE_3__[\"extractImagePatches\"])(img, inputBoxes, { width: 24, height: 24 })];\r\n                case 1:\r\n                    rnetInputs = _c.sent();\r\n                    stats.stage2_extractImagePatches = Date.now() - ts;\r\n                    ts = Date.now();\r\n                    rnetOuts = rnetInputs.map(function (rnetInput) {\r\n                        var out = Object(_RNet__WEBPACK_IMPORTED_MODULE_5__[\"RNet\"])(rnetInput, params);\r\n                        rnetInput.dispose();\r\n                        return out;\r\n                    });\r\n                    stats.stage2_rnet = Date.now() - ts;\r\n                    scoresTensor = rnetOuts.length > 1\r\n                        ? _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"concat\"](rnetOuts.map(function (out) { return out.scores; }))\r\n                        : rnetOuts[0].scores;\r\n                    _b = (_a = Array).from;\r\n                    return [4 /*yield*/, scoresTensor.data()];\r\n                case 2:\r\n                    scores = _b.apply(_a, [_c.sent()]);\r\n                    scoresTensor.dispose();\r\n                    indices = scores\r\n                        .map(function (score, idx) { return ({ score: score, idx: idx }); })\r\n                        .filter(function (c) { return c.score > scoreThreshold; })\r\n                        .map(function (_a) {\r\n                        var idx = _a.idx;\r\n                        return idx;\r\n                    });\r\n                    filteredBoxes = indices.map(function (idx) { return inputBoxes[idx]; });\r\n                    filteredScores = indices.map(function (idx) { return scores[idx]; });\r\n                    finalBoxes = [];\r\n                    finalScores = [];\r\n                    if (filteredBoxes.length > 0) {\r\n                        ts = Date.now();\r\n                        indicesNms = Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"nonMaxSuppression\"])(filteredBoxes, filteredScores, 0.7);\r\n                        stats.stage2_nms = Date.now() - ts;\r\n                        regions_1 = indicesNms.map(function (idx) {\r\n                            var regionsData = rnetOuts[indices[idx]].regions.arraySync();\r\n                            return new _MtcnnBox__WEBPACK_IMPORTED_MODULE_4__[\"MtcnnBox\"](regionsData[0][0], regionsData[0][1], regionsData[0][2], regionsData[0][3]);\r\n                        });\r\n                        finalScores = indicesNms.map(function (idx) { return filteredScores[idx]; });\r\n                        finalBoxes = indicesNms.map(function (idx, i) { return filteredBoxes[idx].calibrate(regions_1[i]); });\r\n                    }\r\n                    rnetOuts.forEach(function (t) {\r\n                        t.regions.dispose();\r\n                        t.scores.dispose();\r\n                    });\r\n                    return [2 /*return*/, {\r\n                            boxes: finalBoxes,\r\n                            scores: finalScores\r\n                        }];\r\n            }\r\n        });\r\n    });\r\n}\r\n//# sourceMappingURL=stage2.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/mtcnn/stage2.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/mtcnn/stage3.js":
/*!************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/mtcnn/stage3.js ***!
  \************************************************************/
/*! exports provided: stage3 */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"stage3\", function() { return stage3; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _extractImagePatches__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./extractImagePatches */ \"./node_modules/face-api.js/build/es6/mtcnn/extractImagePatches.js\");\n/* harmony import */ var _MtcnnBox__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./MtcnnBox */ \"./node_modules/face-api.js/build/es6/mtcnn/MtcnnBox.js\");\n/* harmony import */ var _ONet__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ONet */ \"./node_modules/face-api.js/build/es6/mtcnn/ONet.js\");\n\r\n\r\n\r\n\r\n\r\n\r\nfunction stage3(img, inputBoxes, scoreThreshold, params, stats) {\r\n    return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n        var ts, onetInputs, onetOuts, scoresTensor, scores, _a, _b, indices, filteredRegions, filteredBoxes, filteredScores, finalBoxes, finalScores, points, indicesNms;\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_c) {\r\n            switch (_c.label) {\r\n                case 0:\r\n                    ts = Date.now();\r\n                    return [4 /*yield*/, Object(_extractImagePatches__WEBPACK_IMPORTED_MODULE_3__[\"extractImagePatches\"])(img, inputBoxes, { width: 48, height: 48 })];\r\n                case 1:\r\n                    onetInputs = _c.sent();\r\n                    stats.stage3_extractImagePatches = Date.now() - ts;\r\n                    ts = Date.now();\r\n                    onetOuts = onetInputs.map(function (onetInput) {\r\n                        var out = Object(_ONet__WEBPACK_IMPORTED_MODULE_5__[\"ONet\"])(onetInput, params);\r\n                        onetInput.dispose();\r\n                        return out;\r\n                    });\r\n                    stats.stage3_onet = Date.now() - ts;\r\n                    scoresTensor = onetOuts.length > 1\r\n                        ? _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"concat\"](onetOuts.map(function (out) { return out.scores; }))\r\n                        : onetOuts[0].scores;\r\n                    _b = (_a = Array).from;\r\n                    return [4 /*yield*/, scoresTensor.data()];\r\n                case 2:\r\n                    scores = _b.apply(_a, [_c.sent()]);\r\n                    scoresTensor.dispose();\r\n                    indices = scores\r\n                        .map(function (score, idx) { return ({ score: score, idx: idx }); })\r\n                        .filter(function (c) { return c.score > scoreThreshold; })\r\n                        .map(function (_a) {\r\n                        var idx = _a.idx;\r\n                        return idx;\r\n                    });\r\n                    filteredRegions = indices.map(function (idx) {\r\n                        var regionsData = onetOuts[idx].regions.arraySync();\r\n                        return new _MtcnnBox__WEBPACK_IMPORTED_MODULE_4__[\"MtcnnBox\"](regionsData[0][0], regionsData[0][1], regionsData[0][2], regionsData[0][3]);\r\n                    });\r\n                    filteredBoxes = indices\r\n                        .map(function (idx, i) { return inputBoxes[idx].calibrate(filteredRegions[i]); });\r\n                    filteredScores = indices.map(function (idx) { return scores[idx]; });\r\n                    finalBoxes = [];\r\n                    finalScores = [];\r\n                    points = [];\r\n                    if (filteredBoxes.length > 0) {\r\n                        ts = Date.now();\r\n                        indicesNms = Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"nonMaxSuppression\"])(filteredBoxes, filteredScores, 0.7, false);\r\n                        stats.stage3_nms = Date.now() - ts;\r\n                        finalBoxes = indicesNms.map(function (idx) { return filteredBoxes[idx]; });\r\n                        finalScores = indicesNms.map(function (idx) { return filteredScores[idx]; });\r\n                        points = indicesNms.map(function (idx, i) {\r\n                            return Array(5).fill(0).map(function (_, ptIdx) {\r\n                                var pointsData = onetOuts[idx].points.arraySync();\r\n                                return new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"Point\"](((pointsData[0][ptIdx] * (finalBoxes[i].width + 1)) + finalBoxes[i].left), ((pointsData[0][ptIdx + 5] * (finalBoxes[i].height + 1)) + finalBoxes[i].top));\r\n                            });\r\n                        });\r\n                    }\r\n                    onetOuts.forEach(function (t) {\r\n                        t.regions.dispose();\r\n                        t.scores.dispose();\r\n                        t.points.dispose();\r\n                    });\r\n                    return [2 /*return*/, {\r\n                            boxes: finalBoxes,\r\n                            scores: finalScores,\r\n                            points: points\r\n                        }];\r\n            }\r\n        });\r\n    });\r\n}\r\n//# sourceMappingURL=stage3.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/mtcnn/stage3.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/resizeResults.js":
/*!*************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/resizeResults.js ***!
  \*************************************************************/
/*! exports provided: resizeResults */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"resizeResults\", function() { return resizeResults; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _classes_FaceDetection__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./classes/FaceDetection */ \"./node_modules/face-api.js/build/es6/classes/FaceDetection.js\");\n/* harmony import */ var _classes_FaceLandmarks__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./classes/FaceLandmarks */ \"./node_modules/face-api.js/build/es6/classes/FaceLandmarks.js\");\n/* harmony import */ var _factories_WithFaceDetection__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./factories/WithFaceDetection */ \"./node_modules/face-api.js/build/es6/factories/WithFaceDetection.js\");\n/* harmony import */ var _factories_WithFaceLandmarks__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./factories/WithFaceLandmarks */ \"./node_modules/face-api.js/build/es6/factories/WithFaceLandmarks.js\");\n\r\n\r\n\r\n\r\n\r\nfunction resizeResults(results, dimensions) {\r\n    var _a = new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Dimensions\"](dimensions.width, dimensions.height), width = _a.width, height = _a.height;\r\n    if (width <= 0 || height <= 0) {\r\n        throw new Error(\"resizeResults - invalid dimensions: \" + JSON.stringify({ width: width, height: height }));\r\n    }\r\n    if (Array.isArray(results)) {\r\n        return results.map(function (obj) { return resizeResults(obj, { width: width, height: height }); });\r\n    }\r\n    if (Object(_factories_WithFaceLandmarks__WEBPACK_IMPORTED_MODULE_4__[\"isWithFaceLandmarks\"])(results)) {\r\n        var resizedDetection = results.detection.forSize(width, height);\r\n        var resizedLandmarks = results.unshiftedLandmarks.forSize(resizedDetection.box.width, resizedDetection.box.height);\r\n        return Object(_factories_WithFaceLandmarks__WEBPACK_IMPORTED_MODULE_4__[\"extendWithFaceLandmarks\"])(Object(_factories_WithFaceDetection__WEBPACK_IMPORTED_MODULE_3__[\"extendWithFaceDetection\"])(results, resizedDetection), resizedLandmarks);\r\n    }\r\n    if (Object(_factories_WithFaceDetection__WEBPACK_IMPORTED_MODULE_3__[\"isWithFaceDetection\"])(results)) {\r\n        return Object(_factories_WithFaceDetection__WEBPACK_IMPORTED_MODULE_3__[\"extendWithFaceDetection\"])(results, results.detection.forSize(width, height));\r\n    }\r\n    if (results instanceof _classes_FaceLandmarks__WEBPACK_IMPORTED_MODULE_2__[\"FaceLandmarks\"] || results instanceof _classes_FaceDetection__WEBPACK_IMPORTED_MODULE_1__[\"FaceDetection\"]) {\r\n        return results.forSize(width, height);\r\n    }\r\n    return results;\r\n}\r\n//# sourceMappingURL=resizeResults.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/resizeResults.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/ssdMobilenetv1/SsdMobilenetv1.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/ssdMobilenetv1/SsdMobilenetv1.js ***!
  \*****************************************************************************/
/*! exports provided: SsdMobilenetv1 */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SsdMobilenetv1\", function() { return SsdMobilenetv1; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _classes_FaceDetection__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../classes/FaceDetection */ \"./node_modules/face-api.js/build/es6/classes/FaceDetection.js\");\n/* harmony import */ var _extractParams__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./extractParams */ \"./node_modules/face-api.js/build/es6/ssdMobilenetv1/extractParams.js\");\n/* harmony import */ var _extractParamsFromWeigthMap__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./extractParamsFromWeigthMap */ \"./node_modules/face-api.js/build/es6/ssdMobilenetv1/extractParamsFromWeigthMap.js\");\n/* harmony import */ var _mobileNetV1__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./mobileNetV1 */ \"./node_modules/face-api.js/build/es6/ssdMobilenetv1/mobileNetV1.js\");\n/* harmony import */ var _nonMaxSuppression__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./nonMaxSuppression */ \"./node_modules/face-api.js/build/es6/ssdMobilenetv1/nonMaxSuppression.js\");\n/* harmony import */ var _outputLayer__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./outputLayer */ \"./node_modules/face-api.js/build/es6/ssdMobilenetv1/outputLayer.js\");\n/* harmony import */ var _predictionLayer__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./predictionLayer */ \"./node_modules/face-api.js/build/es6/ssdMobilenetv1/predictionLayer.js\");\n/* harmony import */ var _SsdMobilenetv1Options__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./SsdMobilenetv1Options */ \"./node_modules/face-api.js/build/es6/ssdMobilenetv1/SsdMobilenetv1Options.js\");\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nvar SsdMobilenetv1 = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(SsdMobilenetv1, _super);\r\n    function SsdMobilenetv1() {\r\n        return _super.call(this, 'SsdMobilenetv1') || this;\r\n    }\r\n    SsdMobilenetv1.prototype.forwardInput = function (input) {\r\n        var params = this.params;\r\n        if (!params) {\r\n            throw new Error('SsdMobilenetv1 - load model before inference');\r\n        }\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tidy\"](function () {\r\n            var batchTensor = input.toBatchTensor(512, false).toFloat();\r\n            var x = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"sub\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"mul\"](batchTensor, _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"scalar\"](0.007843137718737125)), _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"scalar\"](1));\r\n            var features = Object(_mobileNetV1__WEBPACK_IMPORTED_MODULE_6__[\"mobileNetV1\"])(x, params.mobilenetv1);\r\n            var _a = Object(_predictionLayer__WEBPACK_IMPORTED_MODULE_9__[\"predictionLayer\"])(features.out, features.conv11, params.prediction_layer), boxPredictions = _a.boxPredictions, classPredictions = _a.classPredictions;\r\n            return Object(_outputLayer__WEBPACK_IMPORTED_MODULE_8__[\"outputLayer\"])(boxPredictions, classPredictions, params.output_layer);\r\n        });\r\n    };\r\n    SsdMobilenetv1.prototype.forward = function (input) {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var _a;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this.forwardInput;\r\n                        return [4 /*yield*/, Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"toNetInput\"])(input)];\r\n                    case 1: return [2 /*return*/, _a.apply(this, [_b.sent()])];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    SsdMobilenetv1.prototype.locateFaces = function (input, options) {\r\n        if (options === void 0) { options = {}; }\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var _a, maxResults, minConfidence, netInput, _b, _boxes, _scores, boxes, scores, i, scoresData, _c, _d, iouThreshold, indices, reshapedDims, inputSize, padX, padY, boxesData, results;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_e) {\r\n                switch (_e.label) {\r\n                    case 0:\r\n                        _a = new _SsdMobilenetv1Options__WEBPACK_IMPORTED_MODULE_10__[\"SsdMobilenetv1Options\"](options), maxResults = _a.maxResults, minConfidence = _a.minConfidence;\r\n                        return [4 /*yield*/, Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"toNetInput\"])(input)];\r\n                    case 1:\r\n                        netInput = _e.sent();\r\n                        _b = this.forwardInput(netInput), _boxes = _b.boxes, _scores = _b.scores;\r\n                        boxes = _boxes[0];\r\n                        scores = _scores[0];\r\n                        for (i = 1; i < _boxes.length; i++) {\r\n                            _boxes[i].dispose();\r\n                            _scores[i].dispose();\r\n                        }\r\n                        _d = (_c = Array).from;\r\n                        return [4 /*yield*/, scores.data()];\r\n                    case 2:\r\n                        scoresData = _d.apply(_c, [_e.sent()]);\r\n                        iouThreshold = 0.5;\r\n                        indices = Object(_nonMaxSuppression__WEBPACK_IMPORTED_MODULE_7__[\"nonMaxSuppression\"])(boxes, scoresData, maxResults, iouThreshold, minConfidence);\r\n                        reshapedDims = netInput.getReshapedInputDimensions(0);\r\n                        inputSize = netInput.inputSize;\r\n                        padX = inputSize / reshapedDims.width;\r\n                        padY = inputSize / reshapedDims.height;\r\n                        boxesData = boxes.arraySync();\r\n                        results = indices\r\n                            .map(function (idx) {\r\n                            var _a = [\r\n                                Math.max(0, boxesData[idx][0]),\r\n                                Math.min(1.0, boxesData[idx][2])\r\n                            ].map(function (val) { return val * padY; }), top = _a[0], bottom = _a[1];\r\n                            var _b = [\r\n                                Math.max(0, boxesData[idx][1]),\r\n                                Math.min(1.0, boxesData[idx][3])\r\n                            ].map(function (val) { return val * padX; }), left = _b[0], right = _b[1];\r\n                            return new _classes_FaceDetection__WEBPACK_IMPORTED_MODULE_3__[\"FaceDetection\"](scoresData[idx], new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"Rect\"](left, top, right - left, bottom - top), {\r\n                                height: netInput.getInputHeight(0),\r\n                                width: netInput.getInputWidth(0)\r\n                            });\r\n                        });\r\n                        boxes.dispose();\r\n                        scores.dispose();\r\n                        return [2 /*return*/, results];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    SsdMobilenetv1.prototype.getDefaultModelName = function () {\r\n        return 'ssd_mobilenetv1_model';\r\n    };\r\n    SsdMobilenetv1.prototype.extractParamsFromWeigthMap = function (weightMap) {\r\n        return Object(_extractParamsFromWeigthMap__WEBPACK_IMPORTED_MODULE_5__[\"extractParamsFromWeigthMap\"])(weightMap);\r\n    };\r\n    SsdMobilenetv1.prototype.extractParams = function (weights) {\r\n        return Object(_extractParams__WEBPACK_IMPORTED_MODULE_4__[\"extractParams\"])(weights);\r\n    };\r\n    return SsdMobilenetv1;\r\n}(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"NeuralNetwork\"]));\r\n\r\n//# sourceMappingURL=SsdMobilenetv1.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/ssdMobilenetv1/SsdMobilenetv1.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/ssdMobilenetv1/SsdMobilenetv1Options.js":
/*!************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/ssdMobilenetv1/SsdMobilenetv1Options.js ***!
  \************************************************************************************/
/*! exports provided: SsdMobilenetv1Options */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SsdMobilenetv1Options\", function() { return SsdMobilenetv1Options; });\nvar SsdMobilenetv1Options = /** @class */ (function () {\r\n    function SsdMobilenetv1Options(_a) {\r\n        var _b = _a === void 0 ? {} : _a, minConfidence = _b.minConfidence, maxResults = _b.maxResults;\r\n        this._name = 'SsdMobilenetv1Options';\r\n        this._minConfidence = minConfidence || 0.5;\r\n        this._maxResults = maxResults || 100;\r\n        if (typeof this._minConfidence !== 'number' || this._minConfidence <= 0 || this._minConfidence >= 1) {\r\n            throw new Error(this._name + \" - expected minConfidence to be a number between 0 and 1\");\r\n        }\r\n        if (typeof this._maxResults !== 'number') {\r\n            throw new Error(this._name + \" - expected maxResults to be a number\");\r\n        }\r\n    }\r\n    Object.defineProperty(SsdMobilenetv1Options.prototype, \"minConfidence\", {\r\n        get: function () { return this._minConfidence; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(SsdMobilenetv1Options.prototype, \"maxResults\", {\r\n        get: function () { return this._maxResults; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    return SsdMobilenetv1Options;\r\n}());\r\n\r\n//# sourceMappingURL=SsdMobilenetv1Options.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/ssdMobilenetv1/SsdMobilenetv1Options.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/ssdMobilenetv1/boxPredictionLayer.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/ssdMobilenetv1/boxPredictionLayer.js ***!
  \*********************************************************************************/
/*! exports provided: boxPredictionLayer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"boxPredictionLayer\", function() { return boxPredictionLayer; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n\r\n\r\nfunction boxPredictionLayer(x, params) {\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () {\r\n        var batchSize = x.shape[0];\r\n        var boxPredictionEncoding = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"reshape\"](tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"TfjsImageRecognitionBase\"].convLayer(x, params.box_encoding_predictor), [batchSize, -1, 1, 4]);\r\n        var classPrediction = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"reshape\"](tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"TfjsImageRecognitionBase\"].convLayer(x, params.class_predictor), [batchSize, -1, 3]);\r\n        return {\r\n            boxPredictionEncoding: boxPredictionEncoding,\r\n            classPrediction: classPrediction\r\n        };\r\n    });\r\n}\r\n//# sourceMappingURL=boxPredictionLayer.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/ssdMobilenetv1/boxPredictionLayer.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/ssdMobilenetv1/extractParams.js":
/*!****************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/ssdMobilenetv1/extractParams.js ***!
  \****************************************************************************/
/*! exports provided: extractParams */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractParams\", function() { return extractParams; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n\r\n\r\nfunction extractorsFactory(extractWeights, paramMappings) {\r\n    function extractDepthwiseConvParams(numChannels, mappedPrefix) {\r\n        var filters = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tensor4d\"](extractWeights(3 * 3 * numChannels), [3, 3, numChannels, 1]);\r\n        var batch_norm_scale = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tensor1d\"](extractWeights(numChannels));\r\n        var batch_norm_offset = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tensor1d\"](extractWeights(numChannels));\r\n        var batch_norm_mean = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tensor1d\"](extractWeights(numChannels));\r\n        var batch_norm_variance = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tensor1d\"](extractWeights(numChannels));\r\n        paramMappings.push({ paramPath: mappedPrefix + \"/filters\" }, { paramPath: mappedPrefix + \"/batch_norm_scale\" }, { paramPath: mappedPrefix + \"/batch_norm_offset\" }, { paramPath: mappedPrefix + \"/batch_norm_mean\" }, { paramPath: mappedPrefix + \"/batch_norm_variance\" });\r\n        return {\r\n            filters: filters,\r\n            batch_norm_scale: batch_norm_scale,\r\n            batch_norm_offset: batch_norm_offset,\r\n            batch_norm_mean: batch_norm_mean,\r\n            batch_norm_variance: batch_norm_variance\r\n        };\r\n    }\r\n    function extractConvParams(channelsIn, channelsOut, filterSize, mappedPrefix, isPointwiseConv) {\r\n        var filters = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tensor4d\"](extractWeights(channelsIn * channelsOut * filterSize * filterSize), [filterSize, filterSize, channelsIn, channelsOut]);\r\n        var bias = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tensor1d\"](extractWeights(channelsOut));\r\n        paramMappings.push({ paramPath: mappedPrefix + \"/filters\" }, { paramPath: mappedPrefix + \"/\" + (isPointwiseConv ? 'batch_norm_offset' : 'bias') });\r\n        return { filters: filters, bias: bias };\r\n    }\r\n    function extractPointwiseConvParams(channelsIn, channelsOut, filterSize, mappedPrefix) {\r\n        var _a = extractConvParams(channelsIn, channelsOut, filterSize, mappedPrefix, true), filters = _a.filters, bias = _a.bias;\r\n        return {\r\n            filters: filters,\r\n            batch_norm_offset: bias\r\n        };\r\n    }\r\n    function extractConvPairParams(channelsIn, channelsOut, mappedPrefix) {\r\n        var depthwise_conv = extractDepthwiseConvParams(channelsIn, mappedPrefix + \"/depthwise_conv\");\r\n        var pointwise_conv = extractPointwiseConvParams(channelsIn, channelsOut, 1, mappedPrefix + \"/pointwise_conv\");\r\n        return { depthwise_conv: depthwise_conv, pointwise_conv: pointwise_conv };\r\n    }\r\n    function extractMobilenetV1Params() {\r\n        var conv_0 = extractPointwiseConvParams(3, 32, 3, 'mobilenetv1/conv_0');\r\n        var conv_1 = extractConvPairParams(32, 64, 'mobilenetv1/conv_1');\r\n        var conv_2 = extractConvPairParams(64, 128, 'mobilenetv1/conv_2');\r\n        var conv_3 = extractConvPairParams(128, 128, 'mobilenetv1/conv_3');\r\n        var conv_4 = extractConvPairParams(128, 256, 'mobilenetv1/conv_4');\r\n        var conv_5 = extractConvPairParams(256, 256, 'mobilenetv1/conv_5');\r\n        var conv_6 = extractConvPairParams(256, 512, 'mobilenetv1/conv_6');\r\n        var conv_7 = extractConvPairParams(512, 512, 'mobilenetv1/conv_7');\r\n        var conv_8 = extractConvPairParams(512, 512, 'mobilenetv1/conv_8');\r\n        var conv_9 = extractConvPairParams(512, 512, 'mobilenetv1/conv_9');\r\n        var conv_10 = extractConvPairParams(512, 512, 'mobilenetv1/conv_10');\r\n        var conv_11 = extractConvPairParams(512, 512, 'mobilenetv1/conv_11');\r\n        var conv_12 = extractConvPairParams(512, 1024, 'mobilenetv1/conv_12');\r\n        var conv_13 = extractConvPairParams(1024, 1024, 'mobilenetv1/conv_13');\r\n        return {\r\n            conv_0: conv_0,\r\n            conv_1: conv_1,\r\n            conv_2: conv_2,\r\n            conv_3: conv_3,\r\n            conv_4: conv_4,\r\n            conv_5: conv_5,\r\n            conv_6: conv_6,\r\n            conv_7: conv_7,\r\n            conv_8: conv_8,\r\n            conv_9: conv_9,\r\n            conv_10: conv_10,\r\n            conv_11: conv_11,\r\n            conv_12: conv_12,\r\n            conv_13: conv_13\r\n        };\r\n    }\r\n    function extractPredictionLayerParams() {\r\n        var conv_0 = extractPointwiseConvParams(1024, 256, 1, 'prediction_layer/conv_0');\r\n        var conv_1 = extractPointwiseConvParams(256, 512, 3, 'prediction_layer/conv_1');\r\n        var conv_2 = extractPointwiseConvParams(512, 128, 1, 'prediction_layer/conv_2');\r\n        var conv_3 = extractPointwiseConvParams(128, 256, 3, 'prediction_layer/conv_3');\r\n        var conv_4 = extractPointwiseConvParams(256, 128, 1, 'prediction_layer/conv_4');\r\n        var conv_5 = extractPointwiseConvParams(128, 256, 3, 'prediction_layer/conv_5');\r\n        var conv_6 = extractPointwiseConvParams(256, 64, 1, 'prediction_layer/conv_6');\r\n        var conv_7 = extractPointwiseConvParams(64, 128, 3, 'prediction_layer/conv_7');\r\n        var box_encoding_0_predictor = extractConvParams(512, 12, 1, 'prediction_layer/box_predictor_0/box_encoding_predictor');\r\n        var class_predictor_0 = extractConvParams(512, 9, 1, 'prediction_layer/box_predictor_0/class_predictor');\r\n        var box_encoding_1_predictor = extractConvParams(1024, 24, 1, 'prediction_layer/box_predictor_1/box_encoding_predictor');\r\n        var class_predictor_1 = extractConvParams(1024, 18, 1, 'prediction_layer/box_predictor_1/class_predictor');\r\n        var box_encoding_2_predictor = extractConvParams(512, 24, 1, 'prediction_layer/box_predictor_2/box_encoding_predictor');\r\n        var class_predictor_2 = extractConvParams(512, 18, 1, 'prediction_layer/box_predictor_2/class_predictor');\r\n        var box_encoding_3_predictor = extractConvParams(256, 24, 1, 'prediction_layer/box_predictor_3/box_encoding_predictor');\r\n        var class_predictor_3 = extractConvParams(256, 18, 1, 'prediction_layer/box_predictor_3/class_predictor');\r\n        var box_encoding_4_predictor = extractConvParams(256, 24, 1, 'prediction_layer/box_predictor_4/box_encoding_predictor');\r\n        var class_predictor_4 = extractConvParams(256, 18, 1, 'prediction_layer/box_predictor_4/class_predictor');\r\n        var box_encoding_5_predictor = extractConvParams(128, 24, 1, 'prediction_layer/box_predictor_5/box_encoding_predictor');\r\n        var class_predictor_5 = extractConvParams(128, 18, 1, 'prediction_layer/box_predictor_5/class_predictor');\r\n        var box_predictor_0 = {\r\n            box_encoding_predictor: box_encoding_0_predictor,\r\n            class_predictor: class_predictor_0\r\n        };\r\n        var box_predictor_1 = {\r\n            box_encoding_predictor: box_encoding_1_predictor,\r\n            class_predictor: class_predictor_1\r\n        };\r\n        var box_predictor_2 = {\r\n            box_encoding_predictor: box_encoding_2_predictor,\r\n            class_predictor: class_predictor_2\r\n        };\r\n        var box_predictor_3 = {\r\n            box_encoding_predictor: box_encoding_3_predictor,\r\n            class_predictor: class_predictor_3\r\n        };\r\n        var box_predictor_4 = {\r\n            box_encoding_predictor: box_encoding_4_predictor,\r\n            class_predictor: class_predictor_4\r\n        };\r\n        var box_predictor_5 = {\r\n            box_encoding_predictor: box_encoding_5_predictor,\r\n            class_predictor: class_predictor_5\r\n        };\r\n        return {\r\n            conv_0: conv_0,\r\n            conv_1: conv_1,\r\n            conv_2: conv_2,\r\n            conv_3: conv_3,\r\n            conv_4: conv_4,\r\n            conv_5: conv_5,\r\n            conv_6: conv_6,\r\n            conv_7: conv_7,\r\n            box_predictor_0: box_predictor_0,\r\n            box_predictor_1: box_predictor_1,\r\n            box_predictor_2: box_predictor_2,\r\n            box_predictor_3: box_predictor_3,\r\n            box_predictor_4: box_predictor_4,\r\n            box_predictor_5: box_predictor_5\r\n        };\r\n    }\r\n    return {\r\n        extractMobilenetV1Params: extractMobilenetV1Params,\r\n        extractPredictionLayerParams: extractPredictionLayerParams\r\n    };\r\n}\r\nfunction extractParams(weights) {\r\n    var paramMappings = [];\r\n    var _a = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"TfjsImageRecognitionBase\"].extractWeightsFactory(weights), extractWeights = _a.extractWeights, getRemainingWeights = _a.getRemainingWeights;\r\n    var _b = extractorsFactory(extractWeights, paramMappings), extractMobilenetV1Params = _b.extractMobilenetV1Params, extractPredictionLayerParams = _b.extractPredictionLayerParams;\r\n    var mobilenetv1 = extractMobilenetV1Params();\r\n    var prediction_layer = extractPredictionLayerParams();\r\n    var extra_dim = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tensor3d\"](extractWeights(5118 * 4), [1, 5118, 4]);\r\n    var output_layer = {\r\n        extra_dim: extra_dim\r\n    };\r\n    paramMappings.push({ paramPath: 'output_layer/extra_dim' });\r\n    if (getRemainingWeights().length !== 0) {\r\n        throw new Error(\"weights remaing after extract: \" + getRemainingWeights().length);\r\n    }\r\n    return {\r\n        params: {\r\n            mobilenetv1: mobilenetv1,\r\n            prediction_layer: prediction_layer,\r\n            output_layer: output_layer\r\n        },\r\n        paramMappings: paramMappings\r\n    };\r\n}\r\n//# sourceMappingURL=extractParams.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/ssdMobilenetv1/extractParams.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/ssdMobilenetv1/extractParamsFromWeigthMap.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/ssdMobilenetv1/extractParamsFromWeigthMap.js ***!
  \*****************************************************************************************/
/*! exports provided: extractParamsFromWeigthMap */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractParamsFromWeigthMap\", function() { return extractParamsFromWeigthMap; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n\r\nfunction extractorsFactory(weightMap, paramMappings) {\r\n    var extractWeightEntry = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].extractWeightEntryFactory(weightMap, paramMappings);\r\n    function extractPointwiseConvParams(prefix, idx, mappedPrefix) {\r\n        var filters = extractWeightEntry(prefix + \"/Conv2d_\" + idx + \"_pointwise/weights\", 4, mappedPrefix + \"/filters\");\r\n        var batch_norm_offset = extractWeightEntry(prefix + \"/Conv2d_\" + idx + \"_pointwise/convolution_bn_offset\", 1, mappedPrefix + \"/batch_norm_offset\");\r\n        return { filters: filters, batch_norm_offset: batch_norm_offset };\r\n    }\r\n    function extractConvPairParams(idx) {\r\n        var mappedPrefix = \"mobilenetv1/conv_\" + idx;\r\n        var prefixDepthwiseConv = \"MobilenetV1/Conv2d_\" + idx + \"_depthwise\";\r\n        var mappedPrefixDepthwiseConv = mappedPrefix + \"/depthwise_conv\";\r\n        var mappedPrefixPointwiseConv = mappedPrefix + \"/pointwise_conv\";\r\n        var filters = extractWeightEntry(prefixDepthwiseConv + \"/depthwise_weights\", 4, mappedPrefixDepthwiseConv + \"/filters\");\r\n        var batch_norm_scale = extractWeightEntry(prefixDepthwiseConv + \"/BatchNorm/gamma\", 1, mappedPrefixDepthwiseConv + \"/batch_norm_scale\");\r\n        var batch_norm_offset = extractWeightEntry(prefixDepthwiseConv + \"/BatchNorm/beta\", 1, mappedPrefixDepthwiseConv + \"/batch_norm_offset\");\r\n        var batch_norm_mean = extractWeightEntry(prefixDepthwiseConv + \"/BatchNorm/moving_mean\", 1, mappedPrefixDepthwiseConv + \"/batch_norm_mean\");\r\n        var batch_norm_variance = extractWeightEntry(prefixDepthwiseConv + \"/BatchNorm/moving_variance\", 1, mappedPrefixDepthwiseConv + \"/batch_norm_variance\");\r\n        return {\r\n            depthwise_conv: {\r\n                filters: filters,\r\n                batch_norm_scale: batch_norm_scale,\r\n                batch_norm_offset: batch_norm_offset,\r\n                batch_norm_mean: batch_norm_mean,\r\n                batch_norm_variance: batch_norm_variance\r\n            },\r\n            pointwise_conv: extractPointwiseConvParams('MobilenetV1', idx, mappedPrefixPointwiseConv)\r\n        };\r\n    }\r\n    function extractMobilenetV1Params() {\r\n        return {\r\n            conv_0: extractPointwiseConvParams('MobilenetV1', 0, 'mobilenetv1/conv_0'),\r\n            conv_1: extractConvPairParams(1),\r\n            conv_2: extractConvPairParams(2),\r\n            conv_3: extractConvPairParams(3),\r\n            conv_4: extractConvPairParams(4),\r\n            conv_5: extractConvPairParams(5),\r\n            conv_6: extractConvPairParams(6),\r\n            conv_7: extractConvPairParams(7),\r\n            conv_8: extractConvPairParams(8),\r\n            conv_9: extractConvPairParams(9),\r\n            conv_10: extractConvPairParams(10),\r\n            conv_11: extractConvPairParams(11),\r\n            conv_12: extractConvPairParams(12),\r\n            conv_13: extractConvPairParams(13)\r\n        };\r\n    }\r\n    function extractConvParams(prefix, mappedPrefix) {\r\n        var filters = extractWeightEntry(prefix + \"/weights\", 4, mappedPrefix + \"/filters\");\r\n        var bias = extractWeightEntry(prefix + \"/biases\", 1, mappedPrefix + \"/bias\");\r\n        return { filters: filters, bias: bias };\r\n    }\r\n    function extractBoxPredictorParams(idx) {\r\n        var box_encoding_predictor = extractConvParams(\"Prediction/BoxPredictor_\" + idx + \"/BoxEncodingPredictor\", \"prediction_layer/box_predictor_\" + idx + \"/box_encoding_predictor\");\r\n        var class_predictor = extractConvParams(\"Prediction/BoxPredictor_\" + idx + \"/ClassPredictor\", \"prediction_layer/box_predictor_\" + idx + \"/class_predictor\");\r\n        return { box_encoding_predictor: box_encoding_predictor, class_predictor: class_predictor };\r\n    }\r\n    function extractPredictionLayerParams() {\r\n        return {\r\n            conv_0: extractPointwiseConvParams('Prediction', 0, 'prediction_layer/conv_0'),\r\n            conv_1: extractPointwiseConvParams('Prediction', 1, 'prediction_layer/conv_1'),\r\n            conv_2: extractPointwiseConvParams('Prediction', 2, 'prediction_layer/conv_2'),\r\n            conv_3: extractPointwiseConvParams('Prediction', 3, 'prediction_layer/conv_3'),\r\n            conv_4: extractPointwiseConvParams('Prediction', 4, 'prediction_layer/conv_4'),\r\n            conv_5: extractPointwiseConvParams('Prediction', 5, 'prediction_layer/conv_5'),\r\n            conv_6: extractPointwiseConvParams('Prediction', 6, 'prediction_layer/conv_6'),\r\n            conv_7: extractPointwiseConvParams('Prediction', 7, 'prediction_layer/conv_7'),\r\n            box_predictor_0: extractBoxPredictorParams(0),\r\n            box_predictor_1: extractBoxPredictorParams(1),\r\n            box_predictor_2: extractBoxPredictorParams(2),\r\n            box_predictor_3: extractBoxPredictorParams(3),\r\n            box_predictor_4: extractBoxPredictorParams(4),\r\n            box_predictor_5: extractBoxPredictorParams(5)\r\n        };\r\n    }\r\n    return {\r\n        extractMobilenetV1Params: extractMobilenetV1Params,\r\n        extractPredictionLayerParams: extractPredictionLayerParams\r\n    };\r\n}\r\nfunction extractParamsFromWeigthMap(weightMap) {\r\n    var paramMappings = [];\r\n    var _a = extractorsFactory(weightMap, paramMappings), extractMobilenetV1Params = _a.extractMobilenetV1Params, extractPredictionLayerParams = _a.extractPredictionLayerParams;\r\n    var extra_dim = weightMap['Output/extra_dim'];\r\n    paramMappings.push({ originalPath: 'Output/extra_dim', paramPath: 'output_layer/extra_dim' });\r\n    if (!Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"isTensor3D\"])(extra_dim)) {\r\n        throw new Error(\"expected weightMap['Output/extra_dim'] to be a Tensor3D, instead have \" + extra_dim);\r\n    }\r\n    var params = {\r\n        mobilenetv1: extractMobilenetV1Params(),\r\n        prediction_layer: extractPredictionLayerParams(),\r\n        output_layer: {\r\n            extra_dim: extra_dim\r\n        }\r\n    };\r\n    tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].disposeUnusedWeightTensors(weightMap, paramMappings);\r\n    return { params: params, paramMappings: paramMappings };\r\n}\r\n//# sourceMappingURL=extractParamsFromWeigthMap.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/ssdMobilenetv1/extractParamsFromWeigthMap.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/ssdMobilenetv1/index.js":
/*!********************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/ssdMobilenetv1/index.js ***!
  \********************************************************************/
/*! exports provided: SsdMobilenetv1, SsdMobilenetv1Options, createSsdMobilenetv1, createFaceDetectionNet, FaceDetectionNet */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"createSsdMobilenetv1\", function() { return createSsdMobilenetv1; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"createFaceDetectionNet\", function() { return createFaceDetectionNet; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"FaceDetectionNet\", function() { return FaceDetectionNet; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _SsdMobilenetv1__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./SsdMobilenetv1 */ \"./node_modules/face-api.js/build/es6/ssdMobilenetv1/SsdMobilenetv1.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SsdMobilenetv1\", function() { return _SsdMobilenetv1__WEBPACK_IMPORTED_MODULE_1__[\"SsdMobilenetv1\"]; });\n\n/* harmony import */ var _SsdMobilenetv1Options__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./SsdMobilenetv1Options */ \"./node_modules/face-api.js/build/es6/ssdMobilenetv1/SsdMobilenetv1Options.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SsdMobilenetv1Options\", function() { return _SsdMobilenetv1Options__WEBPACK_IMPORTED_MODULE_2__[\"SsdMobilenetv1Options\"]; });\n\n\r\n\r\n\r\n\r\nfunction createSsdMobilenetv1(weights) {\r\n    var net = new _SsdMobilenetv1__WEBPACK_IMPORTED_MODULE_1__[\"SsdMobilenetv1\"]();\r\n    net.extractWeights(weights);\r\n    return net;\r\n}\r\nfunction createFaceDetectionNet(weights) {\r\n    return createSsdMobilenetv1(weights);\r\n}\r\n// alias for backward compatibily\r\nvar FaceDetectionNet = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(FaceDetectionNet, _super);\r\n    function FaceDetectionNet() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    return FaceDetectionNet;\r\n}(_SsdMobilenetv1__WEBPACK_IMPORTED_MODULE_1__[\"SsdMobilenetv1\"]));\r\n\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/ssdMobilenetv1/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/ssdMobilenetv1/mobileNetV1.js":
/*!**************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/ssdMobilenetv1/mobileNetV1.js ***!
  \**************************************************************************/
/*! exports provided: mobileNetV1 */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"mobileNetV1\", function() { return mobileNetV1; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var _pointwiseConvLayer__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./pointwiseConvLayer */ \"./node_modules/face-api.js/build/es6/ssdMobilenetv1/pointwiseConvLayer.js\");\n\r\n\r\nvar epsilon = 0.0010000000474974513;\r\nfunction depthwiseConvLayer(x, params, strides) {\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () {\r\n        var out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"depthwiseConv2d\"](x, params.filters, strides, 'same');\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"batchNorm\"](out, params.batch_norm_mean, params.batch_norm_variance, params.batch_norm_offset, params.batch_norm_scale, epsilon);\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"clipByValue\"](out, 0, 6);\r\n    });\r\n}\r\nfunction getStridesForLayerIdx(layerIdx) {\r\n    return [2, 4, 6, 12].some(function (idx) { return idx === layerIdx; }) ? [2, 2] : [1, 1];\r\n}\r\nfunction mobileNetV1(x, params) {\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () {\r\n        var conv11 = null;\r\n        var out = Object(_pointwiseConvLayer__WEBPACK_IMPORTED_MODULE_1__[\"pointwiseConvLayer\"])(x, params.conv_0, [2, 2]);\r\n        var convPairParams = [\r\n            params.conv_1,\r\n            params.conv_2,\r\n            params.conv_3,\r\n            params.conv_4,\r\n            params.conv_5,\r\n            params.conv_6,\r\n            params.conv_7,\r\n            params.conv_8,\r\n            params.conv_9,\r\n            params.conv_10,\r\n            params.conv_11,\r\n            params.conv_12,\r\n            params.conv_13\r\n        ];\r\n        convPairParams.forEach(function (param, i) {\r\n            var layerIdx = i + 1;\r\n            var depthwiseConvStrides = getStridesForLayerIdx(layerIdx);\r\n            out = depthwiseConvLayer(out, param.depthwise_conv, depthwiseConvStrides);\r\n            out = Object(_pointwiseConvLayer__WEBPACK_IMPORTED_MODULE_1__[\"pointwiseConvLayer\"])(out, param.pointwise_conv, [1, 1]);\r\n            if (layerIdx === 11) {\r\n                conv11 = out;\r\n            }\r\n        });\r\n        if (conv11 === null) {\r\n            throw new Error('mobileNetV1 - output of conv layer 11 is null');\r\n        }\r\n        return {\r\n            out: out,\r\n            conv11: conv11\r\n        };\r\n    });\r\n}\r\n//# sourceMappingURL=mobileNetV1.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/ssdMobilenetv1/mobileNetV1.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/ssdMobilenetv1/nonMaxSuppression.js":
/*!********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/ssdMobilenetv1/nonMaxSuppression.js ***!
  \********************************************************************************/
/*! exports provided: nonMaxSuppression */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"nonMaxSuppression\", function() { return nonMaxSuppression; });\nfunction nonMaxSuppression(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {\r\n    var numBoxes = boxes.shape[0];\r\n    var outputSize = Math.min(maxOutputSize, numBoxes);\r\n    var candidates = scores\r\n        .map(function (score, boxIndex) { return ({ score: score, boxIndex: boxIndex }); })\r\n        .filter(function (c) { return c.score > scoreThreshold; })\r\n        .sort(function (c1, c2) { return c2.score - c1.score; });\r\n    var suppressFunc = function (x) { return x <= iouThreshold ? 1 : 0; };\r\n    var selected = [];\r\n    candidates.forEach(function (c) {\r\n        if (selected.length >= outputSize) {\r\n            return;\r\n        }\r\n        var originalScore = c.score;\r\n        for (var j = selected.length - 1; j >= 0; --j) {\r\n            var iou = IOU(boxes, c.boxIndex, selected[j]);\r\n            if (iou === 0.0) {\r\n                continue;\r\n            }\r\n            c.score *= suppressFunc(iou);\r\n            if (c.score <= scoreThreshold) {\r\n                break;\r\n            }\r\n        }\r\n        if (originalScore === c.score) {\r\n            selected.push(c.boxIndex);\r\n        }\r\n    });\r\n    return selected;\r\n}\r\nfunction IOU(boxes, i, j) {\r\n    var boxesData = boxes.arraySync();\r\n    var yminI = Math.min(boxesData[i][0], boxesData[i][2]);\r\n    var xminI = Math.min(boxesData[i][1], boxesData[i][3]);\r\n    var ymaxI = Math.max(boxesData[i][0], boxesData[i][2]);\r\n    var xmaxI = Math.max(boxesData[i][1], boxesData[i][3]);\r\n    var yminJ = Math.min(boxesData[j][0], boxesData[j][2]);\r\n    var xminJ = Math.min(boxesData[j][1], boxesData[j][3]);\r\n    var ymaxJ = Math.max(boxesData[j][0], boxesData[j][2]);\r\n    var xmaxJ = Math.max(boxesData[j][1], boxesData[j][3]);\r\n    var areaI = (ymaxI - yminI) * (xmaxI - xminI);\r\n    var areaJ = (ymaxJ - yminJ) * (xmaxJ - xminJ);\r\n    if (areaI <= 0 || areaJ <= 0) {\r\n        return 0.0;\r\n    }\r\n    var intersectionYmin = Math.max(yminI, yminJ);\r\n    var intersectionXmin = Math.max(xminI, xminJ);\r\n    var intersectionYmax = Math.min(ymaxI, ymaxJ);\r\n    var intersectionXmax = Math.min(xmaxI, xmaxJ);\r\n    var intersectionArea = Math.max(intersectionYmax - intersectionYmin, 0.0) *\r\n        Math.max(intersectionXmax - intersectionXmin, 0.0);\r\n    return intersectionArea / (areaI + areaJ - intersectionArea);\r\n}\r\n//# sourceMappingURL=nonMaxSuppression.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/ssdMobilenetv1/nonMaxSuppression.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/ssdMobilenetv1/outputLayer.js":
/*!**************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/ssdMobilenetv1/outputLayer.js ***!
  \**************************************************************************/
/*! exports provided: outputLayer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"outputLayer\", function() { return outputLayer; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n\r\nfunction getCenterCoordinatesAndSizesLayer(x) {\r\n    var vec = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"unstack\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"transpose\"](x, [1, 0]));\r\n    var sizes = [\r\n        _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"sub\"](vec[2], vec[0]),\r\n        _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"sub\"](vec[3], vec[1])\r\n    ];\r\n    var centers = [\r\n        _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](vec[0], _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"div\"](sizes[0], _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"scalar\"](2))),\r\n        _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](vec[1], _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"div\"](sizes[1], _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"scalar\"](2)))\r\n    ];\r\n    return {\r\n        sizes: sizes,\r\n        centers: centers\r\n    };\r\n}\r\nfunction decodeBoxesLayer(x0, x1) {\r\n    var _a = getCenterCoordinatesAndSizesLayer(x0), sizes = _a.sizes, centers = _a.centers;\r\n    var vec = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"unstack\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"transpose\"](x1, [1, 0]));\r\n    var div0_out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"div\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"mul\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"exp\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"div\"](vec[2], _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"scalar\"](5))), sizes[0]), _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"scalar\"](2));\r\n    var add0_out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"mul\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"div\"](vec[0], _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"scalar\"](10)), sizes[0]), centers[0]);\r\n    var div1_out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"div\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"mul\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"exp\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"div\"](vec[3], _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"scalar\"](5))), sizes[1]), _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"scalar\"](2));\r\n    var add1_out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"mul\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"div\"](vec[1], _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"scalar\"](10)), sizes[1]), centers[1]);\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"transpose\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"stack\"]([\r\n        _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"sub\"](add0_out, div0_out),\r\n        _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"sub\"](add1_out, div1_out),\r\n        _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](add0_out, div0_out),\r\n        _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](add1_out, div1_out)\r\n    ]), [1, 0]);\r\n}\r\nfunction outputLayer(boxPredictions, classPredictions, params) {\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () {\r\n        var batchSize = boxPredictions.shape[0];\r\n        var boxes = decodeBoxesLayer(_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"reshape\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tile\"](params.extra_dim, [batchSize, 1, 1]), [-1, 4]), _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"reshape\"](boxPredictions, [-1, 4]));\r\n        boxes = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"reshape\"](boxes, [batchSize, (boxes.shape[0] / batchSize), 4]);\r\n        var scoresAndClasses = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"sigmoid\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"slice\"](classPredictions, [0, 0, 1], [-1, -1, -1]));\r\n        var scores = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"slice\"](scoresAndClasses, [0, 0, 0], [-1, -1, 1]);\r\n        scores = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"reshape\"](scores, [batchSize, scores.shape[1]]);\r\n        var boxesByBatch = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"unstack\"](boxes);\r\n        var scoresByBatch = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"unstack\"](scores);\r\n        return {\r\n            boxes: boxesByBatch,\r\n            scores: scoresByBatch\r\n        };\r\n    });\r\n}\r\n//# sourceMappingURL=outputLayer.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/ssdMobilenetv1/outputLayer.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/ssdMobilenetv1/pointwiseConvLayer.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/ssdMobilenetv1/pointwiseConvLayer.js ***!
  \*********************************************************************************/
/*! exports provided: pointwiseConvLayer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"pointwiseConvLayer\", function() { return pointwiseConvLayer; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n\r\nfunction pointwiseConvLayer(x, params, strides) {\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () {\r\n        var out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"conv2d\"](x, params.filters, strides, 'same');\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](out, params.batch_norm_offset);\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"clipByValue\"](out, 0, 6);\r\n    });\r\n}\r\n//# sourceMappingURL=pointwiseConvLayer.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/ssdMobilenetv1/pointwiseConvLayer.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/ssdMobilenetv1/predictionLayer.js":
/*!******************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/ssdMobilenetv1/predictionLayer.js ***!
  \******************************************************************************/
/*! exports provided: predictionLayer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"predictionLayer\", function() { return predictionLayer; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var _boxPredictionLayer__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./boxPredictionLayer */ \"./node_modules/face-api.js/build/es6/ssdMobilenetv1/boxPredictionLayer.js\");\n/* harmony import */ var _pointwiseConvLayer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./pointwiseConvLayer */ \"./node_modules/face-api.js/build/es6/ssdMobilenetv1/pointwiseConvLayer.js\");\n\r\n\r\n\r\nfunction predictionLayer(x, conv11, params) {\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () {\r\n        var conv0 = Object(_pointwiseConvLayer__WEBPACK_IMPORTED_MODULE_2__[\"pointwiseConvLayer\"])(x, params.conv_0, [1, 1]);\r\n        var conv1 = Object(_pointwiseConvLayer__WEBPACK_IMPORTED_MODULE_2__[\"pointwiseConvLayer\"])(conv0, params.conv_1, [2, 2]);\r\n        var conv2 = Object(_pointwiseConvLayer__WEBPACK_IMPORTED_MODULE_2__[\"pointwiseConvLayer\"])(conv1, params.conv_2, [1, 1]);\r\n        var conv3 = Object(_pointwiseConvLayer__WEBPACK_IMPORTED_MODULE_2__[\"pointwiseConvLayer\"])(conv2, params.conv_3, [2, 2]);\r\n        var conv4 = Object(_pointwiseConvLayer__WEBPACK_IMPORTED_MODULE_2__[\"pointwiseConvLayer\"])(conv3, params.conv_4, [1, 1]);\r\n        var conv5 = Object(_pointwiseConvLayer__WEBPACK_IMPORTED_MODULE_2__[\"pointwiseConvLayer\"])(conv4, params.conv_5, [2, 2]);\r\n        var conv6 = Object(_pointwiseConvLayer__WEBPACK_IMPORTED_MODULE_2__[\"pointwiseConvLayer\"])(conv5, params.conv_6, [1, 1]);\r\n        var conv7 = Object(_pointwiseConvLayer__WEBPACK_IMPORTED_MODULE_2__[\"pointwiseConvLayer\"])(conv6, params.conv_7, [2, 2]);\r\n        var boxPrediction0 = Object(_boxPredictionLayer__WEBPACK_IMPORTED_MODULE_1__[\"boxPredictionLayer\"])(conv11, params.box_predictor_0);\r\n        var boxPrediction1 = Object(_boxPredictionLayer__WEBPACK_IMPORTED_MODULE_1__[\"boxPredictionLayer\"])(x, params.box_predictor_1);\r\n        var boxPrediction2 = Object(_boxPredictionLayer__WEBPACK_IMPORTED_MODULE_1__[\"boxPredictionLayer\"])(conv1, params.box_predictor_2);\r\n        var boxPrediction3 = Object(_boxPredictionLayer__WEBPACK_IMPORTED_MODULE_1__[\"boxPredictionLayer\"])(conv3, params.box_predictor_3);\r\n        var boxPrediction4 = Object(_boxPredictionLayer__WEBPACK_IMPORTED_MODULE_1__[\"boxPredictionLayer\"])(conv5, params.box_predictor_4);\r\n        var boxPrediction5 = Object(_boxPredictionLayer__WEBPACK_IMPORTED_MODULE_1__[\"boxPredictionLayer\"])(conv7, params.box_predictor_5);\r\n        var boxPredictions = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"concat\"]([\r\n            boxPrediction0.boxPredictionEncoding,\r\n            boxPrediction1.boxPredictionEncoding,\r\n            boxPrediction2.boxPredictionEncoding,\r\n            boxPrediction3.boxPredictionEncoding,\r\n            boxPrediction4.boxPredictionEncoding,\r\n            boxPrediction5.boxPredictionEncoding\r\n        ], 1);\r\n        var classPredictions = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"concat\"]([\r\n            boxPrediction0.classPrediction,\r\n            boxPrediction1.classPrediction,\r\n            boxPrediction2.classPrediction,\r\n            boxPrediction3.classPrediction,\r\n            boxPrediction4.classPrediction,\r\n            boxPrediction5.classPrediction\r\n        ], 1);\r\n        return {\r\n            boxPredictions: boxPredictions,\r\n            classPredictions: classPredictions\r\n        };\r\n    });\r\n}\r\n//# sourceMappingURL=predictionLayer.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/ssdMobilenetv1/predictionLayer.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/tinyFaceDetector/TinyFaceDetector.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/tinyFaceDetector/TinyFaceDetector.js ***!
  \*********************************************************************************/
/*! exports provided: TinyFaceDetector */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TinyFaceDetector\", function() { return TinyFaceDetector; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _classes__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../classes */ \"./node_modules/face-api.js/build/es6/classes/index.js\");\n/* harmony import */ var _const__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./const */ \"./node_modules/face-api.js/build/es6/tinyFaceDetector/const.js\");\n\r\n\r\n\r\n\r\nvar TinyFaceDetector = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(TinyFaceDetector, _super);\r\n    function TinyFaceDetector() {\r\n        var _this = this;\r\n        var config = {\r\n            withSeparableConvs: true,\r\n            iouThreshold: _const__WEBPACK_IMPORTED_MODULE_3__[\"IOU_THRESHOLD\"],\r\n            classes: ['face'],\r\n            anchors: _const__WEBPACK_IMPORTED_MODULE_3__[\"BOX_ANCHORS\"],\r\n            meanRgb: _const__WEBPACK_IMPORTED_MODULE_3__[\"MEAN_RGB\"],\r\n            isFirstLayerConv2d: true,\r\n            filterSizes: [3, 16, 32, 64, 128, 256, 512]\r\n        };\r\n        _this = _super.call(this, config) || this;\r\n        return _this;\r\n    }\r\n    Object.defineProperty(TinyFaceDetector.prototype, \"anchors\", {\r\n        get: function () {\r\n            return this.config.anchors;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    TinyFaceDetector.prototype.locateFaces = function (input, forwardParams) {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var objectDetections;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, this.detect(input, forwardParams)];\r\n                    case 1:\r\n                        objectDetections = _a.sent();\r\n                        return [2 /*return*/, objectDetections.map(function (det) { return new _classes__WEBPACK_IMPORTED_MODULE_2__[\"FaceDetection\"](det.score, det.relativeBox, { width: det.imageWidth, height: det.imageHeight }); })];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    TinyFaceDetector.prototype.getDefaultModelName = function () {\r\n        return 'tiny_face_detector_model';\r\n    };\r\n    TinyFaceDetector.prototype.extractParamsFromWeigthMap = function (weightMap) {\r\n        return _super.prototype.extractParamsFromWeigthMap.call(this, weightMap);\r\n    };\r\n    return TinyFaceDetector;\r\n}(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"TfjsImageRecognitionBase\"].TinyYolov2));\r\n\r\n//# sourceMappingURL=TinyFaceDetector.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/tinyFaceDetector/TinyFaceDetector.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/tinyFaceDetector/TinyFaceDetectorOptions.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/tinyFaceDetector/TinyFaceDetectorOptions.js ***!
  \****************************************************************************************/
/*! exports provided: TinyFaceDetectorOptions */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TinyFaceDetectorOptions\", function() { return TinyFaceDetectorOptions; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n\r\n\r\nvar TinyFaceDetectorOptions = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(TinyFaceDetectorOptions, _super);\r\n    function TinyFaceDetectorOptions() {\r\n        var _this = _super !== null && _super.apply(this, arguments) || this;\r\n        _this._name = 'TinyFaceDetectorOptions';\r\n        return _this;\r\n    }\r\n    return TinyFaceDetectorOptions;\r\n}(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"TfjsImageRecognitionBase\"].TinyYolov2Options));\r\n\r\n//# sourceMappingURL=TinyFaceDetectorOptions.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/tinyFaceDetector/TinyFaceDetectorOptions.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/tinyFaceDetector/const.js":
/*!**********************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/tinyFaceDetector/const.js ***!
  \**********************************************************************/
/*! exports provided: IOU_THRESHOLD, BOX_ANCHORS, MEAN_RGB */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"IOU_THRESHOLD\", function() { return IOU_THRESHOLD; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"BOX_ANCHORS\", function() { return BOX_ANCHORS; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"MEAN_RGB\", function() { return MEAN_RGB; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n\r\nvar IOU_THRESHOLD = 0.4;\r\nvar BOX_ANCHORS = [\r\n    new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Point\"](1.603231, 2.094468),\r\n    new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Point\"](6.041143, 7.080126),\r\n    new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Point\"](2.882459, 3.518061),\r\n    new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Point\"](4.266906, 5.178857),\r\n    new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Point\"](9.041765, 10.66308)\r\n];\r\nvar MEAN_RGB = [117.001, 114.697, 97.404];\r\n//# sourceMappingURL=const.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/tinyFaceDetector/const.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/tinyFaceDetector/index.js":
/*!**********************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/tinyFaceDetector/index.js ***!
  \**********************************************************************/
/*! exports provided: TinyFaceDetector, TinyFaceDetectorOptions, createTinyFaceDetector */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"createTinyFaceDetector\", function() { return createTinyFaceDetector; });\n/* harmony import */ var _TinyFaceDetector__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./TinyFaceDetector */ \"./node_modules/face-api.js/build/es6/tinyFaceDetector/TinyFaceDetector.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TinyFaceDetector\", function() { return _TinyFaceDetector__WEBPACK_IMPORTED_MODULE_0__[\"TinyFaceDetector\"]; });\n\n/* harmony import */ var _TinyFaceDetectorOptions__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./TinyFaceDetectorOptions */ \"./node_modules/face-api.js/build/es6/tinyFaceDetector/TinyFaceDetectorOptions.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TinyFaceDetectorOptions\", function() { return _TinyFaceDetectorOptions__WEBPACK_IMPORTED_MODULE_1__[\"TinyFaceDetectorOptions\"]; });\n\n\r\n\r\n\r\nfunction createTinyFaceDetector(weights) {\r\n    var net = new _TinyFaceDetector__WEBPACK_IMPORTED_MODULE_0__[\"TinyFaceDetector\"]();\r\n    net.extractWeights(weights);\r\n    return net;\r\n}\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/tinyFaceDetector/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/tinyYolov2/TinyYolov2.js":
/*!*********************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/tinyYolov2/TinyYolov2.js ***!
  \*********************************************************************/
/*! exports provided: TinyYolov2 */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TinyYolov2\", function() { return TinyYolov2; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _classes__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../classes */ \"./node_modules/face-api.js/build/es6/classes/index.js\");\n/* harmony import */ var _const__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./const */ \"./node_modules/face-api.js/build/es6/tinyYolov2/const.js\");\n\r\n\r\n\r\n\r\nvar TinyYolov2 = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(TinyYolov2, _super);\r\n    function TinyYolov2(withSeparableConvs) {\r\n        if (withSeparableConvs === void 0) { withSeparableConvs = true; }\r\n        var _this = this;\r\n        var config = Object.assign({}, {\r\n            withSeparableConvs: withSeparableConvs,\r\n            iouThreshold: _const__WEBPACK_IMPORTED_MODULE_3__[\"IOU_THRESHOLD\"],\r\n            classes: ['face']\r\n        }, withSeparableConvs\r\n            ? {\r\n                anchors: _const__WEBPACK_IMPORTED_MODULE_3__[\"BOX_ANCHORS_SEPARABLE\"],\r\n                meanRgb: _const__WEBPACK_IMPORTED_MODULE_3__[\"MEAN_RGB_SEPARABLE\"]\r\n            }\r\n            : {\r\n                anchors: _const__WEBPACK_IMPORTED_MODULE_3__[\"BOX_ANCHORS\"],\r\n                withClassScores: true\r\n            });\r\n        _this = _super.call(this, config) || this;\r\n        return _this;\r\n    }\r\n    Object.defineProperty(TinyYolov2.prototype, \"withSeparableConvs\", {\r\n        get: function () {\r\n            return this.config.withSeparableConvs;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(TinyYolov2.prototype, \"anchors\", {\r\n        get: function () {\r\n            return this.config.anchors;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    TinyYolov2.prototype.locateFaces = function (input, forwardParams) {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var objectDetections;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, this.detect(input, forwardParams)];\r\n                    case 1:\r\n                        objectDetections = _a.sent();\r\n                        return [2 /*return*/, objectDetections.map(function (det) { return new _classes__WEBPACK_IMPORTED_MODULE_2__[\"FaceDetection\"](det.score, det.relativeBox, { width: det.imageWidth, height: det.imageHeight }); })];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    TinyYolov2.prototype.getDefaultModelName = function () {\r\n        return this.withSeparableConvs ? _const__WEBPACK_IMPORTED_MODULE_3__[\"DEFAULT_MODEL_NAME_SEPARABLE_CONV\"] : _const__WEBPACK_IMPORTED_MODULE_3__[\"DEFAULT_MODEL_NAME\"];\r\n    };\r\n    TinyYolov2.prototype.extractParamsFromWeigthMap = function (weightMap) {\r\n        return _super.prototype.extractParamsFromWeigthMap.call(this, weightMap);\r\n    };\r\n    return TinyYolov2;\r\n}(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_1__[\"TfjsImageRecognitionBase\"].TinyYolov2));\r\n\r\n//# sourceMappingURL=TinyYolov2.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/tinyYolov2/TinyYolov2.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/tinyYolov2/const.js":
/*!****************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/tinyYolov2/const.js ***!
  \****************************************************************/
/*! exports provided: IOU_THRESHOLD, BOX_ANCHORS, BOX_ANCHORS_SEPARABLE, MEAN_RGB_SEPARABLE, DEFAULT_MODEL_NAME, DEFAULT_MODEL_NAME_SEPARABLE_CONV */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"IOU_THRESHOLD\", function() { return IOU_THRESHOLD; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"BOX_ANCHORS\", function() { return BOX_ANCHORS; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"BOX_ANCHORS_SEPARABLE\", function() { return BOX_ANCHORS_SEPARABLE; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"MEAN_RGB_SEPARABLE\", function() { return MEAN_RGB_SEPARABLE; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DEFAULT_MODEL_NAME\", function() { return DEFAULT_MODEL_NAME; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DEFAULT_MODEL_NAME_SEPARABLE_CONV\", function() { return DEFAULT_MODEL_NAME_SEPARABLE_CONV; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n\r\nvar IOU_THRESHOLD = 0.4;\r\nvar BOX_ANCHORS = [\r\n    new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Point\"](0.738768, 0.874946),\r\n    new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Point\"](2.42204, 2.65704),\r\n    new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Point\"](4.30971, 7.04493),\r\n    new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Point\"](10.246, 4.59428),\r\n    new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Point\"](12.6868, 11.8741)\r\n];\r\nvar BOX_ANCHORS_SEPARABLE = [\r\n    new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Point\"](1.603231, 2.094468),\r\n    new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Point\"](6.041143, 7.080126),\r\n    new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Point\"](2.882459, 3.518061),\r\n    new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Point\"](4.266906, 5.178857),\r\n    new tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"Point\"](9.041765, 10.66308)\r\n];\r\nvar MEAN_RGB_SEPARABLE = [117.001, 114.697, 97.404];\r\nvar DEFAULT_MODEL_NAME = 'tiny_yolov2_model';\r\nvar DEFAULT_MODEL_NAME_SEPARABLE_CONV = 'tiny_yolov2_separable_conv_model';\r\n//# sourceMappingURL=const.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/tinyYolov2/const.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/tinyYolov2/index.js":
/*!****************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/tinyYolov2/index.js ***!
  \****************************************************************/
/*! exports provided: TinyYolov2, createTinyYolov2 */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"createTinyYolov2\", function() { return createTinyYolov2; });\n/* harmony import */ var _TinyYolov2__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./TinyYolov2 */ \"./node_modules/face-api.js/build/es6/tinyYolov2/TinyYolov2.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TinyYolov2\", function() { return _TinyYolov2__WEBPACK_IMPORTED_MODULE_0__[\"TinyYolov2\"]; });\n\n\r\n\r\nfunction createTinyYolov2(weights, withSeparableConvs) {\r\n    if (withSeparableConvs === void 0) { withSeparableConvs = true; }\r\n    var net = new _TinyYolov2__WEBPACK_IMPORTED_MODULE_0__[\"TinyYolov2\"](withSeparableConvs);\r\n    net.extractWeights(weights);\r\n    return net;\r\n}\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/tinyYolov2/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/xception/TinyXception.js":
/*!*********************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/xception/TinyXception.js ***!
  \*********************************************************************/
/*! exports provided: TinyXception */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TinyXception\", function() { return TinyXception; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _common_depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common/depthwiseSeparableConv */ \"./node_modules/face-api.js/build/es6/common/depthwiseSeparableConv.js\");\n/* harmony import */ var _extractParams__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./extractParams */ \"./node_modules/face-api.js/build/es6/xception/extractParams.js\");\n/* harmony import */ var _extractParamsFromWeigthMap__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./extractParamsFromWeigthMap */ \"./node_modules/face-api.js/build/es6/xception/extractParamsFromWeigthMap.js\");\n\r\n\r\n\r\n\r\n\r\n\r\nfunction conv(x, params, stride) {\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"add\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"conv2d\"](x, params.filters, stride, 'same'), params.bias);\r\n}\r\nfunction reductionBlock(x, params, isActivateInput) {\r\n    if (isActivateInput === void 0) { isActivateInput = true; }\r\n    var out = isActivateInput ? _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"relu\"](x) : x;\r\n    out = Object(_common_depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_3__[\"depthwiseSeparableConv\"])(out, params.separable_conv0, [1, 1]);\r\n    out = Object(_common_depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_3__[\"depthwiseSeparableConv\"])(_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"relu\"](out), params.separable_conv1, [1, 1]);\r\n    out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"maxPool\"](out, [3, 3], [2, 2], 'same');\r\n    out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"add\"](out, conv(x, params.expansion_conv, [2, 2]));\r\n    return out;\r\n}\r\nfunction mainBlock(x, params) {\r\n    var out = Object(_common_depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_3__[\"depthwiseSeparableConv\"])(_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"relu\"](x), params.separable_conv0, [1, 1]);\r\n    out = Object(_common_depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_3__[\"depthwiseSeparableConv\"])(_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"relu\"](out), params.separable_conv1, [1, 1]);\r\n    out = Object(_common_depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_3__[\"depthwiseSeparableConv\"])(_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"relu\"](out), params.separable_conv2, [1, 1]);\r\n    out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"add\"](out, x);\r\n    return out;\r\n}\r\nvar TinyXception = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(TinyXception, _super);\r\n    function TinyXception(numMainBlocks) {\r\n        var _this = _super.call(this, 'TinyXception') || this;\r\n        _this._numMainBlocks = numMainBlocks;\r\n        return _this;\r\n    }\r\n    TinyXception.prototype.forwardInput = function (input) {\r\n        var _this = this;\r\n        var params = this.params;\r\n        if (!params) {\r\n            throw new Error('TinyXception - load model before inference');\r\n        }\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tidy\"](function () {\r\n            var batchTensor = input.toBatchTensor(112, true);\r\n            var meanRgb = [122.782, 117.001, 104.298];\r\n            var normalized = Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"normalize\"])(batchTensor, meanRgb).div(_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"scalar\"](256));\r\n            var out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"relu\"](conv(normalized, params.entry_flow.conv_in, [2, 2]));\r\n            out = reductionBlock(out, params.entry_flow.reduction_block_0, false);\r\n            out = reductionBlock(out, params.entry_flow.reduction_block_1);\r\n            Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"range\"])(_this._numMainBlocks, 0, 1).forEach(function (idx) {\r\n                out = mainBlock(out, params.middle_flow[\"main_block_\" + idx]);\r\n            });\r\n            out = reductionBlock(out, params.exit_flow.reduction_block);\r\n            out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"relu\"](Object(_common_depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_3__[\"depthwiseSeparableConv\"])(out, params.exit_flow.separable_conv, [1, 1]));\r\n            return out;\r\n        });\r\n    };\r\n    TinyXception.prototype.forward = function (input) {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var _a;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this.forwardInput;\r\n                        return [4 /*yield*/, Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"toNetInput\"])(input)];\r\n                    case 1: return [2 /*return*/, _a.apply(this, [_b.sent()])];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    TinyXception.prototype.getDefaultModelName = function () {\r\n        return 'tiny_xception_model';\r\n    };\r\n    TinyXception.prototype.extractParamsFromWeigthMap = function (weightMap) {\r\n        return Object(_extractParamsFromWeigthMap__WEBPACK_IMPORTED_MODULE_5__[\"extractParamsFromWeigthMap\"])(weightMap, this._numMainBlocks);\r\n    };\r\n    TinyXception.prototype.extractParams = function (weights) {\r\n        return Object(_extractParams__WEBPACK_IMPORTED_MODULE_4__[\"extractParams\"])(weights, this._numMainBlocks);\r\n    };\r\n    return TinyXception;\r\n}(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_2__[\"NeuralNetwork\"]));\r\n\r\n//# sourceMappingURL=TinyXception.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/xception/TinyXception.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/xception/extractParams.js":
/*!**********************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/xception/extractParams.js ***!
  \**********************************************************************/
/*! exports provided: extractParams */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractParams\", function() { return extractParams; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n\r\nfunction extractorsFactory(extractWeights, paramMappings) {\r\n    var extractConvParams = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].extractConvParamsFactory(extractWeights, paramMappings);\r\n    var extractSeparableConvParams = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].extractSeparableConvParamsFactory(extractWeights, paramMappings);\r\n    function extractReductionBlockParams(channelsIn, channelsOut, mappedPrefix) {\r\n        var separable_conv0 = extractSeparableConvParams(channelsIn, channelsOut, mappedPrefix + \"/separable_conv0\");\r\n        var separable_conv1 = extractSeparableConvParams(channelsOut, channelsOut, mappedPrefix + \"/separable_conv1\");\r\n        var expansion_conv = extractConvParams(channelsIn, channelsOut, 1, mappedPrefix + \"/expansion_conv\");\r\n        return { separable_conv0: separable_conv0, separable_conv1: separable_conv1, expansion_conv: expansion_conv };\r\n    }\r\n    function extractMainBlockParams(channels, mappedPrefix) {\r\n        var separable_conv0 = extractSeparableConvParams(channels, channels, mappedPrefix + \"/separable_conv0\");\r\n        var separable_conv1 = extractSeparableConvParams(channels, channels, mappedPrefix + \"/separable_conv1\");\r\n        var separable_conv2 = extractSeparableConvParams(channels, channels, mappedPrefix + \"/separable_conv2\");\r\n        return { separable_conv0: separable_conv0, separable_conv1: separable_conv1, separable_conv2: separable_conv2 };\r\n    }\r\n    return {\r\n        extractConvParams: extractConvParams,\r\n        extractSeparableConvParams: extractSeparableConvParams,\r\n        extractReductionBlockParams: extractReductionBlockParams,\r\n        extractMainBlockParams: extractMainBlockParams\r\n    };\r\n}\r\nfunction extractParams(weights, numMainBlocks) {\r\n    var paramMappings = [];\r\n    var _a = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].extractWeightsFactory(weights), extractWeights = _a.extractWeights, getRemainingWeights = _a.getRemainingWeights;\r\n    var _b = extractorsFactory(extractWeights, paramMappings), extractConvParams = _b.extractConvParams, extractSeparableConvParams = _b.extractSeparableConvParams, extractReductionBlockParams = _b.extractReductionBlockParams, extractMainBlockParams = _b.extractMainBlockParams;\r\n    var entry_flow_conv_in = extractConvParams(3, 32, 3, 'entry_flow/conv_in');\r\n    var entry_flow_reduction_block_0 = extractReductionBlockParams(32, 64, 'entry_flow/reduction_block_0');\r\n    var entry_flow_reduction_block_1 = extractReductionBlockParams(64, 128, 'entry_flow/reduction_block_1');\r\n    var entry_flow = {\r\n        conv_in: entry_flow_conv_in,\r\n        reduction_block_0: entry_flow_reduction_block_0,\r\n        reduction_block_1: entry_flow_reduction_block_1\r\n    };\r\n    var middle_flow = {};\r\n    Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"range\"])(numMainBlocks, 0, 1).forEach(function (idx) {\r\n        middle_flow[\"main_block_\" + idx] = extractMainBlockParams(128, \"middle_flow/main_block_\" + idx);\r\n    });\r\n    var exit_flow_reduction_block = extractReductionBlockParams(128, 256, 'exit_flow/reduction_block');\r\n    var exit_flow_separable_conv = extractSeparableConvParams(256, 512, 'exit_flow/separable_conv');\r\n    var exit_flow = {\r\n        reduction_block: exit_flow_reduction_block,\r\n        separable_conv: exit_flow_separable_conv\r\n    };\r\n    if (getRemainingWeights().length !== 0) {\r\n        throw new Error(\"weights remaing after extract: \" + getRemainingWeights().length);\r\n    }\r\n    return {\r\n        paramMappings: paramMappings,\r\n        params: { entry_flow: entry_flow, middle_flow: middle_flow, exit_flow: exit_flow }\r\n    };\r\n}\r\n//# sourceMappingURL=extractParams.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/xception/extractParams.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/es6/xception/extractParamsFromWeigthMap.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/es6/xception/extractParamsFromWeigthMap.js ***!
  \***********************************************************************************/
/*! exports provided: extractParamsFromWeigthMap */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractParamsFromWeigthMap\", function() { return extractParamsFromWeigthMap; });\n/* harmony import */ var tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tfjs-image-recognition-base */ \"./node_modules/tfjs-image-recognition-base/build/es6/index.js\");\n/* harmony import */ var _common_loadConvParamsFactory__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/loadConvParamsFactory */ \"./node_modules/face-api.js/build/es6/common/loadConvParamsFactory.js\");\n\r\n\r\nfunction loadParamsFactory(weightMap, paramMappings) {\r\n    var extractWeightEntry = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].extractWeightEntryFactory(weightMap, paramMappings);\r\n    var extractConvParams = Object(_common_loadConvParamsFactory__WEBPACK_IMPORTED_MODULE_1__[\"loadConvParamsFactory\"])(extractWeightEntry);\r\n    var extractSeparableConvParams = tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].loadSeparableConvParamsFactory(extractWeightEntry);\r\n    function extractReductionBlockParams(mappedPrefix) {\r\n        var separable_conv0 = extractSeparableConvParams(mappedPrefix + \"/separable_conv0\");\r\n        var separable_conv1 = extractSeparableConvParams(mappedPrefix + \"/separable_conv1\");\r\n        var expansion_conv = extractConvParams(mappedPrefix + \"/expansion_conv\");\r\n        return { separable_conv0: separable_conv0, separable_conv1: separable_conv1, expansion_conv: expansion_conv };\r\n    }\r\n    function extractMainBlockParams(mappedPrefix) {\r\n        var separable_conv0 = extractSeparableConvParams(mappedPrefix + \"/separable_conv0\");\r\n        var separable_conv1 = extractSeparableConvParams(mappedPrefix + \"/separable_conv1\");\r\n        var separable_conv2 = extractSeparableConvParams(mappedPrefix + \"/separable_conv2\");\r\n        return { separable_conv0: separable_conv0, separable_conv1: separable_conv1, separable_conv2: separable_conv2 };\r\n    }\r\n    return {\r\n        extractConvParams: extractConvParams,\r\n        extractSeparableConvParams: extractSeparableConvParams,\r\n        extractReductionBlockParams: extractReductionBlockParams,\r\n        extractMainBlockParams: extractMainBlockParams\r\n    };\r\n}\r\nfunction extractParamsFromWeigthMap(weightMap, numMainBlocks) {\r\n    var paramMappings = [];\r\n    var _a = loadParamsFactory(weightMap, paramMappings), extractConvParams = _a.extractConvParams, extractSeparableConvParams = _a.extractSeparableConvParams, extractReductionBlockParams = _a.extractReductionBlockParams, extractMainBlockParams = _a.extractMainBlockParams;\r\n    var entry_flow_conv_in = extractConvParams('entry_flow/conv_in');\r\n    var entry_flow_reduction_block_0 = extractReductionBlockParams('entry_flow/reduction_block_0');\r\n    var entry_flow_reduction_block_1 = extractReductionBlockParams('entry_flow/reduction_block_1');\r\n    var entry_flow = {\r\n        conv_in: entry_flow_conv_in,\r\n        reduction_block_0: entry_flow_reduction_block_0,\r\n        reduction_block_1: entry_flow_reduction_block_1\r\n    };\r\n    var middle_flow = {};\r\n    Object(tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"range\"])(numMainBlocks, 0, 1).forEach(function (idx) {\r\n        middle_flow[\"main_block_\" + idx] = extractMainBlockParams(\"middle_flow/main_block_\" + idx);\r\n    });\r\n    var exit_flow_reduction_block = extractReductionBlockParams('exit_flow/reduction_block');\r\n    var exit_flow_separable_conv = extractSeparableConvParams('exit_flow/separable_conv');\r\n    var exit_flow = {\r\n        reduction_block: exit_flow_reduction_block,\r\n        separable_conv: exit_flow_separable_conv\r\n    };\r\n    tfjs_image_recognition_base__WEBPACK_IMPORTED_MODULE_0__[\"TfjsImageRecognitionBase\"].disposeUnusedWeightTensors(weightMap, paramMappings);\r\n    return { params: { entry_flow: entry_flow, middle_flow: middle_flow, exit_flow: exit_flow }, paramMappings: paramMappings };\r\n}\r\n//# sourceMappingURL=extractParamsFromWeigthMap.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/es6/xception/extractParamsFromWeigthMap.js?");

/***/ }),

/***/ "./node_modules/gsap/AttrPlugin.js":
/*!*****************************************!*\
  !*** ./node_modules/gsap/AttrPlugin.js ***!
  \*****************************************/
/*! exports provided: AttrPlugin, default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AttrPlugin\", function() { return AttrPlugin; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"default\", function() { return AttrPlugin; });\n/* harmony import */ var _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./TweenLite.js */ \"./node_modules/gsap/TweenLite.js\");\n/*!\n * VERSION: 0.6.1\n * DATE: 2018-08-27\n * UPDATES AND DOCS AT: http://greensock.com\n *\n * @license Copyright (c) 2008-2019, GreenSock. All rights reserved.\n * This work is subject to the terms at http://greensock.com/standard-license or for\n * Club GreenSock members, the software agreement that was issued with your membership.\n * \n * @author: Jack Doyle, jack@greensock.com\n */\n/* eslint-disable */\n\n\n\nvar AttrPlugin = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"_gsScope\"]._gsDefine.plugin({\n\tpropName: \"attr\",\n\tAPI: 2,\n\tversion: \"0.6.1\",\n\n\t//called when the tween renders for the first time. This is where initial values should be recorded and any setup routines should run.\n\tinit: function(target, value, tween, index) {\n\t\tvar p, end;\n\t\tif (typeof(target.setAttribute) !== \"function\") {\n\t\t\treturn false;\n\t\t}\n\t\tfor (p in value) {\n\t\t\tend = value[p];\n\t\t\tif (typeof(end) === \"function\") {\n\t\t\t\tend = end(index, target);\n\t\t\t}\n\t\t\tthis._addTween(target, \"setAttribute\", target.getAttribute(p) + \"\", end + \"\", p, false, p);\n\t\t\tthis._overwriteProps.push(p);\n\t\t}\n\t\treturn true;\n\t}\n\n});\n\n\n\n\n\n\n\n//# sourceURL=webpack:///./node_modules/gsap/AttrPlugin.js?");

/***/ }),

/***/ "./node_modules/gsap/BezierPlugin.js":
/*!*******************************************!*\
  !*** ./node_modules/gsap/BezierPlugin.js ***!
  \*******************************************/
/*! exports provided: BezierPlugin, default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"BezierPlugin\", function() { return BezierPlugin; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"default\", function() { return BezierPlugin; });\n/* harmony import */ var _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./TweenLite.js */ \"./node_modules/gsap/TweenLite.js\");\n/*!\n * VERSION: 1.3.9\n * DATE: 2019-05-17\n * UPDATES AND DOCS AT: http://greensock.com\n *\n * @license Copyright (c) 2008-2019, GreenSock. All rights reserved.\n * This work is subject to the terms at http://greensock.com/standard-license or for\n * Club GreenSock members, the software agreement that was issued with your membership.\n * \n * @author: Jack Doyle, jack@greensock.com\n **/\n/* eslint-disable */\n\n\n\t\tvar _RAD2DEG = 180 / Math.PI,\n\t\t\t_r1 = [],\n\t\t\t_r2 = [],\n\t\t\t_r3 = [],\n\t\t\t_corProps = {},\n\t\t\t_globals = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"_gsScope\"]._gsDefine.globals,\n\t\t\tSegment = function(a, b, c, d) {\n\t\t\t\tif (c === d) { //if c and d match, the final autoRotate value could lock at -90 degrees, so differentiate them slightly.\n\t\t\t\t\tc = d - (d - b) / 1000000;\n\t\t\t\t}\n\t\t\t\tif (a === b) { //if a and b match, the starting autoRotate value could lock at -90 degrees, so differentiate them slightly.\n\t\t\t\t\tb = a + (c - a) / 1000000;\n\t\t\t\t}\n\t\t\t\tthis.a = a;\n\t\t\t\tthis.b = b;\n\t\t\t\tthis.c = c;\n\t\t\t\tthis.d = d;\n\t\t\t\tthis.da = d - a;\n\t\t\t\tthis.ca = c - a;\n\t\t\t\tthis.ba = b - a;\n\t\t\t},\n\t\t\t_correlate = \",x,y,z,left,top,right,bottom,marginTop,marginLeft,marginRight,marginBottom,paddingLeft,paddingTop,paddingRight,paddingBottom,backgroundPosition,backgroundPosition_y,\",\n\t\t\tcubicToQuadratic = function(a, b, c, d) {\n\t\t\t\tvar q1 = {a:a},\n\t\t\t\t\tq2 = {},\n\t\t\t\t\tq3 = {},\n\t\t\t\t\tq4 = {c:d},\n\t\t\t\t\tmab = (a + b) / 2,\n\t\t\t\t\tmbc = (b + c) / 2,\n\t\t\t\t\tmcd = (c + d) / 2,\n\t\t\t\t\tmabc = (mab + mbc) / 2,\n\t\t\t\t\tmbcd = (mbc + mcd) / 2,\n\t\t\t\t\tm8 = (mbcd - mabc) / 8;\n\t\t\t\tq1.b = mab + (a - mab) / 4;\n\t\t\t\tq2.b = mabc + m8;\n\t\t\t\tq1.c = q2.a = (q1.b + q2.b) / 2;\n\t\t\t\tq2.c = q3.a = (mabc + mbcd) / 2;\n\t\t\t\tq3.b = mbcd - m8;\n\t\t\t\tq4.b = mcd + (d - mcd) / 4;\n\t\t\t\tq3.c = q4.a = (q3.b + q4.b) / 2;\n\t\t\t\treturn [q1, q2, q3, q4];\n\t\t\t},\n\t\t\t_calculateControlPoints = function(a, curviness, quad, basic, correlate) {\n\t\t\t\tvar l = a.length - 1,\n\t\t\t\t\tii = 0,\n\t\t\t\t\tcp1 = a[0].a,\n\t\t\t\t\ti, p1, p2, p3, seg, m1, m2, mm, cp2, qb, r1, r2, tl;\n\t\t\t\tfor (i = 0; i < l; i++) {\n\t\t\t\t\tseg = a[ii];\n\t\t\t\t\tp1 = seg.a;\n\t\t\t\t\tp2 = seg.d;\n\t\t\t\t\tp3 = a[ii+1].d;\n\n\t\t\t\t\tif (correlate) {\n\t\t\t\t\t\tr1 = _r1[i];\n\t\t\t\t\t\tr2 = _r2[i];\n\t\t\t\t\t\ttl = ((r2 + r1) * curviness * 0.25) / (basic ? 0.5 : _r3[i] || 0.5);\n\t\t\t\t\t\tm1 = p2 - (p2 - p1) * (basic ? curviness * 0.5 : (r1 !== 0 ? tl / r1 : 0));\n\t\t\t\t\t\tm2 = p2 + (p3 - p2) * (basic ? curviness * 0.5 : (r2 !== 0 ? tl / r2 : 0));\n\t\t\t\t\t\tmm = p2 - (m1 + (((m2 - m1) * ((r1 * 3 / (r1 + r2)) + 0.5) / 4) || 0));\n\t\t\t\t\t} else {\n\t\t\t\t\t\tm1 = p2 - (p2 - p1) * curviness * 0.5;\n\t\t\t\t\t\tm2 = p2 + (p3 - p2) * curviness * 0.5;\n\t\t\t\t\t\tmm = p2 - (m1 + m2) / 2;\n\t\t\t\t\t}\n\t\t\t\t\tm1 += mm;\n\t\t\t\t\tm2 += mm;\n\n\t\t\t\t\tseg.c = cp2 = m1;\n\t\t\t\t\tif (i !== 0) {\n\t\t\t\t\t\tseg.b = cp1;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tseg.b = cp1 = seg.a + (seg.c - seg.a) * 0.6; //instead of placing b on a exactly, we move it inline with c so that if the user specifies an ease like Back.easeIn or Elastic.easeIn which goes BEYOND the beginning, it will do so smoothly.\n\t\t\t\t\t}\n\n\t\t\t\t\tseg.da = p2 - p1;\n\t\t\t\t\tseg.ca = cp2 - p1;\n\t\t\t\t\tseg.ba = cp1 - p1;\n\n\t\t\t\t\tif (quad) {\n\t\t\t\t\t\tqb = cubicToQuadratic(p1, cp1, cp2, p2);\n\t\t\t\t\t\ta.splice(ii, 1, qb[0], qb[1], qb[2], qb[3]);\n\t\t\t\t\t\tii += 4;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tii++;\n\t\t\t\t\t}\n\n\t\t\t\t\tcp1 = m2;\n\t\t\t\t}\n\t\t\t\tseg = a[ii];\n\t\t\t\tseg.b = cp1;\n\t\t\t\tseg.c = cp1 + (seg.d - cp1) * 0.4; //instead of placing c on d exactly, we move it inline with b so that if the user specifies an ease like Back.easeOut or Elastic.easeOut which goes BEYOND the end, it will do so smoothly.\n\t\t\t\tseg.da = seg.d - seg.a;\n\t\t\t\tseg.ca = seg.c - seg.a;\n\t\t\t\tseg.ba = cp1 - seg.a;\n\t\t\t\tif (quad) {\n\t\t\t\t\tqb = cubicToQuadratic(seg.a, cp1, seg.c, seg.d);\n\t\t\t\t\ta.splice(ii, 1, qb[0], qb[1], qb[2], qb[3]);\n\t\t\t\t}\n\t\t\t},\n\t\t\t_parseAnchors = function(values, p, correlate, prepend) {\n\t\t\t\tvar a = [],\n\t\t\t\t\tl, i, p1, p2, p3, tmp;\n\t\t\t\tif (prepend) {\n\t\t\t\t\tvalues = [prepend].concat(values);\n\t\t\t\t\ti = values.length;\n\t\t\t\t\twhile (--i > -1) {\n\t\t\t\t\t\tif (typeof( (tmp = values[i][p]) ) === \"string\") if (tmp.charAt(1) === \"=\") {\n\t\t\t\t\t\t\tvalues[i][p] = prepend[p] + Number(tmp.charAt(0) + tmp.substr(2)); //accommodate relative values. Do it inline instead of breaking it out into a function for speed reasons\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tl = values.length - 2;\n\t\t\t\tif (l < 0) {\n\t\t\t\t\ta[0] = new Segment(values[0][p], 0, 0, values[0][p]);\n\t\t\t\t\treturn a;\n\t\t\t\t}\n\t\t\t\tfor (i = 0; i < l; i++) {\n\t\t\t\t\tp1 = values[i][p];\n\t\t\t\t\tp2 = values[i+1][p];\n\t\t\t\t\ta[i] = new Segment(p1, 0, 0, p2);\n\t\t\t\t\tif (correlate) {\n\t\t\t\t\t\tp3 = values[i+2][p];\n\t\t\t\t\t\t_r1[i] = (_r1[i] || 0) + (p2 - p1) * (p2 - p1);\n\t\t\t\t\t\t_r2[i] = (_r2[i] || 0) + (p3 - p2) * (p3 - p2);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ta[i] = new Segment(values[i][p], 0, 0, values[i+1][p]);\n\t\t\t\treturn a;\n\t\t\t},\n\t\t\tbezierThrough = function(values, curviness, quadratic, basic, correlate, prepend) {\n\t\t\t\tvar obj = {},\n\t\t\t\t\tprops = [],\n\t\t\t\t\tfirst = prepend || values[0],\n\t\t\t\t\ti, p, a, j, r, l, seamless, last;\n\t\t\t\tcorrelate = (typeof(correlate) === \"string\") ? \",\"+correlate+\",\" : _correlate;\n\t\t\t\tif (curviness == null) {\n\t\t\t\t\tcurviness = 1;\n\t\t\t\t}\n\t\t\t\tfor (p in values[0]) {\n\t\t\t\t\tprops.push(p);\n\t\t\t\t}\n\t\t\t\t//check to see if the last and first values are identical (well, within 0.05). If so, make seamless by appending the second element to the very end of the values array and the 2nd-to-last element to the very beginning (we'll remove those segments later)\n\t\t\t\tif (values.length > 1) {\n\t\t\t\t\tlast = values[values.length - 1];\n\t\t\t\t\tseamless = true;\n\t\t\t\t\ti = props.length;\n\t\t\t\t\twhile (--i > -1) {\n\t\t\t\t\t\tp = props[i];\n\t\t\t\t\t\tif (Math.abs(first[p] - last[p]) > 0.05) { //build in a tolerance of +/-0.05 to accommodate rounding errors.\n\t\t\t\t\t\t\tseamless = false;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (seamless) {\n\t\t\t\t\t\tvalues = values.concat(); //duplicate the array to avoid contaminating the original which the user may be reusing for other tweens\n\t\t\t\t\t\tif (prepend) {\n\t\t\t\t\t\t\tvalues.unshift(prepend);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tvalues.push(values[1]);\n\t\t\t\t\t\tprepend = values[values.length - 3];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t_r1.length = _r2.length = _r3.length = 0;\n\t\t\t\ti = props.length;\n\t\t\t\twhile (--i > -1) {\n\t\t\t\t\tp = props[i];\n\t\t\t\t\t_corProps[p] = (correlate.indexOf(\",\"+p+\",\") !== -1);\n\t\t\t\t\tobj[p] = _parseAnchors(values, p, _corProps[p], prepend);\n\t\t\t\t}\n\t\t\t\ti = _r1.length;\n\t\t\t\twhile (--i > -1) {\n\t\t\t\t\t_r1[i] = Math.sqrt(_r1[i]);\n\t\t\t\t\t_r2[i] = Math.sqrt(_r2[i]);\n\t\t\t\t}\n\t\t\t\tif (!basic) {\n\t\t\t\t\ti = props.length;\n\t\t\t\t\twhile (--i > -1) {\n\t\t\t\t\t\tif (_corProps[p]) {\n\t\t\t\t\t\t\ta = obj[props[i]];\n\t\t\t\t\t\t\tl = a.length - 1;\n\t\t\t\t\t\t\tfor (j = 0; j < l; j++) {\n\t\t\t\t\t\t\t\tr = (a[j+1].da / _r2[j] + a[j].da / _r1[j]) || 0;\n\t\t\t\t\t\t\t\t_r3[j] = (_r3[j] || 0) + r * r;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\ti = _r3.length;\n\t\t\t\t\twhile (--i > -1) {\n\t\t\t\t\t\t_r3[i] = Math.sqrt(_r3[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ti = props.length;\n\t\t\t\tj = quadratic ? 4 : 1;\n\t\t\t\twhile (--i > -1) {\n\t\t\t\t\tp = props[i];\n\t\t\t\t\ta = obj[p];\n\t\t\t\t\t_calculateControlPoints(a, curviness, quadratic, basic, _corProps[p]); //this method requires that _parseAnchors() and _setSegmentRatios() ran first so that _r1, _r2, and _r3 values are populated for all properties\n\t\t\t\t\tif (seamless) {\n\t\t\t\t\t\ta.splice(0, j);\n\t\t\t\t\t\ta.splice(a.length - j, j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn obj;\n\t\t\t},\n\t\t\t_parseBezierData = function(values, type, prepend) {\n\t\t\t\ttype = type || \"soft\";\n\t\t\t\tvar obj = {},\n\t\t\t\t\tinc = (type === \"cubic\") ? 3 : 2,\n\t\t\t\t\tsoft = (type === \"soft\"),\n\t\t\t\t\tprops = [],\n\t\t\t\t\ta, b, c, d, cur, i, j, l, p, cnt, tmp;\n\t\t\t\tif (soft && prepend) {\n\t\t\t\t\tvalues = [prepend].concat(values);\n\t\t\t\t}\n\t\t\t\tif (values == null || values.length < inc + 1) { throw \"invalid Bezier data\"; }\n\t\t\t\tfor (p in values[0]) {\n\t\t\t\t\tprops.push(p);\n\t\t\t\t}\n\t\t\t\ti = props.length;\n\t\t\t\twhile (--i > -1) {\n\t\t\t\t\tp = props[i];\n\t\t\t\t\tobj[p] = cur = [];\n\t\t\t\t\tcnt = 0;\n\t\t\t\t\tl = values.length;\n\t\t\t\t\tfor (j = 0; j < l; j++) {\n\t\t\t\t\t\ta = (prepend == null) ? values[j][p] : (typeof( (tmp = values[j][p]) ) === \"string\" && tmp.charAt(1) === \"=\") ? prepend[p] + Number(tmp.charAt(0) + tmp.substr(2)) : Number(tmp);\n\t\t\t\t\t\tif (soft) if (j > 1) if (j < l - 1) {\n\t\t\t\t\t\t\tcur[cnt++] = (a + cur[cnt-2]) / 2;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcur[cnt++] = a;\n\t\t\t\t\t}\n\t\t\t\t\tl = cnt - inc + 1;\n\t\t\t\t\tcnt = 0;\n\t\t\t\t\tfor (j = 0; j < l; j += inc) {\n\t\t\t\t\t\ta = cur[j];\n\t\t\t\t\t\tb = cur[j+1];\n\t\t\t\t\t\tc = cur[j+2];\n\t\t\t\t\t\td = (inc === 2) ? 0 : cur[j+3];\n\t\t\t\t\t\tcur[cnt++] = tmp = (inc === 3) ? new Segment(a, b, c, d) : new Segment(a, (2 * b + a) / 3, (2 * b + c) / 3, c);\n\t\t\t\t\t}\n\t\t\t\t\tcur.length = cnt;\n\t\t\t\t}\n\t\t\t\treturn obj;\n\t\t\t},\n\t\t\t_addCubicLengths = function(a, steps, resolution) {\n\t\t\t\tvar inc = 1 / resolution,\n\t\t\t\t\tj = a.length,\n\t\t\t\t\td, d1, s, da, ca, ba, p, i, inv, bez, index;\n\t\t\t\twhile (--j > -1) {\n\t\t\t\t\tbez = a[j];\n\t\t\t\t\ts = bez.a;\n\t\t\t\t\tda = bez.d - s;\n\t\t\t\t\tca = bez.c - s;\n\t\t\t\t\tba = bez.b - s;\n\t\t\t\t\td = d1 = 0;\n\t\t\t\t\tfor (i = 1; i <= resolution; i++) {\n\t\t\t\t\t\tp = inc * i;\n\t\t\t\t\t\tinv = 1 - p;\n\t\t\t\t\t\td = d1 - (d1 = (p * p * da + 3 * inv * (p * ca + inv * ba)) * p);\n\t\t\t\t\t\tindex = j * resolution + i - 1;\n\t\t\t\t\t\tsteps[index] = (steps[index] || 0) + d * d;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t},\n\t\t\t_parseLengthData = function(obj, resolution) {\n\t\t\t\tresolution = resolution >> 0 || 6;\n\t\t\t\tvar a = [],\n\t\t\t\t\tlengths = [],\n\t\t\t\t\td = 0,\n\t\t\t\t\ttotal = 0,\n\t\t\t\t\tthreshold = resolution - 1,\n\t\t\t\t\tsegments = [],\n\t\t\t\t\tcurLS = [], //current length segments array\n\t\t\t\t\tp, i, l, index;\n\t\t\t\tfor (p in obj) {\n\t\t\t\t\t_addCubicLengths(obj[p], a, resolution);\n\t\t\t\t}\n\t\t\t\tl = a.length;\n\t\t\t\tfor (i = 0; i < l; i++) {\n\t\t\t\t\td += Math.sqrt(a[i]);\n\t\t\t\t\tindex = i % resolution;\n\t\t\t\t\tcurLS[index] = d;\n\t\t\t\t\tif (index === threshold) {\n\t\t\t\t\t\ttotal += d;\n\t\t\t\t\t\tindex = (i / resolution) >> 0;\n\t\t\t\t\t\tsegments[index] = curLS;\n\t\t\t\t\t\tlengths[index] = total;\n\t\t\t\t\t\td = 0;\n\t\t\t\t\t\tcurLS = [];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn {length:total, lengths:lengths, segments:segments};\n\t\t\t},\n\n\n\n\t\t\tBezierPlugin = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"_gsScope\"]._gsDefine.plugin({\n\t\t\t\t\tpropName: \"bezier\",\n\t\t\t\t\tpriority: -1,\n\t\t\t\t\tversion: \"1.3.9\",\n\t\t\t\t\tAPI: 2,\n\t\t\t\t\tglobal:true,\n\n\t\t\t\t\t//gets called when the tween renders for the first time. This is where initial values should be recorded and any setup routines should run.\n\t\t\t\t\tinit: function(target, vars, tween) {\n\t\t\t\t\t\tthis._target = target;\n\t\t\t\t\t\tif (vars instanceof Array) {\n\t\t\t\t\t\t\tvars = {values:vars};\n\t\t\t\t\t\t}\n\t\t\t\t\t\tthis._func = {};\n\t\t\t\t\t\tthis._mod = {};\n\t\t\t\t\t\tthis._props = [];\n\t\t\t\t\t\tthis._timeRes = (vars.timeResolution == null) ? 6 : parseInt(vars.timeResolution, 10);\n\t\t\t\t\t\tvar values = vars.values || [],\n\t\t\t\t\t\t\tfirst = {},\n\t\t\t\t\t\t\tsecond = values[0],\n\t\t\t\t\t\t\tautoRotate = vars.autoRotate || tween.vars.orientToBezier,\n\t\t\t\t\t\t\tp, isFunc, i, j, prepend;\n\n\t\t\t\t\t\tthis._autoRotate = autoRotate ? (autoRotate instanceof Array) ? autoRotate : [[\"x\",\"y\",\"rotation\",((autoRotate === true) ? 0 : Number(autoRotate) || 0)]] : null;\n\t\t\t\t\t\tfor (p in second) {\n\t\t\t\t\t\t\tthis._props.push(p);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\ti = this._props.length;\n\t\t\t\t\t\twhile (--i > -1) {\n\t\t\t\t\t\t\tp = this._props[i];\n\n\t\t\t\t\t\t\tthis._overwriteProps.push(p);\n\t\t\t\t\t\t\tisFunc = this._func[p] = (typeof(target[p]) === \"function\");\n\t\t\t\t\t\t\tfirst[p] = (!isFunc) ? parseFloat(target[p]) : target[ ((p.indexOf(\"set\") || typeof(target[\"get\" + p.substr(3)]) !== \"function\") ? p : \"get\" + p.substr(3)) ]();\n\t\t\t\t\t\t\tif (!prepend) if (first[p] !== values[0][p]) {\n\t\t\t\t\t\t\t\tprepend = first;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tthis._beziers = (vars.type !== \"cubic\" && vars.type !== \"quadratic\" && vars.type !== \"soft\") ? bezierThrough(values, isNaN(vars.curviness) ? 1 : vars.curviness, false, (vars.type === \"thruBasic\"), vars.correlate, prepend) : _parseBezierData(values, vars.type, first);\n\t\t\t\t\t\tthis._segCount = this._beziers[p].length;\n\n\t\t\t\t\t\tif (this._timeRes) {\n\t\t\t\t\t\t\tvar ld = _parseLengthData(this._beziers, this._timeRes);\n\t\t\t\t\t\t\tthis._length = ld.length;\n\t\t\t\t\t\t\tthis._lengths = ld.lengths;\n\t\t\t\t\t\t\tthis._segments = ld.segments;\n\t\t\t\t\t\t\tthis._l1 = this._li = this._s1 = this._si = 0;\n\t\t\t\t\t\t\tthis._l2 = this._lengths[0];\n\t\t\t\t\t\t\tthis._curSeg = this._segments[0];\n\t\t\t\t\t\t\tthis._s2 = this._curSeg[0];\n\t\t\t\t\t\t\tthis._prec = 1 / this._curSeg.length;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif ((autoRotate = this._autoRotate)) {\n\t\t\t\t\t\t\tthis._initialRotations = [];\n\t\t\t\t\t\t\tif (!(autoRotate[0] instanceof Array)) {\n\t\t\t\t\t\t\t\tthis._autoRotate = autoRotate = [autoRotate];\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\ti = autoRotate.length;\n\t\t\t\t\t\t\twhile (--i > -1) {\n\t\t\t\t\t\t\t\tfor (j = 0; j < 3; j++) {\n\t\t\t\t\t\t\t\t\tp = autoRotate[i][j];\n\t\t\t\t\t\t\t\t\tthis._func[p] = (typeof(target[p]) === \"function\") ? target[ ((p.indexOf(\"set\") || typeof(target[\"get\" + p.substr(3)]) !== \"function\") ? p : \"get\" + p.substr(3)) ] : false;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tp = autoRotate[i][2];\n\t\t\t\t\t\t\t\tthis._initialRotations[i] = (this._func[p] ? this._func[p].call(this._target) : this._target[p]) || 0;\n\t\t\t\t\t\t\t\tthis._overwriteProps.push(p);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tthis._startRatio = tween.vars.runBackwards ? 1 : 0; //we determine the starting ratio when the tween inits which is always 0 unless the tween has runBackwards:true (indicating it's a from() tween) in which case it's 1.\n\t\t\t\t\t\treturn true;\n\t\t\t\t\t},\n\n\t\t\t\t\t//called each time the values should be updated, and the ratio gets passed as the only parameter (typically it's a value between 0 and 1, but it can exceed those when using an ease like Elastic.easeOut or Back.easeOut, etc.)\n\t\t\t\t\tset: function(v) {\n\t\t\t\t\t\tvar segments = this._segCount,\n\t\t\t\t\t\t\tfunc = this._func,\n\t\t\t\t\t\t\ttarget = this._target,\n\t\t\t\t\t\t\tnotStart = (v !== this._startRatio),\n\t\t\t\t\t\t\tcurIndex, inv, i, p, b, t, val, l, lengths, curSeg, v1;\n\t\t\t\t\t\tif (!this._timeRes) {\n\t\t\t\t\t\t\tcurIndex = (v < 0) ? 0 : (v >= 1) ? segments - 1 : (segments * v) >> 0;\n\t\t\t\t\t\t\tt = (v - (curIndex * (1 / segments))) * segments;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tlengths = this._lengths;\n\t\t\t\t\t\t\tcurSeg = this._curSeg;\n\t\t\t\t\t\t\tv1 = v * this._length;\n\t\t\t\t\t\t\ti = this._li;\n\t\t\t\t\t\t\t//find the appropriate segment (if the currently cached one isn't correct)\n\t\t\t\t\t\t\tif (v1 > this._l2 && i < segments - 1) {\n\t\t\t\t\t\t\t\tl = segments - 1;\n\t\t\t\t\t\t\t\twhile (i < l && (this._l2 = lengths[++i]) <= v1) {\t}\n\t\t\t\t\t\t\t\tthis._l1 = lengths[i-1];\n\t\t\t\t\t\t\t\tthis._li = i;\n\t\t\t\t\t\t\t\tthis._curSeg = curSeg = this._segments[i];\n\t\t\t\t\t\t\t\tthis._s2 = curSeg[(this._s1 = this._si = 0)];\n\t\t\t\t\t\t\t} else if (v1 < this._l1 && i > 0) {\n\t\t\t\t\t\t\t\twhile (i > 0 && (this._l1 = lengths[--i]) >= v1) { }\n\t\t\t\t\t\t\t\tif (i === 0 && v1 < this._l1) {\n\t\t\t\t\t\t\t\t\tthis._l1 = 0;\n\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\ti++;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tthis._l2 = lengths[i];\n\t\t\t\t\t\t\t\tthis._li = i;\n\t\t\t\t\t\t\t\tthis._curSeg = curSeg = this._segments[i];\n\t\t\t\t\t\t\t\tthis._s1 = curSeg[(this._si = curSeg.length - 1) - 1] || 0;\n\t\t\t\t\t\t\t\tthis._s2 = curSeg[this._si];\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcurIndex = i;\n\t\t\t\t\t\t\t//now find the appropriate sub-segment (we split it into the number of pieces that was defined by \"precision\" and measured each one)\n\t\t\t\t\t\t\tv1 -= this._l1;\n\t\t\t\t\t\t\ti = this._si;\n\t\t\t\t\t\t\tif (v1 > this._s2 && i < curSeg.length - 1) {\n\t\t\t\t\t\t\t\tl = curSeg.length - 1;\n\t\t\t\t\t\t\t\twhile (i < l && (this._s2 = curSeg[++i]) <= v1) {\t}\n\t\t\t\t\t\t\t\tthis._s1 = curSeg[i-1];\n\t\t\t\t\t\t\t\tthis._si = i;\n\t\t\t\t\t\t\t} else if (v1 < this._s1 && i > 0) {\n\t\t\t\t\t\t\t\twhile (i > 0 && (this._s1 = curSeg[--i]) >= v1) {\t}\n\t\t\t\t\t\t\t\tif (i === 0 && v1 < this._s1) {\n\t\t\t\t\t\t\t\t\tthis._s1 = 0;\n\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\ti++;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tthis._s2 = curSeg[i];\n\t\t\t\t\t\t\t\tthis._si = i;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tt = (v === 1) ? 1 : ((i + (v1 - this._s1) / (this._s2 - this._s1)) * this._prec) || 0;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tinv = 1 - t;\n\n\t\t\t\t\t\ti = this._props.length;\n\t\t\t\t\t\twhile (--i > -1) {\n\t\t\t\t\t\t\tp = this._props[i];\n\t\t\t\t\t\t\tb = this._beziers[p][curIndex];\n\t\t\t\t\t\t\tval = (t * t * b.da + 3 * inv * (t * b.ca + inv * b.ba)) * t + b.a;\n\t\t\t\t\t\t\tif (this._mod[p]) {\n\t\t\t\t\t\t\t\tval = this._mod[p](val, target);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (func[p]) {\n\t\t\t\t\t\t\t\ttarget[p](val);\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\ttarget[p] = val;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (this._autoRotate) {\n\t\t\t\t\t\t\tvar ar = this._autoRotate,\n\t\t\t\t\t\t\t\tb2, x1, y1, x2, y2, add, conv;\n\t\t\t\t\t\t\ti = ar.length;\n\t\t\t\t\t\t\twhile (--i > -1) {\n\t\t\t\t\t\t\t\tp = ar[i][2];\n\t\t\t\t\t\t\t\tadd = ar[i][3] || 0;\n\t\t\t\t\t\t\t\tconv = (ar[i][4] === true) ? 1 : _RAD2DEG;\n\t\t\t\t\t\t\t\tb = this._beziers[ar[i][0]];\n\t\t\t\t\t\t\t\tb2 = this._beziers[ar[i][1]];\n\n\t\t\t\t\t\t\t\tif (b && b2) { //in case one of the properties got overwritten.\n\t\t\t\t\t\t\t\t\tb = b[curIndex];\n\t\t\t\t\t\t\t\t\tb2 = b2[curIndex];\n\n\t\t\t\t\t\t\t\t\tx1 = b.a + (b.b - b.a) * t;\n\t\t\t\t\t\t\t\t\tx2 = b.b + (b.c - b.b) * t;\n\t\t\t\t\t\t\t\t\tx1 += (x2 - x1) * t;\n\t\t\t\t\t\t\t\t\tx2 += ((b.c + (b.d - b.c) * t) - x2) * t;\n\n\t\t\t\t\t\t\t\t\ty1 = b2.a + (b2.b - b2.a) * t;\n\t\t\t\t\t\t\t\t\ty2 = b2.b + (b2.c - b2.b) * t;\n\t\t\t\t\t\t\t\t\ty1 += (y2 - y1) * t;\n\t\t\t\t\t\t\t\t\ty2 += ((b2.c + (b2.d - b2.c) * t) - y2) * t;\n\n\t\t\t\t\t\t\t\t\tval = notStart ? Math.atan2(y2 - y1, x2 - x1) * conv + add : this._initialRotations[i];\n\n\t\t\t\t\t\t\t\t\tif (this._mod[p]) {\n\t\t\t\t\t\t\t\t\t\tval = this._mod[p](val, target); //for modProps\n\t\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\t\tif (func[p]) {\n\t\t\t\t\t\t\t\t\t\ttarget[p](val);\n\t\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\t\ttarget[p] = val;\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t}),\n\t\t\tp = BezierPlugin.prototype;\n\n\n\t\tBezierPlugin.bezierThrough = bezierThrough;\n\t\tBezierPlugin.cubicToQuadratic = cubicToQuadratic;\n\t\tBezierPlugin._autoCSS = true; //indicates that this plugin can be inserted into the \"css\" object using the autoCSS feature of TweenLite\n\t\tBezierPlugin.quadraticToCubic = function(a, b, c) {\n\t\t\treturn new Segment(a, (2 * b + a) / 3, (2 * b + c) / 3, c);\n\t\t};\n\n\t\tBezierPlugin._cssRegister = function() {\n\t\t\tvar CSSPlugin = _globals.CSSPlugin;\n\t\t\tif (!CSSPlugin) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tvar _internals = CSSPlugin._internals,\n\t\t\t\t_parseToProxy = _internals._parseToProxy,\n\t\t\t\t_setPluginRatio = _internals._setPluginRatio,\n\t\t\t\tCSSPropTween = _internals.CSSPropTween;\n\t\t\t_internals._registerComplexSpecialProp(\"bezier\", {parser:function(t, e, prop, cssp, pt, plugin) {\n\t\t\t\tif (e instanceof Array) {\n\t\t\t\t\te = {values:e};\n\t\t\t\t}\n\t\t\t\tplugin = new BezierPlugin();\n\t\t\t\tvar values = e.values,\n\t\t\t\t\tl = values.length - 1,\n\t\t\t\t\tpluginValues = [],\n\t\t\t\t\tv = {},\n\t\t\t\t\ti, p, data;\n\t\t\t\tif (l < 0) {\n\t\t\t\t\treturn pt;\n\t\t\t\t}\n\t\t\t\tfor (i = 0; i <= l; i++) {\n\t\t\t\t\tdata = _parseToProxy(t, values[i], cssp, pt, plugin, (l !== i));\n\t\t\t\t\tpluginValues[i] = data.end;\n\t\t\t\t}\n\t\t\t\tfor (p in e) {\n\t\t\t\t\tv[p] = e[p]; //duplicate the vars object because we need to alter some things which would cause problems if the user plans to reuse the same vars object for another tween.\n\t\t\t\t}\n\t\t\t\tv.values = pluginValues;\n\t\t\t\tpt = new CSSPropTween(t, \"bezier\", 0, 0, data.pt, 2);\n\t\t\t\tpt.data = data;\n\t\t\t\tpt.plugin = plugin;\n\t\t\t\tpt.setRatio = _setPluginRatio;\n\t\t\t\tif (v.autoRotate === 0) {\n\t\t\t\t\tv.autoRotate = true;\n\t\t\t\t}\n\t\t\t\tif (v.autoRotate && !(v.autoRotate instanceof Array)) {\n\t\t\t\t\ti = (v.autoRotate === true) ? 0 : Number(v.autoRotate);\n\t\t\t\t\tv.autoRotate = (data.end.left != null) ? [[\"left\",\"top\",\"rotation\",i,false]] : (data.end.x != null) ? [[\"x\",\"y\",\"rotation\",i,false]] : false;\n\t\t\t\t}\n\t\t\t\tif (v.autoRotate) {\n\t\t\t\t\tif (!cssp._transform) {\n\t\t\t\t\t\tcssp._enableTransforms(false);\n\t\t\t\t\t}\n\t\t\t\t\tdata.autoRotate = cssp._target._gsTransform;\n\t\t\t\t\tdata.proxy.rotation = data.autoRotate.rotation || 0;\n\t\t\t\t\tcssp._overwriteProps.push(\"rotation\");\n\t\t\t\t}\n\t\t\t\tplugin._onInitTween(data.proxy, v, cssp._tween);\n\t\t\t\treturn pt;\n\t\t\t}});\n\t\t};\n\n\t\tp._mod = function(lookup) {\n\t\t\tvar op = this._overwriteProps,\n\t\t\t\ti = op.length,\n\t\t\t\tval;\n\t\t\twhile (--i > -1) {\n\t\t\t\tval = lookup[op[i]];\n\t\t\t\tif (val && typeof(val) === \"function\") {\n\t\t\t\t\tthis._mod[op[i]] = val;\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\n\t\tp._kill = function(lookup) {\n\t\t\tvar a = this._props,\n\t\t\t\tp, i;\n\t\t\tfor (p in this._beziers) {\n\t\t\t\tif (p in lookup) {\n\t\t\t\t\tdelete this._beziers[p];\n\t\t\t\t\tdelete this._func[p];\n\t\t\t\t\ti = a.length;\n\t\t\t\t\twhile (--i > -1) {\n\t\t\t\t\t\tif (a[i] === p) {\n\t\t\t\t\t\t\ta.splice(i, 1);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\ta = this._autoRotate;\n\t\t\tif (a) {\n\t\t\t\ti = a.length;\n\t\t\t\twhile (--i > -1) {\n\t\t\t\t\tif (lookup[a[i][2]]) {\n\t\t\t\t\t\ta.splice(i, 1);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn this._super._kill.call(this, lookup);\n\t\t};\n\n\n\n//# sourceURL=webpack:///./node_modules/gsap/BezierPlugin.js?");

/***/ }),

/***/ "./node_modules/gsap/CSSPlugin.js":
/*!****************************************!*\
  !*** ./node_modules/gsap/CSSPlugin.js ***!
  \****************************************/
/*! exports provided: CSSPlugin, default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"CSSPlugin\", function() { return CSSPlugin; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"default\", function() { return CSSPlugin; });\n/* harmony import */ var _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./TweenLite.js */ \"./node_modules/gsap/TweenLite.js\");\n/*!\n * VERSION: 2.1.3\n * DATE: 2019-05-17\n * UPDATES AND DOCS AT: http://greensock.com\n *\n * @license Copyright (c) 2008-2019, GreenSock. All rights reserved.\n * This work is subject to the terms at http://greensock.com/standard-license or for\n * Club GreenSock members, the software agreement that was issued with your membership.\n * \n * @author: Jack Doyle, jack@greensock.com\n */\n/* eslint-disable */\n\n\n\n\t_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"_gsScope\"]._gsDefine(\"plugins.CSSPlugin\", [\"plugins.TweenPlugin\",\"TweenLite\"], function() {\n\n\t\t/** @constructor **/\n\t\tvar CSSPlugin = function() {\n\t\t\t\t_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"TweenPlugin\"].call(this, \"css\");\n\t\t\t\tthis._overwriteProps.length = 0;\n\t\t\t\tthis.setRatio = CSSPlugin.prototype.setRatio; //speed optimization (avoid prototype lookup on this \"hot\" method)\n\t\t\t},\n\t\t\t_globals = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"_gsScope\"]._gsDefine.globals,\n\t\t\t_hasPriority, //turns true whenever a CSSPropTween instance is created that has a priority other than 0. This helps us discern whether or not we should spend the time organizing the linked list or not after a CSSPlugin's _onInitTween() method is called.\n\t\t\t_suffixMap, //we set this in _onInitTween() each time as a way to have a persistent variable we can use in other methods like _parse() without having to pass it around as a parameter and we keep _parse() decoupled from a particular CSSPlugin instance\n\t\t\t_cs, //computed style (we store this in a shared variable to conserve memory and make minification tighter\n\t\t\t_overwriteProps, //alias to the currently instantiating CSSPlugin's _overwriteProps array. We use this closure in order to avoid having to pass a reference around from method to method and aid in minification.\n\t\t\t_specialProps = {},\n\t\t\tp = CSSPlugin.prototype = new _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"TweenPlugin\"](\"css\");\n\n\t\tp.constructor = CSSPlugin;\n\t\tCSSPlugin.version = \"2.1.3\";\n\t\tCSSPlugin.API = 2;\n\t\tCSSPlugin.defaultTransformPerspective = 0;\n\t\tCSSPlugin.defaultSkewType = \"compensated\";\n\t\tCSSPlugin.defaultSmoothOrigin = true;\n\t\tp = \"px\"; //we'll reuse the \"p\" variable to keep file size down\n\t\tCSSPlugin.suffixMap = {top:p, right:p, bottom:p, left:p, width:p, height:p, fontSize:p, padding:p, margin:p, perspective:p, lineHeight:\"\"};\n\n\n\t\tvar _numExp = /(?:\\-|\\.|\\b)(\\d|\\.|e\\-)+/g,\n\t\t\t_relNumExp = /(?:\\d|\\-\\d|\\.\\d|\\-\\.\\d|\\+=\\d|\\-=\\d|\\+=.\\d|\\-=\\.\\d)+/g,\n\t\t\t_valuesExp = /(?:\\+=|\\-=|\\-|\\b)[\\d\\-\\.]+[a-zA-Z0-9]*(?:%|\\b)/gi, //finds all the values that begin with numbers or += or -= and then a number. Includes suffixes. We use this to split complex values apart like \"1px 5px 20px rgb(255,102,51)\"\n\t\t\t_valuesExpWithCommas = /(?:\\+=|\\-=|\\-|\\b)[\\d\\-\\.]+[a-zA-Z0-9]*(?:%|\\b),?/gi, //finds all the values that begin with numbers or += or -= and then a number. Includes suffixes. We use this to split complex values apart like \"1px 5px 20px rgb(255,102,51)\"\n\t\t\t_NaNExp = /(?![+-]?\\d*\\.?\\d+|[+-]|e[+-]\\d+)[^0-9]/g, //also allows scientific notation and doesn't kill the leading -/+ in -= and +=\n\t\t\t_suffixExp = /(?:\\d|\\-|\\+|=|#|\\.)*/g,\n\t\t\t_opacityExp = /opacity *= *([^)]*)/i,\n\t\t\t_opacityValExp = /opacity:([^;]*)/i,\n\t\t\t_alphaFilterExp = /alpha\\(opacity *=.+?\\)/i,\n\t\t\t_rgbhslExp = /^(rgb|hsl)/,\n\t\t\t_capsExp = /([A-Z])/g,\n\t\t\t_camelExp = /-([a-z])/gi,\n\t\t\t_urlExp = /(^(?:url\\(\\\"|url\\())|(?:(\\\"\\))$|\\)$)/gi, //for pulling out urls from url(...) or url(\"...\") strings (some browsers wrap urls in quotes, some don't when reporting things like backgroundImage)\n\t\t\t_camelFunc = function(s, g) { return g.toUpperCase(); },\n\t\t\t_horizExp = /(?:Left|Right|Width)/i,\n\t\t\t_ieGetMatrixExp = /(M11|M12|M21|M22)=[\\d\\-\\.e]+/gi,\n\t\t\t_ieSetMatrixExp = /progid\\:DXImageTransform\\.Microsoft\\.Matrix\\(.+?\\)/i,\n\t\t\t_commasOutsideParenExp = /,(?=[^\\)]*(?:\\(|$))/gi, //finds any commas that are not within parenthesis\n\t\t\t_complexExp = /[\\s,\\(]/i, //for testing a string to find if it has a space, comma, or open parenthesis (clues that it's a complex value)\n\t\t\t_DEG2RAD = Math.PI / 180,\n\t\t\t_RAD2DEG = 180 / Math.PI,\n\t\t\t_forcePT = {},\n\t\t\t_dummyElement = {style:{}},\n\t\t\t_doc = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"_gsScope\"].document || {createElement: function() {return _dummyElement;}},\n\t\t\t_createElement = function(type, ns) {\n\t\t\t\tvar e = _doc.createElementNS ? _doc.createElementNS(ns || \"http://www.w3.org/1999/xhtml\", type) : _doc.createElement(type);\n\t\t\t\treturn e.style ? e : _doc.createElement(type); //some environments won't allow access to the element's style when created with a namespace in which case we default to the standard createElement() to work around the issue. Also note that when GSAP is embedded directly inside an SVG file, createElement() won't allow access to the style object in Firefox (see https://greensock.com/forums/topic/20215-problem-using-tweenmax-in-standalone-self-containing-svg-file-err-cannot-set-property-csstext-of-undefined/).\n\t\t\t},\n\t\t\t_tempDiv = _createElement(\"div\"),\n\t\t\t_tempImg = _createElement(\"img\"),\n\t\t\t_internals = CSSPlugin._internals = {_specialProps:_specialProps}, //provides a hook to a few internal methods that we need to access from inside other plugins\n\t\t\t_agent = (_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"_gsScope\"].navigator || {}).userAgent || \"\",\n\t\t\t_autoRound,\n\t\t\t_reqSafariFix, //we won't apply the Safari transform fix until we actually come across a tween that affects a transform property (to maintain best performance).\n\n\t\t\t_isSafari,\n\t\t\t_isFirefox, //Firefox has a bug that causes 3D transformed elements to randomly disappear unless a repaint is forced after each update on each element.\n\t\t\t_isSafariLT6, //Safari (and Android 4 which uses a flavor of Safari) has a bug that prevents changes to \"top\" and \"left\" properties from rendering properly if changed on the same frame as a transform UNLESS we set the element's WebkitBackfaceVisibility to hidden (weird, I know). Doing this for Android 3 and earlier seems to actually cause other problems, though (fun!)\n\t\t\t_ieVers,\n\t\t\t_supportsOpacity = (function() { //we set _isSafari, _ieVers, _isFirefox, and _supportsOpacity all in one function here to reduce file size slightly, especially in the minified version.\n\t\t\t\tvar i = _agent.indexOf(\"Android\"),\n\t\t\t\t\ta = _createElement(\"a\");\n\t\t\t\t_isSafari = (_agent.indexOf(\"Safari\") !== -1 && _agent.indexOf(\"Chrome\") === -1 && (i === -1 || parseFloat(_agent.substr(i+8, 2)) > 3));\n\t\t\t\t_isSafariLT6 = (_isSafari && (parseFloat(_agent.substr(_agent.indexOf(\"Version/\")+8, 2)) < 6));\n\t\t\t\t_isFirefox = (_agent.indexOf(\"Firefox\") !== -1);\n\t\t\t\tif ((/MSIE ([0-9]{1,}[\\.0-9]{0,})/).exec(_agent) || (/Trident\\/.*rv:([0-9]{1,}[\\.0-9]{0,})/).exec(_agent)) {\n\t\t\t\t\t_ieVers = parseFloat( RegExp.$1 );\n\t\t\t\t}\n\t\t\t\tif (!a) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\ta.style.cssText = \"top:1px;opacity:.55;\";\n\t\t\t\treturn /^0.55/.test(a.style.opacity);\n\t\t\t}()),\n\t\t\t_getIEOpacity = function(v) {\n\t\t\t\treturn (_opacityExp.test( ((typeof(v) === \"string\") ? v : (v.currentStyle ? v.currentStyle.filter : v.style.filter) || \"\") ) ? ( parseFloat( RegExp.$1 ) / 100 ) : 1);\n\t\t\t},\n\t\t\t_log = function(s) {//for logging messages, but in a way that won't throw errors in old versions of IE.\n\t\t\t\tif (_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"_gsScope\"].console) {\n\t\t\t\t\tconsole.log(s);\n\t\t\t\t}\n\t\t\t},\n\t\t\t_target, //when initting a CSSPlugin, we set this variable so that we can access it from within many other functions without having to pass it around as params\n\t\t\t_index, //when initting a CSSPlugin, we set this variable so that we can access it from within many other functions without having to pass it around as params\n\n\t\t\t_prefixCSS = \"\", //the non-camelCase vendor prefix like \"-o-\", \"-moz-\", \"-ms-\", or \"-webkit-\"\n\t\t\t_prefix = \"\", //camelCase vendor prefix like \"O\", \"ms\", \"Webkit\", or \"Moz\".\n\n\t\t\t// @private feed in a camelCase property name like \"transform\" and it will check to see if it is valid as-is or if it needs a vendor prefix. It returns the corrected camelCase property name (i.e. \"WebkitTransform\" or \"MozTransform\" or \"transform\" or null if no such property is found, like if the browser is IE8 or before, \"transform\" won't be found at all)\n\t\t\t_checkPropPrefix = function(p, e) {\n\t\t\t\te = e || _tempDiv;\n\t\t\t\tvar s = e.style,\n\t\t\t\t\ta, i;\n\t\t\t\tif (s[p] !== undefined) {\n\t\t\t\t\treturn p;\n\t\t\t\t}\n\t\t\t\tp = p.charAt(0).toUpperCase() + p.substr(1);\n\t\t\t\ta = [\"O\",\"Moz\",\"ms\",\"Ms\",\"Webkit\"];\n\t\t\t\ti = 5;\n\t\t\t\twhile (--i > -1 && s[a[i]+p] === undefined) { }\n\t\t\t\tif (i >= 0) {\n\t\t\t\t\t_prefix = (i === 3) ? \"ms\" : a[i];\n\t\t\t\t\t_prefixCSS = \"-\" + _prefix.toLowerCase() + \"-\";\n\t\t\t\t\treturn _prefix + p;\n\t\t\t\t}\n\t\t\t\treturn null;\n\t\t\t},\n\n\t\t\t_computedStyleScope = (typeof(window) !== \"undefined\" ? window : _doc.defaultView || {getComputedStyle:function() {}}),\n\t\t\t_getComputedStyle = function(e) {\n\t\t\t\treturn _computedStyleScope.getComputedStyle(e); //to avoid errors in Microsoft Edge, we need to call getComputedStyle() from a specific scope, typically window.\n\t\t\t},\n\n\t\t\t/**\n\t\t\t * @private Returns the css style for a particular property of an element. For example, to get whatever the current \"left\" css value for an element with an ID of \"myElement\", you could do:\n\t\t\t * var currentLeft = CSSPlugin.getStyle( document.getElementById(\"myElement\"), \"left\");\n\t\t\t *\n\t\t\t * @param {!Object} t Target element whose style property you want to query\n\t\t\t * @param {!string} p Property name (like \"left\" or \"top\" or \"marginTop\", etc.)\n\t\t\t * @param {Object=} cs Computed style object. This just provides a way to speed processing if you're going to get several properties on the same element in quick succession - you can reuse the result of the getComputedStyle() call.\n\t\t\t * @param {boolean=} calc If true, the value will not be read directly from the element's \"style\" property (if it exists there), but instead the getComputedStyle() result will be used. This can be useful when you want to ensure that the browser itself is interpreting the value.\n\t\t\t * @param {string=} dflt Default value that should be returned in the place of null, \"none\", \"auto\" or \"auto auto\".\n\t\t\t * @return {?string} The current property value\n\t\t\t */\n\t\t\t_getStyle = CSSPlugin.getStyle = function(t, p, cs, calc, dflt) {\n\t\t\t\tvar rv;\n\t\t\t\tif (!_supportsOpacity) if (p === \"opacity\") { //several versions of IE don't use the standard \"opacity\" property - they use things like filter:alpha(opacity=50), so we parse that here.\n\t\t\t\t\treturn _getIEOpacity(t);\n\t\t\t\t}\n\t\t\t\tif (!calc && t.style[p]) {\n\t\t\t\t\trv = t.style[p];\n\t\t\t\t} else if ((cs = cs || _getComputedStyle(t))) {\n\t\t\t\t\trv = cs[p] || cs.getPropertyValue(p) || cs.getPropertyValue(p.replace(_capsExp, \"-$1\").toLowerCase());\n\t\t\t\t} else if (t.currentStyle) {\n\t\t\t\t\trv = t.currentStyle[p];\n\t\t\t\t}\n\t\t\t\treturn (dflt != null && (!rv || rv === \"none\" || rv === \"auto\" || rv === \"auto auto\")) ? dflt : rv;\n\t\t\t},\n\n\t\t\t/**\n\t\t\t * @private Pass the target element, the property name, the numeric value, and the suffix (like \"%\", \"em\", \"px\", etc.) and it will spit back the equivalent pixel number.\n\t\t\t * @param {!Object} t Target element\n\t\t\t * @param {!string} p Property name (like \"left\", \"top\", \"marginLeft\", etc.)\n\t\t\t * @param {!number} v Value\n\t\t\t * @param {string=} sfx Suffix (like \"px\" or \"%\" or \"em\")\n\t\t\t * @param {boolean=} recurse If true, the call is a recursive one. In some browsers (like IE7/8), occasionally the value isn't accurately reported initially, but if we run the function again it will take effect.\n\t\t\t * @return {number} value in pixels\n\t\t\t */\n\t\t\t_convertToPixels = _internals.convertToPixels = function(t, p, v, sfx, recurse) {\n\t\t\t\tif (sfx === \"px\" || (!sfx && p !== \"lineHeight\")) { return v; }\n\t\t\t\tif (sfx === \"auto\" || !v) { return 0; }\n\t\t\t\tvar horiz = _horizExp.test(p),\n\t\t\t\t\tnode = t,\n\t\t\t\t\tstyle = _tempDiv.style,\n\t\t\t\t\tneg = (v < 0),\n\t\t\t\t\tprecise = (v === 1),\n\t\t\t\t\tpix, cache, time;\n\t\t\t\tif (neg) {\n\t\t\t\t\tv = -v;\n\t\t\t\t}\n\t\t\t\tif (precise) {\n\t\t\t\t\tv *= 100;\n\t\t\t\t}\n\t\t\t\tif (p === \"lineHeight\" && !sfx) { //special case of when a simple lineHeight (without a unit) is used. Set it to the value, read back the computed value, and then revert.\n\t\t\t\t\tcache = _getComputedStyle(t).lineHeight;\n\t\t\t\t\tt.style.lineHeight = v;\n\t\t\t\t\tpix = parseFloat(_getComputedStyle(t).lineHeight);\n\t\t\t\t\tt.style.lineHeight = cache;\n\t\t\t\t} else if (sfx === \"%\" && p.indexOf(\"border\") !== -1) {\n\t\t\t\t\tpix = (v / 100) * (horiz ? t.clientWidth : t.clientHeight);\n\t\t\t\t} else {\n\t\t\t\t\tstyle.cssText = \"border:0 solid red;position:\" + _getStyle(t, \"position\") + \";line-height:0;\";\n\t\t\t\t\tif (sfx === \"%\" || !node.appendChild || sfx.charAt(0) === \"v\" || sfx === \"rem\") {\n\t\t\t\t\t\tnode = t.parentNode || _doc.body;\n\t\t\t\t\t\tif (_getStyle(node, \"display\").indexOf(\"flex\") !== -1) { //Edge and IE11 have a bug that causes offsetWidth to report as 0 if the container has display:flex and the child is position:relative. Switching to position: absolute solves it.\n\t\t\t\t\t\t\tstyle.position = \"absolute\";\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcache = node._gsCache;\n\t\t\t\t\t\ttime = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].ticker.frame;\n\t\t\t\t\t\tif (cache && horiz && cache.time === time) { //performance optimization: we record the width of elements along with the ticker frame so that we can quickly get it again on the same tick (seems relatively safe to assume it wouldn't change on the same tick)\n\t\t\t\t\t\t\treturn cache.width * v / 100;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tstyle[(horiz ? \"width\" : \"height\")] = v + sfx;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tstyle[(horiz ? \"borderLeftWidth\" : \"borderTopWidth\")] = v + sfx;\n\t\t\t\t\t}\n\t\t\t\t\tnode.appendChild(_tempDiv);\n\t\t\t\t\tpix = parseFloat(_tempDiv[(horiz ? \"offsetWidth\" : \"offsetHeight\")]);\n\t\t\t\t\tnode.removeChild(_tempDiv);\n\t\t\t\t\tif (horiz && sfx === \"%\" && CSSPlugin.cacheWidths !== false) {\n\t\t\t\t\t\tcache = node._gsCache = node._gsCache || {};\n\t\t\t\t\t\tcache.time = time;\n\t\t\t\t\t\tcache.width = pix / v * 100;\n\t\t\t\t\t}\n\t\t\t\t\tif (pix === 0 && !recurse) {\n\t\t\t\t\t\tpix = _convertToPixels(t, p, v, sfx, true);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (precise) {\n\t\t\t\t\tpix /= 100;\n\t\t\t\t}\n\t\t\t\treturn neg ? -pix : pix;\n\t\t\t},\n\t\t\t_calculateOffset = _internals.calculateOffset = function(t, p, cs) { //for figuring out \"top\" or \"left\" in px when it's \"auto\". We need to factor in margin with the offsetLeft/offsetTop\n\t\t\t\tif (_getStyle(t, \"position\", cs) !== \"absolute\") { return 0; }\n\t\t\t\tvar dim = ((p === \"left\") ? \"Left\" : \"Top\"),\n\t\t\t\t\tv = _getStyle(t, \"margin\" + dim, cs);\n\t\t\t\treturn t[\"offset\" + dim] - (_convertToPixels(t, p, parseFloat(v), v.replace(_suffixExp, \"\")) || 0);\n\t\t\t},\n\n\t\t\t// @private returns at object containing ALL of the style properties in camelCase and their associated values.\n\t\t\t_getAllStyles = function(t, cs) {\n\t\t\t\tvar s = {},\n\t\t\t\t\ti, tr, p;\n\t\t\t\tif ((cs = cs || _getComputedStyle(t, null))) {\n\t\t\t\t\tif ((i = cs.length)) {\n\t\t\t\t\t\twhile (--i > -1) {\n\t\t\t\t\t\t\tp = cs[i];\n\t\t\t\t\t\t\tif (p.indexOf(\"-transform\") === -1 || _transformPropCSS === p) { //Some webkit browsers duplicate transform values, one non-prefixed and one prefixed (\"transform\" and \"WebkitTransform\"), so we must weed out the extra one here.\n\t\t\t\t\t\t\t\ts[p.replace(_camelExp, _camelFunc)] = cs.getPropertyValue(p);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t} else { //some browsers behave differently - cs.length is always 0, so we must do a for...in loop.\n\t\t\t\t\t\tfor (i in cs) {\n\t\t\t\t\t\t\tif (i.indexOf(\"Transform\") === -1 || _transformProp === i) { //Some webkit browsers duplicate transform values, one non-prefixed and one prefixed (\"transform\" and \"WebkitTransform\"), so we must weed out the extra one here.\n\t\t\t\t\t\t\t\ts[i] = cs[i];\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if ((cs = t.currentStyle || t.style)) {\n\t\t\t\t\tfor (i in cs) {\n\t\t\t\t\t\tif (typeof(i) === \"string\" && s[i] === undefined) {\n\t\t\t\t\t\t\ts[i.replace(_camelExp, _camelFunc)] = cs[i];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (!_supportsOpacity) {\n\t\t\t\t\ts.opacity = _getIEOpacity(t);\n\t\t\t\t}\n\t\t\t\ttr = _getTransform(t, cs, false);\n\t\t\t\ts.rotation = tr.rotation;\n\t\t\t\ts.skewX = tr.skewX;\n\t\t\t\ts.scaleX = tr.scaleX;\n\t\t\t\ts.scaleY = tr.scaleY;\n\t\t\t\ts.x = tr.x;\n\t\t\t\ts.y = tr.y;\n\t\t\t\tif (_supports3D) {\n\t\t\t\t\ts.z = tr.z;\n\t\t\t\t\ts.rotationX = tr.rotationX;\n\t\t\t\t\ts.rotationY = tr.rotationY;\n\t\t\t\t\ts.scaleZ = tr.scaleZ;\n\t\t\t\t}\n\t\t\t\tif (s.filters) {\n\t\t\t\t\tdelete s.filters;\n\t\t\t\t}\n\t\t\t\treturn s;\n\t\t\t},\n\n\t\t\t// @private analyzes two style objects (as returned by _getAllStyles()) and only looks for differences between them that contain tweenable values (like a number or color). It returns an object with a \"difs\" property which refers to an object containing only those isolated properties and values for tweening, and a \"firstMPT\" property which refers to the first MiniPropTween instance in a linked list that recorded all the starting values of the different properties so that we can revert to them at the end or beginning of the tween - we don't want the cascading to get messed up. The forceLookup parameter is an optional generic object with properties that should be forced into the results - this is necessary for className tweens that are overwriting others because imagine a scenario where a rollover/rollout adds/removes a class and the user swipes the mouse over the target SUPER fast, thus nothing actually changed yet and the subsequent comparison of the properties would indicate they match (especially when px rounding is taken into consideration), thus no tweening is necessary even though it SHOULD tween and remove those properties after the tween (otherwise the inline styles will contaminate things). See the className SpecialProp code for details.\n\t\t\t_cssDif = function(t, s1, s2, vars, forceLookup) {\n\t\t\t\tvar difs = {},\n\t\t\t\t\tstyle = t.style,\n\t\t\t\t\tval, p, mpt;\n\t\t\t\tfor (p in s2) {\n\t\t\t\t\tif (p !== \"cssText\") if (p !== \"length\") if (isNaN(p)) if (s1[p] !== (val = s2[p]) || (forceLookup && forceLookup[p])) if (p.indexOf(\"Origin\") === -1) if (typeof(val) === \"number\" || typeof(val) === \"string\") {\n\t\t\t\t\t\tdifs[p] = (val === \"auto\" && (p === \"left\" || p === \"top\")) ? _calculateOffset(t, p) : ((val === \"\" || val === \"auto\" || val === \"none\") && typeof(s1[p]) === \"string\" && s1[p].replace(_NaNExp, \"\") !== \"\") ? 0 : val; //if the ending value is defaulting (\"\" or \"auto\"), we check the starting value and if it can be parsed into a number (a string which could have a suffix too, like 700px), then we swap in 0 for \"\" or \"auto\" so that things actually tween.\n\t\t\t\t\t\tif (style[p] !== undefined) { //for className tweens, we must remember which properties already existed inline - the ones that didn't should be removed when the tween isn't in progress because they were only introduced to facilitate the transition between classes.\n\t\t\t\t\t\t\tmpt = new MiniPropTween(style, p, style[p], mpt);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (vars) {\n\t\t\t\t\tfor (p in vars) { //copy properties (except className)\n\t\t\t\t\t\tif (p !== \"className\") {\n\t\t\t\t\t\t\tdifs[p] = vars[p];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn {difs:difs, firstMPT:mpt};\n\t\t\t},\n\t\t\t_dimensions = {width:[\"Left\",\"Right\"], height:[\"Top\",\"Bottom\"]},\n\t\t\t_margins = [\"marginLeft\",\"marginRight\",\"marginTop\",\"marginBottom\"],\n\n\t\t\t/**\n\t\t\t * @private Gets the width or height of an element\n\t\t\t * @param {!Object} t Target element\n\t\t\t * @param {!string} p Property name (\"width\" or \"height\")\n\t\t\t * @param {Object=} cs Computed style object (if one exists). Just a speed optimization.\n\t\t\t * @return {number} Dimension (in pixels)\n\t\t\t */\n\t\t\t_getDimension = function(t, p, cs) {\n\t\t\t\tif ((t.nodeName + \"\").toLowerCase() === \"svg\") { //Chrome no longer supports offsetWidth/offsetHeight on SVG elements.\n\t\t\t\t\treturn (cs || _getComputedStyle(t))[p] || 0;\n\t\t\t\t} else if (t.getCTM && _isSVG(t)) {\n\t\t\t\t\treturn t.getBBox()[p] || 0;\n\t\t\t\t}\n\t\t\t\tvar v = parseFloat((p === \"width\") ? t.offsetWidth : t.offsetHeight),\n\t\t\t\t\ta = _dimensions[p],\n\t\t\t\t\ti = a.length;\n\t\t\t\tcs = cs || _getComputedStyle(t, null);\n\t\t\t\twhile (--i > -1) {\n\t\t\t\t\tv -= parseFloat( _getStyle(t, \"padding\" + a[i], cs, true) ) || 0;\n\t\t\t\t\tv -= parseFloat( _getStyle(t, \"border\" + a[i] + \"Width\", cs, true) ) || 0;\n\t\t\t\t}\n\t\t\t\treturn v;\n\t\t\t},\n\n\t\t\t// @private Parses position-related complex strings like \"top left\" or \"50px 10px\" or \"70% 20%\", etc. which are used for things like transformOrigin or backgroundPosition. Optionally decorates a supplied object (recObj) with the following properties: \"ox\" (offsetX), \"oy\" (offsetY), \"oxp\" (if true, \"ox\" is a percentage not a pixel value), and \"oxy\" (if true, \"oy\" is a percentage not a pixel value)\n\t\t\t_parsePosition = function(v, recObj) {\n\t\t\t\tif (v === \"contain\" || v === \"auto\" || v === \"auto auto\") { //note: Firefox uses \"auto auto\" as default whereas Chrome uses \"auto\".\n\t\t\t\t\treturn v + \" \";\n\t\t\t\t}\n\t\t\t\tif (v == null || v === \"\") {\n\t\t\t\t\tv = \"0 0\";\n\t\t\t\t}\n\t\t\t\tvar a = v.split(\" \"),\n\t\t\t\t\tx = (v.indexOf(\"left\") !== -1) ? \"0%\" : (v.indexOf(\"right\") !== -1) ? \"100%\" : a[0],\n\t\t\t\t\ty = (v.indexOf(\"top\") !== -1) ? \"0%\" : (v.indexOf(\"bottom\") !== -1) ? \"100%\" : a[1],\n\t\t\t\t\ti;\n\t\t\t\tif (a.length > 3 && !recObj) { //multiple positions\n\t\t\t\t\ta = v.split(\", \").join(\",\").split(\",\");\n\t\t\t\t\tv = [];\n\t\t\t\t\tfor (i = 0; i < a.length; i++) {\n\t\t\t\t\t\tv.push(_parsePosition(a[i]));\n\t\t\t\t\t}\n\t\t\t\t\treturn v.join(\",\");\n\t\t\t\t}\n\t\t\t\tif (y == null) {\n\t\t\t\t\ty = (x === \"center\") ? \"50%\" : \"0\";\n\t\t\t\t} else if (y === \"center\") {\n\t\t\t\t\ty = \"50%\";\n\t\t\t\t}\n\t\t\t\tif (x === \"center\" || (isNaN(parseFloat(x)) && (x + \"\").indexOf(\"=\") === -1)) { //remember, the user could flip-flop the values and say \"bottom center\" or \"center bottom\", etc. \"center\" is ambiguous because it could be used to describe horizontal or vertical, hence the isNaN(). If there's an \"=\" sign in the value, it's relative.\n\t\t\t\t\tx = \"50%\";\n\t\t\t\t}\n\t\t\t\tv = x + \" \" + y + ((a.length > 2) ? \" \" + a[2] : \"\");\n\t\t\t\tif (recObj) {\n\t\t\t\t\trecObj.oxp = (x.indexOf(\"%\") !== -1);\n\t\t\t\t\trecObj.oyp = (y.indexOf(\"%\") !== -1);\n\t\t\t\t\trecObj.oxr = (x.charAt(1) === \"=\");\n\t\t\t\t\trecObj.oyr = (y.charAt(1) === \"=\");\n\t\t\t\t\trecObj.ox = parseFloat(x.replace(_NaNExp, \"\"));\n\t\t\t\t\trecObj.oy = parseFloat(y.replace(_NaNExp, \"\"));\n\t\t\t\t\trecObj.v = v;\n\t\t\t\t}\n\t\t\t\treturn recObj || v;\n\t\t\t},\n\n\t\t\t/**\n\t\t\t * @private Takes an ending value (typically a string, but can be a number) and a starting value and returns the change between the two, looking for relative value indicators like += and -= and it also ignores suffixes (but make sure the ending value starts with a number or +=/-= and that the starting value is a NUMBER!)\n\t\t\t * @param {(number|string)} e End value which is typically a string, but could be a number\n\t\t\t * @param {(number|string)} b Beginning value which is typically a string but could be a number\n\t\t\t * @return {number} Amount of change between the beginning and ending values (relative values that have a \"+=\" or \"-=\" are recognized)\n\t\t\t */\n\t\t\t_parseChange = function(e, b) {\n\t\t\t\tif (typeof(e) === \"function\") {\n\t\t\t\t\te = e(_index, _target);\n\t\t\t\t}\n\t\t\t\treturn (typeof(e) === \"string\" && e.charAt(1) === \"=\") ? parseInt(e.charAt(0) + \"1\", 10) * parseFloat(e.substr(2)) : (parseFloat(e) - parseFloat(b)) || 0;\n\t\t\t},\n\n\t\t\t/**\n\t\t\t * @private Takes a value and a default number, checks if the value is relative, null, or numeric and spits back a normalized number accordingly. Primarily used in the _parseTransform() function.\n\t\t\t * @param {Object} v Value to be parsed\n\t\t\t * @param {!number} d Default value (which is also used for relative calculations if \"+=\" or \"-=\" is found in the first parameter)\n\t\t\t * @return {number} Parsed value\n\t\t\t */\n\t\t\t_parseVal = function(v, d) {\n\t\t\t\tif (typeof(v) === \"function\") {\n\t\t\t\t\tv = v(_index, _target);\n\t\t\t\t}\n\t\t\t\tvar isRelative = (typeof(v) === \"string\" && v.charAt(1) === \"=\");\n\t\t\t\tif (typeof(v) === \"string\" && v.charAt(v.length - 2) === \"v\") { //convert vw and vh into px-equivalents.\n\t\t\t\t\tv = (isRelative ? v.substr(0, 2) : 0) + (window[\"inner\" + ((v.substr(-2) === \"vh\") ? \"Height\" : \"Width\")] * (parseFloat(isRelative ? v.substr(2) : v) / 100));\n\t\t\t\t}\n\t\t\t\treturn (v == null) ? d : isRelative ? parseInt(v.charAt(0) + \"1\", 10) * parseFloat(v.substr(2)) + d : parseFloat(v) || 0;\n\t\t\t},\n\n\t\t\t/**\n\t\t\t * @private Translates strings like \"40deg\" or \"40\" or 40rad\" or \"+=40deg\" or \"270_short\" or \"-90_cw\" or \"+=45_ccw\" to a numeric radian angle. Of course a starting/default value must be fed in too so that relative values can be calculated properly.\n\t\t\t * @param {Object} v Value to be parsed\n\t\t\t * @param {!number} d Default value (which is also used for relative calculations if \"+=\" or \"-=\" is found in the first parameter)\n\t\t\t * @param {string=} p property name for directionalEnd (optional - only used when the parsed value is directional (\"_short\", \"_cw\", or \"_ccw\" suffix). We need a way to store the uncompensated value so that at the end of the tween, we set it to exactly what was requested with no directional compensation). Property name would be \"rotation\", \"rotationX\", or \"rotationY\"\n\t\t\t * @param {Object=} directionalEnd An object that will store the raw end values for directional angles (\"_short\", \"_cw\", or \"_ccw\" suffix). We need a way to store the uncompensated value so that at the end of the tween, we set it to exactly what was requested with no directional compensation.\n\t\t\t * @return {number} parsed angle in radians\n\t\t\t */\n\t\t\t_parseAngle = function(v, d, p, directionalEnd) {\n\t\t\t\tvar min = 0.000001,\n\t\t\t\t\tcap, split, dif, result, isRelative;\n\t\t\t\tif (typeof(v) === \"function\") {\n\t\t\t\t\tv = v(_index, _target);\n\t\t\t\t}\n\t\t\t\tif (v == null) {\n\t\t\t\t\tresult = d;\n\t\t\t\t} else if (typeof(v) === \"number\") {\n\t\t\t\t\tresult = v;\n\t\t\t\t} else {\n\t\t\t\t\tcap = 360;\n\t\t\t\t\tsplit = v.split(\"_\");\n\t\t\t\t\tisRelative = (v.charAt(1) === \"=\");\n\t\t\t\t\tdif = (isRelative ? parseInt(v.charAt(0) + \"1\", 10) * parseFloat(split[0].substr(2)) : parseFloat(split[0])) * ((v.indexOf(\"rad\") === -1) ? 1 : _RAD2DEG) - (isRelative ? 0 : d);\n\t\t\t\t\tif (split.length) {\n\t\t\t\t\t\tif (directionalEnd) {\n\t\t\t\t\t\t\tdirectionalEnd[p] = d + dif;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (v.indexOf(\"short\") !== -1) {\n\t\t\t\t\t\t\tdif = dif % cap;\n\t\t\t\t\t\t\tif (dif !== dif % (cap / 2)) {\n\t\t\t\t\t\t\t\tdif = (dif < 0) ? dif + cap : dif - cap;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (v.indexOf(\"_cw\") !== -1 && dif < 0) {\n\t\t\t\t\t\t\tdif = ((dif + cap * 9999999999) % cap) - ((dif / cap) | 0) * cap;\n\t\t\t\t\t\t} else if (v.indexOf(\"ccw\") !== -1 && dif > 0) {\n\t\t\t\t\t\t\tdif = ((dif - cap * 9999999999) % cap) - ((dif / cap) | 0) * cap;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tresult = d + dif;\n\t\t\t\t}\n\t\t\t\tif (result < min && result > -min) {\n\t\t\t\t\tresult = 0;\n\t\t\t\t}\n\t\t\t\treturn result;\n\t\t\t},\n\n\t\t\t_colorLookup = {aqua:[0,255,255],\n\t\t\t\tlime:[0,255,0],\n\t\t\t\tsilver:[192,192,192],\n\t\t\t\tblack:[0,0,0],\n\t\t\t\tmaroon:[128,0,0],\n\t\t\t\tteal:[0,128,128],\n\t\t\t\tblue:[0,0,255],\n\t\t\t\tnavy:[0,0,128],\n\t\t\t\twhite:[255,255,255],\n\t\t\t\tfuchsia:[255,0,255],\n\t\t\t\tolive:[128,128,0],\n\t\t\t\tyellow:[255,255,0],\n\t\t\t\torange:[255,165,0],\n\t\t\t\tgray:[128,128,128],\n\t\t\t\tpurple:[128,0,128],\n\t\t\t\tgreen:[0,128,0],\n\t\t\t\tred:[255,0,0],\n\t\t\t\tpink:[255,192,203],\n\t\t\t\tcyan:[0,255,255],\n\t\t\t\ttransparent:[255,255,255,0]},\n\n\t\t\t_hue = function(h, m1, m2) {\n\t\t\t\th = (h < 0) ? h + 1 : (h > 1) ? h - 1 : h;\n\t\t\t\treturn ((((h * 6 < 1) ? m1 + (m2 - m1) * h * 6 : (h < 0.5) ? m2 : (h * 3 < 2) ? m1 + (m2 - m1) * (2 / 3 - h) * 6 : m1) * 255) + 0.5) | 0;\n\t\t\t},\n\n\t\t\t/**\n\t\t\t * @private Parses a color (like #9F0, #FF9900, rgb(255,51,153) or hsl(108, 50%, 10%)) into an array with 3 elements for red, green, and blue or if toHSL parameter is true, it will populate the array with hue, saturation, and lightness values. If a relative value is found in an hsl() or hsla() string, it will preserve those relative prefixes and all the values in the array will be strings instead of numbers (in all other cases it will be populated with numbers).\n\t\t\t * @param {(string|number)} v The value the should be parsed which could be a string like #9F0 or rgb(255,102,51) or rgba(255,0,0,0.5) or it could be a number like 0xFF00CC or even a named color like red, blue, purple, etc.\n\t\t\t * @param {(boolean)} toHSL If true, an hsl() or hsla() value will be returned instead of rgb() or rgba()\n\t\t\t * @return {Array.<number>} An array containing red, green, and blue (and optionally alpha) in that order, or if the toHSL parameter was true, the array will contain hue, saturation and lightness (and optionally alpha) in that order. Always numbers unless there's a relative prefix found in an hsl() or hsla() string and toHSL is true.\n\t\t\t */\n\t\t\t_parseColor = CSSPlugin.parseColor = function(v, toHSL) {\n\t\t\t\tvar a, r, g, b, h, s, l, max, min, d, wasHSL;\n\t\t\t\tif (!v) {\n\t\t\t\t\ta = _colorLookup.black;\n\t\t\t\t} else if (typeof(v) === \"number\") {\n\t\t\t\t\ta = [v >> 16, (v >> 8) & 255, v & 255];\n\t\t\t\t} else {\n\t\t\t\t\tif (v.charAt(v.length - 1) === \",\") { //sometimes a trailing comma is included and we should chop it off (typically from a comma-delimited list of values like a textShadow:\"2px 2px 2px blue, 5px 5px 5px rgb(255,0,0)\" - in this example \"blue,\" has a trailing comma. We could strip it out inside parseComplex() but we'd need to do it to the beginning and ending values plus it wouldn't provide protection from other potential scenarios like if the user passes in a similar value.\n\t\t\t\t\t\tv = v.substr(0, v.length - 1);\n\t\t\t\t\t}\n\t\t\t\t\tif (_colorLookup[v]) {\n\t\t\t\t\t\ta = _colorLookup[v];\n\t\t\t\t\t} else if (v.charAt(0) === \"#\") {\n\t\t\t\t\t\tif (v.length === 4) { //for shorthand like #9F0\n\t\t\t\t\t\t\tr = v.charAt(1);\n\t\t\t\t\t\t\tg = v.charAt(2);\n\t\t\t\t\t\t\tb = v.charAt(3);\n\t\t\t\t\t\t\tv = \"#\" + r + r + g + g + b + b;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tv = parseInt(v.substr(1), 16);\n\t\t\t\t\t\ta = [v >> 16, (v >> 8) & 255, v & 255];\n\t\t\t\t\t} else if (v.substr(0, 3) === \"hsl\") {\n\t\t\t\t\t\ta = wasHSL = v.match(_numExp);\n\t\t\t\t\t\tif (!toHSL) {\n\t\t\t\t\t\t\th = (Number(a[0]) % 360) / 360;\n\t\t\t\t\t\t\ts = Number(a[1]) / 100;\n\t\t\t\t\t\t\tl = Number(a[2]) / 100;\n\t\t\t\t\t\t\tg = (l <= 0.5) ? l * (s + 1) : l + s - l * s;\n\t\t\t\t\t\t\tr = l * 2 - g;\n\t\t\t\t\t\t\tif (a.length > 3) {\n\t\t\t\t\t\t\t\ta[3] = Number(a[3]);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\ta[0] = _hue(h + 1 / 3, r, g);\n\t\t\t\t\t\t\ta[1] = _hue(h, r, g);\n\t\t\t\t\t\t\ta[2] = _hue(h - 1 / 3, r, g);\n\t\t\t\t\t\t} else if (v.indexOf(\"=\") !== -1) { //if relative values are found, just return the raw strings with the relative prefixes in place.\n\t\t\t\t\t\t\treturn v.match(_relNumExp);\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\ta = v.match(_numExp) || _colorLookup.transparent;\n\t\t\t\t\t}\n\t\t\t\t\ta[0] = Number(a[0]);\n\t\t\t\t\ta[1] = Number(a[1]);\n\t\t\t\t\ta[2] = Number(a[2]);\n\t\t\t\t\tif (a.length > 3) {\n\t\t\t\t\t\ta[3] = Number(a[3]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (toHSL && !wasHSL) {\n\t\t\t\t\tr = a[0] / 255;\n\t\t\t\t\tg = a[1] / 255;\n\t\t\t\t\tb = a[2] / 255;\n\t\t\t\t\tmax = Math.max(r, g, b);\n\t\t\t\t\tmin = Math.min(r, g, b);\n\t\t\t\t\tl = (max + min) / 2;\n\t\t\t\t\tif (max === min) {\n\t\t\t\t\t\th = s = 0;\n\t\t\t\t\t} else {\n\t\t\t\t\t\td = max - min;\n\t\t\t\t\t\ts = l > 0.5 ? d / (2 - max - min) : d / (max + min);\n\t\t\t\t\t\th = (max === r) ? (g - b) / d + (g < b ? 6 : 0) : (max === g) ? (b - r) / d + 2 : (r - g) / d + 4;\n\t\t\t\t\t\th *= 60;\n\t\t\t\t\t}\n\t\t\t\t\ta[0] = (h + 0.5) | 0;\n\t\t\t\t\ta[1] = (s * 100 + 0.5) | 0;\n\t\t\t\t\ta[2] = (l * 100 + 0.5) | 0;\n\t\t\t\t}\n\t\t\t\treturn a;\n\t\t\t},\n\t\t\t_formatColors = function(s, toHSL) {\n\t\t\t\tvar colors = s.match(_colorExp) || [],\n\t\t\t\t\tcharIndex = 0,\n\t\t\t\t\tparsed = \"\",\n\t\t\t\t\ti, color, temp;\n\t\t\t\tif (!colors.length) {\n\t\t\t\t\treturn s;\n\t\t\t\t}\n\t\t\t\tfor (i = 0; i < colors.length; i++) {\n\t\t\t\t\tcolor = colors[i];\n\t\t\t\t\ttemp = s.substr(charIndex, s.indexOf(color, charIndex)-charIndex);\n\t\t\t\t\tcharIndex += temp.length + color.length;\n\t\t\t\t\tcolor = _parseColor(color, toHSL);\n\t\t\t\t\tif (color.length === 3) {\n\t\t\t\t\t\tcolor.push(1);\n\t\t\t\t\t}\n\t\t\t\t\tparsed += temp + (toHSL ? \"hsla(\" + color[0] + \",\" + color[1] + \"%,\" + color[2] + \"%,\" + color[3] : \"rgba(\" + color.join(\",\")) + \")\";\n\t\t\t\t}\n\t\t\t\treturn parsed + s.substr(charIndex);\n\t\t\t},\n\t\t\t_colorExp = \"(?:\\\\b(?:(?:rgb|rgba|hsl|hsla)\\\\(.+?\\\\))|\\\\B#(?:[0-9a-f]{3}){1,2}\\\\b\"; //we'll dynamically build this Regular Expression to conserve file size. After building it, it will be able to find rgb(), rgba(), # (hexadecimal), and named color values like red, blue, purple, etc.\n\n\t\tfor (p in _colorLookup) {\n\t\t\t_colorExp += \"|\" + p + \"\\\\b\";\n\t\t}\n\t\t_colorExp = new RegExp(_colorExp+\")\", \"gi\");\n\n\t\tCSSPlugin.colorStringFilter = function(a) {\n\t\t\tvar combined = a[0] + \" \" + a[1],\n\t\t\t\ttoHSL;\n\t\t\tif (_colorExp.test(combined)) {\n\t\t\t\ttoHSL = (combined.indexOf(\"hsl(\") !== -1 || combined.indexOf(\"hsla(\") !== -1);\n\t\t\t\ta[0] = _formatColors(a[0], toHSL);\n\t\t\t\ta[1] = _formatColors(a[1], toHSL);\n\t\t\t}\n\t\t\t_colorExp.lastIndex = 0;\n\t\t};\n\n\t\tif (!_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].defaultStringFilter) {\n\t\t\t_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].defaultStringFilter = CSSPlugin.colorStringFilter;\n\t\t}\n\n\t\t/**\n\t\t * @private Returns a formatter function that handles taking a string (or number in some cases) and returning a consistently formatted one in terms of delimiters, quantity of values, etc. For example, we may get boxShadow values defined as \"0px red\" or \"0px 0px 10px rgb(255,0,0)\" or \"0px 0px 20px 20px #F00\" and we need to ensure that what we get back is described with 4 numbers and a color. This allows us to feed it into the _parseComplex() method and split the values up appropriately. The neat thing about this _getFormatter() function is that the dflt defines a pattern as well as a default, so for example, _getFormatter(\"0px 0px 0px 0px #777\", true) not only sets the default as 0px for all distances and #777 for the color, but also sets the pattern such that 4 numbers and a color will always get returned.\n\t\t * @param {!string} dflt The default value and pattern to follow. So \"0px 0px 0px 0px #777\" will ensure that 4 numbers and a color will always get returned.\n\t\t * @param {boolean=} clr If true, the values should be searched for color-related data. For example, boxShadow values typically contain a color whereas borderRadius don't.\n\t\t * @param {boolean=} collapsible If true, the value is a top/left/right/bottom style one that acts like margin or padding, where if only one value is received, it's used for all 4; if 2 are received, the first is duplicated for 3rd (bottom) and the 2nd is duplicated for the 4th spot (left), etc.\n\t\t * @return {Function} formatter function\n\t\t */\n\t\tvar _getFormatter = function(dflt, clr, collapsible, multi) {\n\t\t\t\tif (dflt == null) {\n\t\t\t\t\treturn function(v) {return v;};\n\t\t\t\t}\n\t\t\t\tvar dColor = clr ? (dflt.match(_colorExp) || [\"\"])[0] : \"\",\n\t\t\t\t\tdVals = dflt.split(dColor).join(\"\").match(_valuesExp) || [],\n\t\t\t\t\tpfx = dflt.substr(0, dflt.indexOf(dVals[0])),\n\t\t\t\t\tsfx = (dflt.charAt(dflt.length - 1) === \")\") ? \")\" : \"\",\n\t\t\t\t\tdelim = (dflt.indexOf(\" \") !== -1) ? \" \" : \",\",\n\t\t\t\t\tnumVals = dVals.length,\n\t\t\t\t\tdSfx = (numVals > 0) ? dVals[0].replace(_numExp, \"\") : \"\",\n\t\t\t\t\tformatter;\n\t\t\t\tif (!numVals) {\n\t\t\t\t\treturn function(v) {return v;};\n\t\t\t\t}\n\t\t\t\tif (clr) {\n\t\t\t\t\tformatter = function(v) {\n\t\t\t\t\t\tvar color, vals, i, a;\n\t\t\t\t\t\tif (typeof(v) === \"number\") {\n\t\t\t\t\t\t\tv += dSfx;\n\t\t\t\t\t\t} else if (multi && _commasOutsideParenExp.test(v)) {\n\t\t\t\t\t\t\ta = v.replace(_commasOutsideParenExp, \"|\").split(\"|\");\n\t\t\t\t\t\t\tfor (i = 0; i < a.length; i++) {\n\t\t\t\t\t\t\t\ta[i] = formatter(a[i]);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\treturn a.join(\",\");\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcolor = (v.match(_colorExp) || [dColor])[0];\n\t\t\t\t\t\tvals = v.split(color).join(\"\").match(_valuesExp) || [];\n\t\t\t\t\t\ti = vals.length;\n\t\t\t\t\t\tif (numVals > i--) {\n\t\t\t\t\t\t\twhile (++i < numVals) {\n\t\t\t\t\t\t\t\tvals[i] = collapsible ? vals[(((i - 1) / 2) | 0)] : dVals[i];\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn pfx + vals.join(delim) + delim + color + sfx + (v.indexOf(\"inset\") !== -1 ? \" inset\" : \"\");\n\t\t\t\t\t};\n\t\t\t\t\treturn formatter;\n\n\t\t\t\t}\n\t\t\t\tformatter = function(v) {\n\t\t\t\t\tvar vals, a, i;\n\t\t\t\t\tif (typeof(v) === \"number\") {\n\t\t\t\t\t\tv += dSfx;\n\t\t\t\t\t} else if (multi && _commasOutsideParenExp.test(v)) {\n\t\t\t\t\t\ta = v.replace(_commasOutsideParenExp, \"|\").split(\"|\");\n\t\t\t\t\t\tfor (i = 0; i < a.length; i++) {\n\t\t\t\t\t\t\ta[i] = formatter(a[i]);\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn a.join(\",\");\n\t\t\t\t\t}\n\t\t\t\t\tvals = v.match(delim === \",\" ? _valuesExp : _valuesExpWithCommas) || [];\n\t\t\t\t\ti = vals.length;\n\t\t\t\t\tif (numVals > i--) {\n\t\t\t\t\t\twhile (++i < numVals) {\n\t\t\t\t\t\t\tvals[i] = collapsible ? vals[(((i - 1) / 2) | 0)] : dVals[i];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn ((pfx && v !== \"none\") ? v.substr(0, v.indexOf(vals[0])) || pfx : pfx) + vals.join(delim) + sfx; //note: prefix might be different, like for clipPath it could start with inset( or polygon(\n\t\t\t\t};\n\t\t\t\treturn formatter;\n\t\t\t},\n\n\t\t\t/**\n\t\t\t * @private returns a formatter function that's used for edge-related values like marginTop, marginLeft, paddingBottom, paddingRight, etc. Just pass a comma-delimited list of property names related to the edges.\n\t\t\t * @param {!string} props a comma-delimited list of property names in order from top to left, like \"marginTop,marginRight,marginBottom,marginLeft\"\n\t\t\t * @return {Function} a formatter function\n\t\t\t */\n\t\t\t_getEdgeParser = function(props) {\n\t\t\t\tprops = props.split(\",\");\n\t\t\t\treturn function(t, e, p, cssp, pt, plugin, vars) {\n\t\t\t\t\tvar a = (e + \"\").split(\" \"),\n\t\t\t\t\t\ti;\n\t\t\t\t\tvars = {};\n\t\t\t\t\tfor (i = 0; i < 4; i++) {\n\t\t\t\t\t\tvars[props[i]] = a[i] = a[i] || a[(((i - 1) / 2) >> 0)];\n\t\t\t\t\t}\n\t\t\t\t\treturn cssp.parse(t, vars, pt, plugin);\n\t\t\t\t};\n\t\t\t},\n\n\t\t\t// @private used when other plugins must tween values first, like BezierPlugin or ThrowPropsPlugin, etc. That plugin's setRatio() gets called first so that the values are updated, and then we loop through the MiniPropTweens which handle copying the values into their appropriate slots so that they can then be applied correctly in the main CSSPlugin setRatio() method. Remember, we typically create a proxy object that has a bunch of uniquely-named properties that we feed to the sub-plugin and it does its magic normally, and then we must interpret those values and apply them to the css because often numbers must get combined/concatenated, suffixes added, etc. to work with css, like boxShadow could have 4 values plus a color.\n\t\t\t_setPluginRatio = _internals._setPluginRatio = function(v) {\n\t\t\t\tthis.plugin.setRatio(v);\n\t\t\t\tvar d = this.data,\n\t\t\t\t\tproxy = d.proxy,\n\t\t\t\t\tmpt = d.firstMPT,\n\t\t\t\t\tmin = 0.000001,\n\t\t\t\t\tval, pt, i, str, p;\n\t\t\t\twhile (mpt) {\n\t\t\t\t\tval = proxy[mpt.v];\n\t\t\t\t\tif (mpt.r) {\n\t\t\t\t\t\tval = mpt.r(val);\n\t\t\t\t\t} else if (val < min && val > -min) {\n\t\t\t\t\t\tval = 0;\n\t\t\t\t\t}\n\t\t\t\t\tmpt.t[mpt.p] = val;\n\t\t\t\t\tmpt = mpt._next;\n\t\t\t\t}\n\t\t\t\tif (d.autoRotate) {\n\t\t\t\t\td.autoRotate.rotation = d.mod ? d.mod.call(this._tween, proxy.rotation, this.t, this._tween) : proxy.rotation; //special case for ModifyPlugin to hook into an auto-rotating bezier\n\t\t\t\t}\n\t\t\t\t//at the end, we must set the CSSPropTween's \"e\" (end) value dynamically here because that's what is used in the final setRatio() method. Same for \"b\" at the beginning.\n\t\t\t\tif (v === 1 || v === 0) {\n\t\t\t\t\tmpt = d.firstMPT;\n\t\t\t\t\tp = (v === 1) ? \"e\" : \"b\";\n\t\t\t\t\twhile (mpt) {\n\t\t\t\t\t\tpt = mpt.t;\n\t\t\t\t\t\tif (!pt.type) {\n\t\t\t\t\t\t\tpt[p] = pt.s + pt.xs0;\n\t\t\t\t\t\t} else if (pt.type === 1) {\n\t\t\t\t\t\t\tstr = pt.xs0 + pt.s + pt.xs1;\n\t\t\t\t\t\t\tfor (i = 1; i < pt.l; i++) {\n\t\t\t\t\t\t\t\tstr += pt[\"xn\"+i] + pt[\"xs\"+(i+1)];\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tpt[p] = str;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tmpt = mpt._next;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t},\n\n\t\t\t/**\n\t\t\t * @private @constructor Used by a few SpecialProps to hold important values for proxies. For example, _parseToProxy() creates a MiniPropTween instance for each property that must get tweened on the proxy, and we record the original property name as well as the unique one we create for the proxy, plus whether or not the value needs to be rounded plus the original value.\n\t\t\t * @param {!Object} t target object whose property we're tweening (often a CSSPropTween)\n\t\t\t * @param {!string} p property name\n\t\t\t * @param {(number|string|object)} v value\n\t\t\t * @param {MiniPropTween=} next next MiniPropTween in the linked list\n\t\t\t * @param {boolean=} r if true, the tweened value should be rounded to the nearest integer\n\t\t\t */\n\t\t\tMiniPropTween = function(t, p, v, next, r) {\n\t\t\t\tthis.t = t;\n\t\t\t\tthis.p = p;\n\t\t\t\tthis.v = v;\n\t\t\t\tthis.r = r;\n\t\t\t\tif (next) {\n\t\t\t\t\tnext._prev = this;\n\t\t\t\t\tthis._next = next;\n\t\t\t\t}\n\t\t\t},\n\n\t\t\t/**\n\t\t\t * @private Most other plugins (like BezierPlugin and ThrowPropsPlugin and others) can only tween numeric values, but CSSPlugin must accommodate special values that have a bunch of extra data (like a suffix or strings between numeric values, etc.). For example, boxShadow has values like \"10px 10px 20px 30px rgb(255,0,0)\" which would utterly confuse other plugins. This method allows us to split that data apart and grab only the numeric data and attach it to uniquely-named properties of a generic proxy object ({}) so that we can feed that to virtually any plugin to have the numbers tweened. However, we must also keep track of which properties from the proxy go with which CSSPropTween values and instances. So we create a linked list of MiniPropTweens. Each one records a target (the original CSSPropTween), property (like \"s\" or \"xn1\" or \"xn2\") that we're tweening and the unique property name that was used for the proxy (like \"boxShadow_xn1\" and \"boxShadow_xn2\") and whether or not they need to be rounded. That way, in the _setPluginRatio() method we can simply copy the values over from the proxy to the CSSPropTween instance(s). Then, when the main CSSPlugin setRatio() method runs and applies the CSSPropTween values accordingly, they're updated nicely. So the external plugin tweens the numbers, _setPluginRatio() copies them over, and setRatio() acts normally, applying css-specific values to the element.\n\t\t\t * This method returns an object that has the following properties:\n\t\t\t *  - proxy: a generic object containing the starting values for all the properties that will be tweened by the external plugin.  This is what we feed to the external _onInitTween() as the target\n\t\t\t *  - end: a generic object containing the ending values for all the properties that will be tweened by the external plugin. This is what we feed to the external plugin's _onInitTween() as the destination values\n\t\t\t *  - firstMPT: the first MiniPropTween in the linked list\n\t\t\t *  - pt: the first CSSPropTween in the linked list that was created when parsing. If shallow is true, this linked list will NOT attach to the one passed into the _parseToProxy() as the \"pt\" (4th) parameter.\n\t\t\t * @param {!Object} t target object to be tweened\n\t\t\t * @param {!(Object|string)} vars the object containing the information about the tweening values (typically the end/destination values) that should be parsed\n\t\t\t * @param {!CSSPlugin} cssp The CSSPlugin instance\n\t\t\t * @param {CSSPropTween=} pt the next CSSPropTween in the linked list\n\t\t\t * @param {TweenPlugin=} plugin the external TweenPlugin instance that will be handling tweening the numeric values\n\t\t\t * @param {boolean=} shallow if true, the resulting linked list from the parse will NOT be attached to the CSSPropTween that was passed in as the \"pt\" (4th) parameter.\n\t\t\t * @return An object containing the following properties: proxy, end, firstMPT, and pt (see above for descriptions)\n\t\t\t */\n\t\t\t_parseToProxy = _internals._parseToProxy = function(t, vars, cssp, pt, plugin, shallow) {\n\t\t\t\tvar bpt = pt,\n\t\t\t\t\tstart = {},\n\t\t\t\t\tend = {},\n\t\t\t\t\ttransform = cssp._transform,\n\t\t\t\t\toldForce = _forcePT,\n\t\t\t\t\ti, p, xp, mpt, firstPT;\n\t\t\t\tcssp._transform = null;\n\t\t\t\t_forcePT = vars;\n\t\t\t\tpt = firstPT = cssp.parse(t, vars, pt, plugin);\n\t\t\t\t_forcePT = oldForce;\n\t\t\t\t//break off from the linked list so the new ones are isolated.\n\t\t\t\tif (shallow) {\n\t\t\t\t\tcssp._transform = transform;\n\t\t\t\t\tif (bpt) {\n\t\t\t\t\t\tbpt._prev = null;\n\t\t\t\t\t\tif (bpt._prev) {\n\t\t\t\t\t\t\tbpt._prev._next = null;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\twhile (pt && pt !== bpt) {\n\t\t\t\t\tif (pt.type <= 1) {\n\t\t\t\t\t\tp = pt.p;\n\t\t\t\t\t\tend[p] = pt.s + pt.c;\n\t\t\t\t\t\tstart[p] = pt.s;\n\t\t\t\t\t\tif (!shallow) {\n\t\t\t\t\t\t\tmpt = new MiniPropTween(pt, \"s\", p, mpt, pt.r);\n\t\t\t\t\t\t\tpt.c = 0;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (pt.type === 1) {\n\t\t\t\t\t\t\ti = pt.l;\n\t\t\t\t\t\t\twhile (--i > 0) {\n\t\t\t\t\t\t\t\txp = \"xn\" + i;\n\t\t\t\t\t\t\t\tp = pt.p + \"_\" + xp;\n\t\t\t\t\t\t\t\tend[p] = pt.data[xp];\n\t\t\t\t\t\t\t\tstart[p] = pt[xp];\n\t\t\t\t\t\t\t\tif (!shallow) {\n\t\t\t\t\t\t\t\t\tmpt = new MiniPropTween(pt, xp, p, mpt, pt.rxp[xp]);\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tpt = pt._next;\n\t\t\t\t}\n\t\t\t\treturn {proxy:start, end:end, firstMPT:mpt, pt:firstPT};\n\t\t\t},\n\n\n\n\t\t\t/**\n\t\t\t * @constructor Each property that is tweened has at least one CSSPropTween associated with it. These instances store important information like the target, property, starting value, amount of change, etc. They can also optionally have a number of \"extra\" strings and numeric values named xs1, xn1, xs2, xn2, xs3, xn3, etc. where \"s\" indicates string and \"n\" indicates number. These can be pieced together in a complex-value tween (type:1) that has alternating types of data like a string, number, string, number, etc. For example, boxShadow could be \"5px 5px 8px rgb(102, 102, 51)\". In that value, there are 6 numbers that may need to tween and then pieced back together into a string again with spaces, suffixes, etc. xs0 is special in that it stores the suffix for standard (type:0) tweens, -OR- the first string (prefix) in a complex-value (type:1) CSSPropTween -OR- it can be the non-tweening value in a type:-1 CSSPropTween. We do this to conserve memory.\n\t\t\t * CSSPropTweens have the following optional properties as well (not defined through the constructor):\n\t\t\t *  - l: Length in terms of the number of extra properties that the CSSPropTween has (default: 0). For example, for a boxShadow we may need to tween 5 numbers in which case l would be 5; Keep in mind that the start/end values for the first number that's tweened are always stored in the s and c properties to conserve memory. All additional values thereafter are stored in xn1, xn2, etc.\n\t\t\t *  - xfirst: The first instance of any sub-CSSPropTweens that are tweening properties of this instance. For example, we may split up a boxShadow tween so that there's a main CSSPropTween of type:1 that has various xs* and xn* values associated with the h-shadow, v-shadow, blur, color, etc. Then we spawn a CSSPropTween for each of those that has a higher priority and runs BEFORE the main CSSPropTween so that the values are all set by the time it needs to re-assemble them. The xfirst gives us an easy way to identify the first one in that chain which typically ends at the main one (because they're all prepende to the linked list)\n\t\t\t *  - plugin: The TweenPlugin instance that will handle the tweening of any complex values. For example, sometimes we don't want to use normal subtweens (like xfirst refers to) to tween the values - we might want ThrowPropsPlugin or BezierPlugin some other plugin to do the actual tweening, so we create a plugin instance and store a reference here. We need this reference so that if we get a request to round values or disable a tween, we can pass along that request.\n\t\t\t *  - data: Arbitrary data that needs to be stored with the CSSPropTween. Typically if we're going to have a plugin handle the tweening of a complex-value tween, we create a generic object that stores the END values that we're tweening to and the CSSPropTween's xs1, xs2, etc. have the starting values. We store that object as data. That way, we can simply pass that object to the plugin and use the CSSPropTween as the target.\n\t\t\t *  - setRatio: Only used for type:2 tweens that require custom functionality. In this case, we call the CSSPropTween's setRatio() method and pass the ratio each time the tween updates. This isn't quite as efficient as doing things directly in the CSSPlugin's setRatio() method, but it's very convenient and flexible.\n\t\t\t * @param {!Object} t Target object whose property will be tweened. Often a DOM element, but not always. It could be anything.\n\t\t\t * @param {string} p Property to tween (name). For example, to tween element.width, p would be \"width\".\n\t\t\t * @param {number} s Starting numeric value\n\t\t\t * @param {number} c Change in numeric value over the course of the entire tween. For example, if element.width starts at 5 and should end at 100, c would be 95.\n\t\t\t * @param {CSSPropTween=} next The next CSSPropTween in the linked list. If one is defined, we will define its _prev as the new instance, and the new instance's _next will be pointed at it.\n\t\t\t * @param {number=} type The type of CSSPropTween where -1 = a non-tweening value, 0 = a standard simple tween, 1 = a complex value (like one that has multiple numbers in a comma- or space-delimited string like border:\"1px solid red\"), and 2 = one that uses a custom setRatio function that does all of the work of applying the values on each update.\n\t\t\t * @param {string=} n Name of the property that should be used for overwriting purposes which is typically the same as p but not always. For example, we may need to create a subtween for the 2nd part of a \"clip:rect(...)\" tween in which case \"p\" might be xs1 but \"n\" is still \"clip\"\n\t\t\t * @param {boolean=} r If true, the value(s) should be rounded\n\t\t\t * @param {number=} pr Priority in the linked list order. Higher priority CSSPropTweens will be updated before lower priority ones. The default priority is 0.\n\t\t\t * @param {string=} b Beginning value. We store this to ensure that it is EXACTLY what it was when the tween began without any risk of interpretation issues.\n\t\t\t * @param {string=} e Ending value. We store this to ensure that it is EXACTLY what the user defined at the end of the tween without any risk of interpretation issues.\n\t\t\t */\n\t\t\tCSSPropTween = _internals.CSSPropTween = function(t, p, s, c, next, type, n, r, pr, b, e) {\n\t\t\t\tthis.t = t; //target\n\t\t\t\tthis.p = p; //property\n\t\t\t\tthis.s = s; //starting value\n\t\t\t\tthis.c = c; //change value\n\t\t\t\tthis.n = n || p; //name that this CSSPropTween should be associated to (usually the same as p, but not always - n is what overwriting looks at)\n\t\t\t\tif (!(t instanceof CSSPropTween)) {\n\t\t\t\t\t_overwriteProps.push(this.n);\n\t\t\t\t}\n\t\t\t\tthis.r = !r ? r : (typeof(r) === \"function\") ? r : Math.round; //round (boolean)\n\t\t\t\tthis.type = type || 0; //0 = normal tween, -1 = non-tweening (in which case xs0 will be applied to the target's property, like tp.t[tp.p] = tp.xs0), 1 = complex-value SpecialProp, 2 = custom setRatio() that does all the work\n\t\t\t\tif (pr) {\n\t\t\t\t\tthis.pr = pr;\n\t\t\t\t\t_hasPriority = true;\n\t\t\t\t}\n\t\t\t\tthis.b = (b === undefined) ? s : b;\n\t\t\t\tthis.e = (e === undefined) ? s + c : e;\n\t\t\t\tif (next) {\n\t\t\t\t\tthis._next = next;\n\t\t\t\t\tnext._prev = this;\n\t\t\t\t}\n\t\t\t},\n\n\t\t\t_addNonTweeningNumericPT = function(target, prop, start, end, next, overwriteProp) { //cleans up some code redundancies and helps minification. Just a fast way to add a NUMERIC non-tweening CSSPropTween\n\t\t\t\tvar pt = new CSSPropTween(target, prop, start, end - start, next, -1, overwriteProp);\n\t\t\t\tpt.b = start;\n\t\t\t\tpt.e = pt.xs0 = end;\n\t\t\t\treturn pt;\n\t\t\t},\n\n\t\t\t/**\n\t\t\t * Takes a target, the beginning value and ending value (as strings) and parses them into a CSSPropTween (possibly with child CSSPropTweens) that accommodates multiple numbers, colors, comma-delimited values, etc. For example:\n\t\t\t * sp.parseComplex(element, \"boxShadow\", \"5px 10px 20px rgb(255,102,51)\", \"0px 0px 0px red\", true, \"0px 0px 0px rgb(0,0,0,0)\", pt);\n\t\t\t * It will walk through the beginning and ending values (which should be in the same format with the same number and type of values) and figure out which parts are numbers, what strings separate the numeric/tweenable values, and then create the CSSPropTweens accordingly. If a plugin is defined, no child CSSPropTweens will be created. Instead, the ending values will be stored in the \"data\" property of the returned CSSPropTween like: {s:-5, xn1:-10, xn2:-20, xn3:255, xn4:0, xn5:0} so that it can be fed to any other plugin and it'll be plain numeric tweens but the recomposition of the complex value will be handled inside CSSPlugin's setRatio().\n\t\t\t * If a setRatio is defined, the type of the CSSPropTween will be set to 2 and recomposition of the values will be the responsibility of that method.\n\t\t\t *\n\t\t\t * @param {!Object} t Target whose property will be tweened\n\t\t\t * @param {!string} p Property that will be tweened (its name, like \"left\" or \"backgroundColor\" or \"boxShadow\")\n\t\t\t * @param {string} b Beginning value\n\t\t\t * @param {string} e Ending value\n\t\t\t * @param {boolean} clrs If true, the value could contain a color value like \"rgb(255,0,0)\" or \"#F00\" or \"red\". The default is false, so no colors will be recognized (a performance optimization)\n\t\t\t * @param {(string|number|Object)} dflt The default beginning value that should be used if no valid beginning value is defined or if the number of values inside the complex beginning and ending values don't match\n\t\t\t * @param {?CSSPropTween} pt CSSPropTween instance that is the current head of the linked list (we'll prepend to this).\n\t\t\t * @param {number=} pr Priority in the linked list order. Higher priority properties will be updated before lower priority ones. The default priority is 0.\n\t\t\t * @param {TweenPlugin=} plugin If a plugin should handle the tweening of extra properties, pass the plugin instance here. If one is defined, then NO subtweens will be created for any extra properties (the properties will be created - just not additional CSSPropTween instances to tween them) because the plugin is expected to do so. However, the end values WILL be populated in the \"data\" property, like {s:100, xn1:50, xn2:300}\n\t\t\t * @param {function(number)=} setRatio If values should be set in a custom function instead of being pieced together in a type:1 (complex-value) CSSPropTween, define that custom function here.\n\t\t\t * @return {CSSPropTween} The first CSSPropTween in the linked list which includes the new one(s) added by the parseComplex() call.\n\t\t\t */\n\t\t\t_parseComplex = CSSPlugin.parseComplex = function(t, p, b, e, clrs, dflt, pt, pr, plugin, setRatio) {\n\t\t\t\t//DEBUG: _log(\"parseComplex: \"+p+\", b: \"+b+\", e: \"+e);\n\t\t\t\tb = b || dflt || \"\";\n\t\t\t\tif (typeof(e) === \"function\") {\n\t\t\t\t\te = e(_index, _target);\n\t\t\t\t}\n\t\t\t\tpt = new CSSPropTween(t, p, 0, 0, pt, (setRatio ? 2 : 1), null, false, pr, b, e);\n\t\t\t\te += \"\"; //ensures it's a string\n\t\t\t\tif (clrs && _colorExp.test(e + b)) { //if colors are found, normalize the formatting to rgba() or hsla().\n\t\t\t\t\te = [b, e];\n\t\t\t\t\tCSSPlugin.colorStringFilter(e);\n\t\t\t\t\tb = e[0];\n\t\t\t\t\te = e[1];\n\t\t\t\t}\n\t\t\t\tvar ba = b.split(\", \").join(\",\").split(\" \"), //beginning array\n\t\t\t\t\tea = e.split(\", \").join(\",\").split(\" \"), //ending array\n\t\t\t\t\tl = ba.length,\n\t\t\t\t\tautoRound = (_autoRound !== false),\n\t\t\t\t\ti, xi, ni, bv, ev, bnums, enums, bn, hasAlpha, temp, cv, str, useHSL;\n\t\t\t\tif (e.indexOf(\",\") !== -1 || b.indexOf(\",\") !== -1) {\n\t\t\t\t\tif ((e + b).indexOf(\"rgb\") !== -1 || (e + b).indexOf(\"hsl\") !== -1) { //keep rgb(), rgba(), hsl(), and hsla() values together! (remember, we're splitting on spaces)\n\t\t\t\t\t\tba = ba.join(\" \").replace(_commasOutsideParenExp, \", \").split(\" \");\n\t\t\t\t\t\tea = ea.join(\" \").replace(_commasOutsideParenExp, \", \").split(\" \");\n\t\t\t\t\t} else {\n\t\t\t\t\t\tba = ba.join(\" \").split(\",\").join(\", \").split(\" \");\n\t\t\t\t\t\tea = ea.join(\" \").split(\",\").join(\", \").split(\" \");\n\t\t\t\t\t}\n\t\t\t\t\tl = ba.length;\n\t\t\t\t}\n\t\t\t\tif (l !== ea.length) {\n\t\t\t\t\t//DEBUG: _log(\"mismatched formatting detected on \" + p + \" (\" + b + \" vs \" + e + \")\");\n\t\t\t\t\tba = (dflt || \"\").split(\" \");\n\t\t\t\t\tl = ba.length;\n\t\t\t\t}\n\t\t\t\tpt.plugin = plugin;\n\t\t\t\tpt.setRatio = setRatio;\n\t\t\t\t_colorExp.lastIndex = 0;\n\t\t\t\tfor (i = 0; i < l; i++) {\n\t\t\t\t\tbv = ba[i];\n\t\t\t\t\tev = ea[i] + \"\";\n\t\t\t\t\tbn = parseFloat(bv);\n\t\t\t\t\t//if the value begins with a number (most common). It's fine if it has a suffix like px\n\t\t\t\t\tif (bn || bn === 0) {\n\t\t\t\t\t\tpt.appendXtra(\"\", bn, _parseChange(ev, bn), ev.replace(_relNumExp, \"\"), (autoRound && ev.indexOf(\"px\") !== -1) ? Math.round : false, true);\n\n\t\t\t\t\t//if the value is a color\n\t\t\t\t\t} else if (clrs && _colorExp.test(bv)) {\n\t\t\t\t\t\tstr = ev.indexOf(\")\") + 1;\n\t\t\t\t\t\tstr = \")\" + (str ? ev.substr(str) : \"\"); //if there's a comma or ) at the end, retain it.\n\t\t\t\t\t\tuseHSL = (ev.indexOf(\"hsl\") !== -1 && _supportsOpacity);\n\t\t\t\t\t\ttemp = ev; //original string value so we can look for any prefix later.\n\t\t\t\t\t\tbv = _parseColor(bv, useHSL);\n\t\t\t\t\t\tev = _parseColor(ev, useHSL);\n\t\t\t\t\t\thasAlpha = (bv.length + ev.length > 6);\n\t\t\t\t\t\tif (hasAlpha && !_supportsOpacity && ev[3] === 0) { //older versions of IE don't support rgba(), so if the destination alpha is 0, just use \"transparent\" for the end color\n\t\t\t\t\t\t\tpt[\"xs\" + pt.l] += pt.l ? \" transparent\" : \"transparent\";\n\t\t\t\t\t\t\tpt.e = pt.e.split(ea[i]).join(\"transparent\");\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tif (!_supportsOpacity) { //old versions of IE don't support rgba().\n\t\t\t\t\t\t\t\thasAlpha = false;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (useHSL) {\n\t\t\t\t\t\t\t\tpt.appendXtra(temp.substr(0, temp.indexOf(\"hsl\")) + (hasAlpha ? \"hsla(\" : \"hsl(\"), bv[0], _parseChange(ev[0], bv[0]), \",\", false, true)\n\t\t\t\t\t\t\t\t\t.appendXtra(\"\", bv[1], _parseChange(ev[1], bv[1]), \"%,\", false)\n\t\t\t\t\t\t\t\t\t.appendXtra(\"\", bv[2], _parseChange(ev[2], bv[2]), (hasAlpha ? \"%,\" : \"%\" + str), false);\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tpt.appendXtra(temp.substr(0, temp.indexOf(\"rgb\")) + (hasAlpha ? \"rgba(\" : \"rgb(\"), bv[0], ev[0] - bv[0], \",\", Math.round, true)\n\t\t\t\t\t\t\t\t\t.appendXtra(\"\", bv[1], ev[1] - bv[1], \",\", Math.round)\n\t\t\t\t\t\t\t\t\t.appendXtra(\"\", bv[2], ev[2] - bv[2], (hasAlpha ? \",\" : str), Math.round);\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (hasAlpha) {\n\t\t\t\t\t\t\t\tbv = (bv.length < 4) ? 1 : bv[3];\n\t\t\t\t\t\t\t\tpt.appendXtra(\"\", bv, ((ev.length < 4) ? 1 : ev[3]) - bv, str, false);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\t_colorExp.lastIndex = 0; //otherwise the test() on the RegExp could move the lastIndex and taint future results.\n\n\t\t\t\t\t} else {\n\t\t\t\t\t\tbnums = bv.match(_numExp); //gets each group of numbers in the beginning value string and drops them into an array\n\n\t\t\t\t\t\t//if no number is found, treat it as a non-tweening value and just append the string to the current xs.\n\t\t\t\t\t\tif (!bnums) {\n\t\t\t\t\t\t\tpt[\"xs\" + pt.l] += (pt.l || pt[\"xs\" + pt.l]) ? \" \" + ev : ev;\n\n\t\t\t\t\t\t//loop through all the numbers that are found and construct the extra values on the pt.\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tenums = ev.match(_relNumExp); //get each group of numbers in the end value string and drop them into an array. We allow relative values too, like +=50 or -=.5\n\t\t\t\t\t\t\tif (!enums || enums.length !== bnums.length) {\n\t\t\t\t\t\t\t\t//DEBUG: _log(\"mismatched formatting detected on \" + p + \" (\" + b + \" vs \" + e + \")\");\n\t\t\t\t\t\t\t\treturn pt;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tni = 0;\n\t\t\t\t\t\t\tfor (xi = 0; xi < bnums.length; xi++) {\n\t\t\t\t\t\t\t\tcv = bnums[xi];\n\t\t\t\t\t\t\t\ttemp = bv.indexOf(cv, ni);\n\t\t\t\t\t\t\t\tpt.appendXtra(bv.substr(ni, temp - ni), Number(cv), _parseChange(enums[xi], cv), \"\", (autoRound && bv.substr(temp + cv.length, 2) === \"px\") ? Math.round : false, (xi === 0));\n\t\t\t\t\t\t\t\tni = temp + cv.length;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tpt[\"xs\" + pt.l] += bv.substr(ni);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t//if there are relative values (\"+=\" or \"-=\" prefix), we need to adjust the ending value to eliminate the prefixes and combine the values properly.\n\t\t\t\tif (e.indexOf(\"=\") !== -1) if (pt.data) {\n\t\t\t\t\tstr = pt.xs0 + pt.data.s;\n\t\t\t\t\tfor (i = 1; i < pt.l; i++) {\n\t\t\t\t\t\tstr += pt[\"xs\" + i] + pt.data[\"xn\" + i];\n\t\t\t\t\t}\n\t\t\t\t\tpt.e = str + pt[\"xs\" + i];\n\t\t\t\t}\n\t\t\t\tif (!pt.l) {\n\t\t\t\t\tpt.type = -1;\n\t\t\t\t\tpt.xs0 = pt.e;\n\t\t\t\t}\n\t\t\t\treturn pt.xfirst || pt;\n\t\t\t},\n\t\t\ti = 9;\n\n\n\t\tp = CSSPropTween.prototype;\n\t\tp.l = p.pr = 0; //length (number of extra properties like xn1, xn2, xn3, etc.\n\t\twhile (--i > 0) {\n\t\t\tp[\"xn\" + i] = 0;\n\t\t\tp[\"xs\" + i] = \"\";\n\t\t}\n\t\tp.xs0 = \"\";\n\t\tp._next = p._prev = p.xfirst = p.data = p.plugin = p.setRatio = p.rxp = null;\n\n\n\t\t/**\n\t\t * Appends and extra tweening value to a CSSPropTween and automatically manages any prefix and suffix strings. The first extra value is stored in the s and c of the main CSSPropTween instance, but thereafter any extras are stored in the xn1, xn2, xn3, etc. The prefixes and suffixes are stored in the xs0, xs1, xs2, etc. properties. For example, if I walk through a clip value like \"rect(10px, 5px, 0px, 20px)\", the values would be stored like this:\n\t\t * xs0:\"rect(\", s:10, xs1:\"px, \", xn1:5, xs2:\"px, \", xn2:0, xs3:\"px, \", xn3:20, xn4:\"px)\"\n\t\t * And they'd all get joined together when the CSSPlugin renders (in the setRatio() method).\n\t\t * @param {string=} pfx Prefix (if any)\n\t\t * @param {!number} s Starting value\n\t\t * @param {!number} c Change in numeric value over the course of the entire tween. For example, if the start is 5 and the end is 100, the change would be 95.\n\t\t * @param {string=} sfx Suffix (if any)\n\t\t * @param {boolean=} r Round (if true).\n\t\t * @param {boolean=} pad If true, this extra value should be separated by the previous one by a space. If there is no previous extra and pad is true, it will automatically drop the space.\n\t\t * @return {CSSPropTween} returns itself so that multiple methods can be chained together.\n\t\t */\n\t\tp.appendXtra = function(pfx, s, c, sfx, r, pad) {\n\t\t\tvar pt = this,\n\t\t\t\tl = pt.l;\n\t\t\tpt[\"xs\" + l] += (pad && (l || pt[\"xs\" + l])) ? \" \" + pfx : pfx || \"\";\n\t\t\tif (!c) if (l !== 0 && !pt.plugin) { //typically we'll combine non-changing values right into the xs to optimize performance, but we don't combine them when there's a plugin that will be tweening the values because it may depend on the values being split apart, like for a bezier, if a value doesn't change between the first and second iteration but then it does on the 3rd, we'll run into trouble because there's no xn slot for that value!\n\t\t\t\tpt[\"xs\" + l] += s + (sfx || \"\");\n\t\t\t\treturn pt;\n\t\t\t}\n\t\t\tpt.l++;\n\t\t\tpt.type = pt.setRatio ? 2 : 1;\n\t\t\tpt[\"xs\" + pt.l] = sfx || \"\";\n\t\t\tif (l > 0) {\n\t\t\t\tpt.data[\"xn\" + l] = s + c;\n\t\t\t\tpt.rxp[\"xn\" + l] = r; //round extra property (we need to tap into this in the _parseToProxy() method)\n\t\t\t\tpt[\"xn\" + l] = s;\n\t\t\t\tif (!pt.plugin) {\n\t\t\t\t\tpt.xfirst = new CSSPropTween(pt, \"xn\" + l, s, c, pt.xfirst || pt, 0, pt.n, r, pt.pr);\n\t\t\t\t\tpt.xfirst.xs0 = 0; //just to ensure that the property stays numeric which helps modern browsers speed up processing. Remember, in the setRatio() method, we do pt.t[pt.p] = val + pt.xs0 so if pt.xs0 is \"\" (the default), it'll cast the end value as a string. When a property is a number sometimes and a string sometimes, it prevents the compiler from locking in the data type, slowing things down slightly.\n\t\t\t\t}\n\t\t\t\treturn pt;\n\t\t\t}\n\t\t\tpt.data = {s:s + c};\n\t\t\tpt.rxp = {};\n\t\t\tpt.s = s;\n\t\t\tpt.c = c;\n\t\t\tpt.r = r;\n\t\t\treturn pt;\n\t\t};\n\n\t\t/**\n\t\t * @constructor A SpecialProp is basically a css property that needs to be treated in a non-standard way, like if it may contain a complex value like boxShadow:\"5px 10px 15px rgb(255, 102, 51)\" or if it is associated with another plugin like ThrowPropsPlugin or BezierPlugin. Every SpecialProp is associated with a particular property name like \"boxShadow\" or \"throwProps\" or \"bezier\" and it will intercept those values in the vars object that's passed to the CSSPlugin and handle them accordingly.\n\t\t * @param {!string} p Property name (like \"boxShadow\" or \"throwProps\")\n\t\t * @param {Object=} options An object containing any of the following configuration options:\n\t\t *                      - defaultValue: the default value\n\t\t *                      - parser: A function that should be called when the associated property name is found in the vars. This function should return a CSSPropTween instance and it should ensure that it is properly inserted into the linked list. It will receive 4 paramters: 1) The target, 2) The value defined in the vars, 3) The CSSPlugin instance (whose _firstPT should be used for the linked list), and 4) A computed style object if one was calculated (this is a speed optimization that allows retrieval of starting values quicker)\n\t\t *                      - formatter: a function that formats any value received for this special property (for example, boxShadow could take \"5px 5px red\" and format it to \"5px 5px 0px 0px red\" so that both the beginning and ending values have a common order and quantity of values.)\n\t\t *                      - prefix: if true, we'll determine whether or not this property requires a vendor prefix (like Webkit or Moz or ms or O)\n\t\t *                      - color: set this to true if the value for this SpecialProp may contain color-related values like rgb(), rgba(), etc.\n\t\t *                      - priority: priority in the linked list order. Higher priority SpecialProps will be updated before lower priority ones. The default priority is 0.\n\t\t *                      - multi: if true, the formatter should accommodate a comma-delimited list of values, like boxShadow could have multiple boxShadows listed out.\n\t\t *                      - collapsible: if true, the formatter should treat the value like it's a top/right/bottom/left value that could be collapsed, like \"5px\" would apply to all, \"5px, 10px\" would use 5px for top/bottom and 10px for right/left, etc.\n\t\t *                      - keyword: a special keyword that can [optionally] be found inside the value (like \"inset\" for boxShadow). This allows us to validate beginning/ending values to make sure they match (if the keyword is found in one, it'll be added to the other for consistency by default).\n\t\t */\n\t\tvar SpecialProp = function(p, options) {\n\t\t\t\toptions = options || {};\n\t\t\t\tthis.p = options.prefix ? _checkPropPrefix(p) || p : p;\n\t\t\t\t_specialProps[p] = _specialProps[this.p] = this;\n\t\t\t\tthis.format = options.formatter || _getFormatter(options.defaultValue, options.color, options.collapsible, options.multi);\n\t\t\t\tif (options.parser) {\n\t\t\t\t\tthis.parse = options.parser;\n\t\t\t\t}\n\t\t\t\tthis.clrs = options.color;\n\t\t\t\tthis.multi = options.multi;\n\t\t\t\tthis.keyword = options.keyword;\n\t\t\t\tthis.dflt = options.defaultValue;\n\t\t\t\tthis.allowFunc = options.allowFunc;\n\t\t\t\tthis.pr = options.priority || 0;\n\t\t\t},\n\n\t\t\t//shortcut for creating a new SpecialProp that can accept multiple properties as a comma-delimited list (helps minification). dflt can be an array for multiple values (we don't do a comma-delimited list because the default value may contain commas, like rect(0px,0px,0px,0px)). We attach this method to the SpecialProp class/object instead of using a private _createSpecialProp() method so that we can tap into it externally if necessary, like from another plugin.\n\t\t\t_registerComplexSpecialProp = _internals._registerComplexSpecialProp = function(p, options, defaults) {\n\t\t\t\tif (typeof(options) !== \"object\") {\n\t\t\t\t\toptions = {parser:defaults}; //to make backwards compatible with older versions of BezierPlugin and ThrowPropsPlugin\n\t\t\t\t}\n\t\t\t\tvar a = p.split(\",\"),\n\t\t\t\t\td = options.defaultValue,\n\t\t\t\t\ti, temp;\n\t\t\t\tdefaults = defaults || [d];\n\t\t\t\tfor (i = 0; i < a.length; i++) {\n\t\t\t\t\toptions.prefix = (i === 0 && options.prefix);\n\t\t\t\t\toptions.defaultValue = defaults[i] || d;\n\t\t\t\t\ttemp = new SpecialProp(a[i], options);\n\t\t\t\t}\n\t\t\t},\n\n\t\t\t//creates a placeholder special prop for a plugin so that the property gets caught the first time a tween of it is attempted, and at that time it makes the plugin register itself, thus taking over for all future tweens of that property. This allows us to not mandate that things load in a particular order and it also allows us to log() an error that informs the user when they attempt to tween an external plugin-related property without loading its .js file.\n\t\t\t_registerPluginProp = _internals._registerPluginProp = function(p) {\n\t\t\t\tif (!_specialProps[p]) {\n\t\t\t\t\tvar pluginName = p.charAt(0).toUpperCase() + p.substr(1) + \"Plugin\";\n\t\t\t\t\t_registerComplexSpecialProp(p, {parser:function(t, e, p, cssp, pt, plugin, vars) {\n\t\t\t\t\t\tvar pluginClass = _globals.com.greensock.plugins[pluginName];\n\t\t\t\t\t\tif (!pluginClass) {\n\t\t\t\t\t\t\t_log(\"Error: \" + pluginName + \" js file not loaded.\");\n\t\t\t\t\t\t\treturn pt;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tpluginClass._cssRegister();\n\t\t\t\t\t\treturn _specialProps[p].parse(t, e, p, cssp, pt, plugin, vars);\n\t\t\t\t\t}});\n\t\t\t\t}\n\t\t\t};\n\n\n\t\tp = SpecialProp.prototype;\n\n\t\t/**\n\t\t * Alias for _parseComplex() that automatically plugs in certain values for this SpecialProp, like its property name, whether or not colors should be sensed, the default value, and priority. It also looks for any keyword that the SpecialProp defines (like \"inset\" for boxShadow) and ensures that the beginning and ending values have the same number of values for SpecialProps where multi is true (like boxShadow and textShadow can have a comma-delimited list)\n\t\t * @param {!Object} t target element\n\t\t * @param {(string|number|object)} b beginning value\n\t\t * @param {(string|number|object)} e ending (destination) value\n\t\t * @param {CSSPropTween=} pt next CSSPropTween in the linked list\n\t\t * @param {TweenPlugin=} plugin If another plugin will be tweening the complex value, that TweenPlugin instance goes here.\n\t\t * @param {function=} setRatio If a custom setRatio() method should be used to handle this complex value, that goes here.\n\t\t * @return {CSSPropTween=} First CSSPropTween in the linked list\n\t\t */\n\t\tp.parseComplex = function(t, b, e, pt, plugin, setRatio) {\n\t\t\tvar kwd = this.keyword,\n\t\t\t\ti, ba, ea, l, bi, ei;\n\t\t\t//if this SpecialProp's value can contain a comma-delimited list of values (like boxShadow or textShadow), we must parse them in a special way, and look for a keyword (like \"inset\" for boxShadow) and ensure that the beginning and ending BOTH have it if the end defines it as such. We also must ensure that there are an equal number of values specified (we can't tween 1 boxShadow to 3 for example)\n\t\t\tif (this.multi) if (_commasOutsideParenExp.test(e) || _commasOutsideParenExp.test(b)) {\n\t\t\t\tba = b.replace(_commasOutsideParenExp, \"|\").split(\"|\");\n\t\t\t\tea = e.replace(_commasOutsideParenExp, \"|\").split(\"|\");\n\t\t\t} else if (kwd) {\n\t\t\t\tba = [b];\n\t\t\t\tea = [e];\n\t\t\t}\n\t\t\tif (ea) {\n\t\t\t\tl = (ea.length > ba.length) ? ea.length : ba.length;\n\t\t\t\tfor (i = 0; i < l; i++) {\n\t\t\t\t\tb = ba[i] = ba[i] || this.dflt;\n\t\t\t\t\te = ea[i] = ea[i] || this.dflt;\n\t\t\t\t\tif (kwd) {\n\t\t\t\t\t\tbi = b.indexOf(kwd);\n\t\t\t\t\t\tei = e.indexOf(kwd);\n\t\t\t\t\t\tif (bi !== ei) {\n\t\t\t\t\t\t\tif (ei === -1) { //if the keyword isn't in the end value, remove it from the beginning one.\n\t\t\t\t\t\t\t\tba[i] = ba[i].split(kwd).join(\"\");\n\t\t\t\t\t\t\t} else if (bi === -1) { //if the keyword isn't in the beginning, add it.\n\t\t\t\t\t\t\t\tba[i] += \" \" + kwd;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tb = ba.join(\", \");\n\t\t\t\te = ea.join(\", \");\n\t\t\t}\n\t\t\treturn _parseComplex(t, this.p, b, e, this.clrs, this.dflt, pt, this.pr, plugin, setRatio);\n\t\t};\n\n\t\t/**\n\t\t * Accepts a target and end value and spits back a CSSPropTween that has been inserted into the CSSPlugin's linked list and conforms with all the conventions we use internally, like type:-1, 0, 1, or 2, setting up any extra property tweens, priority, etc. For example, if we have a boxShadow SpecialProp and call:\n\t\t * this._firstPT = sp.parse(element, \"5px 10px 20px rgb(2550,102,51)\", \"boxShadow\", this);\n\t\t * It should figure out the starting value of the element's boxShadow, compare it to the provided end value and create all the necessary CSSPropTweens of the appropriate types to tween the boxShadow. The CSSPropTween that gets spit back should already be inserted into the linked list (the 4th parameter is the current head, so prepend to that).\n\t\t * @param {!Object} t Target object whose property is being tweened\n\t\t * @param {Object} e End value as provided in the vars object (typically a string, but not always - like a throwProps would be an object).\n\t\t * @param {!string} p Property name\n\t\t * @param {!CSSPlugin} cssp The CSSPlugin instance that should be associated with this tween.\n\t\t * @param {?CSSPropTween} pt The CSSPropTween that is the current head of the linked list (we'll prepend to it)\n\t\t * @param {TweenPlugin=} plugin If a plugin will be used to tween the parsed value, this is the plugin instance.\n\t\t * @param {Object=} vars Original vars object that contains the data for parsing.\n\t\t * @return {CSSPropTween} The first CSSPropTween in the linked list which includes the new one(s) added by the parse() call.\n\t\t */\n\t\tp.parse = function(t, e, p, cssp, pt, plugin, vars) {\n\t\t\treturn this.parseComplex(t.style, this.format(_getStyle(t, this.p, _cs, false, this.dflt)), this.format(e), pt, plugin);\n\t\t};\n\n\t\t/**\n\t\t * Registers a special property that should be intercepted from any \"css\" objects defined in tweens. This allows you to handle them however you want without CSSPlugin doing it for you. The 2nd parameter should be a function that accepts 3 parameters:\n\t\t *  1) Target object whose property should be tweened (typically a DOM element)\n\t\t *  2) The end/destination value (could be a string, number, object, or whatever you want)\n\t\t *  3) The tween instance (you probably don't need to worry about this, but it can be useful for looking up information like the duration)\n\t\t *\n\t\t * Then, your function should return a function which will be called each time the tween gets rendered, passing a numeric \"ratio\" parameter to your function that indicates the change factor (usually between 0 and 1). For example:\n\t\t *\n\t\t * CSSPlugin.registerSpecialProp(\"myCustomProp\", function(target, value, tween) {\n\t\t *      var start = target.style.width;\n\t\t *      return function(ratio) {\n\t\t *              target.style.width = (start + value * ratio) + \"px\";\n\t\t *              console.log(\"set width to \" + target.style.width);\n\t\t *          }\n\t\t * }, 0);\n\t\t *\n\t\t * Then, when I do this tween, it will trigger my special property:\n\t\t *\n\t\t * TweenLite.to(element, 1, {css:{myCustomProp:100}});\n\t\t *\n\t\t * In the example, of course, we're just changing the width, but you can do anything you want.\n\t\t *\n\t\t * @param {!string} name Property name (or comma-delimited list of property names) that should be intercepted and handled by your function. For example, if I define \"myCustomProp\", then it would handle that portion of the following tween: TweenLite.to(element, 1, {css:{myCustomProp:100}})\n\t\t * @param {!function(Object, Object, Object, string):function(number)} onInitTween The function that will be called when a tween of this special property is performed. The function will receive 4 parameters: 1) Target object that should be tweened, 2) Value that was passed to the tween, 3) The tween instance itself (rarely used), and 4) The property name that's being tweened. Your function should return a function that should be called on every update of the tween. That function will receive a single parameter that is a \"change factor\" value (typically between 0 and 1) indicating the amount of change as a ratio. You can use this to determine how to set the values appropriately in your function.\n\t\t * @param {number=} priority Priority that helps the engine determine the order in which to set the properties (default: 0). Higher priority properties will be updated before lower priority ones.\n\t\t */\n\t\tCSSPlugin.registerSpecialProp = function(name, onInitTween, priority) {\n\t\t\t_registerComplexSpecialProp(name, {parser:function(t, e, p, cssp, pt, plugin, vars) {\n\t\t\t\tvar rv = new CSSPropTween(t, p, 0, 0, pt, 2, p, false, priority);\n\t\t\t\trv.plugin = plugin;\n\t\t\t\trv.setRatio = onInitTween(t, e, cssp._tween, p);\n\t\t\t\treturn rv;\n\t\t\t}, priority:priority});\n\t\t};\n\n\n\n\n\n\n\t\t//transform-related methods and properties\n\t\tCSSPlugin.useSVGTransformAttr = true; //Safari and Firefox both have some rendering bugs when applying CSS transforms to SVG elements, so default to using the \"transform\" attribute instead (users can override this).\n\t\tvar _transformProps = (\"scaleX,scaleY,scaleZ,x,y,z,skewX,skewY,rotation,rotationX,rotationY,perspective,xPercent,yPercent\").split(\",\"),\n\t\t\t_transformProp = _checkPropPrefix(\"transform\"), //the Javascript (camelCase) transform property, like msTransform, WebkitTransform, MozTransform, or OTransform.\n\t\t\t_transformPropCSS = _prefixCSS + \"transform\",\n\t\t\t_transformOriginProp = _checkPropPrefix(\"transformOrigin\"),\n\t\t\t_supports3D = (_checkPropPrefix(\"perspective\") !== null),\n\t\t\tTransform = _internals.Transform = function() {\n\t\t\t\tthis.perspective = parseFloat(CSSPlugin.defaultTransformPerspective) || 0;\n\t\t\t\tthis.force3D = (CSSPlugin.defaultForce3D === false || !_supports3D) ? false : CSSPlugin.defaultForce3D || \"auto\";\n\t\t\t},\n\t\t\t_SVGElement = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"_gsScope\"].SVGElement,\n\t\t\t_useSVGTransformAttr,\n\t\t\t//Some browsers (like Firefox and IE) don't honor transform-origin properly in SVG elements, so we need to manually adjust the matrix accordingly. We feature detect here rather than always doing the conversion for certain browsers because they may fix the problem at some point in the future.\n\n\t\t\t_createSVG = function(type, container, attributes) {\n\t\t\t\tvar element = _doc.createElementNS(\"http://www.w3.org/2000/svg\", type),\n\t\t\t\t\treg = /([a-z])([A-Z])/g,\n\t\t\t\t\tp;\n\t\t\t\tfor (p in attributes) {\n\t\t\t\t\telement.setAttributeNS(null, p.replace(reg, \"$1-$2\").toLowerCase(), attributes[p]);\n\t\t\t\t}\n\t\t\t\tcontainer.appendChild(element);\n\t\t\t\treturn element;\n\t\t\t},\n\t\t\t_docElement = _doc.documentElement || {},\n\t\t\t_forceSVGTransformAttr = (function() {\n\t\t\t\t//IE and Android stock don't support CSS transforms on SVG elements, so we must write them to the \"transform\" attribute. We populate this variable in the _parseTransform() method, and only if/when we come across an SVG element\n\t\t\t\tvar force = _ieVers || (/Android/i.test(_agent) && !_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"_gsScope\"].chrome),\n\t\t\t\t\tsvg, rect, width;\n\t\t\t\tif (_doc.createElementNS && _docElement.appendChild && !force) { //IE8 and earlier doesn't support SVG anyway\n\t\t\t\t\tsvg = _createSVG(\"svg\", _docElement);\n\t\t\t\t\trect = _createSVG(\"rect\", svg, {width:100, height:50, x:100});\n\t\t\t\t\twidth = rect.getBoundingClientRect().width;\n\t\t\t\t\trect.style[_transformOriginProp] = \"50% 50%\";\n\t\t\t\t\trect.style[_transformProp] = \"scaleX(0.5)\";\n\t\t\t\t\tforce = (width === rect.getBoundingClientRect().width && !(_isFirefox && _supports3D)); //note: Firefox fails the test even though it does support CSS transforms in 3D. Since we can't push 3D stuff into the transform attribute, we force Firefox to pass the test here (as long as it does truly support 3D).\n\t\t\t\t\t_docElement.removeChild(svg);\n\t\t\t\t}\n\t\t\t\treturn force;\n\t\t\t})(),\n\t\t\t_parseSVGOrigin = function(e, local, decoratee, absolute, smoothOrigin, skipRecord) {\n\t\t\t\tvar tm = e._gsTransform,\n\t\t\t\t\tm = _getMatrix(e, true),\n\t\t\t\t\tv, x, y, xOrigin, yOrigin, a, b, c, d, tx, ty, determinant, xOriginOld, yOriginOld;\n\t\t\t\tif (tm) {\n\t\t\t\t\txOriginOld = tm.xOrigin; //record the original values before we alter them.\n\t\t\t\t\tyOriginOld = tm.yOrigin;\n\t\t\t\t}\n\t\t\t\tif (!absolute || (v = absolute.split(\" \")).length < 2) {\n\t\t\t\t\tb = e.getBBox();\n\t\t\t\t\tif (b.x === 0 && b.y === 0 && b.width + b.height === 0) { //some browsers (like Firefox) misreport the bounds if the element has zero width and height (it just assumes it's at x:0, y:0), thus we need to manually grab the position in that case.\n\t\t\t\t\t\tb = {x: parseFloat(e.hasAttribute(\"x\") ? e.getAttribute(\"x\") : e.hasAttribute(\"cx\") ? e.getAttribute(\"cx\") : 0) || 0, y: parseFloat(e.hasAttribute(\"y\") ? e.getAttribute(\"y\") : e.hasAttribute(\"cy\") ? e.getAttribute(\"cy\") : 0) || 0, width:0, height:0};\n\t\t\t\t\t}\n\t\t\t\t\tlocal = _parsePosition(local).split(\" \");\n\t\t\t\t\tv = [(local[0].indexOf(\"%\") !== -1 ? parseFloat(local[0]) / 100 * b.width : parseFloat(local[0])) + b.x,\n\t\t\t\t\t\t (local[1].indexOf(\"%\") !== -1 ? parseFloat(local[1]) / 100 * b.height : parseFloat(local[1])) + b.y];\n\t\t\t\t}\n\t\t\t\tdecoratee.xOrigin = xOrigin = parseFloat(v[0]);\n\t\t\t\tdecoratee.yOrigin = yOrigin = parseFloat(v[1]);\n\t\t\t\tif (absolute && m !== _identity2DMatrix) { //if svgOrigin is being set, we must invert the matrix and determine where the absolute point is, factoring in the current transforms. Otherwise, the svgOrigin would be based on the element's non-transformed position on the canvas.\n\t\t\t\t\ta = m[0];\n\t\t\t\t\tb = m[1];\n\t\t\t\t\tc = m[2];\n\t\t\t\t\td = m[3];\n\t\t\t\t\ttx = m[4];\n\t\t\t\t\tty = m[5];\n\t\t\t\t\tdeterminant = (a * d - b * c);\n\t\t\t\t\tif (determinant) { //if it's zero (like if scaleX and scaleY are zero), skip it to avoid errors with dividing by zero.\n\t\t\t\t\t\tx = xOrigin * (d / determinant) + yOrigin * (-c / determinant) + ((c * ty - d * tx) / determinant);\n\t\t\t\t\t\ty = xOrigin * (-b / determinant) + yOrigin * (a / determinant) - ((a * ty - b * tx) / determinant);\n\t\t\t\t\t\txOrigin = decoratee.xOrigin = v[0] = x;\n\t\t\t\t\t\tyOrigin = decoratee.yOrigin = v[1] = y;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (tm) { //avoid jump when transformOrigin is changed - adjust the x/y values accordingly\n\t\t\t\t\tif (skipRecord) {\n\t\t\t\t\t\tdecoratee.xOffset = tm.xOffset;\n\t\t\t\t\t\tdecoratee.yOffset = tm.yOffset;\n\t\t\t\t\t\ttm = decoratee;\n\t\t\t\t\t}\n\t\t\t\t\tif (smoothOrigin || (smoothOrigin !== false && CSSPlugin.defaultSmoothOrigin !== false)) {\n\t\t\t\t\t\tx = xOrigin - xOriginOld;\n\t\t\t\t\t\ty = yOrigin - yOriginOld;\n\t\t\t\t\t\t//originally, we simply adjusted the x and y values, but that would cause problems if, for example, you created a rotational tween part-way through an x/y tween. Managing the offset in a separate variable gives us ultimate flexibility.\n\t\t\t\t\t\t//tm.x -= x - (x * m[0] + y * m[2]);\n\t\t\t\t\t\t//tm.y -= y - (x * m[1] + y * m[3]);\n\t\t\t\t\t\ttm.xOffset += (x * m[0] + y * m[2]) - x;\n\t\t\t\t\t\ttm.yOffset += (x * m[1] + y * m[3]) - y;\n\t\t\t\t\t} else {\n\t\t\t\t\t\ttm.xOffset = tm.yOffset = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (!skipRecord) {\n\t\t\t\t\te.setAttribute(\"data-svg-origin\", v.join(\" \"));\n\t\t\t\t}\n\t\t\t},\n\t\t\t_getBBoxHack = function(swapIfPossible) { //works around issues in some browsers (like Firefox) that don't correctly report getBBox() on SVG elements inside a <defs> element and/or <mask>. We try creating an SVG, adding it to the documentElement and toss the element in there so that it's definitely part of the rendering tree, then grab the bbox and if it works, we actually swap out the original getBBox() method for our own that does these extra steps whenever getBBox is needed. This helps ensure that performance is optimal (only do all these extra steps when absolutely necessary...most elements don't need it).\n\t\t\t\tvar svg = _createElement(\"svg\", (this.ownerSVGElement && this.ownerSVGElement.getAttribute(\"xmlns\")) || \"http://www.w3.org/2000/svg\"),\n\t\t\t\t\toldParent = this.parentNode,\n\t\t\t\t\toldSibling = this.nextSibling,\n\t\t\t\t\toldCSS = this.style.cssText,\n\t\t\t\t\tbbox;\n\t\t\t\t_docElement.appendChild(svg);\n\t\t\t\tsvg.appendChild(this);\n\t\t\t\tthis.style.display = \"block\";\n\t\t\t\tif (swapIfPossible) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tbbox = this.getBBox();\n\t\t\t\t\t\tthis._originalGetBBox = this.getBBox;\n\t\t\t\t\t\tthis.getBBox = _getBBoxHack;\n\t\t\t\t\t} catch (e) { }\n\t\t\t\t} else if (this._originalGetBBox) {\n\t\t\t\t\tbbox = this._originalGetBBox();\n\t\t\t\t}\n\t\t\t\tif (oldSibling) {\n\t\t\t\t\toldParent.insertBefore(this, oldSibling);\n\t\t\t\t} else {\n\t\t\t\t\toldParent.appendChild(this);\n\t\t\t\t}\n\t\t\t\t_docElement.removeChild(svg);\n\t\t\t\tthis.style.cssText = oldCSS;\n\t\t\t\treturn bbox;\n\t\t\t},\n\t\t\t_getBBox = function(e) {\n\t\t\t\ttry {\n\t\t\t\t\treturn e.getBBox(); //Firefox throws errors if you try calling getBBox() on an SVG element that's not rendered (like in a <symbol> or <defs>). https://bugzilla.mozilla.org/show_bug.cgi?id=612118\n\t\t\t\t} catch (error) {\n\t\t\t\t\treturn _getBBoxHack.call(e, true);\n\t\t\t\t}\n\t\t\t},\n\t\t\t_isSVG = function(e) { //reports if the element is an SVG on which getBBox() actually works\n\t\t\t\treturn !!(_SVGElement && e.getCTM && (!e.parentNode || e.ownerSVGElement) && _getBBox(e));\n\t\t\t},\n\t\t\t_identity2DMatrix = [1,0,0,1,0,0],\n\t\t\t_getMatrix = function(e, force2D) {\n\t\t\t\tvar tm = e._gsTransform || new Transform(),\n\t\t\t\t\trnd = 100000,\n\t\t\t\t\tstyle = e.style,\n\t\t\t\t\tisDefault, s, m, n, dec, nextSibling, parent;\n\t\t\t\tif (_transformProp) {\n\t\t\t\t\ts = _getStyle(e, _transformPropCSS, null, true);\n\t\t\t\t} else if (e.currentStyle) {\n\t\t\t\t\t//for older versions of IE, we need to interpret the filter portion that is in the format: progid:DXImageTransform.Microsoft.Matrix(M11=6.123233995736766e-17, M12=-1, M21=1, M22=6.123233995736766e-17, sizingMethod='auto expand') Notice that we need to swap b and c compared to a normal matrix.\n\t\t\t\t\ts = e.currentStyle.filter.match(_ieGetMatrixExp);\n\t\t\t\t\ts = (s && s.length === 4) ? [s[0].substr(4), Number(s[2].substr(4)), Number(s[1].substr(4)), s[3].substr(4), (tm.x || 0), (tm.y || 0)].join(\",\") : \"\";\n\t\t\t\t}\n\t\t\t\tisDefault = (!s || s === \"none\" || s === \"matrix(1, 0, 0, 1, 0, 0)\");\n\t\t\t\tif (_transformProp && isDefault && !e.offsetParent && e !== _docElement) { //note: if offsetParent is null, that means the element isn't in the normal document flow, like if it has display:none or one of its ancestors has display:none). Firefox returns null for getComputedStyle() if the element is in an iframe that has display:none. https://bugzilla.mozilla.org/show_bug.cgi?id=548397\n\t\t\t\t\t//browsers don't report transforms accurately unless the element is in the DOM and has a display value that's not \"none\". Firefox and Microsoft browsers have a partial bug where they'll report transforms even if display:none BUT not any percentage-based values like translate(-50%, 8px) will be reported as if it's translate(0, 8px).\n\t\t\t\t\tn = style.display;\n\t\t\t\t\tstyle.display = \"block\";\n\t\t\t\t\tparent = e.parentNode;\n\t\t\t\t\tif (!parent || !e.offsetParent) {\n\t\t\t\t\t\tdec = 1; //flag\n\t\t\t\t\t\tnextSibling = e.nextSibling;\n\t\t\t\t\t\t_docElement.appendChild(e); //we must add it to the DOM in order to get values properly\n\t\t\t\t\t}\n\t\t\t\t\ts = _getStyle(e, _transformPropCSS, null, true);\n\t\t\t\t\tisDefault = (!s || s === \"none\" || s === \"matrix(1, 0, 0, 1, 0, 0)\");\n\t\t\t\t\tif (n) {\n\t\t\t\t\t\tstyle.display = n;\n\t\t\t\t\t} else {\n\t\t\t\t\t\t_removeProp(style, \"display\");\n\t\t\t\t\t}\n\t\t\t\t\tif (dec) {\n\t\t\t\t\t\tif (nextSibling) {\n\t\t\t\t\t\t\tparent.insertBefore(e, nextSibling);\n\t\t\t\t\t\t} else if (parent) {\n\t\t\t\t\t\t\tparent.appendChild(e);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t_docElement.removeChild(e);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (tm.svg || (e.getCTM && _isSVG(e))) {\n\t\t\t\t\tif (isDefault && (style[_transformProp] + \"\").indexOf(\"matrix\") !== -1) { //some browsers (like Chrome 40) don't correctly report transforms that are applied inline on an SVG element (they don't get included in the computed style), so we double-check here and accept matrix values\n\t\t\t\t\t\ts = style[_transformProp];\n\t\t\t\t\t\tisDefault = 0;\n\t\t\t\t\t}\n\t\t\t\t\tm = e.getAttribute(\"transform\");\n\t\t\t\t\tif (isDefault && m) {\n\t\t\t\t\t\tm = e.transform.baseVal.consolidate().matrix; //ensures that even complex values like \"translate(50,60) rotate(135,0,0)\" are parsed because it mashes it into a matrix.\n\t\t\t\t\t\ts = \"matrix(\" + m.a + \",\" + m.b + \",\" + m.c + \",\" + m.d + \",\" + m.e + \",\" + m.f + \")\";\n\t\t\t\t\t\tisDefault = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (isDefault) {\n\t\t\t\t\treturn _identity2DMatrix;\n\t\t\t\t}\n\t\t\t\t//split the matrix values out into an array (m for matrix)\n\t\t\t\tm = (s || \"\").match(_numExp) || [];\n\t\t\t\ti = m.length;\n\t\t\t\twhile (--i > -1) {\n\t\t\t\t\tn = Number(m[i]);\n\t\t\t\t\tm[i] = (dec = n - (n |= 0)) ? ((dec * rnd + (dec < 0 ? -0.5 : 0.5)) | 0) / rnd + n : n; //convert strings to Numbers and round to 5 decimal places to avoid issues with tiny numbers. Roughly 20x faster than Number.toFixed(). We also must make sure to round before dividing so that values like 0.9999999999 become 1 to avoid glitches in browser rendering and interpretation of flipped/rotated 3D matrices. And don't just multiply the number by rnd, floor it, and then divide by rnd because the bitwise operations max out at a 32-bit signed integer, thus it could get clipped at a relatively low value (like 22,000.00000 for example).\n\t\t\t\t}\n\t\t\t\treturn (force2D && m.length > 6) ? [m[0], m[1], m[4], m[5], m[12], m[13]] : m;\n\t\t\t},\n\n\t\t\t/**\n\t\t\t * Parses the transform values for an element, returning an object with x, y, z, scaleX, scaleY, scaleZ, rotation, rotationX, rotationY, skewX, and skewY properties. Note: by default (for performance reasons), all skewing is combined into skewX and rotation but skewY still has a place in the transform object so that we can record how much of the skew is attributed to skewX vs skewY. Remember, a skewY of 10 looks the same as a rotation of 10 and skewX of -10.\n\t\t\t * @param {!Object} t target element\n\t\t\t * @param {Object=} cs computed style object (optional)\n\t\t\t * @param {boolean=} rec if true, the transform values will be recorded to the target element's _gsTransform object, like target._gsTransform = {x:0, y:0, z:0, scaleX:1...}\n\t\t\t * @param {boolean=} parse if true, we'll ignore any _gsTransform values that already exist on the element, and force a reparsing of the css (calculated style)\n\t\t\t * @return {object} object containing all of the transform properties/values like {x:0, y:0, z:0, scaleX:1...}\n\t\t\t */\n\t\t\t_getTransform = _internals.getTransform = function(t, cs, rec, parse) {\n\t\t\t\tif (t._gsTransform && rec && !parse) {\n\t\t\t\t\treturn t._gsTransform; //if the element already has a _gsTransform, use that. Note: some browsers don't accurately return the calculated style for the transform (particularly for SVG), so it's almost always safest to just use the values we've already applied rather than re-parsing things.\n\t\t\t\t}\n\t\t\t\tvar tm = rec ? t._gsTransform || new Transform() : new Transform(),\n\t\t\t\t\tinvX = (tm.scaleX < 0), //in order to interpret things properly, we need to know if the user applied a negative scaleX previously so that we can adjust the rotation and skewX accordingly. Otherwise, if we always interpret a flipped matrix as affecting scaleY and the user only wants to tween the scaleX on multiple sequential tweens, it would keep the negative scaleY without that being the user's intent.\n\t\t\t\t\tmin = 0.00002,\n\t\t\t\t\trnd = 100000,\n\t\t\t\t\tzOrigin = _supports3D ? parseFloat(_getStyle(t, _transformOriginProp, cs, false, \"0 0 0\").split(\" \")[2]) || tm.zOrigin  || 0 : 0,\n\t\t\t\t\tdefaultTransformPerspective = parseFloat(CSSPlugin.defaultTransformPerspective) || 0,\n\t\t\t\t\tm, i, scaleX, scaleY, rotation, skewX;\n\n\t\t\t\ttm.svg = !!(t.getCTM && _isSVG(t));\n\t\t\t\tif (tm.svg) {\n\t\t\t\t\t_parseSVGOrigin(t, _getStyle(t, _transformOriginProp, cs, false, \"50% 50%\") + \"\", tm, t.getAttribute(\"data-svg-origin\"));\n\t\t\t\t\t_useSVGTransformAttr = CSSPlugin.useSVGTransformAttr || _forceSVGTransformAttr;\n\t\t\t\t}\n\t\t\t\tm = _getMatrix(t);\n\t\t\t\tif (m !== _identity2DMatrix) {\n\n\t\t\t\t\tif (m.length === 16) {\n\t\t\t\t\t\t//we'll only look at these position-related 6 variables first because if x/y/z all match, it's relatively safe to assume we don't need to re-parse everything which risks losing important rotational information (like rotationX:180 plus rotationY:180 would look the same as rotation:180 - there's no way to know for sure which direction was taken based solely on the matrix3d() values)\n\t\t\t\t\t\tvar a11 = m[0], a21 = m[1], a31 = m[2], a41 = m[3],\n\t\t\t\t\t\t\ta12 = m[4], a22 = m[5], a32 = m[6], a42 = m[7],\n\t\t\t\t\t\t\ta13 = m[8], a23 = m[9], a33 = m[10],\n\t\t\t\t\t\t\ta14 = m[12], a24 = m[13], a34 = m[14],\n\t\t\t\t\t\t\ta43 = m[11],\n\t\t\t\t\t\t\tangle = Math.atan2(a32, a33),\n\t\t\t\t\t\t\tt1, t2, t3, t4, cos, sin;\n\t\t\t\t\t\t//we manually compensate for non-zero z component of transformOrigin to work around bugs in Safari\n\t\t\t\t\t\tif (tm.zOrigin) {\n\t\t\t\t\t\t\ta34 = -tm.zOrigin;\n\t\t\t\t\t\t\ta14 = a13*a34-m[12];\n\t\t\t\t\t\t\ta24 = a23*a34-m[13];\n\t\t\t\t\t\t\ta34 = a33*a34+tm.zOrigin-m[14];\n\t\t\t\t\t\t}\n\t\t\t\t\t\t//note for possible future consolidation: rotationX: Math.atan2(a32, a33), rotationY: Math.atan2(-a31, Math.sqrt(a33 * a33 + a32 * a32)), rotation: Math.atan2(a21, a11), skew: Math.atan2(a12, a22). However, it doesn't seem to be quite as reliable as the full-on backwards rotation procedure.\n\t\t\t\t\t\ttm.rotationX = angle * _RAD2DEG;\n\t\t\t\t\t\t//rotationX\n\t\t\t\t\t\tif (angle) {\n\t\t\t\t\t\t\tcos = Math.cos(-angle);\n\t\t\t\t\t\t\tsin = Math.sin(-angle);\n\t\t\t\t\t\t\tt1 = a12*cos+a13*sin;\n\t\t\t\t\t\t\tt2 = a22*cos+a23*sin;\n\t\t\t\t\t\t\tt3 = a32*cos+a33*sin;\n\t\t\t\t\t\t\ta13 = a12*-sin+a13*cos;\n\t\t\t\t\t\t\ta23 = a22*-sin+a23*cos;\n\t\t\t\t\t\t\ta33 = a32*-sin+a33*cos;\n\t\t\t\t\t\t\ta43 = a42*-sin+a43*cos;\n\t\t\t\t\t\t\ta12 = t1;\n\t\t\t\t\t\t\ta22 = t2;\n\t\t\t\t\t\t\ta32 = t3;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t//rotationY\n\t\t\t\t\t\tangle = Math.atan2(-a31, a33);\n\t\t\t\t\t\ttm.rotationY = angle * _RAD2DEG;\n\t\t\t\t\t\tif (angle) {\n\t\t\t\t\t\t\tcos = Math.cos(-angle);\n\t\t\t\t\t\t\tsin = Math.sin(-angle);\n\t\t\t\t\t\t\tt1 = a11*cos-a13*sin;\n\t\t\t\t\t\t\tt2 = a21*cos-a23*sin;\n\t\t\t\t\t\t\tt3 = a31*cos-a33*sin;\n\t\t\t\t\t\t\ta23 = a21*sin+a23*cos;\n\t\t\t\t\t\t\ta33 = a31*sin+a33*cos;\n\t\t\t\t\t\t\ta43 = a41*sin+a43*cos;\n\t\t\t\t\t\t\ta11 = t1;\n\t\t\t\t\t\t\ta21 = t2;\n\t\t\t\t\t\t\ta31 = t3;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t//rotationZ\n\t\t\t\t\t\tangle = Math.atan2(a21, a11);\n\t\t\t\t\t\ttm.rotation = angle * _RAD2DEG;\n\t\t\t\t\t\tif (angle) {\n\t\t\t\t\t\t\tcos = Math.cos(angle);\n\t\t\t\t\t\t\tsin = Math.sin(angle);\n\t\t\t\t\t\t\tt1 = a11*cos+a21*sin;\n\t\t\t\t\t\t\tt2 = a12*cos+a22*sin;\n\t\t\t\t\t\t\tt3 = a13*cos+a23*sin;\n\t\t\t\t\t\t\ta21 = a21*cos-a11*sin;\n\t\t\t\t\t\t\ta22 = a22*cos-a12*sin;\n\t\t\t\t\t\t\ta23 = a23*cos-a13*sin;\n\t\t\t\t\t\t\ta11 = t1;\n\t\t\t\t\t\t\ta12 = t2;\n\t\t\t\t\t\t\ta13 = t3;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (tm.rotationX && Math.abs(tm.rotationX) + Math.abs(tm.rotation) > 359.9) { //when rotationY is set, it will often be parsed as 180 degrees different than it should be, and rotationX and rotation both being 180 (it looks the same), so we adjust for that here.\n\t\t\t\t\t\t\ttm.rotationX = tm.rotation = 0;\n\t\t\t\t\t\t\ttm.rotationY = 180 - tm.rotationY;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t//skewX\n\t\t\t\t\t\tangle = Math.atan2(a12, a22);\n\n\t\t\t\t\t\t//scales\n\t\t\t\t\t\ttm.scaleX = ((Math.sqrt(a11 * a11 + a21 * a21 + a31 * a31) * rnd + 0.5) | 0) / rnd;\n\t\t\t\t\t\ttm.scaleY = ((Math.sqrt(a22 * a22 + a32 * a32) * rnd + 0.5) | 0) / rnd;\n\t\t\t\t\t\ttm.scaleZ = ((Math.sqrt(a13 * a13 + a23 * a23 + a33 * a33) * rnd + 0.5) | 0) / rnd;\n\t\t\t\t\t\ta11 /= tm.scaleX;\n\t\t\t\t\t\ta12 /= tm.scaleY;\n\t\t\t\t\t\ta21 /= tm.scaleX;\n\t\t\t\t\t\ta22 /= tm.scaleY;\n\t\t\t\t\t\tif (Math.abs(angle) > min) {\n\t\t\t\t\t\t\ttm.skewX = angle * _RAD2DEG;\n\t\t\t\t\t\t\ta12 = 0; //unskews\n\t\t\t\t\t\t\tif (tm.skewType !== \"simple\") {\n\t\t\t\t\t\t\t\ttm.scaleY *= 1 / Math.cos(angle); //by default, we compensate the scale based on the skew so that the element maintains a similar proportion when skewed, so we have to alter the scaleY here accordingly to match the default (non-adjusted) skewing that CSS does (stretching more and more as it skews).\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\ttm.skewX = 0;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t/* //for testing purposes\n\t\t\t\t\t\tvar transform = \"matrix3d(\",\n\t\t\t\t\t\t\tcomma = \",\",\n\t\t\t\t\t\t\tzero = \"0\";\n\t\t\t\t\t\ta13 /= tm.scaleZ;\n\t\t\t\t\t\ta23 /= tm.scaleZ;\n\t\t\t\t\t\ta31 /= tm.scaleX;\n\t\t\t\t\t\ta32 /= tm.scaleY;\n\t\t\t\t\t\ta33 /= tm.scaleZ;\n\t\t\t\t\t\ttransform += ((a11 < min && a11 > -min) ? zero : a11) + comma + ((a21 < min && a21 > -min) ? zero : a21) + comma + ((a31 < min && a31 > -min) ? zero : a31);\n\t\t\t\t\t\ttransform += comma + ((a41 < min && a41 > -min) ? zero : a41) + comma + ((a12 < min && a12 > -min) ? zero : a12) + comma + ((a22 < min && a22 > -min) ? zero : a22);\n\t\t\t\t\t\ttransform += comma + ((a32 < min && a32 > -min) ? zero : a32) + comma + ((a42 < min && a42 > -min) ? zero : a42) + comma + ((a13 < min && a13 > -min) ? zero : a13);\n\t\t\t\t\t\ttransform += comma + ((a23 < min && a23 > -min) ? zero : a23) + comma + ((a33 < min && a33 > -min) ? zero : a33) + comma + ((a43 < min && a43 > -min) ? zero : a43) + comma;\n\t\t\t\t\t\ttransform += a14 + comma + a24 + comma + a34 + comma + (tm.perspective ? (1 + (-a34 / tm.perspective)) : 1) + \")\";\n\t\t\t\t\t\tconsole.log(transform);\n\t\t\t\t\t\tdocument.querySelector(\".test\").style[_transformProp] = transform;\n\t\t\t\t\t\t*/\n\n\t\t\t\t\t\ttm.perspective = a43 ? 1 / ((a43 < 0) ? -a43 : a43) : 0;\n\t\t\t\t\t\ttm.x = a14;\n\t\t\t\t\t\ttm.y = a24;\n\t\t\t\t\t\ttm.z = a34;\n\t\t\t\t\t\tif (tm.svg) {\n\t\t\t\t\t\t\ttm.x -= tm.xOrigin - (tm.xOrigin * a11 - tm.yOrigin * a12);\n\t\t\t\t\t\t\ttm.y -= tm.yOrigin - (tm.yOrigin * a21 - tm.xOrigin * a22);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else if ((!_supports3D || parse || !m.length || tm.x !== m[4] || tm.y !== m[5] || (!tm.rotationX && !tm.rotationY))) { //sometimes a 6-element matrix is returned even when we performed 3D transforms, like if rotationX and rotationY are 180. In cases like this, we still need to honor the 3D transforms. If we just rely on the 2D info, it could affect how the data is interpreted, like scaleY might get set to -1 or rotation could get offset by 180 degrees. For example, do a TweenLite.to(element, 1, {css:{rotationX:180, rotationY:180}}) and then later, TweenLite.to(element, 1, {css:{rotationX:0}}) and without this conditional logic in place, it'd jump to a state of being unrotated when the 2nd tween starts. Then again, we need to honor the fact that the user COULD alter the transforms outside of CSSPlugin, like by manually applying new css, so we try to sense that by looking at x and y because if those changed, we know the changes were made outside CSSPlugin and we force a reinterpretation of the matrix values. Also, in Webkit browsers, if the element's \"display\" is \"none\", its calculated style value will always return empty, so if we've already recorded the values in the _gsTransform object, we'll just rely on those.\n\t\t\t\t\t\tvar k = (m.length >= 6),\n\t\t\t\t\t\t\ta = k ? m[0] : 1,\n\t\t\t\t\t\t\tb = m[1] || 0,\n\t\t\t\t\t\t\tc = m[2] || 0,\n\t\t\t\t\t\t\td = k ? m[3] : 1;\n\t\t\t\t\t\ttm.x = m[4] || 0;\n\t\t\t\t\t\ttm.y = m[5] || 0;\n\t\t\t\t\t\tscaleX = Math.sqrt(a * a + b * b);\n\t\t\t\t\t\tscaleY = Math.sqrt(d * d + c * c);\n\t\t\t\t\t\trotation = (a || b) ? Math.atan2(b, a) * _RAD2DEG : tm.rotation || 0; //note: if scaleX is 0, we cannot accurately measure rotation. Same for skewX with a scaleY of 0. Therefore, we default to the previously recorded value (or zero if that doesn't exist).\n\t\t\t\t\t\tskewX = (c || d) ? Math.atan2(c, d) * _RAD2DEG + rotation : tm.skewX || 0;\n\t\t\t\t\t\ttm.scaleX = scaleX;\n\t\t\t\t\t\ttm.scaleY = scaleY;\n\t\t\t\t\t\ttm.rotation = rotation;\n\t\t\t\t\t\ttm.skewX = skewX;\n\t\t\t\t\t\tif (_supports3D) {\n\t\t\t\t\t\t\ttm.rotationX = tm.rotationY = tm.z = 0;\n\t\t\t\t\t\t\ttm.perspective = defaultTransformPerspective;\n\t\t\t\t\t\t\ttm.scaleZ = 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (tm.svg) {\n\t\t\t\t\t\t\ttm.x -= tm.xOrigin - (tm.xOrigin * a + tm.yOrigin * c);\n\t\t\t\t\t\t\ttm.y -= tm.yOrigin - (tm.xOrigin * b + tm.yOrigin * d);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (Math.abs(tm.skewX) > 90 && Math.abs(tm.skewX) < 270) {\n\t\t\t\t\t\tif (invX) {\n\t\t\t\t\t\t\ttm.scaleX *= -1;\n\t\t\t\t\t\t\ttm.skewX += (tm.rotation <= 0) ? 180 : -180;\n\t\t\t\t\t\t\ttm.rotation += (tm.rotation <= 0) ? 180 : -180;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\ttm.scaleY *= -1;\n\t\t\t\t\t\t\ttm.skewX += (tm.skewX <= 0) ? 180 : -180;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\ttm.zOrigin = zOrigin;\n\t\t\t\t\t//some browsers have a hard time with very small values like 2.4492935982947064e-16 (notice the \"e-\" towards the end) and would render the object slightly off. So we round to 0 in these cases. The conditional logic here is faster than calling Math.abs(). Also, browsers tend to render a SLIGHTLY rotated object in a fuzzy way, so we need to snap to exactly 0 when appropriate.\n\t\t\t\t\tfor (i in tm) {\n\t\t\t\t\t\tif (tm[i] < min) if (tm[i] > -min) {\n\t\t\t\t\t\t\ttm[i] = 0;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t//DEBUG: _log(\"parsed rotation of \" + t.getAttribute(\"id\")+\": \"+(tm.rotationX)+\", \"+(tm.rotationY)+\", \"+(tm.rotation)+\", scale: \"+tm.scaleX+\", \"+tm.scaleY+\", \"+tm.scaleZ+\", position: \"+tm.x+\", \"+tm.y+\", \"+tm.z+\", perspective: \"+tm.perspective+ \", origin: \"+ tm.xOrigin+ \",\"+ tm.yOrigin);\n\t\t\t\tif (rec) {\n\t\t\t\t\tt._gsTransform = tm; //record to the object's _gsTransform which we use so that tweens can control individual properties independently (we need all the properties to accurately recompose the matrix in the setRatio() method)\n\t\t\t\t\tif (tm.svg) { //if we're supposed to apply transforms to the SVG element's \"transform\" attribute, make sure there aren't any CSS transforms applied or they'll override the attribute ones. Also clear the transform attribute if we're using CSS, just to be clean.\n\t\t\t\t\t\tif (_useSVGTransformAttr && t.style[_transformProp]) {\n\t\t\t\t\t\t\t_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].delayedCall(0.001, function(){ //if we apply this right away (before anything has rendered), we risk there being no transforms for a brief moment and it also interferes with adjusting the transformOrigin in a tween with immediateRender:true (it'd try reading the matrix and it wouldn't have the appropriate data in place because we just removed it).\n\t\t\t\t\t\t\t\t_removeProp(t.style, _transformProp);\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t} else if (!_useSVGTransformAttr && t.getAttribute(\"transform\")) {\n\t\t\t\t\t\t\t_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].delayedCall(0.001, function(){\n\t\t\t\t\t\t\t\tt.removeAttribute(\"transform\");\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn tm;\n\t\t\t},\n\n\t\t\t//for setting 2D transforms in IE6, IE7, and IE8 (must use a \"filter\" to emulate the behavior of modern day browser transforms)\n\t\t\t_setIETransformRatio = function(v) {\n\t\t\t\tvar t = this.data, //refers to the element's _gsTransform object\n\t\t\t\t\tang = -t.rotation * _DEG2RAD,\n\t\t\t\t\tskew = ang + t.skewX * _DEG2RAD,\n\t\t\t\t\trnd = 100000,\n\t\t\t\t\ta = ((Math.cos(ang) * t.scaleX * rnd) | 0) / rnd,\n\t\t\t\t\tb = ((Math.sin(ang) * t.scaleX * rnd) | 0) / rnd,\n\t\t\t\t\tc = ((Math.sin(skew) * -t.scaleY * rnd) | 0) / rnd,\n\t\t\t\t\td = ((Math.cos(skew) * t.scaleY * rnd) | 0) / rnd,\n\t\t\t\t\tstyle = this.t.style,\n\t\t\t\t\tcs = this.t.currentStyle,\n\t\t\t\t\tfilters, val;\n\t\t\t\tif (!cs) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tval = b; //just for swapping the variables an inverting them (reused \"val\" to avoid creating another variable in memory). IE's filter matrix uses a non-standard matrix configuration (angle goes the opposite way, and b and c are reversed and inverted)\n\t\t\t\tb = -c;\n\t\t\t\tc = -val;\n\t\t\t\tfilters = cs.filter;\n\t\t\t\tstyle.filter = \"\"; //remove filters so that we can accurately measure offsetWidth/offsetHeight\n\t\t\t\tvar w = this.t.offsetWidth,\n\t\t\t\t\th = this.t.offsetHeight,\n\t\t\t\t\tclip = (cs.position !== \"absolute\"),\n\t\t\t\t\tm = \"progid:DXImageTransform.Microsoft.Matrix(M11=\" + a + \", M12=\" + b + \", M21=\" + c + \", M22=\" + d,\n\t\t\t\t\tox = t.x + (w * t.xPercent / 100),\n\t\t\t\t\toy = t.y + (h * t.yPercent / 100),\n\t\t\t\t\tdx, dy;\n\n\t\t\t\t//if transformOrigin is being used, adjust the offset x and y\n\t\t\t\tif (t.ox != null) {\n\t\t\t\t\tdx = ((t.oxp) ? w * t.ox * 0.01 : t.ox) - w / 2;\n\t\t\t\t\tdy = ((t.oyp) ? h * t.oy * 0.01 : t.oy) - h / 2;\n\t\t\t\t\tox += dx - (dx * a + dy * b);\n\t\t\t\t\toy += dy - (dx * c + dy * d);\n\t\t\t\t}\n\n\t\t\t\tif (!clip) {\n\t\t\t\t\tm += \", sizingMethod='auto expand')\";\n\t\t\t\t} else {\n\t\t\t\t\tdx = (w / 2);\n\t\t\t\t\tdy = (h / 2);\n\t\t\t\t\t//translate to ensure that transformations occur around the correct origin (default is center).\n\t\t\t\t\tm += \", Dx=\" + (dx - (dx * a + dy * b) + ox) + \", Dy=\" + (dy - (dx * c + dy * d) + oy) + \")\";\n\t\t\t\t}\n\t\t\t\tif (filters.indexOf(\"DXImageTransform.Microsoft.Matrix(\") !== -1) {\n\t\t\t\t\tstyle.filter = filters.replace(_ieSetMatrixExp, m);\n\t\t\t\t} else {\n\t\t\t\t\tstyle.filter = m + \" \" + filters; //we must always put the transform/matrix FIRST (before alpha(opacity=xx)) to avoid an IE bug that slices part of the object when rotation is applied with alpha.\n\t\t\t\t}\n\n\t\t\t\t//at the end or beginning of the tween, if the matrix is normal (1, 0, 0, 1) and opacity is 100 (or doesn't exist), remove the filter to improve browser performance.\n\t\t\t\tif (v === 0 || v === 1) if (a === 1) if (b === 0) if (c === 0) if (d === 1) if (!clip || m.indexOf(\"Dx=0, Dy=0\") !== -1) if (!_opacityExp.test(filters) || parseFloat(RegExp.$1) === 100) if (filters.indexOf( true && filters.indexOf(\"Alpha\")) === -1) {\n\t\t\t\t\tstyle.removeAttribute(\"filter\");\n\t\t\t\t}\n\n\t\t\t\t//we must set the margins AFTER applying the filter in order to avoid some bugs in IE8 that could (in rare scenarios) cause them to be ignored intermittently (vibration).\n\t\t\t\tif (!clip) {\n\t\t\t\t\tvar mult = (_ieVers < 8) ? 1 : -1, //in Internet Explorer 7 and before, the box model is broken, causing the browser to treat the width/height of the actual rotated filtered image as the width/height of the box itself, but Microsoft corrected that in IE8. We must use a negative offset in IE8 on the right/bottom\n\t\t\t\t\t\tmarg, prop, dif;\n\t\t\t\t\tdx = t.ieOffsetX || 0;\n\t\t\t\t\tdy = t.ieOffsetY || 0;\n\t\t\t\t\tt.ieOffsetX = Math.round((w - ((a < 0 ? -a : a) * w + (b < 0 ? -b : b) * h)) / 2 + ox);\n\t\t\t\t\tt.ieOffsetY = Math.round((h - ((d < 0 ? -d : d) * h + (c < 0 ? -c : c) * w)) / 2 + oy);\n\t\t\t\t\tfor (i = 0; i < 4; i++) {\n\t\t\t\t\t\tprop = _margins[i];\n\t\t\t\t\t\tmarg = cs[prop];\n\t\t\t\t\t\t//we need to get the current margin in case it is being tweened separately (we want to respect that tween's changes)\n\t\t\t\t\t\tval = (marg.indexOf(\"px\") !== -1) ? parseFloat(marg) : _convertToPixels(this.t, prop, parseFloat(marg), marg.replace(_suffixExp, \"\")) || 0;\n\t\t\t\t\t\tif (val !== t[prop]) {\n\t\t\t\t\t\t\tdif = (i < 2) ? -t.ieOffsetX : -t.ieOffsetY; //if another tween is controlling a margin, we cannot only apply the difference in the ieOffsets, so we essentially zero-out the dx and dy here in that case. We record the margin(s) later so that we can keep comparing them, making this code very flexible.\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tdif = (i < 2) ? dx - t.ieOffsetX : dy - t.ieOffsetY;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tstyle[prop] = (t[prop] = Math.round( val - dif * ((i === 0 || i === 2) ? 1 : mult) )) + \"px\";\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t},\n\n\t\t\t/* translates a super small decimal to a string WITHOUT scientific notation\n\t\t\t_safeDecimal = function(n) {\n\t\t\t\tvar s = (n < 0 ? -n : n) + \"\",\n\t\t\t\t\ta = s.split(\"e-\");\n\t\t\t\treturn (n < 0 ? \"-0.\" : \"0.\") + new Array(parseInt(a[1], 10) || 0).join(\"0\") + a[0].split(\".\").join(\"\");\n\t\t\t},\n\t\t\t*/\n\n\t\t\t_setTransformRatio = _internals.set3DTransformRatio = _internals.setTransformRatio = function(v) {\n\t\t\t\tvar t = this.data, //refers to the element's _gsTransform object\n\t\t\t\t\tstyle = this.t.style,\n\t\t\t\t\tangle = t.rotation,\n\t\t\t\t\trotationX = t.rotationX,\n\t\t\t\t\trotationY = t.rotationY,\n\t\t\t\t\tsx = t.scaleX,\n\t\t\t\t\tsy = t.scaleY,\n\t\t\t\t\tsz = t.scaleZ,\n\t\t\t\t\tx = t.x,\n\t\t\t\t\ty = t.y,\n\t\t\t\t\tz = t.z,\n\t\t\t\t\tisSVG = t.svg,\n\t\t\t\t\tperspective = t.perspective,\n\t\t\t\t\tforce3D = t.force3D,\n\t\t\t\t\tskewY = t.skewY,\n\t\t\t\t\tskewX = t.skewX,\n\t\t\t\t\tt1,\ta11, a12, a13, a21, a22, a23, a31, a32, a33, a41, a42, a43,\n\t\t\t\t\tzOrigin, min, cos, sin, t2, transform, comma, zero, skew, rnd;\n\t\t\t\tif (skewY) { //for performance reasons, we combine all skewing into the skewX and rotation values. Remember, a skewY of 10 degrees looks the same as a rotation of 10 degrees plus a skewX of 10 degrees.\n\t\t\t\t\tskewX += skewY;\n\t\t\t\t\tangle += skewY;\n\t\t\t\t}\n\n\t\t\t\t//check to see if we should render as 2D (and SVGs must use 2D when _useSVGTransformAttr is true)\n\t\t\t\tif (((((v === 1 || v === 0) && force3D === \"auto\" && (this.tween._totalTime === this.tween._totalDuration || !this.tween._totalTime)) || !force3D) && !z && !perspective && !rotationY && !rotationX && sz === 1) || (_useSVGTransformAttr && isSVG) || !_supports3D) { //on the final render (which could be 0 for a from tween), if there are no 3D aspects, render in 2D to free up memory and improve performance especially on mobile devices. Check the tween's totalTime/totalDuration too in order to make sure it doesn't happen between repeats if it's a repeating tween.\n\n\t\t\t\t\t//2D\n\t\t\t\t\tif (angle || skewX || isSVG) {\n\t\t\t\t\t\tangle *= _DEG2RAD;\n\t\t\t\t\t\tskew = skewX * _DEG2RAD;\n\t\t\t\t\t\trnd = 100000;\n\t\t\t\t\t\ta11 = Math.cos(angle) * sx;\n\t\t\t\t\t\ta21 = Math.sin(angle) * sx;\n\t\t\t\t\t\ta12 = Math.sin(angle - skew) * -sy;\n\t\t\t\t\t\ta22 = Math.cos(angle - skew) * sy;\n\t\t\t\t\t\tif (skew && t.skewType === \"simple\") { //by default, we compensate skewing on the other axis to make it look more natural, but you can set the skewType to \"simple\" to use the uncompensated skewing that CSS does\n\t\t\t\t\t\t\tt1 = Math.tan(skew - skewY * _DEG2RAD);\n\t\t\t\t\t\t\tt1 = Math.sqrt(1 + t1 * t1);\n\t\t\t\t\t\t\ta12 *= t1;\n\t\t\t\t\t\t\ta22 *= t1;\n\t\t\t\t\t\t\tif (skewY) {\n\t\t\t\t\t\t\t\tt1 = Math.tan(skewY * _DEG2RAD);\n\t\t\t\t\t\t\t\tt1 = Math.sqrt(1 + t1 * t1);\n\t\t\t\t\t\t\t\ta11 *= t1;\n\t\t\t\t\t\t\t\ta21 *= t1;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (isSVG) {\n\t\t\t\t\t\t\tx += t.xOrigin - (t.xOrigin * a11 + t.yOrigin * a12) + t.xOffset;\n\t\t\t\t\t\t\ty += t.yOrigin - (t.xOrigin * a21 + t.yOrigin * a22) + t.yOffset;\n\t\t\t\t\t\t\tif (_useSVGTransformAttr && (t.xPercent || t.yPercent)) { //The SVG spec doesn't support percentage-based translation in the \"transform\" attribute, so we merge it into the matrix to simulate it.\n\t\t\t\t\t\t\t\tmin = this.t.getBBox();\n\t\t\t\t\t\t\t\tx += t.xPercent * 0.01 * min.width;\n\t\t\t\t\t\t\t\ty += t.yPercent * 0.01 * min.height;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tmin = 0.000001;\n\t\t\t\t\t\t\tif (x < min) if (x > -min) {\n\t\t\t\t\t\t\t\tx = 0;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (y < min) if (y > -min) {\n\t\t\t\t\t\t\t\ty = 0;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\ttransform = (((a11 * rnd) | 0) / rnd) + \",\" + (((a21 * rnd) | 0) / rnd) + \",\" + (((a12 * rnd) | 0) / rnd) + \",\" + (((a22 * rnd) | 0) / rnd) + \",\" + x + \",\" + y + \")\";\n\t\t\t\t\t\tif (isSVG && _useSVGTransformAttr) {\n\t\t\t\t\t\t\tthis.t.setAttribute(\"transform\", \"matrix(\" + transform);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t//some browsers have a hard time with very small values like 2.4492935982947064e-16 (notice the \"e-\" towards the end) and would render the object slightly off. So we round to 5 decimal places.\n\t\t\t\t\t\t\tstyle[_transformProp] = ((t.xPercent || t.yPercent) ? \"translate(\" + t.xPercent + \"%,\" + t.yPercent + \"%) matrix(\" : \"matrix(\") + transform;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tstyle[_transformProp] = ((t.xPercent || t.yPercent) ? \"translate(\" + t.xPercent + \"%,\" + t.yPercent + \"%) matrix(\" : \"matrix(\") + sx + \",0,0,\" + sy + \",\" + x + \",\" + y + \")\";\n\t\t\t\t\t}\n\t\t\t\t\treturn;\n\n\t\t\t\t}\n\t\t\t\tif (_isFirefox) { //Firefox has a bug (at least in v25) that causes it to render the transparent part of 32-bit PNG images as black when displayed inside an iframe and the 3D scale is very small and doesn't change sufficiently enough between renders (like if you use a Power4.easeInOut to scale from 0 to 1 where the beginning values only change a tiny amount to begin the tween before accelerating). In this case, we force the scale to be 0.00002 instead which is visually the same but works around the Firefox issue.\n\t\t\t\t\tmin = 0.0001;\n\t\t\t\t\tif (sx < min && sx > -min) {\n\t\t\t\t\t\tsx = sz = 0.00002;\n\t\t\t\t\t}\n\t\t\t\t\tif (sy < min && sy > -min) {\n\t\t\t\t\t\tsy = sz = 0.00002;\n\t\t\t\t\t}\n\t\t\t\t\tif (perspective && !t.z && !t.rotationX && !t.rotationY) { //Firefox has a bug that causes elements to have an odd super-thin, broken/dotted black border on elements that have a perspective set but aren't utilizing 3D space (no rotationX, rotationY, or z).\n\t\t\t\t\t\tperspective = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (angle || skewX) {\n\t\t\t\t\tangle *= _DEG2RAD;\n\t\t\t\t\tcos = a11 = Math.cos(angle);\n\t\t\t\t\tsin = a21 = Math.sin(angle);\n\t\t\t\t\tif (skewX) {\n\t\t\t\t\t\tangle -= skewX * _DEG2RAD;\n\t\t\t\t\t\tcos = Math.cos(angle);\n\t\t\t\t\t\tsin = Math.sin(angle);\n\t\t\t\t\t\tif (t.skewType === \"simple\") { //by default, we compensate skewing on the other axis to make it look more natural, but you can set the skewType to \"simple\" to use the uncompensated skewing that CSS does\n\t\t\t\t\t\t\tt1 = Math.tan((skewX - skewY) * _DEG2RAD);\n\t\t\t\t\t\t\tt1 = Math.sqrt(1 + t1 * t1);\n\t\t\t\t\t\t\tcos *= t1;\n\t\t\t\t\t\t\tsin *= t1;\n\t\t\t\t\t\t\tif (t.skewY) {\n\t\t\t\t\t\t\t\tt1 = Math.tan(skewY * _DEG2RAD);\n\t\t\t\t\t\t\t\tt1 = Math.sqrt(1 + t1 * t1);\n\t\t\t\t\t\t\t\ta11 *= t1;\n\t\t\t\t\t\t\t\ta21 *= t1;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\ta12 = -sin;\n\t\t\t\t\ta22 = cos;\n\n\t\t\t\t} else if (!rotationY && !rotationX && sz === 1 && !perspective && !isSVG) { //if we're only translating and/or 2D scaling, this is faster...\n\t\t\t\t\tstyle[_transformProp] = ((t.xPercent || t.yPercent) ? \"translate(\" + t.xPercent + \"%,\" + t.yPercent + \"%) translate3d(\" : \"translate3d(\") + x + \"px,\" + y + \"px,\" + z +\"px)\" + ((sx !== 1 || sy !== 1) ? \" scale(\" + sx + \",\" + sy + \")\" : \"\");\n\t\t\t\t\treturn;\n\t\t\t\t} else {\n\t\t\t\t\ta11 = a22 = 1;\n\t\t\t\t\ta12 = a21 = 0;\n\t\t\t\t}\n\t\t\t\t// KEY  INDEX   AFFECTS a[row][column]\n\t\t\t\t// a11  0       rotation, rotationY, scaleX\n\t\t\t\t// a21  1       rotation, rotationY, scaleX\n\t\t\t\t// a31  2       rotationY, scaleX\n\t\t\t\t// a41  3       rotationY, scaleX\n\t\t\t\t// a12  4       rotation, skewX, rotationX, scaleY\n\t\t\t\t// a22  5       rotation, skewX, rotationX, scaleY\n\t\t\t\t// a32  6       rotationX, scaleY\n\t\t\t\t// a42  7       rotationX, scaleY\n\t\t\t\t// a13  8       rotationY, rotationX, scaleZ\n\t\t\t\t// a23  9       rotationY, rotationX, scaleZ\n\t\t\t\t// a33  10      rotationY, rotationX, scaleZ\n\t\t\t\t// a43  11      rotationY, rotationX, perspective, scaleZ\n\t\t\t\t// a14  12      x, zOrigin, svgOrigin\n\t\t\t\t// a24  13      y, zOrigin, svgOrigin\n\t\t\t\t// a34  14      z, zOrigin\n\t\t\t\t// a44  15\n\t\t\t\t// rotation: Math.atan2(a21, a11)\n\t\t\t\t// rotationY: Math.atan2(a13, a33) (or Math.atan2(a13, a11))\n\t\t\t\t// rotationX: Math.atan2(a32, a33)\n\t\t\t\ta33 = 1;\n\t\t\t\ta13 = a23 = a31 = a32 = a41 = a42 = 0;\n\t\t\t\ta43 = (perspective) ? -1 / perspective : 0;\n\t\t\t\tzOrigin = t.zOrigin;\n\t\t\t\tmin = 0.000001; //threshold below which browsers use scientific notation which won't work.\n\t\t\t\tcomma = \",\";\n\t\t\t\tzero = \"0\";\n\t\t\t\tangle = rotationY * _DEG2RAD;\n\t\t\t\tif (angle) {\n\t\t\t\t\tcos = Math.cos(angle);\n\t\t\t\t\tsin = Math.sin(angle);\n\t\t\t\t\ta31 = -sin;\n\t\t\t\t\ta41 = a43*-sin;\n\t\t\t\t\ta13 = a11*sin;\n\t\t\t\t\ta23 = a21*sin;\n\t\t\t\t\ta33 = cos;\n\t\t\t\t\ta43 *= cos;\n\t\t\t\t\ta11 *= cos;\n\t\t\t\t\ta21 *= cos;\n\t\t\t\t}\n\t\t\t\tangle = rotationX * _DEG2RAD;\n\t\t\t\tif (angle) {\n\t\t\t\t\tcos = Math.cos(angle);\n\t\t\t\t\tsin = Math.sin(angle);\n\t\t\t\t\tt1 = a12*cos+a13*sin;\n\t\t\t\t\tt2 = a22*cos+a23*sin;\n\t\t\t\t\ta32 = a33*sin;\n\t\t\t\t\ta42 = a43*sin;\n\t\t\t\t\ta13 = a12*-sin+a13*cos;\n\t\t\t\t\ta23 = a22*-sin+a23*cos;\n\t\t\t\t\ta33 = a33*cos;\n\t\t\t\t\ta43 = a43*cos;\n\t\t\t\t\ta12 = t1;\n\t\t\t\t\ta22 = t2;\n\t\t\t\t}\n\t\t\t\tif (sz !== 1) {\n\t\t\t\t\ta13*=sz;\n\t\t\t\t\ta23*=sz;\n\t\t\t\t\ta33*=sz;\n\t\t\t\t\ta43*=sz;\n\t\t\t\t}\n\t\t\t\tif (sy !== 1) {\n\t\t\t\t\ta12*=sy;\n\t\t\t\t\ta22*=sy;\n\t\t\t\t\ta32*=sy;\n\t\t\t\t\ta42*=sy;\n\t\t\t\t}\n\t\t\t\tif (sx !== 1) {\n\t\t\t\t\ta11*=sx;\n\t\t\t\t\ta21*=sx;\n\t\t\t\t\ta31*=sx;\n\t\t\t\t\ta41*=sx;\n\t\t\t\t}\n\n\t\t\t\tif (zOrigin || isSVG) {\n\t\t\t\t\tif (zOrigin) {\n\t\t\t\t\t\tx += a13*-zOrigin;\n\t\t\t\t\t\ty += a23*-zOrigin;\n\t\t\t\t\t\tz += a33*-zOrigin+zOrigin;\n\t\t\t\t\t}\n\t\t\t\t\tif (isSVG) { //due to bugs in some browsers, we need to manage the transform-origin of SVG manually\n\t\t\t\t\t\tx += t.xOrigin - (t.xOrigin * a11 + t.yOrigin * a12) + t.xOffset;\n\t\t\t\t\t\ty += t.yOrigin - (t.xOrigin * a21 + t.yOrigin * a22) + t.yOffset;\n\t\t\t\t\t}\n\t\t\t\t\tif (x < min && x > -min) {\n\t\t\t\t\t\tx = zero;\n\t\t\t\t\t}\n\t\t\t\t\tif (y < min && y > -min) {\n\t\t\t\t\t\ty = zero;\n\t\t\t\t\t}\n\t\t\t\t\tif (z < min && z > -min) {\n\t\t\t\t\t\tz = 0; //don't use string because we calculate perspective later and need the number.\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t//optimized way of concatenating all the values into a string. If we do it all in one shot, it's slower because of the way browsers have to create temp strings and the way it affects memory. If we do it piece-by-piece with +=, it's a bit slower too. We found that doing it in these sized chunks works best overall:\n\t\t\t\ttransform = ((t.xPercent || t.yPercent) ? \"translate(\" + t.xPercent + \"%,\" + t.yPercent + \"%) matrix3d(\" : \"matrix3d(\");\n\t\t\t\ttransform += ((a11 < min && a11 > -min) ? zero : a11) + comma + ((a21 < min && a21 > -min) ? zero : a21) + comma + ((a31 < min && a31 > -min) ? zero : a31);\n\t\t\t\ttransform += comma + ((a41 < min && a41 > -min) ? zero : a41) + comma + ((a12 < min && a12 > -min) ? zero : a12) + comma + ((a22 < min && a22 > -min) ? zero : a22);\n\t\t\t\tif (rotationX || rotationY || sz !== 1) { //performance optimization (often there's no rotationX or rotationY, so we can skip these calculations)\n\t\t\t\t\ttransform += comma + ((a32 < min && a32 > -min) ? zero : a32) + comma + ((a42 < min && a42 > -min) ? zero : a42) + comma + ((a13 < min && a13 > -min) ? zero : a13);\n\t\t\t\t\ttransform += comma + ((a23 < min && a23 > -min) ? zero : a23) + comma + ((a33 < min && a33 > -min) ? zero : a33) + comma + ((a43 < min && a43 > -min) ? zero : a43) + comma;\n\t\t\t\t} else {\n\t\t\t\t\ttransform += \",0,0,0,0,1,0,\";\n\t\t\t\t}\n\t\t\t\ttransform += x + comma + y + comma + z + comma + (perspective ? (1 + (-z / perspective)) : 1) + \")\";\n\n\t\t\t\tstyle[_transformProp] = transform;\n\t\t\t};\n\n\t\tp = Transform.prototype;\n\t\tp.x = p.y = p.z = p.skewX = p.skewY = p.rotation = p.rotationX = p.rotationY = p.zOrigin = p.xPercent = p.yPercent = p.xOffset = p.yOffset = 0;\n\t\tp.scaleX = p.scaleY = p.scaleZ = 1;\n\n\t\t_registerComplexSpecialProp(\"transform,scale,scaleX,scaleY,scaleZ,x,y,z,rotation,rotationX,rotationY,rotationZ,skewX,skewY,shortRotation,shortRotationX,shortRotationY,shortRotationZ,transformOrigin,svgOrigin,transformPerspective,directionalRotation,parseTransform,force3D,skewType,xPercent,yPercent,smoothOrigin\", {parser:function(t, e, parsingProp, cssp, pt, plugin, vars) {\n\t\t\tif (cssp._lastParsedTransform === vars) { return pt; } //only need to parse the transform once, and only if the browser supports it.\n\t\t\tcssp._lastParsedTransform = vars;\n\t\t\tvar scaleFunc = (vars.scale && typeof(vars.scale) === \"function\") ? vars.scale : 0; //if there's a function-based \"scale\" value, swap in the resulting numeric value temporarily. Otherwise, if it's called for both scaleX and scaleY independently, they may not match (like if the function uses Math.random()).\n\t\t\tif (scaleFunc) {\n\t\t\t\tvars.scale = scaleFunc(_index, t);\n\t\t\t}\n\t\t\tvar originalGSTransform = t._gsTransform,\n\t\t\t\tstyle = t.style,\n\t\t\t\tmin = 0.000001,\n\t\t\t\ti = _transformProps.length,\n\t\t\t\tv = vars,\n\t\t\t\tendRotations = {},\n\t\t\t\ttransformOriginString = \"transformOrigin\",\n\t\t\t\tm1 = _getTransform(t, _cs, true, v.parseTransform),\n\t\t\t\torig = v.transform && ((typeof(v.transform) === \"function\") ? v.transform(_index, _target) : v.transform),\n\t\t\t\tm2, copy, has3D, hasChange, dr, x, y, matrix, p;\n\t\t\tm1.skewType = v.skewType || m1.skewType || CSSPlugin.defaultSkewType;\n\t\t\tcssp._transform = m1;\n\t\t\tif (\"rotationZ\" in v) {\n\t\t\t\tv.rotation = v.rotationZ;\n\t\t\t}\n\t\t\tif (orig && typeof(orig) === \"string\" && _transformProp) { //for values like transform:\"rotate(60deg) scale(0.5, 0.8)\"\n\t\t\t\tcopy = _tempDiv.style; //don't use the original target because it might be SVG in which case some browsers don't report computed style correctly.\n\t\t\t\tcopy[_transformProp] = orig;\n\t\t\t\tcopy.display = \"block\"; //if display is \"none\", the browser often refuses to report the transform properties correctly.\n\t\t\t\tcopy.position = \"absolute\";\n\t\t\t\tif (orig.indexOf(\"%\") !== -1) { //%-based translations will fail unless we set the width/height to match the original target...\n\t\t\t\t\tcopy.width = _getStyle(t, \"width\");\n\t\t\t\t\tcopy.height = _getStyle(t, \"height\");\n\t\t\t\t}\n\t\t\t\t_doc.body.appendChild(_tempDiv);\n\t\t\t\tm2 = _getTransform(_tempDiv, null, false);\n\t\t\t\tif (m1.skewType === \"simple\") { //the default _getTransform() reports the skewX/scaleY as if skewType is \"compensated\", thus we need to adjust that here if skewType is \"simple\".\n\t\t\t\t\tm2.scaleY *= Math.cos(m2.skewX * _DEG2RAD);\n\t\t\t\t}\n\t\t\t\tif (m1.svg) { //if it's an SVG element, x/y part of the matrix will be affected by whatever we use as the origin and the offsets, so compensate here...\n\t\t\t\t\tx = m1.xOrigin;\n\t\t\t\t\ty = m1.yOrigin;\n\t\t\t\t\tm2.x -= m1.xOffset;\n\t\t\t\t\tm2.y -= m1.yOffset;\n\t\t\t\t\tif (v.transformOrigin || v.svgOrigin) { //if this tween is altering the origin, we must factor that in here. The actual work of recording the transformOrigin values and setting up the PropTween is done later (still inside this function) so we cannot leave the changes intact here - we only want to update the x/y accordingly.\n\t\t\t\t\t\torig = {};\n\t\t\t\t\t\t_parseSVGOrigin(t, _parsePosition(v.transformOrigin), orig, v.svgOrigin, v.smoothOrigin, true);\n\t\t\t\t\t\tx = orig.xOrigin;\n\t\t\t\t\t\ty = orig.yOrigin;\n\t\t\t\t\t\tm2.x -= orig.xOffset - m1.xOffset;\n\t\t\t\t\t\tm2.y -= orig.yOffset - m1.yOffset;\n\t\t\t\t\t}\n\t\t\t\t\tif (x || y) {\n\t\t\t\t\t\tmatrix = _getMatrix(_tempDiv, true);\n\t\t\t\t\t\tm2.x -= x - (x * matrix[0] + y * matrix[2]);\n\t\t\t\t\t\tm2.y -= y - (x * matrix[1] + y * matrix[3]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t_doc.body.removeChild(_tempDiv);\n\t\t\t\tif (!m2.perspective) {\n\t\t\t\t\tm2.perspective = m1.perspective; //tweening to no perspective gives very unintuitive results - just keep the same perspective in that case.\n\t\t\t\t}\n\t\t\t\tif (v.xPercent != null) {\n\t\t\t\t\tm2.xPercent = _parseVal(v.xPercent, m1.xPercent);\n\t\t\t\t}\n\t\t\t\tif (v.yPercent != null) {\n\t\t\t\t\tm2.yPercent = _parseVal(v.yPercent, m1.yPercent);\n\t\t\t\t}\n\t\t\t} else if (typeof(v) === \"object\") { //for values like scaleX, scaleY, rotation, x, y, skewX, and skewY or transform:{...} (object)\n\t\t\t\tm2 = {scaleX:_parseVal((v.scaleX != null) ? v.scaleX : v.scale, m1.scaleX),\n\t\t\t\t\tscaleY:_parseVal((v.scaleY != null) ? v.scaleY : v.scale, m1.scaleY),\n\t\t\t\t\tscaleZ:_parseVal(v.scaleZ, m1.scaleZ),\n\t\t\t\t\tx:_parseVal(v.x, m1.x),\n\t\t\t\t\ty:_parseVal(v.y, m1.y),\n\t\t\t\t\tz:_parseVal(v.z, m1.z),\n\t\t\t\t\txPercent:_parseVal(v.xPercent, m1.xPercent),\n\t\t\t\t\tyPercent:_parseVal(v.yPercent, m1.yPercent),\n\t\t\t\t\tperspective:_parseVal(v.transformPerspective, m1.perspective)};\n\t\t\t\tdr = v.directionalRotation;\n\t\t\t\tif (dr != null) {\n\t\t\t\t\tif (typeof(dr) === \"object\") {\n\t\t\t\t\t\tfor (copy in dr) {\n\t\t\t\t\t\t\tv[copy] = dr[copy];\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tv.rotation = dr;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (typeof(v.x) === \"string\" && v.x.indexOf(\"%\") !== -1) {\n\t\t\t\t\tm2.x = 0;\n\t\t\t\t\tm2.xPercent = _parseVal(v.x, m1.xPercent);\n\t\t\t\t}\n\t\t\t\tif (typeof(v.y) === \"string\" && v.y.indexOf(\"%\") !== -1) {\n\t\t\t\t\tm2.y = 0;\n\t\t\t\t\tm2.yPercent = _parseVal(v.y, m1.yPercent);\n\t\t\t\t}\n\n\t\t\t\tm2.rotation = _parseAngle((\"rotation\" in v) ? v.rotation : (\"shortRotation\" in v) ? v.shortRotation + \"_short\" : m1.rotation, m1.rotation, \"rotation\", endRotations);\n\t\t\t\tif (_supports3D) {\n\t\t\t\t\tm2.rotationX = _parseAngle((\"rotationX\" in v) ? v.rotationX : (\"shortRotationX\" in v) ? v.shortRotationX + \"_short\" : m1.rotationX || 0, m1.rotationX, \"rotationX\", endRotations);\n\t\t\t\t\tm2.rotationY = _parseAngle((\"rotationY\" in v) ? v.rotationY : (\"shortRotationY\" in v) ? v.shortRotationY + \"_short\" : m1.rotationY || 0, m1.rotationY, \"rotationY\", endRotations);\n\t\t\t\t}\n\t\t\t\tm2.skewX = _parseAngle(v.skewX, m1.skewX);\n\t\t\t\tm2.skewY = _parseAngle(v.skewY, m1.skewY);\n\t\t\t}\n\t\t\tif (_supports3D && v.force3D != null) {\n\t\t\t\tm1.force3D = v.force3D;\n\t\t\t\thasChange = true;\n\t\t\t}\n\n\t\t\thas3D = (m1.force3D || m1.z || m1.rotationX || m1.rotationY || m2.z || m2.rotationX || m2.rotationY || m2.perspective);\n\t\t\tif (!has3D && v.scale != null) {\n\t\t\t\tm2.scaleZ = 1; //no need to tween scaleZ.\n\t\t\t}\n\n\t\t\twhile (--i > -1) {\n\t\t\t\tp = _transformProps[i];\n\t\t\t\torig = m2[p] - m1[p];\n\t\t\t\tif (orig > min || orig < -min || v[p] != null || _forcePT[p] != null) {\n\t\t\t\t\thasChange = true;\n\t\t\t\t\tpt = new CSSPropTween(m1, p, m1[p], orig, pt);\n\t\t\t\t\tif (p in endRotations) {\n\t\t\t\t\t\tpt.e = endRotations[p]; //directional rotations typically have compensated values during the tween, but we need to make sure they end at exactly what the user requested\n\t\t\t\t\t}\n\t\t\t\t\tpt.xs0 = 0; //ensures the value stays numeric in setRatio()\n\t\t\t\t\tpt.plugin = plugin;\n\t\t\t\t\tcssp._overwriteProps.push(pt.n);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\torig = (typeof(v.transformOrigin) === \"function\") ? v.transformOrigin(_index, _target) : v.transformOrigin;\n\t\t\tif (m1.svg && (orig || v.svgOrigin)) {\n\t\t\t\tx = m1.xOffset; //when we change the origin, in order to prevent things from jumping we adjust the x/y so we must record those here so that we can create PropTweens for them and flip them at the same time as the origin\n\t\t\t\ty = m1.yOffset;\n\t\t\t\t_parseSVGOrigin(t, _parsePosition(orig), m2, v.svgOrigin, v.smoothOrigin);\n\t\t\t\tpt = _addNonTweeningNumericPT(m1, \"xOrigin\", (originalGSTransform ? m1 : m2).xOrigin, m2.xOrigin, pt, transformOriginString); //note: if there wasn't a transformOrigin defined yet, just start with the destination one; it's wasteful otherwise, and it causes problems with fromTo() tweens. For example, TweenLite.to(\"#wheel\", 3, {rotation:180, transformOrigin:\"50% 50%\", delay:1}); TweenLite.fromTo(\"#wheel\", 3, {scale:0.5, transformOrigin:\"50% 50%\"}, {scale:1, delay:2}); would cause a jump when the from values revert at the beginning of the 2nd tween.\n\t\t\t\tpt = _addNonTweeningNumericPT(m1, \"yOrigin\", (originalGSTransform ? m1 : m2).yOrigin, m2.yOrigin, pt, transformOriginString);\n\t\t\t\tif (x !== m1.xOffset || y !== m1.yOffset) {\n\t\t\t\t\tpt = _addNonTweeningNumericPT(m1, \"xOffset\", (originalGSTransform ? x : m1.xOffset), m1.xOffset, pt, transformOriginString);\n\t\t\t\t\tpt = _addNonTweeningNumericPT(m1, \"yOffset\", (originalGSTransform ? y : m1.yOffset), m1.yOffset, pt, transformOriginString);\n\t\t\t\t}\n\t\t\t\torig = \"0px 0px\"; //certain browsers (like firefox) completely botch transform-origin, so we must remove it to prevent it from contaminating transforms. We manage it ourselves with xOrigin and yOrigin\n\t\t\t}\n\t\t\tif (orig || (_supports3D && has3D && m1.zOrigin)) { //if anything 3D is happening and there's a transformOrigin with a z component that's non-zero, we must ensure that the transformOrigin's z-component is set to 0 so that we can manually do those calculations to get around Safari bugs. Even if the user didn't specifically define a \"transformOrigin\" in this particular tween (maybe they did it via css directly).\n\t\t\t\tif (_transformProp) {\n\t\t\t\t\thasChange = true;\n\t\t\t\t\tp = _transformOriginProp;\n\t\t\t\t\tif (!orig) {\n\t\t\t\t\t\torig = (_getStyle(t, p, _cs, false, \"50% 50%\") + \"\").split(\" \");\n\t\t\t\t\t\torig = orig[0] + \" \" + orig[1] + \" \" + m1.zOrigin + \"px\";\n\t\t\t\t\t}\n\t\t\t\t\torig += \"\";\n\t\t\t\t\tpt = new CSSPropTween(style, p, 0, 0, pt, -1, transformOriginString);\n\t\t\t\t\tpt.b = style[p];\n\t\t\t\t\tpt.plugin = plugin;\n\t\t\t\t\tif (_supports3D) {\n\t\t\t\t\t\tcopy = m1.zOrigin;\n\t\t\t\t\t\torig = orig.split(\" \");\n\t\t\t\t\t\tm1.zOrigin = ((orig.length > 2) ? parseFloat(orig[2]) : copy) || 0; //Safari doesn't handle the z part of transformOrigin correctly, so we'll manually handle it in the _set3DTransformRatio() method.\n\t\t\t\t\t\tpt.xs0 = pt.e = orig[0] + \" \" + (orig[1] || \"50%\") + \" 0px\"; //we must define a z value of 0px specifically otherwise iOS 5 Safari will stick with the old one (if one was defined)!\n\t\t\t\t\t\tpt = new CSSPropTween(m1, \"zOrigin\", 0, 0, pt, -1, pt.n); //we must create a CSSPropTween for the _gsTransform.zOrigin so that it gets reset properly at the beginning if the tween runs backward (as opposed to just setting m1.zOrigin here)\n\t\t\t\t\t\tpt.b = copy;\n\t\t\t\t\t\tpt.xs0 = pt.e = m1.zOrigin;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tpt.xs0 = pt.e = orig;\n\t\t\t\t\t}\n\n\t\t\t\t\t//for older versions of IE (6-8), we need to manually calculate things inside the setRatio() function. We record origin x and y (ox and oy) and whether or not the values are percentages (oxp and oyp).\n\t\t\t\t} else {\n\t\t\t\t\t_parsePosition(orig + \"\", m1);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (hasChange) {\n\t\t\t\tcssp._transformType = (!(m1.svg && _useSVGTransformAttr) && (has3D || this._transformType === 3)) ? 3 : 2; //quicker than calling cssp._enableTransforms();\n\t\t\t}\n\t\t\tif (scaleFunc) {\n\t\t\t\tvars.scale = scaleFunc;\n\t\t\t}\n\t\t\treturn pt;\n\t\t}, allowFunc:true, prefix:true});\n\n\t\t_registerComplexSpecialProp(\"boxShadow\", {defaultValue:\"0px 0px 0px 0px #999\", prefix:true, color:true, multi:true, keyword:\"inset\"});\n\t\t_registerComplexSpecialProp(\"clipPath\", {defaultValue:\"inset(0%)\", prefix:true, multi:true, formatter:_getFormatter(\"inset(0% 0% 0% 0%)\", false, true)});\n\n\t\t_registerComplexSpecialProp(\"borderRadius\", {defaultValue:\"0px\", parser:function(t, e, p, cssp, pt, plugin) {\n\t\t\te = this.format(e);\n\t\t\tvar props = [\"borderTopLeftRadius\",\"borderTopRightRadius\",\"borderBottomRightRadius\",\"borderBottomLeftRadius\"],\n\t\t\t\tstyle = t.style,\n\t\t\t\tea1, i, es2, bs2, bs, es, bn, en, w, h, esfx, bsfx, rel, hn, vn, em;\n\t\t\tw = parseFloat(t.offsetWidth);\n\t\t\th = parseFloat(t.offsetHeight);\n\t\t\tea1 = e.split(\" \");\n\t\t\tfor (i = 0; i < props.length; i++) { //if we're dealing with percentages, we must convert things separately for the horizontal and vertical axis!\n\t\t\t\tif (this.p.indexOf(\"border\")) { //older browsers used a prefix\n\t\t\t\t\tprops[i] = _checkPropPrefix(props[i]);\n\t\t\t\t}\n\t\t\t\tbs = bs2 = _getStyle(t, props[i], _cs, false, \"0px\");\n\t\t\t\tif (bs.indexOf(\" \") !== -1) {\n\t\t\t\t\tbs2 = bs.split(\" \");\n\t\t\t\t\tbs = bs2[0];\n\t\t\t\t\tbs2 = bs2[1];\n\t\t\t\t}\n\t\t\t\tes = es2 = ea1[i];\n\t\t\t\tbn = parseFloat(bs);\n\t\t\t\tbsfx = bs.substr((bn + \"\").length);\n\t\t\t\trel = (es.charAt(1) === \"=\");\n\t\t\t\tif (rel) {\n\t\t\t\t\ten = parseInt(es.charAt(0)+\"1\", 10);\n\t\t\t\t\tes = es.substr(2);\n\t\t\t\t\ten *= parseFloat(es);\n\t\t\t\t\tesfx = es.substr((en + \"\").length - (en < 0 ? 1 : 0)) || \"\";\n\t\t\t\t} else {\n\t\t\t\t\ten = parseFloat(es);\n\t\t\t\t\tesfx = es.substr((en + \"\").length);\n\t\t\t\t}\n\t\t\t\tif (esfx === \"\") {\n\t\t\t\t\tesfx = _suffixMap[p] || bsfx;\n\t\t\t\t}\n\t\t\t\tif (esfx !== bsfx) {\n\t\t\t\t\thn = _convertToPixels(t, \"borderLeft\", bn, bsfx); //horizontal number (we use a bogus \"borderLeft\" property just because the _convertToPixels() method searches for the keywords \"Left\", \"Right\", \"Top\", and \"Bottom\" to determine of it's a horizontal or vertical property, and we need \"border\" in the name so that it knows it should measure relative to the element itself, not its parent.\n\t\t\t\t\tvn = _convertToPixels(t, \"borderTop\", bn, bsfx); //vertical number\n\t\t\t\t\tif (esfx === \"%\") {\n\t\t\t\t\t\tbs = (hn / w * 100) + \"%\";\n\t\t\t\t\t\tbs2 = (vn / h * 100) + \"%\";\n\t\t\t\t\t} else if (esfx === \"em\") {\n\t\t\t\t\t\tem = _convertToPixels(t, \"borderLeft\", 1, \"em\");\n\t\t\t\t\t\tbs = (hn / em) + \"em\";\n\t\t\t\t\t\tbs2 = (vn / em) + \"em\";\n\t\t\t\t\t} else {\n\t\t\t\t\t\tbs = hn + \"px\";\n\t\t\t\t\t\tbs2 = vn + \"px\";\n\t\t\t\t\t}\n\t\t\t\t\tif (rel) {\n\t\t\t\t\t\tes = (parseFloat(bs) + en) + esfx;\n\t\t\t\t\t\tes2 = (parseFloat(bs2) + en) + esfx;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tpt = _parseComplex(style, props[i], bs + \" \" + bs2, es + \" \" + es2, false, \"0px\", pt);\n\t\t\t}\n\t\t\treturn pt;\n\t\t}, prefix:true, formatter:_getFormatter(\"0px 0px 0px 0px\", false, true)});\n\t\t_registerComplexSpecialProp(\"borderBottomLeftRadius,borderBottomRightRadius,borderTopLeftRadius,borderTopRightRadius\", {defaultValue:\"0px\", parser:function(t, e, p, cssp, pt, plugin) {\n\t\t\treturn _parseComplex(t.style, p, this.format(_getStyle(t, p, _cs, false, \"0px 0px\")), this.format(e), false, \"0px\", pt);\n\t\t}, prefix:true, formatter:_getFormatter(\"0px 0px\", false, true)});\n\t\t_registerComplexSpecialProp(\"backgroundPosition\", {defaultValue:\"0 0\", parser:function(t, e, p, cssp, pt, plugin) {\n\t\t\tvar bp = \"background-position\",\n\t\t\t\tcs = (_cs || _getComputedStyle(t, null)),\n\t\t\t\tbs = this.format( ((cs) ? _ieVers ? cs.getPropertyValue(bp + \"-x\") + \" \" + cs.getPropertyValue(bp + \"-y\") : cs.getPropertyValue(bp) : t.currentStyle.backgroundPositionX + \" \" + t.currentStyle.backgroundPositionY) || \"0 0\"), //Internet Explorer doesn't report background-position correctly - we must query background-position-x and background-position-y and combine them (even in IE10). Before IE9, we must do the same with the currentStyle object and use camelCase\n\t\t\t\tes = this.format(e),\n\t\t\t\tba, ea, i, pct, overlap, src;\n\t\t\tif ((bs.indexOf(\"%\") !== -1) !== (es.indexOf(\"%\") !== -1) && es.split(\",\").length < 2) {\n\t\t\t\tsrc = _getStyle(t, \"backgroundImage\").replace(_urlExp, \"\");\n\t\t\t\tif (src && src !== \"none\") {\n\t\t\t\t\tba = bs.split(\" \");\n\t\t\t\t\tea = es.split(\" \");\n\t\t\t\t\t_tempImg.setAttribute(\"src\", src); //set the temp IMG's src to the background-image so that we can measure its width/height\n\t\t\t\t\ti = 2;\n\t\t\t\t\twhile (--i > -1) {\n\t\t\t\t\t\tbs = ba[i];\n\t\t\t\t\t\tpct = (bs.indexOf(\"%\") !== -1);\n\t\t\t\t\t\tif (pct !== (ea[i].indexOf(\"%\") !== -1)) {\n\t\t\t\t\t\t\toverlap = (i === 0) ? t.offsetWidth - _tempImg.width : t.offsetHeight - _tempImg.height;\n\t\t\t\t\t\t\tba[i] = pct ? (parseFloat(bs) / 100 * overlap) + \"px\" : (parseFloat(bs) / overlap * 100) + \"%\";\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbs = ba.join(\" \");\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn this.parseComplex(t.style, bs, es, pt, plugin);\n\t\t}, formatter:_parsePosition});\n\t\t_registerComplexSpecialProp(\"backgroundSize\", {defaultValue:\"0 0\", formatter:function(v) {\n\t\t\tv += \"\"; //ensure it's a string\n\t\t\treturn (v.substr(0,2) === \"co\") ? v : _parsePosition(v.indexOf(\" \") === -1 ? v + \" \" + v : v); //if set to something like \"100% 100%\", Safari typically reports the computed style as just \"100%\" (no 2nd value), but we should ensure that there are two values, so copy the first one. Otherwise, it'd be interpreted as \"100% 0\" (wrong). Also remember that it could be \"cover\" or \"contain\" which we can't tween but should be able to set.\n\t\t}});\n\t\t_registerComplexSpecialProp(\"perspective\", {defaultValue:\"0px\", prefix:true});\n\t\t_registerComplexSpecialProp(\"perspectiveOrigin\", {defaultValue:\"50% 50%\", prefix:true});\n\t\t_registerComplexSpecialProp(\"transformStyle\", {prefix:true});\n\t\t_registerComplexSpecialProp(\"backfaceVisibility\", {prefix:true});\n\t\t_registerComplexSpecialProp(\"userSelect\", {prefix:true});\n\t\t_registerComplexSpecialProp(\"margin\", {parser:_getEdgeParser(\"marginTop,marginRight,marginBottom,marginLeft\")});\n\t\t_registerComplexSpecialProp(\"padding\", {parser:_getEdgeParser(\"paddingTop,paddingRight,paddingBottom,paddingLeft\")});\n\t\t_registerComplexSpecialProp(\"clip\", {defaultValue:\"rect(0px,0px,0px,0px)\", parser:function(t, e, p, cssp, pt, plugin){\n\t\t\tvar b, cs, delim;\n\t\t\tif (_ieVers < 9) { //IE8 and earlier don't report a \"clip\" value in the currentStyle - instead, the values are split apart into clipTop, clipRight, clipBottom, and clipLeft. Also, in IE7 and earlier, the values inside rect() are space-delimited, not comma-delimited.\n\t\t\t\tcs = t.currentStyle;\n\t\t\t\tdelim = _ieVers < 8 ? \" \" : \",\";\n\t\t\t\tb = \"rect(\" + cs.clipTop + delim + cs.clipRight + delim + cs.clipBottom + delim + cs.clipLeft + \")\";\n\t\t\t\te = this.format(e).split(\",\").join(delim);\n\t\t\t} else {\n\t\t\t\tb = this.format(_getStyle(t, this.p, _cs, false, this.dflt));\n\t\t\t\te = this.format(e);\n\t\t\t}\n\t\t\treturn this.parseComplex(t.style, b, e, pt, plugin);\n\t\t}});\n\t\t_registerComplexSpecialProp(\"textShadow\", {defaultValue:\"0px 0px 0px #999\", color:true, multi:true});\n\t\t_registerComplexSpecialProp(\"autoRound,strictUnits\", {parser:function(t, e, p, cssp, pt) {return pt;}}); //just so that we can ignore these properties (not tween them)\n\t\t_registerComplexSpecialProp(\"border\", {defaultValue:\"0px solid #000\", parser:function(t, e, p, cssp, pt, plugin) {\n\t\t\tvar bw = _getStyle(t, \"borderTopWidth\", _cs, false, \"0px\"),\n\t\t\t\tend = this.format(e).split(\" \"),\n\t\t\t\tesfx = end[0].replace(_suffixExp, \"\");\n\t\t\tif (esfx !== \"px\") { //if we're animating to a non-px value, we need to convert the beginning width to that unit.\n\t\t\t\tbw = (parseFloat(bw) / _convertToPixels(t, \"borderTopWidth\", 1, esfx)) + esfx;\n\t\t\t}\n\t\t\treturn this.parseComplex(t.style, this.format(bw + \" \" + _getStyle(t, \"borderTopStyle\", _cs, false, \"solid\") + \" \" + _getStyle(t, \"borderTopColor\", _cs, false, \"#000\")), end.join(\" \"), pt, plugin);\n\t\t\t}, color:true, formatter:function(v) {\n\t\t\t\tvar a = v.split(\" \");\n\t\t\t\treturn a[0] + \" \" + (a[1] || \"solid\") + \" \" + (v.match(_colorExp) || [\"#000\"])[0];\n\t\t\t}});\n\t\t_registerComplexSpecialProp(\"borderWidth\", {parser:_getEdgeParser(\"borderTopWidth,borderRightWidth,borderBottomWidth,borderLeftWidth\")}); //Firefox doesn't pick up on borderWidth set in style sheets (only inline).\n\t\t_registerComplexSpecialProp(\"float,cssFloat,styleFloat\", {parser:function(t, e, p, cssp, pt, plugin) {\n\t\t\tvar s = t.style,\n\t\t\t\tprop = (\"cssFloat\" in s) ? \"cssFloat\" : \"styleFloat\";\n\t\t\treturn new CSSPropTween(s, prop, 0, 0, pt, -1, p, false, 0, s[prop], e);\n\t\t}});\n\n\t\t//opacity-related\n\t\tvar _setIEOpacityRatio = function(v) {\n\t\t\t\tvar t = this.t, //refers to the element's style property\n\t\t\t\t\tfilters = t.filter || _getStyle(this.data, \"filter\") || \"\",\n\t\t\t\t\tval = (this.s + this.c * v) | 0,\n\t\t\t\t\tskip;\n\t\t\t\tif (val === 100) { //for older versions of IE that need to use a filter to apply opacity, we should remove the filter if opacity hits 1 in order to improve performance, but make sure there isn't a transform (matrix) or gradient in the filters.\n\t\t\t\t\tif (filters.indexOf(\"atrix(\") === -1 && filters.indexOf(\"radient(\") === -1 && filters.indexOf(\"oader(\") === -1) {\n\t\t\t\t\t\tt.removeAttribute(\"filter\");\n\t\t\t\t\t\tskip = (!_getStyle(this.data, \"filter\")); //if a class is applied that has an alpha filter, it will take effect (we don't want that), so re-apply our alpha filter in that case. We must first remove it and then check.\n\t\t\t\t\t} else {\n\t\t\t\t\t\tt.filter = filters.replace(_alphaFilterExp, \"\");\n\t\t\t\t\t\tskip = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (!skip) {\n\t\t\t\t\tif (this.xn1) {\n\t\t\t\t\t\tt.filter = filters = filters || (\"alpha(opacity=\" + val + \")\"); //works around bug in IE7/8 that prevents changes to \"visibility\" from being applied properly if the filter is changed to a different alpha on the same frame.\n\t\t\t\t\t}\n\t\t\t\t\tif (filters.indexOf(\"pacity\") === -1) { //only used if browser doesn't support the standard opacity style property (IE 7 and 8). We omit the \"O\" to avoid case-sensitivity issues\n\t\t\t\t\t\tif (val !== 0 || !this.xn1) { //bugs in IE7/8 won't render the filter properly if opacity is ADDED on the same frame/render as \"visibility\" changes (this.xn1 is 1 if this tween is an \"autoAlpha\" tween)\n\t\t\t\t\t\t\tt.filter = filters + \" alpha(opacity=\" + val + \")\"; //we round the value because otherwise, bugs in IE7/8 can prevent \"visibility\" changes from being applied properly.\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tt.filter = filters.replace(_opacityExp, \"opacity=\" + val);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t_registerComplexSpecialProp(\"opacity,alpha,autoAlpha\", {defaultValue:\"1\", parser:function(t, e, p, cssp, pt, plugin) {\n\t\t\tvar b = parseFloat(_getStyle(t, \"opacity\", _cs, false, \"1\")),\n\t\t\t\tstyle = t.style,\n\t\t\t\tisAutoAlpha = (p === \"autoAlpha\");\n\t\t\tif (typeof(e) === \"string\" && e.charAt(1) === \"=\") {\n\t\t\t\te = ((e.charAt(0) === \"-\") ? -1 : 1) * parseFloat(e.substr(2)) + b;\n\t\t\t}\n\t\t\tif (isAutoAlpha && b === 1 && _getStyle(t, \"visibility\", _cs) === \"hidden\" && e !== 0) { //if visibility is initially set to \"hidden\", we should interpret that as intent to make opacity 0 (a convenience)\n\t\t\t\tb = 0;\n\t\t\t}\n\t\t\tif (_supportsOpacity) {\n\t\t\t\tpt = new CSSPropTween(style, \"opacity\", b, e - b, pt);\n\t\t\t} else {\n\t\t\t\tpt = new CSSPropTween(style, \"opacity\", b * 100, (e - b) * 100, pt);\n\t\t\t\tpt.xn1 = isAutoAlpha ? 1 : 0; //we need to record whether or not this is an autoAlpha so that in the setRatio(), we know to duplicate the setting of the alpha in order to work around a bug in IE7 and IE8 that prevents changes to \"visibility\" from taking effect if the filter is changed to a different alpha(opacity) at the same time. Setting it to the SAME value first, then the new value works around the IE7/8 bug.\n\t\t\t\tstyle.zoom = 1; //helps correct an IE issue.\n\t\t\t\tpt.type = 2;\n\t\t\t\tpt.b = \"alpha(opacity=\" + pt.s + \")\";\n\t\t\t\tpt.e = \"alpha(opacity=\" + (pt.s + pt.c) + \")\";\n\t\t\t\tpt.data = t;\n\t\t\t\tpt.plugin = plugin;\n\t\t\t\tpt.setRatio = _setIEOpacityRatio;\n\t\t\t}\n\t\t\tif (isAutoAlpha) { //we have to create the \"visibility\" PropTween after the opacity one in the linked list so that they run in the order that works properly in IE8 and earlier\n\t\t\t\tpt = new CSSPropTween(style, \"visibility\", 0, 0, pt, -1, null, false, 0, ((b !== 0) ? \"inherit\" : \"hidden\"), ((e === 0) ? \"hidden\" : \"inherit\"));\n\t\t\t\tpt.xs0 = \"inherit\";\n\t\t\t\tcssp._overwriteProps.push(pt.n);\n\t\t\t\tcssp._overwriteProps.push(p);\n\t\t\t}\n\t\t\treturn pt;\n\t\t}});\n\n\n\t\tvar _removeProp = function(s, p) {\n\t\t\t\tif (p) {\n\t\t\t\t\tif (s.removeProperty) {\n\t\t\t\t\t\tif (p.substr(0,2) === \"ms\" || p.substr(0,6) === \"webkit\") { //Microsoft and some Webkit browsers don't conform to the standard of capitalizing the first prefix character, so we adjust so that when we prefix the caps with a dash, it's correct (otherwise it'd be \"ms-transform\" instead of \"-ms-transform\" for IE9, for example)\n\t\t\t\t\t\t\tp = \"-\" + p;\n\t\t\t\t\t\t}\n\t\t\t\t\t\ts.removeProperty(p.replace(_capsExp, \"-$1\").toLowerCase());\n\t\t\t\t\t} else { //note: old versions of IE use \"removeAttribute()\" instead of \"removeProperty()\"\n\t\t\t\t\t\ts.removeAttribute(p);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t},\n\t\t\t_setClassNameRatio = function(v) {\n\t\t\t\tthis.t._gsClassPT = this;\n\t\t\t\tif (v === 1 || v === 0) {\n\t\t\t\t\tthis.t.setAttribute(\"class\", (v === 0) ? this.b : this.e);\n\t\t\t\t\tvar mpt = this.data, //first MiniPropTween\n\t\t\t\t\t\ts = this.t.style;\n\t\t\t\t\twhile (mpt) {\n\t\t\t\t\t\tif (!mpt.v) {\n\t\t\t\t\t\t\t_removeProp(s, mpt.p);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\ts[mpt.p] = mpt.v;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tmpt = mpt._next;\n\t\t\t\t\t}\n\t\t\t\t\tif (v === 1 && this.t._gsClassPT === this) {\n\t\t\t\t\t\tthis.t._gsClassPT = null;\n\t\t\t\t\t}\n\t\t\t\t} else if (this.t.getAttribute(\"class\") !== this.e) {\n\t\t\t\t\tthis.t.setAttribute(\"class\", this.e);\n\t\t\t\t}\n\t\t\t};\n\t\t_registerComplexSpecialProp(\"className\", {parser:function(t, e, p, cssp, pt, plugin, vars) {\n\t\t\tvar b = t.getAttribute(\"class\") || \"\", //don't use t.className because it doesn't work consistently on SVG elements; getAttribute(\"class\") and setAttribute(\"class\", value\") is more reliable.\n\t\t\t\tcssText = t.style.cssText,\n\t\t\t\tdifData, bs, cnpt, cnptLookup, mpt;\n\t\t\tpt = cssp._classNamePT = new CSSPropTween(t, p, 0, 0, pt, 2);\n\t\t\tpt.setRatio = _setClassNameRatio;\n\t\t\tpt.pr = -11;\n\t\t\t_hasPriority = true;\n\t\t\tpt.b = b;\n\t\t\tbs = _getAllStyles(t, _cs);\n\t\t\t//if there's a className tween already operating on the target, force it to its end so that the necessary inline styles are removed and the class name is applied before we determine the end state (we don't want inline styles interfering that were there just for class-specific values)\n\t\t\tcnpt = t._gsClassPT;\n\t\t\tif (cnpt) {\n\t\t\t\tcnptLookup = {};\n\t\t\t\tmpt = cnpt.data; //first MiniPropTween which stores the inline styles - we need to force these so that the inline styles don't contaminate things. Otherwise, there's a small chance that a tween could start and the inline values match the destination values and they never get cleaned.\n\t\t\t\twhile (mpt) {\n\t\t\t\t\tcnptLookup[mpt.p] = 1;\n\t\t\t\t\tmpt = mpt._next;\n\t\t\t\t}\n\t\t\t\tcnpt.setRatio(1);\n\t\t\t}\n\t\t\tt._gsClassPT = pt;\n\t\t\tpt.e = (e.charAt(1) !== \"=\") ? e : b.replace(new RegExp(\"(?:\\\\s|^)\" + e.substr(2) + \"(?![\\\\w-])\"), \"\") + ((e.charAt(0) === \"+\") ? \" \" + e.substr(2) : \"\");\n\t\t\tt.setAttribute(\"class\", pt.e);\n\t\t\tdifData = _cssDif(t, bs, _getAllStyles(t), vars, cnptLookup);\n\t\t\tt.setAttribute(\"class\", b);\n\t\t\tpt.data = difData.firstMPT;\n\t\t\tif (t.style.cssText !== cssText) { //only apply if things change. Otherwise, in cases like a background-image that's pulled dynamically, it could cause a refresh. See https://greensock.com/forums/topic/20368-possible-gsap-bug-switching-classnames-in-chrome/.\n\t\t\t\tt.style.cssText = cssText; //we recorded cssText before we swapped classes and ran _getAllStyles() because in cases when a className tween is overwritten, we remove all the related tweening properties from that class change (otherwise class-specific stuff can't override properties we've directly set on the target's style object due to specificity).\n\t\t\t}\n\t\t\tpt = pt.xfirst = cssp.parse(t, difData.difs, pt, plugin); //we record the CSSPropTween as the xfirst so that we can handle overwriting propertly (if \"className\" gets overwritten, we must kill all the properties associated with the className part of the tween, so we can loop through from xfirst to the pt itself)\n\t\t\treturn pt;\n\t\t}});\n\n\n\t\tvar _setClearPropsRatio = function(v) {\n\t\t\tif (v === 1 || v === 0) if (this.data._totalTime === this.data._totalDuration && this.data.data !== \"isFromStart\") { //this.data refers to the tween. Only clear at the END of the tween (remember, from() tweens make the ratio go from 1 to 0, so we can't just check that and if the tween is the zero-duration one that's created internally to render the starting values in a from() tween, ignore that because otherwise, for example, from(...{height:100, clearProps:\"height\", delay:1}) would wipe the height at the beginning of the tween and after 1 second, it'd kick back in).\n\t\t\t\tvar s = this.t.style,\n\t\t\t\t\ttransformParse = _specialProps.transform.parse,\n\t\t\t\t\ta, p, i, clearTransform, transform;\n\t\t\t\tif (this.e === \"all\") {\n\t\t\t\t\ts.cssText = \"\";\n\t\t\t\t\tclearTransform = true;\n\t\t\t\t} else {\n\t\t\t\t\ta = this.e.split(\" \").join(\"\").split(\",\");\n\t\t\t\t\ti = a.length;\n\t\t\t\t\twhile (--i > -1) {\n\t\t\t\t\t\tp = a[i];\n\t\t\t\t\t\tif (_specialProps[p]) {\n\t\t\t\t\t\t\tif (_specialProps[p].parse === transformParse) {\n\t\t\t\t\t\t\t\tclearTransform = true;\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tp = (p === \"transformOrigin\") ? _transformOriginProp : _specialProps[p].p; //ensures that special properties use the proper browser-specific property name, like \"scaleX\" might be \"-webkit-transform\" or \"boxShadow\" might be \"-moz-box-shadow\"\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\t_removeProp(s, p);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (clearTransform) {\n\t\t\t\t\t_removeProp(s, _transformProp);\n\t\t\t\t\ttransform = this.t._gsTransform;\n\t\t\t\t\tif (transform) {\n\t\t\t\t\t\tif (transform.svg) {\n\t\t\t\t\t\t\tthis.t.removeAttribute(\"data-svg-origin\");\n\t\t\t\t\t\t\tthis.t.removeAttribute(\"transform\");\n\t\t\t\t\t\t}\n\t\t\t\t\t\tdelete this.t._gsTransform;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t}\n\t\t};\n\t\t_registerComplexSpecialProp(\"clearProps\", {parser:function(t, e, p, cssp, pt) {\n\t\t\tpt = new CSSPropTween(t, p, 0, 0, pt, 2);\n\t\t\tpt.setRatio = _setClearPropsRatio;\n\t\t\tpt.e = e;\n\t\t\tpt.pr = -10;\n\t\t\tpt.data = cssp._tween;\n\t\t\t_hasPriority = true;\n\t\t\treturn pt;\n\t\t}});\n\n\t\tp = \"bezier,throwProps,physicsProps,physics2D\".split(\",\");\n\t\ti = p.length;\n\t\twhile (i--) {\n\t\t\t_registerPluginProp(p[i]);\n\t\t}\n\n\n\n\n\n\n\n\n\t\tp = CSSPlugin.prototype;\n\t\tp._firstPT = p._lastParsedTransform = p._transform = null;\n\n\t\t//gets called when the tween renders for the first time. This kicks everything off, recording start/end values, etc.\n\t\tp._onInitTween = function(target, vars, tween, index) {\n\t\t\tif (!target.nodeType) { //css is only for dom elements\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tthis._target = _target = target;\n\t\t\tthis._tween = tween;\n\t\t\tthis._vars = vars;\n\t\t\t_index = index;\n\t\t\t_autoRound = vars.autoRound;\n\t\t\t_hasPriority = false;\n\t\t\t_suffixMap = vars.suffixMap || CSSPlugin.suffixMap;\n\t\t\t_cs = _getComputedStyle(target, \"\");\n\t\t\t_overwriteProps = this._overwriteProps;\n\t\t\tvar style = target.style,\n\t\t\t\tv, pt, pt2, first, last, next, zIndex, tpt, threeD;\n\t\t\tif (_reqSafariFix) if (style.zIndex === \"\") {\n\t\t\t\tv = _getStyle(target, \"zIndex\", _cs);\n\t\t\t\tif (v === \"auto\" || v === \"\") {\n\t\t\t\t\t//corrects a bug in [non-Android] Safari that prevents it from repainting elements in their new positions if they don't have a zIndex set. We also can't just apply this inside _parseTransform() because anything that's moved in any way (like using \"left\" or \"top\" instead of transforms like \"x\" and \"y\") can be affected, so it is best to ensure that anything that's tweening has a z-index. Setting \"WebkitPerspective\" to a non-zero value worked too except that on iOS Safari things would flicker randomly. Plus zIndex is less memory-intensive.\n\t\t\t\t\tthis._addLazySet(style, \"zIndex\", 0);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (typeof(vars) === \"string\") {\n\t\t\t\tfirst = style.cssText;\n\t\t\t\tv = _getAllStyles(target, _cs);\n\t\t\t\tstyle.cssText = first + \";\" + vars;\n\t\t\t\tv = _cssDif(target, v, _getAllStyles(target)).difs;\n\t\t\t\tif (!_supportsOpacity && _opacityValExp.test(vars)) {\n\t\t\t\t\tv.opacity = parseFloat( RegExp.$1 );\n\t\t\t\t}\n\t\t\t\tvars = v;\n\t\t\t\tstyle.cssText = first;\n\t\t\t}\n\n\t\t\tif (vars.className) { //className tweens will combine any differences they find in the css with the vars that are passed in, so {className:\"myClass\", scale:0.5, left:20} would work.\n\t\t\t\tthis._firstPT = pt = _specialProps.className.parse(target, vars.className, \"className\", this, null, null, vars);\n\t\t\t} else {\n\t\t\t\tthis._firstPT = pt = this.parse(target, vars, null);\n\t\t\t}\n\n\t\t\tif (this._transformType) {\n\t\t\t\tthreeD = (this._transformType === 3);\n\t\t\t\tif (!_transformProp) {\n\t\t\t\t\tstyle.zoom = 1; //helps correct an IE issue.\n\t\t\t\t} else if (_isSafari) {\n\t\t\t\t\t_reqSafariFix = true;\n\t\t\t\t\t//if zIndex isn't set, iOS Safari doesn't repaint things correctly sometimes (seemingly at random).\n\t\t\t\t\tif (style.zIndex === \"\") {\n\t\t\t\t\t\tzIndex = _getStyle(target, \"zIndex\", _cs);\n\t\t\t\t\t\tif (zIndex === \"auto\" || zIndex === \"\") {\n\t\t\t\t\t\t\tthis._addLazySet(style, \"zIndex\", 0);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t//Setting WebkitBackfaceVisibility corrects 3 bugs:\n\t\t\t\t\t// 1) [non-Android] Safari skips rendering changes to \"top\" and \"left\" that are made on the same frame/render as a transform update.\n\t\t\t\t\t// 2) iOS Safari sometimes neglects to repaint elements in their new positions. Setting \"WebkitPerspective\" to a non-zero value worked too except that on iOS Safari things would flicker randomly.\n\t\t\t\t\t// 3) Safari sometimes displayed odd artifacts when tweening the transform (or WebkitTransform) property, like ghosts of the edges of the element remained. Definitely a browser bug.\n\t\t\t\t\t//Note: we allow the user to override the auto-setting by defining WebkitBackfaceVisibility in the vars of the tween.\n\t\t\t\t\tif (_isSafariLT6) {\n\t\t\t\t\t\tthis._addLazySet(style, \"WebkitBackfaceVisibility\", this._vars.WebkitBackfaceVisibility || (threeD ? \"visible\" : \"hidden\"));\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tpt2 = pt;\n\t\t\t\twhile (pt2 && pt2._next) {\n\t\t\t\t\tpt2 = pt2._next;\n\t\t\t\t}\n\t\t\t\ttpt = new CSSPropTween(target, \"transform\", 0, 0, null, 2);\n\t\t\t\tthis._linkCSSP(tpt, null, pt2);\n\t\t\t\ttpt.setRatio = _transformProp ? _setTransformRatio : _setIETransformRatio;\n\t\t\t\ttpt.data = this._transform || _getTransform(target, _cs, true);\n\t\t\t\ttpt.tween = tween;\n\t\t\t\ttpt.pr = -1; //ensures that the transforms get applied after the components are updated.\n\t\t\t\t_overwriteProps.pop(); //we don't want to force the overwrite of all \"transform\" tweens of the target - we only care about individual transform properties like scaleX, rotation, etc. The CSSPropTween constructor automatically adds the property to _overwriteProps which is why we need to pop() here.\n\t\t\t}\n\n\t\t\tif (_hasPriority) {\n\t\t\t\t//reorders the linked list in order of pr (priority)\n\t\t\t\twhile (pt) {\n\t\t\t\t\tnext = pt._next;\n\t\t\t\t\tpt2 = first;\n\t\t\t\t\twhile (pt2 && pt2.pr > pt.pr) {\n\t\t\t\t\t\tpt2 = pt2._next;\n\t\t\t\t\t}\n\t\t\t\t\tif ((pt._prev = pt2 ? pt2._prev : last)) {\n\t\t\t\t\t\tpt._prev._next = pt;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tfirst = pt;\n\t\t\t\t\t}\n\t\t\t\t\tif ((pt._next = pt2)) {\n\t\t\t\t\t\tpt2._prev = pt;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tlast = pt;\n\t\t\t\t\t}\n\t\t\t\t\tpt = next;\n\t\t\t\t}\n\t\t\t\tthis._firstPT = first;\n\t\t\t}\n\t\t\treturn true;\n\t\t};\n\n\n\t\tp.parse = function(target, vars, pt, plugin) {\n\t\t\tvar style = target.style,\n\t\t\t\tp, sp, bn, en, bs, es, bsfx, esfx, isStr, rel;\n\t\t\tfor (p in vars) {\n\t\t\t\tes = vars[p]; //ending value string\n\t\t\t\tsp = _specialProps[p]; //SpecialProp lookup.\n\t\t\t\tif (typeof(es) === \"function\" && !(sp && sp.allowFunc)) {\n\t\t\t\t\tes = es(_index, _target);\n\t\t\t\t}\n\t\t\t\tif (sp) {\n\t\t\t\t\tpt = sp.parse(target, es, p, this, pt, plugin, vars);\n\t\t\t\t} else if (p.substr(0,2) === \"--\") { //for tweening CSS variables (which always start with \"--\"). To maximize performance and simplicity, we bypass CSSPlugin altogether and just add a normal property tween to the tween instance itself.\n\t\t\t\t\tthis._tween._propLookup[p] = this._addTween.call(this._tween, target.style, \"setProperty\", _getComputedStyle(target).getPropertyValue(p) + \"\", es + \"\", p, false, p);\n\t\t\t\t\tcontinue;\n\t\t\t\t} else {\n\t\t\t\t\tbs = _getStyle(target, p, _cs) + \"\";\n\t\t\t\t\tisStr = (typeof(es) === \"string\");\n\t\t\t\t\tif (p === \"color\" || p === \"fill\" || p === \"stroke\" || p.indexOf(\"Color\") !== -1 || (isStr && _rgbhslExp.test(es))) { //Opera uses background: to define color sometimes in addition to backgroundColor:\n\t\t\t\t\t\tif (!isStr) {\n\t\t\t\t\t\t\tes = _parseColor(es);\n\t\t\t\t\t\t\tes = ((es.length > 3) ? \"rgba(\" : \"rgb(\") + es.join(\",\") + \")\";\n\t\t\t\t\t\t}\n\t\t\t\t\t\tpt = _parseComplex(style, p, bs, es, true, \"transparent\", pt, 0, plugin);\n\n\t\t\t\t\t} else if (isStr && _complexExp.test(es)) {\n\t\t\t\t\t\tpt = _parseComplex(style, p, bs, es, true, null, pt, 0, plugin);\n\n\t\t\t\t\t} else {\n\t\t\t\t\t\tbn = parseFloat(bs);\n\t\t\t\t\t\tbsfx = (bn || bn === 0) ? bs.substr((bn + \"\").length) : \"\"; //remember, bs could be non-numeric like \"normal\" for fontWeight, so we should default to a blank suffix in that case.\n\n\t\t\t\t\t\tif (bs === \"\" || bs === \"auto\") {\n\t\t\t\t\t\t\tif (p === \"width\" || p === \"height\") {\n\t\t\t\t\t\t\t\tbn = _getDimension(target, p, _cs);\n\t\t\t\t\t\t\t\tbsfx = \"px\";\n\t\t\t\t\t\t\t} else if (p === \"left\" || p === \"top\") {\n\t\t\t\t\t\t\t\tbn = _calculateOffset(target, p, _cs);\n\t\t\t\t\t\t\t\tbsfx = \"px\";\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tbn = (p !== \"opacity\") ? 0 : 1;\n\t\t\t\t\t\t\t\tbsfx = \"\";\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\trel = (isStr && es.charAt(1) === \"=\");\n\t\t\t\t\t\tif (rel) {\n\t\t\t\t\t\t\ten = parseInt(es.charAt(0) + \"1\", 10);\n\t\t\t\t\t\t\tes = es.substr(2);\n\t\t\t\t\t\t\ten *= parseFloat(es);\n\t\t\t\t\t\t\tesfx = es.replace(_suffixExp, \"\");\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\ten = parseFloat(es);\n\t\t\t\t\t\t\tesfx = isStr ? es.replace(_suffixExp, \"\") : \"\";\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (esfx === \"\") {\n\t\t\t\t\t\t\tesfx = (p in _suffixMap) ? _suffixMap[p] : bsfx; //populate the end suffix, prioritizing the map, then if none is found, use the beginning suffix.\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tes = (en || en === 0) ? (rel ? en + bn : en) + esfx : vars[p]; //ensures that any += or -= prefixes are taken care of. Record the end value before normalizing the suffix because we always want to end the tween on exactly what they intended even if it doesn't match the beginning value's suffix.\n\t\t\t\t\t\t//if the beginning/ending suffixes don't match, normalize them...\n\t\t\t\t\t\tif (bsfx !== esfx) if (esfx !== \"\" || p === \"lineHeight\") if (en || en === 0) if (bn) { //note: if the beginning value (bn) is 0, we don't need to convert units!\n\t\t\t\t\t\t\tbn = _convertToPixels(target, p, bn, bsfx);\n\t\t\t\t\t\t\tif (esfx === \"%\") {\n\t\t\t\t\t\t\t\tbn /= _convertToPixels(target, p, 100, \"%\") / 100;\n\t\t\t\t\t\t\t\tif (vars.strictUnits !== true) { //some browsers report only \"px\" values instead of allowing \"%\" with getComputedStyle(), so we assume that if we're tweening to a %, we should start there too unless strictUnits:true is defined. This approach is particularly useful for responsive designs that use from() tweens.\n\t\t\t\t\t\t\t\t\tbs = bn + \"%\";\n\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t} else if (esfx === \"em\" || esfx === \"rem\" || esfx === \"vw\" || esfx === \"vh\") {\n\t\t\t\t\t\t\t\tbn /= _convertToPixels(target, p, 1, esfx);\n\n\t\t\t\t\t\t\t//otherwise convert to pixels.\n\t\t\t\t\t\t\t} else if (esfx !== \"px\") {\n\t\t\t\t\t\t\t\ten = _convertToPixels(target, p, en, esfx);\n\t\t\t\t\t\t\t\tesfx = \"px\"; //we don't use bsfx after this, so we don't need to set it to px too.\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (rel) if (en || en === 0) {\n\t\t\t\t\t\t\t\tes = (en + bn) + esfx; //the changes we made affect relative calculations, so adjust the end value here.\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (rel) {\n\t\t\t\t\t\t\ten += bn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif ((bn || bn === 0) && (en || en === 0)) { //faster than isNaN(). Also, previously we required en !== bn but that doesn't really gain much performance and it prevents _parseToProxy() from working properly if beginning and ending values match but need to get tweened by an external plugin anyway. For example, a bezier tween where the target starts at left:0 and has these points: [{left:50},{left:0}] wouldn't work properly because when parsing the last point, it'd match the first (current) one and a non-tweening CSSPropTween would be recorded when we actually need a normal tween (type:0) so that things get updated during the tween properly.\n\t\t\t\t\t\t\tpt = new CSSPropTween(style, p, bn, en - bn, pt, 0, p, (_autoRound !== false && (esfx === \"px\" || p === \"zIndex\")), 0, bs, es);\n\t\t\t\t\t\t\tpt.xs0 = esfx;\n\t\t\t\t\t\t\t//DEBUG: _log(\"tween \"+p+\" from \"+pt.b+\" (\"+bn+esfx+\") to \"+pt.e+\" with suffix: \"+pt.xs0);\n\t\t\t\t\t\t} else if (style[p] === undefined || !es && (es + \"\" === \"NaN\" || es == null)) {\n\t\t\t\t\t\t\t_log(\"invalid \" + p + \" tween value: \" + vars[p]);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tpt = new CSSPropTween(style, p, en || bn || 0, 0, pt, -1, p, false, 0, bs, es);\n\t\t\t\t\t\t\tpt.xs0 = (es === \"none\" && (p === \"display\" || p.indexOf(\"Style\") !== -1)) ? bs : es; //intermediate value should typically be set immediately (end value) except for \"display\" or things like borderTopStyle, borderBottomStyle, etc. which should use the beginning value during the tween.\n\t\t\t\t\t\t\t//DEBUG: _log(\"non-tweening value \"+p+\": \"+pt.xs0);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (plugin) if (pt && !pt.plugin) {\n\t\t\t\t\tpt.plugin = plugin;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn pt;\n\t\t};\n\n\n\t\t//gets called every time the tween updates, passing the new ratio (typically a value between 0 and 1, but not always (for example, if an Elastic.easeOut is used, the value can jump above 1 mid-tween). It will always start and 0 and end at 1.\n\t\tp.setRatio = function(v) {\n\t\t\tvar pt = this._firstPT,\n\t\t\t\tmin = 0.000001,\n\t\t\t\tval, str, i;\n\t\t\t//at the end of the tween, we set the values to exactly what we received in order to make sure non-tweening values (like \"position\" or \"float\" or whatever) are set and so that if the beginning/ending suffixes (units) didn't match and we normalized to px, the value that the user passed in is used here. We check to see if the tween is at its beginning in case it's a from() tween in which case the ratio will actually go from 1 to 0 over the course of the tween (backwards).\n\t\t\tif (v === 1 && (this._tween._time === this._tween._duration || this._tween._time === 0)) {\n\t\t\t\twhile (pt) {\n\t\t\t\t\tif (pt.type !== 2) {\n\t\t\t\t\t\tif (pt.r && pt.type !== -1) {\n\t\t\t\t\t\t\tval = pt.r(pt.s + pt.c);\n\t\t\t\t\t\t\tif (!pt.type) {\n\t\t\t\t\t\t\t\tpt.t[pt.p] = val + pt.xs0;\n\t\t\t\t\t\t\t} else if (pt.type === 1) { //complex value (one that typically has multiple numbers inside a string, like \"rect(5px,10px,20px,25px)\"\n\t\t\t\t\t\t\t\ti = pt.l;\n\t\t\t\t\t\t\t\tstr = pt.xs0 + val + pt.xs1;\n\t\t\t\t\t\t\t\tfor (i = 1; i < pt.l; i++) {\n\t\t\t\t\t\t\t\t\tstr += pt[\"xn\"+i] + pt[\"xs\"+(i+1)];\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tpt.t[pt.p] = str;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tpt.t[pt.p] = pt.e;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tpt.setRatio(v);\n\t\t\t\t\t}\n\t\t\t\t\tpt = pt._next;\n\t\t\t\t}\n\n\t\t\t} else if (v || !(this._tween._time === this._tween._duration || this._tween._time === 0) || this._tween._rawPrevTime === -0.000001) {\n\t\t\t\twhile (pt) {\n\t\t\t\t\tval = pt.c * v + pt.s;\n\t\t\t\t\tif (pt.r) {\n\t\t\t\t\t\tval = pt.r(val);\n\t\t\t\t\t} else if (val < min) if (val > -min) {\n\t\t\t\t\t\tval = 0;\n\t\t\t\t\t}\n\t\t\t\t\tif (!pt.type) {\n\t\t\t\t\t\tpt.t[pt.p] = val + pt.xs0;\n\t\t\t\t\t} else if (pt.type === 1) { //complex value (one that typically has multiple numbers inside a string, like \"rect(5px,10px,20px,25px)\"\n\t\t\t\t\t\ti = pt.l;\n\t\t\t\t\t\tif (i === 2) {\n\t\t\t\t\t\t\tpt.t[pt.p] = pt.xs0 + val + pt.xs1 + pt.xn1 + pt.xs2;\n\t\t\t\t\t\t} else if (i === 3) {\n\t\t\t\t\t\t\tpt.t[pt.p] = pt.xs0 + val + pt.xs1 + pt.xn1 + pt.xs2 + pt.xn2 + pt.xs3;\n\t\t\t\t\t\t} else if (i === 4) {\n\t\t\t\t\t\t\tpt.t[pt.p] = pt.xs0 + val + pt.xs1 + pt.xn1 + pt.xs2 + pt.xn2 + pt.xs3 + pt.xn3 + pt.xs4;\n\t\t\t\t\t\t} else if (i === 5) {\n\t\t\t\t\t\t\tpt.t[pt.p] = pt.xs0 + val + pt.xs1 + pt.xn1 + pt.xs2 + pt.xn2 + pt.xs3 + pt.xn3 + pt.xs4 + pt.xn4 + pt.xs5;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tstr = pt.xs0 + val + pt.xs1;\n\t\t\t\t\t\t\tfor (i = 1; i < pt.l; i++) {\n\t\t\t\t\t\t\t\tstr += pt[\"xn\"+i] + pt[\"xs\"+(i+1)];\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tpt.t[pt.p] = str;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else if (pt.type === -1) { //non-tweening value\n\t\t\t\t\t\tpt.t[pt.p] = pt.xs0;\n\n\t\t\t\t\t} else if (pt.setRatio) { //custom setRatio() for things like SpecialProps, external plugins, etc.\n\t\t\t\t\t\tpt.setRatio(v);\n\t\t\t\t\t}\n\t\t\t\t\tpt = pt._next;\n\t\t\t\t}\n\n\t\t\t//if the tween is reversed all the way back to the beginning, we need to restore the original values which may have different units (like % instead of px or em or whatever).\n\t\t\t} else {\n\t\t\t\twhile (pt) {\n\t\t\t\t\tif (pt.type !== 2) {\n\t\t\t\t\t\tpt.t[pt.p] = pt.b;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tpt.setRatio(v);\n\t\t\t\t\t}\n\t\t\t\t\tpt = pt._next;\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\n\t\t/**\n\t\t * @private\n\t\t * Forces rendering of the target's transforms (rotation, scale, etc.) whenever the CSSPlugin's setRatio() is called.\n\t\t * Basically, this tells the CSSPlugin to create a CSSPropTween (type 2) after instantiation that runs last in the linked\n\t\t * list and calls the appropriate (3D or 2D) rendering function. We separate this into its own method so that we can call\n\t\t * it from other plugins like BezierPlugin if, for example, it needs to apply an autoRotation and this CSSPlugin\n\t\t * doesn't have any transform-related properties of its own. You can call this method as many times as you\n\t\t * want and it won't create duplicate CSSPropTweens.\n\t\t *\n\t\t * @param {boolean} threeD if true, it should apply 3D tweens (otherwise, just 2D ones are fine and typically faster)\n\t\t */\n\t\tp._enableTransforms = function(threeD) {\n\t\t\tthis._transform = this._transform || _getTransform(this._target, _cs, true); //ensures that the element has a _gsTransform property with the appropriate values.\n\t\t\tthis._transformType = (!(this._transform.svg && _useSVGTransformAttr) && (threeD || this._transformType === 3)) ? 3 : 2;\n\t\t};\n\n\t\tvar lazySet = function(v) {\n\t\t\tthis.t[this.p] = this.e;\n\t\t\tthis.data._linkCSSP(this, this._next, null, true); //we purposefully keep this._next even though it'd make sense to null it, but this is a performance optimization, as this happens during the while (pt) {} loop in setRatio() at the bottom of which it sets pt = pt._next, so if we null it, the linked list will be broken in that loop.\n\t\t};\n\t\t/** @private Gives us a way to set a value on the first render (and only the first render). **/\n\t\tp._addLazySet = function(t, p, v) {\n\t\t\tvar pt = this._firstPT = new CSSPropTween(t, p, 0, 0, this._firstPT, 2);\n\t\t\tpt.e = v;\n\t\t\tpt.setRatio = lazySet;\n\t\t\tpt.data = this;\n\t\t};\n\n\t\t/** @private **/\n\t\tp._linkCSSP = function(pt, next, prev, remove) {\n\t\t\tif (pt) {\n\t\t\t\tif (next) {\n\t\t\t\t\tnext._prev = pt;\n\t\t\t\t}\n\t\t\t\tif (pt._next) {\n\t\t\t\t\tpt._next._prev = pt._prev;\n\t\t\t\t}\n\t\t\t\tif (pt._prev) {\n\t\t\t\t\tpt._prev._next = pt._next;\n\t\t\t\t} else if (this._firstPT === pt) {\n\t\t\t\t\tthis._firstPT = pt._next;\n\t\t\t\t\tremove = true; //just to prevent resetting this._firstPT 5 lines down in case pt._next is null. (optimized for speed)\n\t\t\t\t}\n\t\t\t\tif (prev) {\n\t\t\t\t\tprev._next = pt;\n\t\t\t\t} else if (!remove && this._firstPT === null) {\n\t\t\t\t\tthis._firstPT = pt;\n\t\t\t\t}\n\t\t\t\tpt._next = next;\n\t\t\t\tpt._prev = prev;\n\t\t\t}\n\t\t\treturn pt;\n\t\t};\n\n\t\tp._mod = function(lookup) {\n\t\t\tvar pt = this._firstPT;\n\t\t\twhile (pt) {\n\t\t\t\tif (typeof(lookup[pt.p]) === \"function\") { //only gets called by RoundPropsPlugin (ModifyPlugin manages all the rendering internally for CSSPlugin properties that need modification). Remember, we handle rounding a bit differently in this plugin for performance reasons, leveraging \"r\" as an indicator that the value should be rounded internally.\n\t\t\t\t\tpt.r = lookup[pt.p];\n\t\t\t\t}\n\t\t\t\tpt = pt._next;\n\t\t\t}\n\t\t};\n\n\t\t//we need to make sure that if alpha or autoAlpha is killed, opacity is too. And autoAlpha affects the \"visibility\" property.\n\t\tp._kill = function(lookup) {\n\t\t\tvar copy = lookup,\n\t\t\t\tpt, p, xfirst;\n\t\t\tif (lookup.autoAlpha || lookup.alpha) {\n\t\t\t\tcopy = {};\n\t\t\t\tfor (p in lookup) { //copy the lookup so that we're not changing the original which may be passed elsewhere.\n\t\t\t\t\tcopy[p] = lookup[p];\n\t\t\t\t}\n\t\t\t\tcopy.opacity = 1;\n\t\t\t\tif (copy.autoAlpha) {\n\t\t\t\t\tcopy.visibility = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (lookup.className && (pt = this._classNamePT)) { //for className tweens, we need to kill any associated CSSPropTweens too; a linked list starts at the className's \"xfirst\".\n\t\t\t\txfirst = pt.xfirst;\n\t\t\t\tif (xfirst && xfirst._prev) {\n\t\t\t\t\tthis._linkCSSP(xfirst._prev, pt._next, xfirst._prev._prev); //break off the prev\n\t\t\t\t} else if (xfirst === this._firstPT) {\n\t\t\t\t\tthis._firstPT = pt._next;\n\t\t\t\t}\n\t\t\t\tif (pt._next) {\n\t\t\t\t\tthis._linkCSSP(pt._next, pt._next._next, xfirst._prev);\n\t\t\t\t}\n\t\t\t\tthis._classNamePT = null;\n\t\t\t}\n\t\t\tpt = this._firstPT;\n\t\t\twhile (pt) {\n\t\t\t\tif (pt.plugin && pt.plugin !== p && pt.plugin._kill) { //for plugins that are registered with CSSPlugin, we should notify them of the kill.\n\t\t\t\t\tpt.plugin._kill(lookup);\n\t\t\t\t\tp = pt.plugin;\n\t\t\t\t}\n\t\t\t\tpt = pt._next;\n\t\t\t}\n\t\t\treturn _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"TweenPlugin\"].prototype._kill.call(this, copy);\n\t\t};\n\n\n\n\t\t//used by cascadeTo() for gathering all the style properties of each child element into an array for comparison.\n\t\tvar _getChildStyles = function(e, props, targets) {\n\t\t\t\tvar children, i, child, type;\n\t\t\t\tif (e.slice) {\n\t\t\t\t\ti = e.length;\n\t\t\t\t\twhile (--i > -1) {\n\t\t\t\t\t\t_getChildStyles(e[i], props, targets);\n\t\t\t\t\t}\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tchildren = e.childNodes;\n\t\t\t\ti = children.length;\n\t\t\t\twhile (--i > -1) {\n\t\t\t\t\tchild = children[i];\n\t\t\t\t\ttype = child.type;\n\t\t\t\t\tif (child.style) {\n\t\t\t\t\t\tprops.push(_getAllStyles(child));\n\t\t\t\t\t\tif (targets) {\n\t\t\t\t\t\t\ttargets.push(child);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif ((type === 1 || type === 9 || type === 11) && child.childNodes.length) {\n\t\t\t\t\t\t_getChildStyles(child, props, targets);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\n\t\t/**\n\t\t * Typically only useful for className tweens that may affect child elements, this method creates a TweenLite\n\t\t * and then compares the style properties of all the target's child elements at the tween's start and end, and\n\t\t * if any are different, it also creates tweens for those and returns an array containing ALL of the resulting\n\t\t * tweens (so that you can easily add() them to a TimelineLite, for example). The reason this functionality is\n\t\t * wrapped into a separate static method of CSSPlugin instead of being integrated into all regular className tweens\n\t\t * is because it creates entirely new tweens that may have completely different targets than the original tween,\n\t\t * so if they were all lumped into the original tween instance, it would be inconsistent with the rest of the API\n\t\t * and it would create other problems. For example:\n\t\t *  - If I create a tween of elementA, that tween instance may suddenly change its target to include 50 other elements (unintuitive if I specifically defined the target I wanted)\n\t\t *  - We can't just create new independent tweens because otherwise, what happens if the original/parent tween is reversed or pause or dropped into a TimelineLite for tight control? You'd expect that tween's behavior to affect all the others.\n\t\t *  - Analyzing every style property of every child before and after the tween is an expensive operation when there are many children, so this behavior shouldn't be imposed on all className tweens by default, especially since it's probably rare that this extra functionality is needed.\n\t\t *\n\t\t * @param {Object} target object to be tweened\n\t\t * @param {number} Duration in seconds (or frames for frames-based tweens)\n\t\t * @param {Object} Object containing the end values, like {className:\"newClass\", ease:Linear.easeNone}\n\t\t * @return {Array} An array of TweenLite instances\n\t\t */\n\t\tCSSPlugin.cascadeTo = function(target, duration, vars) {\n\t\t\tvar tween = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].to(target, duration, vars),\n\t\t\t\tresults = [tween],\n\t\t\t\tb = [],\n\t\t\t\te = [],\n\t\t\t\ttargets = [],\n\t\t\t\t_reservedProps = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]._internals.reservedProps,\n\t\t\t\ti, difs, p, from;\n\t\t\ttarget = tween._targets || tween.target;\n\t\t\t_getChildStyles(target, b, targets);\n\t\t\ttween.render(duration, true, true);\n\t\t\t_getChildStyles(target, e);\n\t\t\ttween.render(0, true, true);\n\t\t\ttween._enabled(true);\n\t\t\ti = targets.length;\n\t\t\twhile (--i > -1) {\n\t\t\t\tdifs = _cssDif(targets[i], b[i], e[i]);\n\t\t\t\tif (difs.firstMPT) {\n\t\t\t\t\tdifs = difs.difs;\n\t\t\t\t\tfor (p in vars) {\n\t\t\t\t\t\tif (_reservedProps[p]) {\n\t\t\t\t\t\t\tdifs[p] = vars[p];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tfrom = {};\n\t\t\t\t\tfor (p in difs) {\n\t\t\t\t\t\tfrom[p] = b[i][p];\n\t\t\t\t\t}\n\t\t\t\t\tresults.push(_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].fromTo(targets[i], duration, from, difs));\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn results;\n\t\t};\n\n\t\t_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"TweenPlugin\"].activate([CSSPlugin]);\n\t\treturn CSSPlugin;\n\n\t}, true);\n\nvar CSSPlugin = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"globals\"].CSSPlugin;\n\n\n//# sourceURL=webpack:///./node_modules/gsap/CSSPlugin.js?");

/***/ }),

/***/ "./node_modules/gsap/DirectionalRotationPlugin.js":
/*!********************************************************!*\
  !*** ./node_modules/gsap/DirectionalRotationPlugin.js ***!
  \********************************************************/
/*! exports provided: DirectionalRotationPlugin, default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DirectionalRotationPlugin\", function() { return DirectionalRotationPlugin; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"default\", function() { return DirectionalRotationPlugin; });\n/* harmony import */ var _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./TweenLite.js */ \"./node_modules/gsap/TweenLite.js\");\n/*!\n * VERSION: 0.3.1\n * DATE: 2018-08-27\n * UPDATES AND DOCS AT: http://greensock.com\n *\n * @license Copyright (c) 2008-2019, GreenSock. All rights reserved.\n * This work is subject to the terms at http://greensock.com/standard-license or for\n * Club GreenSock members, the software agreement that was issued with your membership.\n * \n * @author: Jack Doyle, jack@greensock.com\n **/\n/* eslint-disable */\n\n\n\nvar DirectionalRotationPlugin = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"_gsScope\"]._gsDefine.plugin({\n\t\tpropName: \"directionalRotation\",\n\t\tversion: \"0.3.1\",\n\t\tAPI: 2,\n\n\t\t//called when the tween renders for the first time. This is where initial values should be recorded and any setup routines should run.\n\t\tinit: function(target, value, tween, index) {\n\t\t\tif (typeof(value) !== \"object\") {\n\t\t\t\tvalue = {rotation:value};\n\t\t\t}\n\t\t\tthis.finals = {};\n\t\t\tvar cap = (value.useRadians === true) ? Math.PI * 2 : 360,\n\t\t\t\tmin = 0.000001,\n\t\t\t\tp, v, start, end, dif, split;\n\t\t\tfor (p in value) {\n\t\t\t\tif (p !== \"useRadians\") {\n\t\t\t\t\tend = value[p];\n\t\t\t\t\tif (typeof(end) === \"function\") {\n\t\t\t\t\t\tend = end(index, target);\n\t\t\t\t\t}\n\t\t\t\t\tsplit = (end + \"\").split(\"_\");\n\t\t\t\t\tv = split[0];\n\t\t\t\t\tstart = parseFloat( (typeof(target[p]) !== \"function\") ? target[p] : target[ ((p.indexOf(\"set\") || typeof(target[\"get\" + p.substr(3)]) !== \"function\") ? p : \"get\" + p.substr(3)) ]() );\n\t\t\t\t\tend = this.finals[p] = (typeof(v) === \"string\" && v.charAt(1) === \"=\") ? start + parseInt(v.charAt(0) + \"1\", 10) * Number(v.substr(2)) : Number(v) || 0;\n\t\t\t\t\tdif = end - start;\n\t\t\t\t\tif (split.length) {\n\t\t\t\t\t\tv = split.join(\"_\");\n\t\t\t\t\t\tif (v.indexOf(\"short\") !== -1) {\n\t\t\t\t\t\t\tdif = dif % cap;\n\t\t\t\t\t\t\tif (dif !== dif % (cap / 2)) {\n\t\t\t\t\t\t\t\tdif = (dif < 0) ? dif + cap : dif - cap;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (v.indexOf(\"_cw\") !== -1 && dif < 0) {\n\t\t\t\t\t\t\tdif = ((dif + cap * 9999999999) % cap) - ((dif / cap) | 0) * cap;\n\t\t\t\t\t\t} else if (v.indexOf(\"ccw\") !== -1 && dif > 0) {\n\t\t\t\t\t\t\tdif = ((dif - cap * 9999999999) % cap) - ((dif / cap) | 0) * cap;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (dif > min || dif < -min) {\n\t\t\t\t\t\tthis._addTween(target, p, start, start + dif, p);\n\t\t\t\t\t\tthis._overwriteProps.push(p);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn true;\n\t\t},\n\n\t\t//called each time the values should be updated, and the ratio gets passed as the only parameter (typically it's a value between 0 and 1, but it can exceed those when using an ease like Elastic.easeOut or Back.easeOut, etc.)\n\t\tset: function(ratio) {\n\t\t\tvar pt;\n\t\t\tif (ratio !== 1) {\n\t\t\t\tthis._super.setRatio.call(this, ratio);\n\t\t\t} else {\n\t\t\t\tpt = this._firstPT;\n\t\t\t\twhile (pt) {\n\t\t\t\t\tif (pt.f) {\n\t\t\t\t\t\tpt.t[pt.p](this.finals[pt.p]);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tpt.t[pt.p] = this.finals[pt.p];\n\t\t\t\t\t}\n\t\t\t\t\tpt = pt._next;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t});\n\nDirectionalRotationPlugin._autoCSS = true;\n\n\n\n//# sourceURL=webpack:///./node_modules/gsap/DirectionalRotationPlugin.js?");

/***/ }),

/***/ "./node_modules/gsap/EasePack.js":
/*!***************************************!*\
  !*** ./node_modules/gsap/EasePack.js ***!
  \***************************************/
/*! exports provided: Back, Elastic, Bounce, RoughEase, SlowMo, SteppedEase, Circ, Expo, Sine, ExpoScaleEase, Linear, Power0, Power1, Power2, Power3, Power4 */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Back\", function() { return Back; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Elastic\", function() { return Elastic; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Bounce\", function() { return Bounce; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"RoughEase\", function() { return RoughEase; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SlowMo\", function() { return SlowMo; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SteppedEase\", function() { return SteppedEase; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Circ\", function() { return Circ; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Expo\", function() { return Expo; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Sine\", function() { return Sine; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ExpoScaleEase\", function() { return ExpoScaleEase; });\n/* harmony import */ var _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./TweenLite.js */ \"./node_modules/gsap/TweenLite.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Linear\", function() { return _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Linear\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Power0\", function() { return _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Power0\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Power1\", function() { return _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Power1\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Power2\", function() { return _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Power2\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Power3\", function() { return _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Power3\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Power4\", function() { return _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Power4\"]; });\n\n/*!\n * VERSION: 1.16.1\n * DATE: 2018-08-27\n * UPDATES AND DOCS AT: http://greensock.com\n *\n * @license Copyright (c) 2008-2019, GreenSock. All rights reserved.\n * This work is subject to the terms at http://greensock.com/standard-license or for\n * Club GreenSock members, the software agreement that was issued with your membership.\n * \n * @author: Jack Doyle, jack@greensock.com\n **/\n/* eslint-disable */\n\n\n\n_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"_gsScope\"]._gsDefine(\"easing.Back\", [\"easing.Ease\"], function() {\n\t\t\n\t\tvar w = (_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"_gsScope\"].GreenSockGlobals || _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"_gsScope\"]),\n\t\t\tgs = w.com.greensock,\n\t\t\t_2PI = Math.PI * 2,\n\t\t\t_HALF_PI = Math.PI / 2,\n\t\t\t_class = gs._class,\n\t\t\t_create = function(n, f) {\n\t\t\t\tvar C = _class(\"easing.\" + n, function(){}, true),\n\t\t\t\t\tp = C.prototype = new _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Ease\"]();\n\t\t\t\tp.constructor = C;\n\t\t\t\tp.getRatio = f;\n\t\t\t\treturn C;\n\t\t\t},\n\t\t\t_easeReg = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Ease\"].register || function(){}, //put an empty function in place just as a safety measure in case someone loads an OLD version of TweenLite.js where Ease.register doesn't exist.\n\t\t\t_wrap = function(name, EaseOut, EaseIn, EaseInOut, aliases) {\n\t\t\t\tvar C = _class(\"easing.\"+name, {\n\t\t\t\t\teaseOut:new EaseOut(),\n\t\t\t\t\teaseIn:new EaseIn(),\n\t\t\t\t\teaseInOut:new EaseInOut()\n\t\t\t\t}, true);\n\t\t\t\t_easeReg(C, name);\n\t\t\t\treturn C;\n\t\t\t},\n\t\t\tEasePoint = function(time, value, next) {\n\t\t\t\tthis.t = time;\n\t\t\t\tthis.v = value;\n\t\t\t\tif (next) {\n\t\t\t\t\tthis.next = next;\n\t\t\t\t\tnext.prev = this;\n\t\t\t\t\tthis.c = next.v - value;\n\t\t\t\t\tthis.gap = next.t - time;\n\t\t\t\t}\n\t\t\t},\n\n\t\t\t//Back\n\t\t\t_createBack = function(n, f) {\n\t\t\t\tvar C = _class(\"easing.\" + n, function(overshoot) {\n\t\t\t\t\t\tthis._p1 = (overshoot || overshoot === 0) ? overshoot : 1.70158;\n\t\t\t\t\t\tthis._p2 = this._p1 * 1.525;\n\t\t\t\t\t}, true), \n\t\t\t\t\tp = C.prototype = new _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Ease\"]();\n\t\t\t\tp.constructor = C;\n\t\t\t\tp.getRatio = f;\n\t\t\t\tp.config = function(overshoot) {\n\t\t\t\t\treturn new C(overshoot);\n\t\t\t\t};\n\t\t\t\treturn C;\n\t\t\t},\n\n\t\t\tBack = _wrap(\"Back\",\n\t\t\t\t_createBack(\"BackOut\", function(p) {\n\t\t\t\t\treturn ((p = p - 1) * p * ((this._p1 + 1) * p + this._p1) + 1);\n\t\t\t\t}),\n\t\t\t\t_createBack(\"BackIn\", function(p) {\n\t\t\t\t\treturn p * p * ((this._p1 + 1) * p - this._p1);\n\t\t\t\t}),\n\t\t\t\t_createBack(\"BackInOut\", function(p) {\n\t\t\t\t\treturn ((p *= 2) < 1) ? 0.5 * p * p * ((this._p2 + 1) * p - this._p2) : 0.5 * ((p -= 2) * p * ((this._p2 + 1) * p + this._p2) + 2);\n\t\t\t\t})\n\t\t\t),\n\n\n\t\t\t//SlowMo\n\t\t\tSlowMo = _class(\"easing.SlowMo\", function(linearRatio, power, yoyoMode) {\n\t\t\t\tpower = (power || power === 0) ? power : 0.7;\n\t\t\t\tif (linearRatio == null) {\n\t\t\t\t\tlinearRatio = 0.7;\n\t\t\t\t} else if (linearRatio > 1) {\n\t\t\t\t\tlinearRatio = 1;\n\t\t\t\t}\n\t\t\t\tthis._p = (linearRatio !== 1) ? power : 0;\n\t\t\t\tthis._p1 = (1 - linearRatio) / 2;\n\t\t\t\tthis._p2 = linearRatio;\n\t\t\t\tthis._p3 = this._p1 + this._p2;\n\t\t\t\tthis._calcEnd = (yoyoMode === true);\n\t\t\t}, true),\n\t\t\tp = SlowMo.prototype = new _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Ease\"](),\n\t\t\tSteppedEase, ExpoScaleEase, RoughEase, _createElastic;\n\t\t\t\n\t\tp.constructor = SlowMo;\n\t\tp.getRatio = function(p) {\n\t\t\tvar r = p + (0.5 - p) * this._p;\n\t\t\tif (p < this._p1) {\n\t\t\t\treturn this._calcEnd ? 1 - ((p = 1 - (p / this._p1)) * p) : r - ((p = 1 - (p / this._p1)) * p * p * p * r);\n\t\t\t} else if (p > this._p3) {\n\t\t\t\treturn this._calcEnd ? (p === 1 ? 0 : 1 - (p = (p - this._p3) / this._p1) * p) : r + ((p - r) * (p = (p - this._p3) / this._p1) * p * p * p); //added p === 1 ? 0 to avoid floating point rounding errors from affecting the final value, like 1 - 0.7 = 0.30000000000000004 instead of 0.3\n\t\t\t}\n\t\t\treturn this._calcEnd ? 1 : r;\n\t\t};\n\t\tSlowMo.ease = new SlowMo(0.7, 0.7);\n\t\t\n\t\tp.config = SlowMo.config = function(linearRatio, power, yoyoMode) {\n\t\t\treturn new SlowMo(linearRatio, power, yoyoMode);\n\t\t};\n\n\n\t\t//SteppedEase\n\t\tSteppedEase = _class(\"easing.SteppedEase\", function(steps, immediateStart) {\n\t\t\t\tsteps = steps || 1;\n\t\t\t\tthis._p1 = 1 / steps;\n\t\t\t\tthis._p2 = steps + (immediateStart ? 0 : 1);\n\t\t\t\tthis._p3 = immediateStart ? 1 : 0;\n\t\t\t}, true);\n\t\tp = SteppedEase.prototype = new _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Ease\"]();\t\n\t\tp.constructor = SteppedEase;\n\t\tp.getRatio = function(p) {\n\t\t\tif (p < 0) {\n\t\t\t\tp = 0;\n\t\t\t} else if (p >= 1) {\n\t\t\t\tp = 0.999999999;\n\t\t\t}\n\t\t\treturn (((this._p2 * p) | 0) + this._p3) * this._p1;\n\t\t};\n\t\tp.config = SteppedEase.config = function(steps, immediateStart) {\n\t\t\treturn new SteppedEase(steps, immediateStart);\n\t\t};\n\n\n\t\t//ExpoScaleEase\n\t\tExpoScaleEase = _class(\"easing.ExpoScaleEase\", function(start, end, ease) {\n\t\t\tthis._p1 = Math.log(end / start);\n\t\t\tthis._p2 = end - start;\n\t\t\tthis._p3 = start;\n\t\t\tthis._ease = ease;\n\t\t}, true);\n\t\tp = ExpoScaleEase.prototype = new _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Ease\"]();\n\t\tp.constructor = ExpoScaleEase;\n\t\tp.getRatio = function(p) {\n\t\t\tif (this._ease) {\n\t\t\t\tp = this._ease.getRatio(p);\n\t\t\t}\n\t\t\treturn (this._p3 * Math.exp(this._p1 * p) - this._p3) / this._p2;\n\t\t};\n\t\tp.config = ExpoScaleEase.config = function(start, end, ease) {\n\t\t\treturn new ExpoScaleEase(start, end, ease);\n\t\t};\n\n\n\t\t//RoughEase\n\t\tRoughEase = _class(\"easing.RoughEase\", function(vars) {\n\t\t\tvars = vars || {};\n\t\t\tvar taper = vars.taper || \"none\",\n\t\t\t\ta = [],\n\t\t\t\tcnt = 0,\n\t\t\t\tpoints = (vars.points || 20) | 0,\n\t\t\t\ti = points,\n\t\t\t\trandomize = (vars.randomize !== false),\n\t\t\t\tclamp = (vars.clamp === true),\n\t\t\t\ttemplate = (vars.template instanceof _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Ease\"]) ? vars.template : null,\n\t\t\t\tstrength = (typeof(vars.strength) === \"number\") ? vars.strength * 0.4 : 0.4,\n\t\t\t\tx, y, bump, invX, obj, pnt;\n\t\t\twhile (--i > -1) {\n\t\t\t\tx = randomize ? Math.random() : (1 / points) * i;\n\t\t\t\ty = template ? template.getRatio(x) : x;\n\t\t\t\tif (taper === \"none\") {\n\t\t\t\t\tbump = strength;\n\t\t\t\t} else if (taper === \"out\") {\n\t\t\t\t\tinvX = 1 - x;\n\t\t\t\t\tbump = invX * invX * strength;\n\t\t\t\t} else if (taper === \"in\") {\n\t\t\t\t\tbump = x * x * strength;\n\t\t\t\t} else if (x < 0.5) {  //\"both\" (start)\n\t\t\t\t\tinvX = x * 2;\n\t\t\t\t\tbump = invX * invX * 0.5 * strength;\n\t\t\t\t} else {\t\t\t\t//\"both\" (end)\n\t\t\t\t\tinvX = (1 - x) * 2;\n\t\t\t\t\tbump = invX * invX * 0.5 * strength;\n\t\t\t\t}\n\t\t\t\tif (randomize) {\n\t\t\t\t\ty += (Math.random() * bump) - (bump * 0.5);\n\t\t\t\t} else if (i % 2) {\n\t\t\t\t\ty += bump * 0.5;\n\t\t\t\t} else {\n\t\t\t\t\ty -= bump * 0.5;\n\t\t\t\t}\n\t\t\t\tif (clamp) {\n\t\t\t\t\tif (y > 1) {\n\t\t\t\t\t\ty = 1;\n\t\t\t\t\t} else if (y < 0) {\n\t\t\t\t\t\ty = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ta[cnt++] = {x:x, y:y};\n\t\t\t}\n\t\t\ta.sort(function(a, b) {\n\t\t\t\treturn a.x - b.x;\n\t\t\t});\n\n\t\t\tpnt = new EasePoint(1, 1, null);\n\t\t\ti = points;\n\t\t\twhile (--i > -1) {\n\t\t\t\tobj = a[i];\n\t\t\t\tpnt = new EasePoint(obj.x, obj.y, pnt);\n\t\t\t}\n\n\t\t\tthis._prev = new EasePoint(0, 0, (pnt.t !== 0) ? pnt : pnt.next);\n\t\t}, true);\n\t\tp = RoughEase.prototype = new _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Ease\"]();\n\t\tp.constructor = RoughEase;\n\t\tp.getRatio = function(p) {\n\t\t\tvar pnt = this._prev;\n\t\t\tif (p > pnt.t) {\n\t\t\t\twhile (pnt.next && p >= pnt.t) {\n\t\t\t\t\tpnt = pnt.next;\n\t\t\t\t}\n\t\t\t\tpnt = pnt.prev;\n\t\t\t} else {\n\t\t\t\twhile (pnt.prev && p <= pnt.t) {\n\t\t\t\t\tpnt = pnt.prev;\n\t\t\t\t}\n\t\t\t}\n\t\t\tthis._prev = pnt;\n\t\t\treturn (pnt.v + ((p - pnt.t) / pnt.gap) * pnt.c);\n\t\t};\n\t\tp.config = function(vars) {\n\t\t\treturn new RoughEase(vars);\n\t\t};\n\t\tRoughEase.ease = new RoughEase();\n\n\n\t\t//Bounce\n\t\t_wrap(\"Bounce\",\n\t\t\t_create(\"BounceOut\", function(p) {\n\t\t\t\tif (p < 1 / 2.75) {\n\t\t\t\t\treturn 7.5625 * p * p;\n\t\t\t\t} else if (p < 2 / 2.75) {\n\t\t\t\t\treturn 7.5625 * (p -= 1.5 / 2.75) * p + 0.75;\n\t\t\t\t} else if (p < 2.5 / 2.75) {\n\t\t\t\t\treturn 7.5625 * (p -= 2.25 / 2.75) * p + 0.9375;\n\t\t\t\t}\n\t\t\t\treturn 7.5625 * (p -= 2.625 / 2.75) * p + 0.984375;\n\t\t\t}),\n\t\t\t_create(\"BounceIn\", function(p) {\n\t\t\t\tif ((p = 1 - p) < 1 / 2.75) {\n\t\t\t\t\treturn 1 - (7.5625 * p * p);\n\t\t\t\t} else if (p < 2 / 2.75) {\n\t\t\t\t\treturn 1 - (7.5625 * (p -= 1.5 / 2.75) * p + 0.75);\n\t\t\t\t} else if (p < 2.5 / 2.75) {\n\t\t\t\t\treturn 1 - (7.5625 * (p -= 2.25 / 2.75) * p + 0.9375);\n\t\t\t\t}\n\t\t\t\treturn 1 - (7.5625 * (p -= 2.625 / 2.75) * p + 0.984375);\n\t\t\t}),\n\t\t\t_create(\"BounceInOut\", function(p) {\n\t\t\t\tvar invert = (p < 0.5);\n\t\t\t\tif (invert) {\n\t\t\t\t\tp = 1 - (p * 2);\n\t\t\t\t} else {\n\t\t\t\t\tp = (p * 2) - 1;\n\t\t\t\t}\n\t\t\t\tif (p < 1 / 2.75) {\n\t\t\t\t\tp = 7.5625 * p * p;\n\t\t\t\t} else if (p < 2 / 2.75) {\n\t\t\t\t\tp = 7.5625 * (p -= 1.5 / 2.75) * p + 0.75;\n\t\t\t\t} else if (p < 2.5 / 2.75) {\n\t\t\t\t\tp = 7.5625 * (p -= 2.25 / 2.75) * p + 0.9375;\n\t\t\t\t} else {\n\t\t\t\t\tp = 7.5625 * (p -= 2.625 / 2.75) * p + 0.984375;\n\t\t\t\t}\n\t\t\t\treturn invert ? (1 - p) * 0.5 : p * 0.5 + 0.5;\n\t\t\t})\n\t\t);\n\n\n\t\t//CIRC\n\t\t_wrap(\"Circ\",\n\t\t\t_create(\"CircOut\", function(p) {\n\t\t\t\treturn Math.sqrt(1 - (p = p - 1) * p);\n\t\t\t}),\n\t\t\t_create(\"CircIn\", function(p) {\n\t\t\t\treturn -(Math.sqrt(1 - (p * p)) - 1);\n\t\t\t}),\n\t\t\t_create(\"CircInOut\", function(p) {\n\t\t\t\treturn ((p*=2) < 1) ? -0.5 * (Math.sqrt(1 - p * p) - 1) : 0.5 * (Math.sqrt(1 - (p -= 2) * p) + 1);\n\t\t\t})\n\t\t);\n\n\n\t\t//Elastic\n\t\t_createElastic = function(n, f, def) {\n\t\t\tvar C = _class(\"easing.\" + n, function(amplitude, period) {\n\t\t\t\t\tthis._p1 = (amplitude >= 1) ? amplitude : 1; //note: if amplitude is < 1, we simply adjust the period for a more natural feel. Otherwise the math doesn't work right and the curve starts at 1.\n\t\t\t\t\tthis._p2 = (period || def) / (amplitude < 1 ? amplitude : 1);\n\t\t\t\t\tthis._p3 = this._p2 / _2PI * (Math.asin(1 / this._p1) || 0);\n\t\t\t\t\tthis._p2 = _2PI / this._p2; //precalculate to optimize\n\t\t\t\t}, true),\n\t\t\t\tp = C.prototype = new _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Ease\"]();\n\t\t\tp.constructor = C;\n\t\t\tp.getRatio = f;\n\t\t\tp.config = function(amplitude, period) {\n\t\t\t\treturn new C(amplitude, period);\n\t\t\t};\n\t\t\treturn C;\n\t\t};\n\t\t_wrap(\"Elastic\",\n\t\t\t_createElastic(\"ElasticOut\", function(p) {\n\t\t\t\treturn this._p1 * Math.pow(2, -10 * p) * Math.sin( (p - this._p3) * this._p2 ) + 1;\n\t\t\t}, 0.3),\n\t\t\t_createElastic(\"ElasticIn\", function(p) {\n\t\t\t\treturn -(this._p1 * Math.pow(2, 10 * (p -= 1)) * Math.sin( (p - this._p3) * this._p2 ));\n\t\t\t}, 0.3),\n\t\t\t_createElastic(\"ElasticInOut\", function(p) {\n\t\t\t\treturn ((p *= 2) < 1) ? -0.5 * (this._p1 * Math.pow(2, 10 * (p -= 1)) * Math.sin( (p - this._p3) * this._p2)) : this._p1 * Math.pow(2, -10 *(p -= 1)) * Math.sin( (p - this._p3) * this._p2 ) * 0.5 + 1;\n\t\t\t}, 0.45)\n\t\t);\n\n\n\t\t//Expo\n\t\t_wrap(\"Expo\",\n\t\t\t_create(\"ExpoOut\", function(p) {\n\t\t\t\treturn 1 - Math.pow(2, -10 * p);\n\t\t\t}),\n\t\t\t_create(\"ExpoIn\", function(p) {\n\t\t\t\treturn Math.pow(2, 10 * (p - 1)) - 0.001;\n\t\t\t}),\n\t\t\t_create(\"ExpoInOut\", function(p) {\n\t\t\t\treturn ((p *= 2) < 1) ? 0.5 * Math.pow(2, 10 * (p - 1)) : 0.5 * (2 - Math.pow(2, -10 * (p - 1)));\n\t\t\t})\n\t\t);\n\n\n\t\t//Sine\n\t\t_wrap(\"Sine\",\n\t\t\t_create(\"SineOut\", function(p) {\n\t\t\t\treturn Math.sin(p * _HALF_PI);\n\t\t\t}),\n\t\t\t_create(\"SineIn\", function(p) {\n\t\t\t\treturn -Math.cos(p * _HALF_PI) + 1;\n\t\t\t}),\n\t\t\t_create(\"SineInOut\", function(p) {\n\t\t\t\treturn -0.5 * (Math.cos(Math.PI * p) - 1);\n\t\t\t})\n\t\t);\n\n\t\t_class(\"easing.EaseLookup\", {\n\t\t\t\tfind:function(s) {\n\t\t\t\t\treturn _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Ease\"].map[s];\n\t\t\t\t}\n\t\t\t}, true);\n\n\t\t//register the non-standard eases\n\t\t_easeReg(w.SlowMo, \"SlowMo\", \"ease,\");\n\t\t_easeReg(RoughEase, \"RoughEase\", \"ease,\");\n\t\t_easeReg(SteppedEase, \"SteppedEase\", \"ease,\");\n\t\t\n\t\treturn Back;\n\t\t\n\t}, true);\n\nvar Back = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"globals\"].Back;\nvar Elastic = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"globals\"].Elastic;\nvar Bounce = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"globals\"].Bounce;\nvar RoughEase = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"globals\"].RoughEase;\nvar SlowMo = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"globals\"].SlowMo;\nvar SteppedEase = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"globals\"].SteppedEase;\nvar Circ = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"globals\"].Circ;\nvar Expo = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"globals\"].Expo;\nvar Sine = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"globals\"].Sine;\nvar ExpoScaleEase = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"globals\"].ExpoScaleEase;\n\n\n//# sourceURL=webpack:///./node_modules/gsap/EasePack.js?");

/***/ }),

/***/ "./node_modules/gsap/RoundPropsPlugin.js":
/*!***********************************************!*\
  !*** ./node_modules/gsap/RoundPropsPlugin.js ***!
  \***********************************************/
/*! exports provided: RoundPropsPlugin, _getRoundFunc, _roundLinkedList, p, default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"RoundPropsPlugin\", function() { return RoundPropsPlugin; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"_getRoundFunc\", function() { return _getRoundFunc; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"_roundLinkedList\", function() { return _roundLinkedList; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"p\", function() { return p; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"default\", function() { return RoundPropsPlugin; });\n/* harmony import */ var _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./TweenLite.js */ \"./node_modules/gsap/TweenLite.js\");\n/*!\n * VERSION: 1.6.0\n * DATE: 2018-08-27\n * UPDATES AND DOCS AT: http://greensock.com\n *\n * @license Copyright (c) 2008-2019, GreenSock. All rights reserved.\n * This work is subject to the terms at http://greensock.com/standard-license or for\n * Club GreenSock members, the software agreement that was issued with your membership.\n * \n * @author: Jack Doyle, jack@greensock.com\n **/\n/* eslint-disable */\n\n\n\nvar RoundPropsPlugin = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"_gsScope\"]._gsDefine.plugin({\n\t\t\t\tpropName: \"roundProps\",\n\t\t\t\tversion: \"1.7.0\",\n\t\t\t\tpriority: -1,\n\t\t\t\tAPI: 2,\n\n\t\t\t\t//called when the tween renders for the first time. This is where initial values should be recorded and any setup routines should run.\n\t\t\t\tinit: function(target, value, tween) {\n\t\t\t\t\tthis._tween = tween;\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\n\t\t\t}),\n\t\t\t_getRoundFunc = function(v) { //pass in 0.1 get a function that'll round to the nearest tenth, or 5 to round to the closest 5, or 0.001 to the closest 1000th, etc.\n\t\t\t\tvar p = v < 1 ? Math.pow(10, (v + \"\").length - 2) : 1; //to avoid floating point math errors (like 24 * 0.1 == 2.4000000000000004), we chop off at a specific number of decimal places (much faster than toFixed()\n\t\t\t\treturn function(n) {\n\t\t\t\t\treturn ((Math.round(n / v) * v * p) | 0) / p;\n\t\t\t\t};\n\t\t\t},\n\t\t\t_roundLinkedList = function(node, mod) {\n\t\t\t\twhile (node) {\n\t\t\t\t\tif (!node.f && !node.blob) {\n\t\t\t\t\t\tnode.m = mod || Math.round;\n\t\t\t\t\t}\n\t\t\t\t\tnode = node._next;\n\t\t\t\t}\n\t\t\t},\n\t\t\tp = RoundPropsPlugin.prototype;\n\n\t\tp._onInitAllProps = function() {\n\t\t\tvar tween = this._tween,\n\t\t\t\trp = tween.vars.roundProps,\n\t\t\t\tlookup = {},\n\t\t\t\trpt = tween._propLookup.roundProps,\n\t\t\t\tpt, next, i, p;\n\t\t\tif (typeof(rp) === \"object\" && !rp.push) {\n\t\t\t\tfor (p in rp) {\n\t\t\t\t\tlookup[p] = _getRoundFunc(rp[p]);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (typeof(rp) === \"string\") {\n\t\t\t\t\trp = rp.split(\",\");\n\t\t\t\t}\n\t\t\t\ti = rp.length;\n\t\t\t\twhile (--i > -1) {\n\t\t\t\t\tlookup[rp[i]] = Math.round;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tfor (p in lookup) {\n\t\t\t\tpt = tween._firstPT;\n\t\t\t\twhile (pt) {\n\t\t\t\t\tnext = pt._next; //record here, because it may get removed\n\t\t\t\t\tif (pt.pg) {\n\t\t\t\t\t\tpt.t._mod(lookup);\n\t\t\t\t\t} else if (pt.n === p) {\n\t\t\t\t\t\tif (pt.f === 2 && pt.t) { //a blob (text containing multiple numeric values)\n\t\t\t\t\t\t\t_roundLinkedList(pt.t._firstPT, lookup[p]);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tthis._add(pt.t, p, pt.s, pt.c, lookup[p]);\n\t\t\t\t\t\t\t//remove from linked list\n\t\t\t\t\t\t\tif (next) {\n\t\t\t\t\t\t\t\tnext._prev = pt._prev;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (pt._prev) {\n\t\t\t\t\t\t\t\tpt._prev._next = next;\n\t\t\t\t\t\t\t} else if (tween._firstPT === pt) {\n\t\t\t\t\t\t\t\ttween._firstPT = next;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tpt._next = pt._prev = null;\n\t\t\t\t\t\t\ttween._propLookup[p] = rpt;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tpt = next;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn false;\n\t\t};\n\n\t\tp._add = function(target, p, s, c, mod) {\n\t\t\tthis._addTween(target, p, s, s + c, p, mod || Math.round);\n\t\t\tthis._overwriteProps.push(p);\n\t\t};\n\n\n\n\n//# sourceURL=webpack:///./node_modules/gsap/RoundPropsPlugin.js?");

/***/ }),

/***/ "./node_modules/gsap/TimelineLite.js":
/*!*******************************************!*\
  !*** ./node_modules/gsap/TimelineLite.js ***!
  \*******************************************/
/*! exports provided: TimelineLite, default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TimelineLite\", function() { return TimelineLite; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"default\", function() { return TimelineLite; });\n/* harmony import */ var _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./TweenLite.js */ \"./node_modules/gsap/TweenLite.js\");\n/*!\n * VERSION: 2.1.3\n * DATE: 2019-05-17\n * UPDATES AND DOCS AT: http://greensock.com\n *\n * @license Copyright (c) 2008-2019, GreenSock. All rights reserved.\n * This work is subject to the terms at http://greensock.com/standard-license or for\n * Club GreenSock members, the software agreement that was issued with your membership.\n * \n * @author: Jack Doyle, jack@greensock.com\n */\n/* eslint-disable */\n\n\n\n_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"_gsScope\"]._gsDefine(\"TimelineLite\", [\"core.Animation\",\"core.SimpleTimeline\",\"TweenLite\"], function() {\n\n\t\tvar TimelineLite = function(vars) {\n\t\t\t\t_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"SimpleTimeline\"].call(this, vars);\n\t\t\t\tvar self = this,\n\t\t\t\t\tv = self.vars,\n\t\t\t\t\tval, p;\n\t\t\t\tself._labels = {};\n\t\t\t\tself.autoRemoveChildren = !!v.autoRemoveChildren;\n\t\t\t\tself.smoothChildTiming = !!v.smoothChildTiming;\n\t\t\t\tself._sortChildren = true;\n\t\t\t\tself._onUpdate = v.onUpdate;\n\t\t\t\tfor (p in v) {\n\t\t\t\t\tval = v[p];\n\t\t\t\t\tif (_isArray(val)) if (val.join(\"\").indexOf(\"{self}\") !== -1) {\n\t\t\t\t\t\tv[p] = self._swapSelfInParams(val);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (_isArray(v.tweens)) {\n\t\t\t\t\tself.add(v.tweens, 0, v.align, v.stagger);\n\t\t\t\t}\n\t\t\t},\n\t\t\t_tinyNum = 0.00000001,\n\t\t\tTweenLiteInternals = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]._internals,\n\t\t\t_internals = TimelineLite._internals = {},\n\t\t\t_isSelector = TweenLiteInternals.isSelector,\n\t\t\t_isArray = TweenLiteInternals.isArray,\n\t\t\t_lazyTweens = TweenLiteInternals.lazyTweens,\n\t\t\t_lazyRender = TweenLiteInternals.lazyRender,\n\t\t\t_globals = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"_gsScope\"]._gsDefine.globals,\n\t\t\t_copy = function(vars) {\n\t\t\t\tvar copy = {}, p;\n\t\t\t\tfor (p in vars) {\n\t\t\t\t\tcopy[p] = vars[p];\n\t\t\t\t}\n\t\t\t\treturn copy;\n\t\t\t},\n\t\t\t_applyCycle = function(vars, targets, i) {\n\t\t\t\tvar alt = vars.cycle,\n\t\t\t\t\tp, val;\n\t\t\t\tfor (p in alt) {\n\t\t\t\t\tval = alt[p];\n\t\t\t\t\tvars[p] = (typeof(val) === \"function\") ? val(i, targets[i], targets) : val[i % val.length];\n\t\t\t\t}\n\t\t\t\tdelete vars.cycle;\n\t\t\t},\n\t\t\t_pauseCallback = _internals.pauseCallback = function() {},\n\t\t\t_slice = function(a) { //don't use [].slice because that doesn't work in IE8 with a NodeList that's returned by querySelectorAll()\n\t\t\t\tvar b = [],\n\t\t\t\t\tl = a.length,\n\t\t\t\t\ti;\n\t\t\t\tfor (i = 0; i !== l; b.push(a[i++]));\n\t\t\t\treturn b;\n\t\t\t},\n\t\t\t_defaultImmediateRender = function(tl, toVars, fromVars, defaultFalse) { //default to immediateRender:true unless otherwise set in toVars, fromVars or if defaultFalse is passed in as true\n\t\t\t\tvar ir = \"immediateRender\";\n\t\t\t\tif (!(ir in toVars)) {\n\t\t\t\t\ttoVars[ir] = !((fromVars && fromVars[ir] === false) || defaultFalse);\n\t\t\t\t}\n\t\t\t\treturn toVars;\n\t\t\t},\n\t\t\t//for distributing values across an array. Can accept a number, a function or (most commonly) a function which can contain the following properties: {base, amount, from, ease, grid, axis, length, each}. Returns a function that expects the following parameters: index, target, array. Recognizes the following\n\t\t\t_distribute = function(v) {\n\t\t\t\tif (typeof(v) === \"function\") {\n\t\t\t\t\treturn v;\n\t\t\t\t}\n\t\t\t\tvar vars = (typeof(v) === \"object\") ? v : {each:v}, //n:1 is just to indicate v was a number; we leverage that later to set v according to the length we get. If a number is passed in, we treat it like the old stagger value where 0.1, for example, would mean that things would be distributed with 0.1 between each element in the array rather than a total \"amount\" that's chunked out among them all.\n\t\t\t\t\tease = vars.ease,\n\t\t\t\t\tfrom = vars.from || 0,\n\t\t\t\t\tbase = vars.base || 0,\n\t\t\t\t\tcache = {},\n\t\t\t\t\tisFromKeyword = isNaN(from),\n\t\t\t\t\taxis = vars.axis,\n\t\t\t\t\tratio = {center:0.5, end:1}[from] || 0;\n\t\t\t\treturn function(i, target, a) {\n\t\t\t\t\tvar l = (a || vars).length,\n\t\t\t\t\t\tdistances = cache[l],\n\t\t\t\t\t\toriginX, originY, x, y, d, j, max, min, wrap;\n\t\t\t\t\tif (!distances) {\n\t\t\t\t\t\twrap = (vars.grid === \"auto\") ? 0 : (vars.grid || [Infinity])[0];\n\t\t\t\t\t\tif (!wrap) {\n\t\t\t\t\t\t\tmax = -Infinity;\n\t\t\t\t\t\t\twhile (max < (max = a[wrap++].getBoundingClientRect().left) && wrap < l) { }\n\t\t\t\t\t\t\twrap--;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tdistances = cache[l] = [];\n\t\t\t\t\t\toriginX = isFromKeyword ? (Math.min(wrap, l) * ratio) - 0.5 : from % wrap;\n\t\t\t\t\t\toriginY = isFromKeyword ? l * ratio / wrap - 0.5 : (from / wrap) | 0;\n\t\t\t\t\t\tmax = 0;\n\t\t\t\t\t\tmin = Infinity;\n\t\t\t\t\t\tfor (j = 0; j < l; j++) {\n\t\t\t\t\t\t\tx = (j % wrap) - originX;\n\t\t\t\t\t\t\ty = originY - ((j / wrap) | 0);\n\t\t\t\t\t\t\tdistances[j] = d = !axis ? Math.sqrt(x * x + y * y) : Math.abs((axis === \"y\") ? y : x);\n\t\t\t\t\t\t\tif (d > max) {\n\t\t\t\t\t\t\t\tmax = d;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (d < min) {\n\t\t\t\t\t\t\t\tmin = d;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tdistances.max = max - min;\n\t\t\t\t\t\tdistances.min = min;\n\t\t\t\t\t\tdistances.v = l = vars.amount || (vars.each * (wrap > l ? l - 1 : !axis ? Math.max(wrap, l / wrap) : axis === \"y\" ? l / wrap : wrap)) || 0;\n\t\t\t\t\t\tdistances.b = (l < 0) ? base - l : base;\n\t\t\t\t\t}\n\t\t\t\t\tl = (distances[i] - distances.min) / distances.max;\n\t\t\t\t\treturn distances.b + (ease ? ease.getRatio(l) : l) * distances.v;\n\t\t\t\t};\n\t\t\t},\n\t\t\tp = TimelineLite.prototype = new _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"SimpleTimeline\"]();\n\n\t\tTimelineLite.version = \"2.1.3\";\n\t\tTimelineLite.distribute = _distribute;\n\t\tp.constructor = TimelineLite;\n\t\tp.kill()._gc = p._forcingPlayhead = p._hasPause = false;\n\n\t\t/* might use later...\n\t\t//translates a local time inside an animation to the corresponding time on the root/global timeline, factoring in all nesting and timeScales.\n\t\tfunction localToGlobal(time, animation) {\n\t\t\twhile (animation) {\n\t\t\t\ttime = (time / animation._timeScale) + animation._startTime;\n\t\t\t\tanimation = animation.timeline;\n\t\t\t}\n\t\t\treturn time;\n\t\t}\n\n\t\t//translates the supplied time on the root/global timeline into the corresponding local time inside a particular animation, factoring in all nesting and timeScales\n\t\tfunction globalToLocal(time, animation) {\n\t\t\tvar scale = 1;\n\t\t\ttime -= localToGlobal(0, animation);\n\t\t\twhile (animation) {\n\t\t\t\tscale *= animation._timeScale;\n\t\t\t\tanimation = animation.timeline;\n\t\t\t}\n\t\t\treturn time * scale;\n\t\t}\n\t\t*/\n\n\t\tp.to = function(target, duration, vars, position) {\n\t\t\tvar Engine = (vars.repeat && _globals.TweenMax) || _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"];\n\t\t\treturn duration ? this.add( new Engine(target, duration, vars), position) : this.set(target, vars, position);\n\t\t};\n\n\t\tp.from = function(target, duration, vars, position) {\n\t\t\treturn this.add( ((vars.repeat && _globals.TweenMax) || _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]).from(target, duration, _defaultImmediateRender(this, vars)), position);\n\t\t};\n\n\t\tp.fromTo = function(target, duration, fromVars, toVars, position) {\n\t\t\tvar Engine = (toVars.repeat && _globals.TweenMax) || _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"];\n\t\t\ttoVars = _defaultImmediateRender(this, toVars, fromVars);\n\t\t\treturn duration ? this.add( Engine.fromTo(target, duration, fromVars, toVars), position) : this.set(target, toVars, position);\n\t\t};\n\n\t\tp.staggerTo = function(targets, duration, vars, stagger, position, onCompleteAll, onCompleteAllParams, onCompleteAllScope) {\n\t\t\tvar tl = new TimelineLite({onComplete:onCompleteAll, onCompleteParams:onCompleteAllParams, callbackScope:onCompleteAllScope, smoothChildTiming:this.smoothChildTiming}),\n\t\t\t\tstaggerFunc = _distribute(vars.stagger || stagger),\n\t\t\t\tstartAt = vars.startAt,\n\t\t\t\tcycle = vars.cycle,\n\t\t\t\tcopy, i;\n\t\t\tif (typeof(targets) === \"string\") {\n\t\t\t\ttargets = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].selector(targets) || targets;\n\t\t\t}\n\t\t\ttargets = targets || [];\n\t\t\tif (_isSelector(targets)) { //if the targets object is a selector, translate it into an array.\n\t\t\t\ttargets = _slice(targets);\n\t\t\t}\n\t\t\tfor (i = 0; i < targets.length; i++) {\n\t\t\t\tcopy = _copy(vars);\n\t\t\t\tif (startAt) {\n\t\t\t\t\tcopy.startAt = _copy(startAt);\n\t\t\t\t\tif (startAt.cycle) {\n\t\t\t\t\t\t_applyCycle(copy.startAt, targets, i);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (cycle) {\n\t\t\t\t\t_applyCycle(copy, targets, i);\n\t\t\t\t\tif (copy.duration != null) {\n\t\t\t\t\t\tduration = copy.duration;\n\t\t\t\t\t\tdelete copy.duration;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ttl.to(targets[i], duration, copy, staggerFunc(i, targets[i], targets));\n\t\t\t}\n\t\t\treturn this.add(tl, position);\n\t\t};\n\n\t\tp.staggerFrom = function(targets, duration, vars, stagger, position, onCompleteAll, onCompleteAllParams, onCompleteAllScope) {\n\t\t\tvars.runBackwards = true;\n\t\t\treturn this.staggerTo(targets, duration, _defaultImmediateRender(this, vars), stagger, position, onCompleteAll, onCompleteAllParams, onCompleteAllScope);\n\t\t};\n\n\t\tp.staggerFromTo = function(targets, duration, fromVars, toVars, stagger, position, onCompleteAll, onCompleteAllParams, onCompleteAllScope) {\n\t\t\ttoVars.startAt = fromVars;\n\t\t\treturn this.staggerTo(targets, duration, _defaultImmediateRender(this, toVars, fromVars), stagger, position, onCompleteAll, onCompleteAllParams, onCompleteAllScope);\n\t\t};\n\n\t\tp.call = function(callback, params, scope, position) {\n\t\t\treturn this.add( _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].delayedCall(0, callback, params, scope), position);\n\t\t};\n\n\t\tp.set = function(target, vars, position) {\n\t\t\treturn this.add( new _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"](target, 0, _defaultImmediateRender(this, vars, null, true)), position);\n\t\t};\n\n\t\tTimelineLite.exportRoot = function(vars, ignoreDelayedCalls) {\n\t\t\tvars = vars || {};\n\t\t\tif (vars.smoothChildTiming == null) {\n\t\t\t\tvars.smoothChildTiming = true;\n\t\t\t}\n\t\t\tvar tl = new TimelineLite(vars),\n\t\t\t\troot = tl._timeline,\n\t\t\t\thasNegativeStart, time,\ttween, next;\n\t\t\tif (ignoreDelayedCalls == null) {\n\t\t\t\tignoreDelayedCalls = true;\n\t\t\t}\n\t\t\troot._remove(tl, true);\n\t\t\ttl._startTime = 0;\n\t\t\ttl._rawPrevTime = tl._time = tl._totalTime = root._time;\n\t\t\ttween = root._first;\n\t\t\twhile (tween) {\n\t\t\t\tnext = tween._next;\n\t\t\t\tif (!ignoreDelayedCalls || !(tween instanceof _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"] && tween.target === tween.vars.onComplete)) {\n\t\t\t\t\ttime = tween._startTime - tween._delay;\n\t\t\t\t\tif (time < 0) {\n\t\t\t\t\t\thasNegativeStart = 1;\n\t\t\t\t\t}\n\t\t\t\t\ttl.add(tween, time);\n\t\t\t\t}\n\t\t\t\ttween = next;\n\t\t\t}\n\t\t\troot.add(tl, 0);\n\t\t\tif (hasNegativeStart) { //calling totalDuration() will force the adjustment necessary to shift the children forward so none of them start before zero, and moves the timeline backwards the same amount, so the playhead is still aligned where it should be globally, but the timeline doesn't have illegal children that start before zero.\n\t\t\t\ttl.totalDuration();\n\t\t\t}\n\t\t\treturn tl;\n\t\t};\n\n\t\tp.add = function(value, position, align, stagger) {\n\t\t\tvar self = this,\n\t\t\t\tcurTime, l, i, child, tl, beforeRawTime;\n\t\t\tif (typeof(position) !== \"number\") {\n\t\t\t\tposition = self._parseTimeOrLabel(position, 0, true, value);\n\t\t\t}\n\t\t\tif (!(value instanceof _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Animation\"])) {\n\t\t\t\tif ((value instanceof Array) || (value && value.push && _isArray(value))) {\n\t\t\t\t\talign = align || \"normal\";\n\t\t\t\t\tstagger = stagger || 0;\n\t\t\t\t\tcurTime = position;\n\t\t\t\t\tl = value.length;\n\t\t\t\t\tfor (i = 0; i < l; i++) {\n\t\t\t\t\t\tif (_isArray(child = value[i])) {\n\t\t\t\t\t\t\tchild = new TimelineLite({tweens:child});\n\t\t\t\t\t\t}\n\t\t\t\t\t\tself.add(child, curTime);\n\t\t\t\t\t\tif (typeof(child) !== \"string\" && typeof(child) !== \"function\") {\n\t\t\t\t\t\t\tif (align === \"sequence\") {\n\t\t\t\t\t\t\t\tcurTime = child._startTime + (child.totalDuration() / child._timeScale);\n\t\t\t\t\t\t\t} else if (align === \"start\") {\n\t\t\t\t\t\t\t\tchild._startTime -= child.delay();\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcurTime += stagger;\n\t\t\t\t\t}\n\t\t\t\t\treturn self._uncache(true);\n\t\t\t\t} else if (typeof(value) === \"string\") {\n\t\t\t\t\treturn self.addLabel(value, position);\n\t\t\t\t} else if (typeof(value) === \"function\") {\n\t\t\t\t\tvalue = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].delayedCall(0, value);\n\t\t\t\t} else {\n\t\t\t\t\tthrow(\"Cannot add \" + value + \" into the timeline; it is not a tween, timeline, function, or string.\");\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"SimpleTimeline\"].prototype.add.call(self, value, position);\n\n\t\t\tif (value._time || (!value._duration && value._initted)) { //in case, for example, the _startTime is moved on a tween that has already rendered. Imagine it's at its end state, then the startTime is moved WAY later (after the end of this timeline), it should render at its beginning.\n\t\t\t\tcurTime = (self.rawTime() - value._startTime) * value._timeScale;\n\t\t\t\tif (!value._duration || Math.abs(Math.max(0, Math.min(value.totalDuration(), curTime))) - value._totalTime > 0.00001) {\n\t\t\t\t\tvalue.render(curTime, false, false);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t//if the timeline has already ended but the inserted tween/timeline extends the duration, we should enable this timeline again so that it renders properly. We should also align the playhead with the parent timeline's when appropriate.\n\t\t\tif (self._gc || self._time === self._duration) if (!self._paused) if (self._duration < self.duration()) {\n\t\t\t\t//in case any of the ancestors had completed but should now be enabled...\n\t\t\t\ttl = self;\n\t\t\t\tbeforeRawTime = (tl.rawTime() > value._startTime); //if the tween is placed on the timeline so that it starts BEFORE the current rawTime, we should align the playhead (move the timeline). This is because sometimes users will create a timeline, let it finish, and much later append a tween and expect it to run instead of jumping to its end state. While technically one could argue that it should jump to its end state, that's not what users intuitively expect.\n\t\t\t\twhile (tl._timeline) {\n\t\t\t\t\tif (beforeRawTime && tl._timeline.smoothChildTiming) {\n\t\t\t\t\t\ttl.totalTime(tl._totalTime, true); //moves the timeline (shifts its startTime) if necessary, and also enables it.\n\t\t\t\t\t} else if (tl._gc) {\n\t\t\t\t\t\ttl._enabled(true, false);\n\t\t\t\t\t}\n\t\t\t\t\ttl = tl._timeline;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn self;\n\t\t};\n\n\t\tp.remove = function(value) {\n\t\t\tif (value instanceof _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Animation\"]) {\n\t\t\t\tthis._remove(value, false);\n\t\t\t\tvar tl = value._timeline = value.vars.useFrames ? _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Animation\"]._rootFramesTimeline : _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Animation\"]._rootTimeline; //now that it's removed, default it to the root timeline so that if it gets played again, it doesn't jump back into this timeline.\n\t\t\t\tvalue._startTime = (value._paused ? value._pauseTime : tl._time) - ((!value._reversed ? value._totalTime : value.totalDuration() - value._totalTime) / value._timeScale); //ensure that if it gets played again, the timing is correct.\n\t\t\t\treturn this;\n\t\t\t} else if (value instanceof Array || (value && value.push && _isArray(value))) {\n\t\t\t\tvar i = value.length;\n\t\t\t\twhile (--i > -1) {\n\t\t\t\t\tthis.remove(value[i]);\n\t\t\t\t}\n\t\t\t\treturn this;\n\t\t\t} else if (typeof(value) === \"string\") {\n\t\t\t\treturn this.removeLabel(value);\n\t\t\t}\n\t\t\treturn this.kill(null, value);\n\t\t};\n\n\t\tp._remove = function(tween, skipDisable) {\n\t\t\t_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"SimpleTimeline\"].prototype._remove.call(this, tween, skipDisable);\n\t\t\tvar last = this._last;\n\t\t\tif (!last) {\n\t\t\t\tthis._time = this._totalTime = this._duration = this._totalDuration = 0;\n\t\t\t} else if (this._time > this.duration()) {\n\t\t\t\tthis._time = this._duration;\n\t\t\t\tthis._totalTime = this._totalDuration;\n\t\t\t}\n\t\t\treturn this;\n\t\t};\n\n\t\tp.append = function(value, offsetOrLabel) {\n\t\t\treturn this.add(value, this._parseTimeOrLabel(null, offsetOrLabel, true, value));\n\t\t};\n\n\t\tp.insert = p.insertMultiple = function(value, position, align, stagger) {\n\t\t\treturn this.add(value, position || 0, align, stagger);\n\t\t};\n\n\t\tp.appendMultiple = function(tweens, offsetOrLabel, align, stagger) {\n\t\t\treturn this.add(tweens, this._parseTimeOrLabel(null, offsetOrLabel, true, tweens), align, stagger);\n\t\t};\n\n\t\tp.addLabel = function(label, position) {\n\t\t\tthis._labels[label] = this._parseTimeOrLabel(position);\n\t\t\treturn this;\n\t\t};\n\n\t\tp.addPause = function(position, callback, params, scope) {\n\t\t\tvar t = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].delayedCall(0, _pauseCallback, params, scope || this);\n\t\t\tt.vars.onComplete = t.vars.onReverseComplete = callback;\n\t\t\tt.data = \"isPause\";\n\t\t\tthis._hasPause = true;\n\t\t\treturn this.add(t, position);\n\t\t};\n\n\t\tp.removeLabel = function(label) {\n\t\t\tdelete this._labels[label];\n\t\t\treturn this;\n\t\t};\n\n\t\tp.getLabelTime = function(label) {\n\t\t\treturn (this._labels[label] != null) ? this._labels[label] : -1;\n\t\t};\n\n\t\tp._parseTimeOrLabel = function(timeOrLabel, offsetOrLabel, appendIfAbsent, ignore) {\n\t\t\tvar clippedDuration, i;\n\t\t\t//if we're about to add a tween/timeline (or an array of them) that's already a child of this timeline, we should remove it first so that it doesn't contaminate the duration().\n\t\t\tif (ignore instanceof _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Animation\"] && ignore.timeline === this) {\n\t\t\t\tthis.remove(ignore);\n\t\t\t} else if (ignore && ((ignore instanceof Array) || (ignore.push && _isArray(ignore)))) {\n\t\t\t\ti = ignore.length;\n\t\t\t\twhile (--i > -1) {\n\t\t\t\t\tif (ignore[i] instanceof _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Animation\"] && ignore[i].timeline === this) {\n\t\t\t\t\t\tthis.remove(ignore[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tclippedDuration = (typeof(timeOrLabel) === \"number\" && !offsetOrLabel) ? 0 : (this.duration() > 99999999999) ? this.recent().endTime(false) : this._duration; //in case there's a child that infinitely repeats, users almost never intend for the insertion point of a new child to be based on a SUPER long value like that so we clip it and assume the most recently-added child's endTime should be used instead.\n\t\t\tif (typeof(offsetOrLabel) === \"string\") {\n\t\t\t\treturn this._parseTimeOrLabel(offsetOrLabel, (appendIfAbsent && typeof(timeOrLabel) === \"number\" && this._labels[offsetOrLabel] == null) ? timeOrLabel - clippedDuration : 0, appendIfAbsent);\n\t\t\t}\n\t\t\toffsetOrLabel = offsetOrLabel || 0;\n\t\t\tif (typeof(timeOrLabel) === \"string\" && (isNaN(timeOrLabel) || this._labels[timeOrLabel] != null)) { //if the string is a number like \"1\", check to see if there's a label with that name, otherwise interpret it as a number (absolute value).\n\t\t\t\ti = timeOrLabel.indexOf(\"=\");\n\t\t\t\tif (i === -1) {\n\t\t\t\t\tif (this._labels[timeOrLabel] == null) {\n\t\t\t\t\t\treturn appendIfAbsent ? (this._labels[timeOrLabel] = clippedDuration + offsetOrLabel) : offsetOrLabel;\n\t\t\t\t\t}\n\t\t\t\t\treturn this._labels[timeOrLabel] + offsetOrLabel;\n\t\t\t\t}\n\t\t\t\toffsetOrLabel = parseInt(timeOrLabel.charAt(i-1) + \"1\", 10) * Number(timeOrLabel.substr(i+1));\n\t\t\t\ttimeOrLabel = (i > 1) ? this._parseTimeOrLabel(timeOrLabel.substr(0, i-1), 0, appendIfAbsent) : clippedDuration;\n\t\t\t} else if (timeOrLabel == null) {\n\t\t\t\ttimeOrLabel = clippedDuration;\n\t\t\t}\n\t\t\treturn Number(timeOrLabel) + offsetOrLabel;\n\t\t};\n\n\t\tp.seek = function(position, suppressEvents) {\n\t\t\treturn this.totalTime((typeof(position) === \"number\") ? position : this._parseTimeOrLabel(position), (suppressEvents !== false));\n\t\t};\n\n\t\tp.stop = function() {\n\t\t\treturn this.paused(true);\n\t\t};\n\n\t\tp.gotoAndPlay = function(position, suppressEvents) {\n\t\t\treturn this.play(position, suppressEvents);\n\t\t};\n\n\t\tp.gotoAndStop = function(position, suppressEvents) {\n\t\t\treturn this.pause(position, suppressEvents);\n\t\t};\n\n\t\tp.render = function(time, suppressEvents, force) {\n\t\t\tif (this._gc) {\n\t\t\t\tthis._enabled(true, false);\n\t\t\t}\n\t\t\tvar self = this,\n\t\t\t\tprevTime = self._time,\n\t\t\t\ttotalDur = (!self._dirty) ? self._totalDuration : self.totalDuration(),\n\t\t\t\tprevStart = self._startTime,\n\t\t\t\tprevTimeScale = self._timeScale,\n\t\t\t\tprevPaused = self._paused,\n\t\t\t\ttween, isComplete, next, callback, internalForce, pauseTween, curTime, pauseTime;\n\t\t\tif (prevTime !== self._time) { //if totalDuration() finds a child with a negative startTime and smoothChildTiming is true, things get shifted around internally so we need to adjust the time accordingly. For example, if a tween starts at -30 we must shift EVERYTHING forward 30 seconds and move this timeline's startTime backward by 30 seconds so that things align with the playhead (no jump).\n\t\t\t\ttime += self._time - prevTime;\n\t\t\t}\n\t\t\tif (self._hasPause && !self._forcingPlayhead && !suppressEvents) {\n\t\t\t\tif (time > prevTime) {\n\t\t\t\t\ttween = self._first;\n\t\t\t\t\twhile (tween && tween._startTime <= time && !pauseTween) {\n\t\t\t\t\t\tif (!tween._duration) if (tween.data === \"isPause\" && !tween.ratio && !(tween._startTime === 0 && self._rawPrevTime === 0)) {\n\t\t\t\t\t\t\tpauseTween = tween;\n\t\t\t\t\t\t}\n\t\t\t\t\t\ttween = tween._next;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\ttween = self._last;\n\t\t\t\t\twhile (tween && tween._startTime >= time && !pauseTween) {\n\t\t\t\t\t\tif (!tween._duration) if (tween.data === \"isPause\" && tween._rawPrevTime > 0) {\n\t\t\t\t\t\t\tpauseTween = tween;\n\t\t\t\t\t\t}\n\t\t\t\t\t\ttween = tween._prev;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (pauseTween) {\n\t\t\t\t\tself._time = self._totalTime = time = pauseTween._startTime;\n\t\t\t\t\tpauseTime = self._startTime + (self._reversed ? self._duration - time : time) / self._timeScale;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (time >= totalDur - _tinyNum && time >= 0) { //to work around occasional floating point math artifacts.\n\t\t\t\tself._totalTime = self._time = totalDur;\n\t\t\t\tif (!self._reversed) if (!self._hasPausedChild()) {\n\t\t\t\t\tisComplete = true;\n\t\t\t\t\tcallback = \"onComplete\";\n\t\t\t\t\tinternalForce = !!self._timeline.autoRemoveChildren; //otherwise, if the animation is unpaused/activated after it's already finished, it doesn't get removed from the parent timeline.\n\t\t\t\t\tif (self._duration === 0) if ((time <= 0 && time >= -_tinyNum) || self._rawPrevTime < 0 || self._rawPrevTime === _tinyNum) if (self._rawPrevTime !== time && self._first) {\n\t\t\t\t\t\tinternalForce = true;\n\t\t\t\t\t\tif (self._rawPrevTime > _tinyNum) {\n\t\t\t\t\t\t\tcallback = \"onReverseComplete\";\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tself._rawPrevTime = (self._duration || !suppressEvents || time || self._rawPrevTime === time) ? time : _tinyNum; //when the playhead arrives at EXACTLY time 0 (right on top) of a zero-duration timeline or tween, we need to discern if events are suppressed so that when the playhead moves again (next time), it'll trigger the callback. If events are NOT suppressed, obviously the callback would be triggered in this render. Basically, the callback should fire either when the playhead ARRIVES or LEAVES this exact spot, not both. Imagine doing a timeline.seek(0) and there's a callback that sits at 0. Since events are suppressed on that seek() by default, nothing will fire, but when the playhead moves off of that position, the callback should fire. This behavior is what people intuitively expect. We set the _rawPrevTime to be a precise tiny number to indicate this scenario rather than using another property/variable which would increase memory usage. This technique is less readable, but more efficient.\n\t\t\t\ttime = totalDur + 0.0001; //to avoid occasional floating point rounding errors - sometimes child tweens/timelines were not being fully completed (their progress might be 0.999999999999998 instead of 1 because when _time - tween._startTime is performed, floating point errors would return a value that was SLIGHTLY off). Try (999999999999.7 - 999999999999) * 1 = 0.699951171875 instead of 0.7.\n\n\t\t\t} else if (time < _tinyNum) { //to work around occasional floating point math artifacts, round super small values to 0.\n\t\t\t\tself._totalTime = self._time = 0;\n\t\t\t\tif (time > -_tinyNum) {\n\t\t\t\t\ttime = 0;\n\t\t\t\t}\n\t\t\t\tif (prevTime !== 0 || (self._duration === 0 && self._rawPrevTime !== _tinyNum && (self._rawPrevTime > 0 || (time < 0 && self._rawPrevTime >= 0)))) {\n\t\t\t\t\tcallback = \"onReverseComplete\";\n\t\t\t\t\tisComplete = self._reversed;\n\t\t\t\t}\n\t\t\t\tif (time < 0) {\n\t\t\t\t\tself._active = false;\n\t\t\t\t\tif (self._timeline.autoRemoveChildren && self._reversed) { //ensures proper GC if a timeline is resumed after it's finished reversing.\n\t\t\t\t\t\tinternalForce = isComplete = true;\n\t\t\t\t\t\tcallback = \"onReverseComplete\";\n\t\t\t\t\t} else if (self._rawPrevTime >= 0 && self._first) { //when going back beyond the start, force a render so that zero-duration tweens that sit at the very beginning render their start values properly. Otherwise, if the parent timeline's playhead lands exactly at this timeline's startTime, and then moves backwards, the zero-duration tweens at the beginning would still be at their end state.\n\t\t\t\t\t\tinternalForce = true;\n\t\t\t\t\t}\n\t\t\t\t\tself._rawPrevTime = time;\n\t\t\t\t} else {\n\t\t\t\t\tself._rawPrevTime = (self._duration || !suppressEvents || time || self._rawPrevTime === time) ? time : _tinyNum; //when the playhead arrives at EXACTLY time 0 (right on top) of a zero-duration timeline or tween, we need to discern if events are suppressed so that when the playhead moves again (next time), it'll trigger the callback. If events are NOT suppressed, obviously the callback would be triggered in this render. Basically, the callback should fire either when the playhead ARRIVES or LEAVES this exact spot, not both. Imagine doing a timeline.seek(0) and there's a callback that sits at 0. Since events are suppressed on that seek() by default, nothing will fire, but when the playhead moves off of that position, the callback should fire. This behavior is what people intuitively expect. We set the _rawPrevTime to be a precise tiny number to indicate this scenario rather than using another property/variable which would increase memory usage. This technique is less readable, but more efficient.\n\t\t\t\t\tif (time === 0 && isComplete) { //if there's a zero-duration tween at the very beginning of a timeline and the playhead lands EXACTLY at time 0, that tween will correctly render its end values, but we need to keep the timeline alive for one more render so that the beginning values render properly as the parent's playhead keeps moving beyond the begining. Imagine obj.x starts at 0 and then we do tl.set(obj, {x:100}).to(obj, 1, {x:200}) and then later we tl.reverse()...the goal is to have obj.x revert to 0. If the playhead happens to land on exactly 0, without this chunk of code, it'd complete the timeline and remove it from the rendering queue (not good).\n\t\t\t\t\t\ttween = self._first;\n\t\t\t\t\t\twhile (tween && tween._startTime === 0) {\n\t\t\t\t\t\t\tif (!tween._duration) {\n\t\t\t\t\t\t\t\tisComplete = false;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\ttween = tween._next;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\ttime = 0; //to avoid occasional floating point rounding errors (could cause problems especially with zero-duration tweens at the very beginning of the timeline)\n\t\t\t\t\tif (!self._initted) {\n\t\t\t\t\t\tinternalForce = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t} else {\n\t\t\t\tself._totalTime = self._time = self._rawPrevTime = time;\n\t\t\t}\n\t\t\tif ((self._time === prevTime || !self._first) && !force && !internalForce && !pauseTween) {\n\t\t\t\treturn;\n\t\t\t} else if (!self._initted) {\n\t\t\t\tself._initted = true;\n\t\t\t}\n\n\t\t\tif (!self._active) if (!self._paused && self._time !== prevTime && time > 0) {\n\t\t\t\tself._active = true;  //so that if the user renders the timeline (as opposed to the parent timeline rendering it), it is forced to re-render and align it with the proper time/frame on the next rendering cycle. Maybe the timeline already finished but the user manually re-renders it as halfway done, for example.\n\t\t\t}\n\n\t\t\tif (prevTime === 0) if (self.vars.onStart) if (self._time !== 0 || !self._duration) if (!suppressEvents) {\n\t\t\t\tself._callback(\"onStart\");\n\t\t\t}\n\n\t\t\tcurTime = self._time;\n\t\t\tif (curTime >= prevTime) {\n\t\t\t\ttween = self._first;\n\t\t\t\twhile (tween) {\n\t\t\t\t\tnext = tween._next; //record it here because the value could change after rendering...\n\t\t\t\t\tif (curTime !== self._time || (self._paused && !prevPaused)) { //in case a tween pauses or seeks the timeline when rendering, like inside of an onUpdate/onComplete\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t} else if (tween._active || (tween._startTime <= curTime && !tween._paused && !tween._gc)) {\n\t\t\t\t\t\tif (pauseTween === tween) {\n\t\t\t\t\t\t\tself.pause();\n\t\t\t\t\t\t\tself._pauseTime = pauseTime; //so that when we resume(), it's starting from exactly the right spot (the pause() method uses the rawTime for the parent, but that may be a bit too far ahead)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (!tween._reversed) {\n\t\t\t\t\t\t\ttween.render((time - tween._startTime) * tween._timeScale, suppressEvents, force);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\ttween.render(((!tween._dirty) ? tween._totalDuration : tween.totalDuration()) - ((time - tween._startTime) * tween._timeScale), suppressEvents, force);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\ttween = next;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\ttween = self._last;\n\t\t\t\twhile (tween) {\n\t\t\t\t\tnext = tween._prev; //record it here because the value could change after rendering...\n\t\t\t\t\tif (curTime !== self._time || (self._paused && !prevPaused)) { //in case a tween pauses or seeks the timeline when rendering, like inside of an onUpdate/onComplete\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t} else if (tween._active || (tween._startTime <= prevTime && !tween._paused && !tween._gc)) {\n\t\t\t\t\t\tif (pauseTween === tween) {\n\t\t\t\t\t\t\tpauseTween = tween._prev; //the linked list is organized by _startTime, thus it's possible that a tween could start BEFORE the pause and end after it, in which case it would be positioned before the pause tween in the linked list, but we should render it before we pause() the timeline and cease rendering. This is only a concern when going in reverse.\n\t\t\t\t\t\t\twhile (pauseTween && pauseTween.endTime() > self._time) {\n\t\t\t\t\t\t\t\tpauseTween.render( (pauseTween._reversed ? pauseTween.totalDuration() - ((time - pauseTween._startTime) * pauseTween._timeScale) : (time - pauseTween._startTime) * pauseTween._timeScale), suppressEvents, force);\n\t\t\t\t\t\t\t\tpauseTween = pauseTween._prev;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tpauseTween = null;\n\t\t\t\t\t\t\tself.pause();\n\t\t\t\t\t\t\tself._pauseTime = pauseTime; //so that when we resume(), it's starting from exactly the right spot (the pause() method uses the rawTime for the parent, but that may be a bit too far ahead)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (!tween._reversed) {\n\t\t\t\t\t\t\ttween.render((time - tween._startTime) * tween._timeScale, suppressEvents, force);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\ttween.render(((!tween._dirty) ? tween._totalDuration : tween.totalDuration()) - ((time - tween._startTime) * tween._timeScale), suppressEvents, force);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\ttween = next;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (self._onUpdate) if (!suppressEvents) {\n\t\t\t\tif (_lazyTweens.length) { //in case rendering caused any tweens to lazy-init, we should render them because typically when a timeline finishes, users expect things to have rendered fully. Imagine an onUpdate on a timeline that reports/checks tweened values.\n\t\t\t\t\t_lazyRender();\n\t\t\t\t}\n\t\t\t\tself._callback(\"onUpdate\");\n\t\t\t}\n\n\t\t\tif (callback) if (!self._gc) if (prevStart === self._startTime || prevTimeScale !== self._timeScale) if (self._time === 0 || totalDur >= self.totalDuration()) { //if one of the tweens that was rendered altered this timeline's startTime (like if an onComplete reversed the timeline), it probably isn't complete. If it is, don't worry, because whatever call altered the startTime would complete if it was necessary at the new time. The only exception is the timeScale property. Also check _gc because there's a chance that kill() could be called in an onUpdate\n\t\t\t\tif (isComplete) {\n\t\t\t\t\tif (_lazyTweens.length) { //in case rendering caused any tweens to lazy-init, we should render them because typically when a timeline finishes, users expect things to have rendered fully. Imagine an onComplete on a timeline that reports/checks tweened values.\n\t\t\t\t\t\t_lazyRender();\n\t\t\t\t\t}\n\t\t\t\t\tif (self._timeline.autoRemoveChildren) {\n\t\t\t\t\t\tself._enabled(false, false);\n\t\t\t\t\t}\n\t\t\t\t\tself._active = false;\n\t\t\t\t}\n\t\t\t\tif (!suppressEvents && self.vars[callback]) {\n\t\t\t\t\tself._callback(callback);\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\n\t\tp._hasPausedChild = function() {\n\t\t\tvar tween = this._first;\n\t\t\twhile (tween) {\n\t\t\t\tif (tween._paused || ((tween instanceof TimelineLite) && tween._hasPausedChild())) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t\ttween = tween._next;\n\t\t\t}\n\t\t\treturn false;\n\t\t};\n\n\t\tp.getChildren = function(nested, tweens, timelines, ignoreBeforeTime) {\n\t\t\tignoreBeforeTime = ignoreBeforeTime || -9999999999;\n\t\t\tvar a = [],\n\t\t\t\ttween = this._first,\n\t\t\t\tcnt = 0;\n\t\t\twhile (tween) {\n\t\t\t\tif (tween._startTime < ignoreBeforeTime) {\n\t\t\t\t\t//do nothing\n\t\t\t\t} else if (tween instanceof _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]) {\n\t\t\t\t\tif (tweens !== false) {\n\t\t\t\t\t\ta[cnt++] = tween;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tif (timelines !== false) {\n\t\t\t\t\t\ta[cnt++] = tween;\n\t\t\t\t\t}\n\t\t\t\t\tif (nested !== false) {\n\t\t\t\t\t\ta = a.concat(tween.getChildren(true, tweens, timelines));\n\t\t\t\t\t\tcnt = a.length;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ttween = tween._next;\n\t\t\t}\n\t\t\treturn a;\n\t\t};\n\n\t\tp.getTweensOf = function(target, nested) {\n\t\t\tvar disabled = this._gc,\n\t\t\t\ta = [],\n\t\t\t\tcnt = 0,\n\t\t\t\ttweens, i;\n\t\t\tif (disabled) {\n\t\t\t\tthis._enabled(true, true); //getTweensOf() filters out disabled tweens, and we have to mark them as _gc = true when the timeline completes in order to allow clean garbage collection, so temporarily re-enable the timeline here.\n\t\t\t}\n\t\t\ttweens = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].getTweensOf(target);\n\t\t\ti = tweens.length;\n\t\t\twhile (--i > -1) {\n\t\t\t\tif (tweens[i].timeline === this || (nested && this._contains(tweens[i]))) {\n\t\t\t\t\ta[cnt++] = tweens[i];\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (disabled) {\n\t\t\t\tthis._enabled(false, true);\n\t\t\t}\n\t\t\treturn a;\n\t\t};\n\n\t\tp.recent = function() {\n\t\t\treturn this._recent;\n\t\t};\n\n\t\tp._contains = function(tween) {\n\t\t\tvar tl = tween.timeline;\n\t\t\twhile (tl) {\n\t\t\t\tif (tl === this) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t\ttl = tl.timeline;\n\t\t\t}\n\t\t\treturn false;\n\t\t};\n\n\t\tp.shiftChildren = function(amount, adjustLabels, ignoreBeforeTime) {\n\t\t\tignoreBeforeTime = ignoreBeforeTime || 0;\n\t\t\tvar tween = this._first,\n\t\t\t\tlabels = this._labels,\n\t\t\t\tp;\n\t\t\twhile (tween) {\n\t\t\t\tif (tween._startTime >= ignoreBeforeTime) {\n\t\t\t\t\ttween._startTime += amount;\n\t\t\t\t}\n\t\t\t\ttween = tween._next;\n\t\t\t}\n\t\t\tif (adjustLabels) {\n\t\t\t\tfor (p in labels) {\n\t\t\t\t\tif (labels[p] >= ignoreBeforeTime) {\n\t\t\t\t\t\tlabels[p] += amount;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn this._uncache(true);\n\t\t};\n\n\t\tp._kill = function(vars, target) {\n\t\t\tif (!vars && !target) {\n\t\t\t\treturn this._enabled(false, false);\n\t\t\t}\n\t\t\tvar tweens = (!target) ? this.getChildren(true, true, false) : this.getTweensOf(target),\n\t\t\t\ti = tweens.length,\n\t\t\t\tchanged = false;\n\t\t\twhile (--i > -1) {\n\t\t\t\tif (tweens[i]._kill(vars, target)) {\n\t\t\t\t\tchanged = true;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn changed;\n\t\t};\n\n\t\tp.clear = function(labels) {\n\t\t\tvar tweens = this.getChildren(false, true, true),\n\t\t\t\ti = tweens.length;\n\t\t\tthis._time = this._totalTime = 0;\n\t\t\twhile (--i > -1) {\n\t\t\t\ttweens[i]._enabled(false, false);\n\t\t\t}\n\t\t\tif (labels !== false) {\n\t\t\t\tthis._labels = {};\n\t\t\t}\n\t\t\treturn this._uncache(true);\n\t\t};\n\n\t\tp.invalidate = function() {\n\t\t\tvar tween = this._first;\n\t\t\twhile (tween) {\n\t\t\t\ttween.invalidate();\n\t\t\t\ttween = tween._next;\n\t\t\t}\n\t\t\treturn _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Animation\"].prototype.invalidate.call(this);;\n\t\t};\n\n\t\tp._enabled = function(enabled, ignoreTimeline) {\n\t\t\tif (enabled === this._gc) {\n\t\t\t\tvar tween = this._first;\n\t\t\t\twhile (tween) {\n\t\t\t\t\ttween._enabled(enabled, true);\n\t\t\t\t\ttween = tween._next;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"SimpleTimeline\"].prototype._enabled.call(this, enabled, ignoreTimeline);\n\t\t};\n\n\t\tp.totalTime = function(time, suppressEvents, uncapped) {\n\t\t\tthis._forcingPlayhead = true;\n\t\t\tvar val = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Animation\"].prototype.totalTime.apply(this, arguments);\n\t\t\tthis._forcingPlayhead = false;\n\t\t\treturn val;\n\t\t};\n\n\t\tp.duration = function(value) {\n\t\t\tif (!arguments.length) {\n\t\t\t\tif (this._dirty) {\n\t\t\t\t\tthis.totalDuration(); //just triggers recalculation\n\t\t\t\t}\n\t\t\t\treturn this._duration;\n\t\t\t}\n\t\t\tif (this.duration() !== 0 && value !== 0) {\n\t\t\t\tthis.timeScale(this._duration / value);\n\t\t\t}\n\t\t\treturn this;\n\t\t};\n\n\t\tp.totalDuration = function(value) {\n\t\t\tif (!arguments.length) {\n\t\t\t\tif (this._dirty) {\n\t\t\t\t\tvar max = 0,\n\t\t\t\t\t\tself = this,\n\t\t\t\t\t\ttween = self._last,\n\t\t\t\t\t\tprevStart = 999999999999,\n\t\t\t\t\t\tprev, end;\n\t\t\t\t\twhile (tween) {\n\t\t\t\t\t\tprev = tween._prev; //record it here in case the tween changes position in the sequence...\n\t\t\t\t\t\tif (tween._dirty) {\n\t\t\t\t\t\t\ttween.totalDuration(); //could change the tween._startTime, so make sure the tween's cache is clean before analyzing it.\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (tween._startTime > prevStart && self._sortChildren && !tween._paused && !self._calculatingDuration) { //in case one of the tweens shifted out of order, it needs to be re-inserted into the correct position in the sequence\n\t\t\t\t\t\t\tself._calculatingDuration = 1; //prevent endless recursive calls - there are methods that get triggered that check duration/totalDuration when we add(), like _parseTimeOrLabel().\n\t\t\t\t\t\t\tself.add(tween, tween._startTime - tween._delay);\n\t\t\t\t\t\t\tself._calculatingDuration = 0;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tprevStart = tween._startTime;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (tween._startTime < 0 && !tween._paused) { //children aren't allowed to have negative startTimes unless smoothChildTiming is true, so adjust here if one is found.\n\t\t\t\t\t\t\tmax -= tween._startTime;\n\t\t\t\t\t\t\tif (self._timeline.smoothChildTiming) {\n\t\t\t\t\t\t\t\tself._startTime += tween._startTime / self._timeScale;\n\t\t\t\t\t\t\t\tself._time -= tween._startTime;\n\t\t\t\t\t\t\t\tself._totalTime -= tween._startTime;\n\t\t\t\t\t\t\t\tself._rawPrevTime -= tween._startTime;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tself.shiftChildren(-tween._startTime, false, -9999999999);\n\t\t\t\t\t\t\tprevStart = 0;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tend = tween._startTime + (tween._totalDuration / tween._timeScale);\n\t\t\t\t\t\tif (end > max) {\n\t\t\t\t\t\t\tmax = end;\n\t\t\t\t\t\t}\n\t\t\t\t\t\ttween = prev;\n\t\t\t\t\t}\n\t\t\t\t\tself._duration = self._totalDuration = max;\n\t\t\t\t\tself._dirty = false;\n\t\t\t\t}\n\t\t\t\treturn this._totalDuration;\n\t\t\t}\n\t\t\treturn (value && this.totalDuration()) ? this.timeScale(this._totalDuration / value) : this;\n\t\t};\n\n\t\tp.paused = function(value) {\n\t\t\tif (value === false && this._paused) { //if there's a pause directly at the spot from where we're unpausing, skip it.\n\t\t\t\tvar tween = this._first;\n\t\t\t\twhile (tween) {\n\t\t\t\t\tif (tween._startTime === this._time && tween.data === \"isPause\") {\n\t\t\t\t\t\ttween._rawPrevTime = 0; //remember, _rawPrevTime is how zero-duration tweens/callbacks sense directionality and determine whether or not to fire. If _rawPrevTime is the same as _startTime on the next render, it won't fire.\n\t\t\t\t\t}\n\t\t\t\t\ttween = tween._next;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Animation\"].prototype.paused.apply(this, arguments);\n\t\t};\n\n\t\tp.usesFrames = function() {\n\t\t\tvar tl = this._timeline;\n\t\t\twhile (tl._timeline) {\n\t\t\t\ttl = tl._timeline;\n\t\t\t}\n\t\t\treturn (tl === _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Animation\"]._rootFramesTimeline);\n\t\t};\n\n\t\tp.rawTime = function(wrapRepeats) {\n\t\t\treturn (wrapRepeats && (this._paused || (this._repeat && this.time() > 0 && this.totalProgress() < 1))) ? this._totalTime % (this._duration + this._repeatDelay) : this._paused ? this._totalTime : (this._timeline.rawTime(wrapRepeats) - this._startTime) * this._timeScale;\n\t\t};\n\n\t\treturn TimelineLite;\n\n\t}, true);\n\nvar TimelineLite = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"globals\"].TimelineLite;\n\n\n\n//# sourceURL=webpack:///./node_modules/gsap/TimelineLite.js?");

/***/ }),

/***/ "./node_modules/gsap/TimelineMax.js":
/*!******************************************!*\
  !*** ./node_modules/gsap/TimelineMax.js ***!
  \******************************************/
/*! exports provided: TimelineMax, TimelineLite, default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TimelineMax\", function() { return TimelineMax; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"default\", function() { return TimelineMax; });\n/* harmony import */ var _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./TweenLite.js */ \"./node_modules/gsap/TweenLite.js\");\n/* harmony import */ var _TimelineLite_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./TimelineLite.js */ \"./node_modules/gsap/TimelineLite.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TimelineLite\", function() { return _TimelineLite_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]; });\n\n/*!\n * VERSION: 2.1.3\n * DATE: 2019-05-17\n * UPDATES AND DOCS AT: http://greensock.com\n *\n * @license Copyright (c) 2008-2019, GreenSock. All rights reserved.\n * This work is subject to the terms at http://greensock.com/standard-license or for\n * Club GreenSock members, the software agreement that was issued with your membership.\n * \n * @author: Jack Doyle, jack@greensock.com\n */\n/* eslint-disable */\n\n\n\n\n_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"_gsScope\"]._gsDefine(\"TimelineMax\", [\"TimelineLite\",\"TweenLite\",\"easing.Ease\"], function() {\n\t\t\n\t\tvar TimelineMax = function(vars) {\n\t\t\t\t_TimelineLite_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].call(this, vars);\n\t\t\t\tthis._repeat = this.vars.repeat || 0;\n\t\t\t\tthis._repeatDelay = this.vars.repeatDelay || 0;\n\t\t\t\tthis._cycle = 0;\n\t\t\t\tthis._yoyo = !!this.vars.yoyo;\n\t\t\t\tthis._dirty = true;\n\t\t\t},\n\t\t\t_tinyNum = 0.00000001,\n\t\t\tTweenLiteInternals = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]._internals,\n\t\t\t_lazyTweens = TweenLiteInternals.lazyTweens,\n\t\t\t_lazyRender = TweenLiteInternals.lazyRender,\n\t\t\t_globals = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"_gsScope\"]._gsDefine.globals,\n\t\t\t_easeNone = new _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Ease\"](null, null, 1, 0),\n\t\t\tp = TimelineMax.prototype = new _TimelineLite_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]();\n\n\t\tp.constructor = TimelineMax;\n\t\tp.kill()._gc = false;\n\t\tTimelineMax.version = \"2.1.3\";\n\n\t\tp.invalidate = function() {\n\t\t\tthis._yoyo = !!this.vars.yoyo;\n\t\t\tthis._repeat = this.vars.repeat || 0;\n\t\t\tthis._repeatDelay = this.vars.repeatDelay || 0;\n\t\t\tthis._uncache(true);\n\t\t\treturn _TimelineLite_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].prototype.invalidate.call(this);\n\t\t};\n\n\t\tp.addCallback = function(callback, position, params, scope) {\n\t\t\treturn this.add( _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].delayedCall(0, callback, params, scope), position);\n\t\t};\n\n\t\tp.removeCallback = function(callback, position) {\n\t\t\tif (callback) {\n\t\t\t\tif (position == null) {\n\t\t\t\t\tthis._kill(null, callback);\n\t\t\t\t} else {\n\t\t\t\t\tvar a = this.getTweensOf(callback, false),\n\t\t\t\t\t\ti = a.length,\n\t\t\t\t\t\ttime = this._parseTimeOrLabel(position);\n\t\t\t\t\twhile (--i > -1) {\n\t\t\t\t\t\tif (a[i]._startTime === time) {\n\t\t\t\t\t\t\ta[i]._enabled(false, false);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn this;\n\t\t};\n\n\t\tp.removePause = function(position) {\n\t\t\treturn this.removeCallback(_TimelineLite_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]._internals.pauseCallback, position);\n\t\t};\n\n\t\tp.tweenTo = function(position, vars) {\n\t\t\tvars = vars || {};\n\t\t\tvar copy = {ease:_easeNone, useFrames:this.usesFrames(), immediateRender:false, lazy:false},\n\t\t\t\tEngine = (vars.repeat && _globals.TweenMax) || _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"],\n\t\t\t\tduration, p, t;\n\t\t\tfor (p in vars) {\n\t\t\t\tcopy[p] = vars[p];\n\t\t\t}\n\t\t\tcopy.time = this._parseTimeOrLabel(position);\n\t\t\tduration = (Math.abs(Number(copy.time) - this._time) / this._timeScale) || 0.001;\n\t\t\tt = new Engine(this, duration, copy);\n\t\t\tcopy.onStart = function() {\n\t\t\t\tt.target.paused(true);\n\t\t\t\tif (t.vars.time !== t.target.time() && duration === t.duration() && !t.isFromTo) { //don't make the duration zero - if it's supposed to be zero, don't worry because it's already initting the tween and will complete immediately, effectively making the duration zero anyway. If we make duration zero, the tween won't run at all.\n\t\t\t\t\tt.duration( Math.abs( t.vars.time - t.target.time()) / t.target._timeScale ).render(t.time(), true, true); //render() right away to ensure that things look right, especially in the case of .tweenTo(0).\n\t\t\t\t}\n\t\t\t\tif (vars.onStart) { //in case the user had an onStart in the vars - we don't want to overwrite it.\n\t\t\t\t\tvars.onStart.apply(vars.onStartScope || vars.callbackScope || t, vars.onStartParams || []); //don't use t._callback(\"onStart\") or it'll point to the copy.onStart and we'll get a recursion error.\n\t\t\t\t}\n\t\t\t};\n\t\t\treturn t;\n\t\t};\n\n\t\tp.tweenFromTo = function(fromPosition, toPosition, vars) {\n\t\t\tvars = vars || {};\n\t\t\tfromPosition = this._parseTimeOrLabel(fromPosition);\n\t\t\tvars.startAt = {onComplete:this.seek, onCompleteParams:[fromPosition], callbackScope:this};\n\t\t\tvars.immediateRender = (vars.immediateRender !== false);\n\t\t\tvar t = this.tweenTo(toPosition, vars);\n\t\t\tt.isFromTo = 1; //to ensure we don't mess with the duration in the onStart (we've got the start and end values here, so lock it in)\n\t\t\treturn t.duration((Math.abs( t.vars.time - fromPosition) / this._timeScale) || 0.001);\n\t\t};\n\n\t\tp.render = function(time, suppressEvents, force) {\n\t\t\tif (this._gc) {\n\t\t\t\tthis._enabled(true, false);\n\t\t\t}\n\t\t\tvar self = this,\n\t\t\t\tprevTime = self._time,\n\t\t\t\ttotalDur = (!self._dirty) ? self._totalDuration : self.totalDuration(),\n\t\t\t\tdur = self._duration,\n\t\t\t\tprevTotalTime = self._totalTime,\n\t\t\t\tprevStart = self._startTime,\n\t\t\t\tprevTimeScale = self._timeScale,\n\t\t\t\tprevRawPrevTime = self._rawPrevTime,\n\t\t\t\tprevPaused = self._paused,\n\t\t\t\tprevCycle = self._cycle,\n\t\t\t\ttween, isComplete, next, callback, internalForce, cycleDuration, pauseTween, curTime, pauseTime;\n\t\t\tif (prevTime !== self._time) { //if totalDuration() finds a child with a negative startTime and smoothChildTiming is true, things get shifted around internally so we need to adjust the time accordingly. For example, if a tween starts at -30 we must shift EVERYTHING forward 30 seconds and move this timeline's startTime backward by 30 seconds so that things align with the playhead (no jump).\n\t\t\t\ttime += self._time - prevTime;\n\t\t\t}\n\t\t\tif (time >= totalDur - _tinyNum && time >= 0) { //to work around occasional floating point math artifacts.\n\t\t\t\tif (!self._locked) {\n\t\t\t\t\tself._totalTime = totalDur;\n\t\t\t\t\tself._cycle = self._repeat;\n\t\t\t\t}\n\t\t\t\tif (!self._reversed) if (!self._hasPausedChild()) {\n\t\t\t\t\tisComplete = true;\n\t\t\t\t\tcallback = \"onComplete\";\n\t\t\t\t\tinternalForce = !!self._timeline.autoRemoveChildren; //otherwise, if the animation is unpaused/activated after it's already finished, it doesn't get removed from the parent timeline.\n\t\t\t\t\tif (self._duration === 0) if ((time <= 0 && time >= -_tinyNum) || prevRawPrevTime < 0 || prevRawPrevTime === _tinyNum) if (prevRawPrevTime !== time && self._first) {\n\t\t\t\t\t\tinternalForce = true;\n\t\t\t\t\t\tif (prevRawPrevTime > _tinyNum) {\n\t\t\t\t\t\t\tcallback = \"onReverseComplete\";\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tself._rawPrevTime = (self._duration || !suppressEvents || time || self._rawPrevTime === time) ? time : _tinyNum; //when the playhead arrives at EXACTLY time 0 (right on top) of a zero-duration timeline or tween, we need to discern if events are suppressed so that when the playhead moves again (next time), it'll trigger the callback. If events are NOT suppressed, obviously the callback would be triggered in this render. Basically, the callback should fire either when the playhead ARRIVES or LEAVES this exact spot, not both. Imagine doing a timeline.seek(0) and there's a callback that sits at 0. Since events are suppressed on that seek() by default, nothing will fire, but when the playhead moves off of that position, the callback should fire. This behavior is what people intuitively expect. We set the _rawPrevTime to be a precise tiny number to indicate this scenario rather than using another property/variable which would increase memory usage. This technique is less readable, but more efficient.\n\t\t\t\tif (self._yoyo && (self._cycle & 1)) {\n\t\t\t\t\tself._time = time = 0;\n\t\t\t\t} else {\n\t\t\t\t\tself._time = dur;\n\t\t\t\t\ttime = dur + 0.0001; //to avoid occasional floating point rounding errors - sometimes child tweens/timelines were not being fully completed (their progress might be 0.999999999999998 instead of 1 because when _time - tween._startTime is performed, floating point errors would return a value that was SLIGHTLY off). Try (999999999999.7 - 999999999999) * 1 = 0.699951171875 instead of 0.7. We cannot do less then 0.0001 because the same issue can occur when the duration is extremely large like 999999999999 in which case adding 0.00000001, for example, causes it to act like nothing was added.\n\t\t\t\t}\n\n\t\t\t} else if (time < _tinyNum) { //to work around occasional floating point math artifacts, round super small values to 0.\n\t\t\t\tif (!self._locked) {\n\t\t\t\t\tself._totalTime = self._cycle = 0;\n\t\t\t\t}\n\t\t\t\tself._time = 0;\n\t\t\t\tif (time > -_tinyNum) {\n\t\t\t\t\ttime = 0;\n\t\t\t\t}\n\t\t\t\tif (prevTime !== 0 || (dur === 0 && prevRawPrevTime !== _tinyNum && (prevRawPrevTime > 0 || (time < 0 && prevRawPrevTime >= 0)) && !self._locked)) { //edge case for checking time < 0 && prevRawPrevTime >= 0: a zero-duration fromTo() tween inside a zero-duration timeline (yeah, very rare)\n\t\t\t\t\tcallback = \"onReverseComplete\";\n\t\t\t\t\tisComplete = self._reversed;\n\t\t\t\t}\n\t\t\t\tif (time < 0) {\n\t\t\t\t\tself._active = false;\n\t\t\t\t\tif (self._timeline.autoRemoveChildren && self._reversed) {\n\t\t\t\t\t\tinternalForce = isComplete = true;\n\t\t\t\t\t\tcallback = \"onReverseComplete\";\n\t\t\t\t\t} else if (prevRawPrevTime >= 0 && self._first) { //when going back beyond the start, force a render so that zero-duration tweens that sit at the very beginning render their start values properly. Otherwise, if the parent timeline's playhead lands exactly at this timeline's startTime, and then moves backwards, the zero-duration tweens at the beginning would still be at their end state.\n\t\t\t\t\t\tinternalForce = true;\n\t\t\t\t\t}\n\t\t\t\t\tself._rawPrevTime = time;\n\t\t\t\t} else {\n\t\t\t\t\tself._rawPrevTime = (dur || !suppressEvents || time || self._rawPrevTime === time) ? time : _tinyNum; //when the playhead arrives at EXACTLY time 0 (right on top) of a zero-duration timeline or tween, we need to discern if events are suppressed so that when the playhead moves again (next time), it'll trigger the callback. If events are NOT suppressed, obviously the callback would be triggered in this render. Basically, the callback should fire either when the playhead ARRIVES or LEAVES this exact spot, not both. Imagine doing a timeline.seek(0) and there's a callback that sits at 0. Since events are suppressed on that seek() by default, nothing will fire, but when the playhead moves off of that position, the callback should fire. This behavior is what people intuitively expect. We set the _rawPrevTime to be a precise tiny number to indicate this scenario rather than using another property/variable which would increase memory usage. This technique is less readable, but more efficient.\n\t\t\t\t\tif (time === 0 && isComplete) { //if there's a zero-duration tween at the very beginning of a timeline and the playhead lands EXACTLY at time 0, that tween will correctly render its end values, but we need to keep the timeline alive for one more render so that the beginning values render properly as the parent's playhead keeps moving beyond the begining. Imagine obj.x starts at 0 and then we do tl.set(obj, {x:100}).to(obj, 1, {x:200}) and then later we tl.reverse()...the goal is to have obj.x revert to 0. If the playhead happens to land on exactly 0, without this chunk of code, it'd complete the timeline and remove it from the rendering queue (not good).\n\t\t\t\t\t\ttween = self._first;\n\t\t\t\t\t\twhile (tween && tween._startTime === 0) {\n\t\t\t\t\t\t\tif (!tween._duration) {\n\t\t\t\t\t\t\t\tisComplete = false;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\ttween = tween._next;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\ttime = 0; //to avoid occasional floating point rounding errors (could cause problems especially with zero-duration tweens at the very beginning of the timeline)\n\t\t\t\t\tif (!self._initted) {\n\t\t\t\t\t\tinternalForce = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t} else {\n\t\t\t\tif (dur === 0 && prevRawPrevTime < 0) { //without this, zero-duration repeating timelines (like with a simple callback nested at the very beginning and a repeatDelay) wouldn't render the first time through.\n\t\t\t\t\tinternalForce = true;\n\t\t\t\t}\n\t\t\t\tself._time = self._rawPrevTime = time;\n\t\t\t\tif (!self._locked) {\n\t\t\t\t\tself._totalTime = time;\n\t\t\t\t\tif (self._repeat !== 0) {\n\t\t\t\t\t\tcycleDuration = dur + self._repeatDelay;\n\t\t\t\t\t\tself._cycle = (self._totalTime / cycleDuration) >> 0; //originally _totalTime % cycleDuration but floating point errors caused problems, so I normalized it. (4 % 0.8 should be 0 but it gets reported as 0.79999999!)\n\t\t\t\t\t\tif (self._cycle) if (self._cycle === self._totalTime / cycleDuration && prevTotalTime <= time) {\n\t\t\t\t\t\t\tself._cycle--; //otherwise when rendered exactly at the end time, it will act as though it is repeating (at the beginning)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tself._time = self._totalTime - (self._cycle * cycleDuration);\n\t\t\t\t\t\tif (self._yoyo) if (self._cycle & 1) {\n\t\t\t\t\t\t\tself._time = dur - self._time;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (self._time > dur) {\n\t\t\t\t\t\t\tself._time = dur;\n\t\t\t\t\t\t\ttime = dur + 0.0001; //to avoid occasional floating point rounding error\n\t\t\t\t\t\t} else if (self._time < 0) {\n\t\t\t\t\t\t\tself._time = time = 0;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\ttime = self._time;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (self._hasPause && !self._forcingPlayhead && !suppressEvents) {\n\t\t\t\ttime = self._time;\n\t\t\t\tif (time > prevTime || (self._repeat && prevCycle !== self._cycle)) {\n\t\t\t\t\ttween = self._first;\n\t\t\t\t\twhile (tween && tween._startTime <= time && !pauseTween) {\n\t\t\t\t\t\tif (!tween._duration) if (tween.data === \"isPause\" && !tween.ratio && !(tween._startTime === 0 && self._rawPrevTime === 0)) {\n\t\t\t\t\t\t\tpauseTween = tween;\n\t\t\t\t\t\t}\n\t\t\t\t\t\ttween = tween._next;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\ttween = self._last;\n\t\t\t\t\twhile (tween && tween._startTime >= time && !pauseTween) {\n\t\t\t\t\t\tif (!tween._duration) if (tween.data === \"isPause\" && tween._rawPrevTime > 0) {\n\t\t\t\t\t\t\tpauseTween = tween;\n\t\t\t\t\t\t}\n\t\t\t\t\t\ttween = tween._prev;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (pauseTween) {\n\t\t\t\t\tpauseTime = self._startTime + (self._reversed ? self._duration - pauseTween._startTime : pauseTween._startTime) / self._timeScale;\n\t\t\t\t\tif (pauseTween._startTime < dur) {\n\t\t\t\t\t\tself._time = self._rawPrevTime = time = pauseTween._startTime;\n\t\t\t\t\t\tself._totalTime = time + (self._cycle * (self._totalDuration + self._repeatDelay));\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (self._cycle !== prevCycle) if (!self._locked) {\n\t\t\t\t/*\n\t\t\t\tmake sure children at the end/beginning of the timeline are rendered properly. If, for example,\n\t\t\t\ta 3-second long timeline rendered at 2.9 seconds previously, and now renders at 3.2 seconds (which\n\t\t\t\twould get translated to 2.8 seconds if the timeline yoyos or 0.2 seconds if it just repeats), there\n\t\t\t\tcould be a callback or a short tween that's at 2.95 or 3 seconds in which wouldn't render. So\n\t\t\t\twe need to push the timeline to the end (and/or beginning depending on its yoyo value). Also we must\n\t\t\t\tensure that zero-duration tweens at the very beginning or end of the TimelineMax work.\n\t\t\t\t*/\n\t\t\t\tvar backwards = (self._yoyo && (prevCycle & 1) !== 0),\n\t\t\t\t\twrap = (backwards === (self._yoyo && (self._cycle & 1) !== 0)),\n\t\t\t\t\trecTotalTime = self._totalTime,\n\t\t\t\t\trecCycle = self._cycle,\n\t\t\t\t\trecRawPrevTime = self._rawPrevTime,\n\t\t\t\t\trecTime = self._time;\n\n\t\t\t\tself._totalTime = prevCycle * dur;\n\t\t\t\tif (self._cycle < prevCycle) {\n\t\t\t\t\tbackwards = !backwards;\n\t\t\t\t} else {\n\t\t\t\t\tself._totalTime += dur;\n\t\t\t\t}\n\t\t\t\tself._time = prevTime; //temporarily revert _time so that render() renders the children in the correct order. Without this, tweens won't rewind correctly. We could arhictect things in a \"cleaner\" way by splitting out the rendering queue into a separate method but for performance reasons, we kept it all inside this method.\n\n\t\t\t\tself._rawPrevTime = (dur === 0) ? prevRawPrevTime - 0.0001 : prevRawPrevTime;\n\t\t\t\tself._cycle = prevCycle;\n\t\t\t\tself._locked = true; //prevents changes to totalTime and skips repeat/yoyo behavior when we recursively call render()\n\t\t\t\tprevTime = (backwards) ? 0 : dur;\n\t\t\t\tself.render(prevTime, suppressEvents, (dur === 0));\n\t\t\t\tif (!suppressEvents) if (!self._gc) {\n\t\t\t\t\tif (self.vars.onRepeat) {\n\t\t\t\t\t\tself._cycle = recCycle; //in case the onRepeat alters the playhead or invalidates(), we shouldn't stay locked or use the previous cycle.\n\t\t\t\t\t\tself._locked = false;\n\t\t\t\t\t\tself._callback(\"onRepeat\");\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (prevTime !== self._time) { //in case there's a callback like onComplete in a nested tween/timeline that changes the playhead position, like via seek(), we should just abort.\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tif (wrap) {\n\t\t\t\t\tself._cycle = prevCycle; //if there's an onRepeat, we reverted this above, so make sure it's set properly again. We also unlocked in that scenario, so reset that too.\n\t\t\t\t\tself._locked = true;\n\t\t\t\t\tprevTime = (backwards) ? dur + 0.0001 : -0.0001;\n\t\t\t\t\tself.render(prevTime, true, false);\n\t\t\t\t}\n\t\t\t\tself._locked = false;\n\t\t\t\tif (self._paused && !prevPaused) { //if the render() triggered callback that paused this timeline, we should abort (very rare, but possible)\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tself._time = recTime;\n\t\t\t\tself._totalTime = recTotalTime;\n\t\t\t\tself._cycle = recCycle;\n\t\t\t\tself._rawPrevTime = recRawPrevTime;\n\t\t\t}\n\n\t\t\tif ((self._time === prevTime || !self._first) && !force && !internalForce && !pauseTween) {\n\t\t\t\tif (prevTotalTime !== self._totalTime) if (self._onUpdate) if (!suppressEvents) { //so that onUpdate fires even during the repeatDelay - as long as the totalTime changed, we should trigger onUpdate.\n\t\t\t\t\tself._callback(\"onUpdate\");\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t} else if (!self._initted) {\n\t\t\t\tself._initted = true;\n\t\t\t}\n\n\t\t\tif (!self._active) if (!self._paused && self._totalTime !== prevTotalTime && time > 0) {\n\t\t\t\tself._active = true;  //so that if the user renders the timeline (as opposed to the parent timeline rendering it), it is forced to re-render and align it with the proper time/frame on the next rendering cycle. Maybe the timeline already finished but the user manually re-renders it as halfway done, for example.\n\t\t\t}\n\n\t\t\tif (prevTotalTime === 0) if (self.vars.onStart) if (self._totalTime !== 0 || !self._totalDuration) if (!suppressEvents) {\n\t\t\t\tself._callback(\"onStart\");\n\t\t\t}\n\n\t\t\tcurTime = self._time;\n\t\t\tif (curTime >= prevTime) {\n\t\t\t\ttween = self._first;\n\t\t\t\twhile (tween) {\n\t\t\t\t\tnext = tween._next; //record it here because the value could change after rendering...\n\t\t\t\t\tif (curTime !== self._time || (self._paused && !prevPaused)) { //in case a tween pauses or seeks the timeline when rendering, like inside of an onUpdate/onComplete\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t} else if (tween._active || (tween._startTime <= self._time && !tween._paused && !tween._gc)) {\n\t\t\t\t\t\tif (pauseTween === tween) {\n\t\t\t\t\t\t\tself.pause();\n\t\t\t\t\t\t\tself._pauseTime = pauseTime; //so that when we resume(), it's starting from exactly the right spot (the pause() method uses the rawTime for the parent, but that may be a bit too far ahead)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (!tween._reversed) {\n\t\t\t\t\t\t\ttween.render((time - tween._startTime) * tween._timeScale, suppressEvents, force);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\ttween.render(((!tween._dirty) ? tween._totalDuration : tween.totalDuration()) - ((time - tween._startTime) * tween._timeScale), suppressEvents, force);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\ttween = next;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\ttween = self._last;\n\t\t\t\twhile (tween) {\n\t\t\t\t\tnext = tween._prev; //record it here because the value could change after rendering...\n\t\t\t\t\tif (curTime !== self._time || (self._paused && !prevPaused)) { //in case a tween pauses or seeks the timeline when rendering, like inside of an onUpdate/onComplete\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t} else if (tween._active || (tween._startTime <= prevTime && !tween._paused && !tween._gc)) {\n\t\t\t\t\t\tif (pauseTween === tween) {\n\t\t\t\t\t\t\tpauseTween = tween._prev; //the linked list is organized by _startTime, thus it's possible that a tween could start BEFORE the pause and end after it, in which case it would be positioned before the pause tween in the linked list, but we should render it before we pause() the timeline and cease rendering. This is only a concern when going in reverse.\n\t\t\t\t\t\t\twhile (pauseTween && pauseTween.endTime() > self._time) {\n\t\t\t\t\t\t\t\tpauseTween.render( (pauseTween._reversed ? pauseTween.totalDuration() - ((time - pauseTween._startTime) * pauseTween._timeScale) : (time - pauseTween._startTime) * pauseTween._timeScale), suppressEvents, force);\n\t\t\t\t\t\t\t\tpauseTween = pauseTween._prev;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tpauseTween = null;\n\t\t\t\t\t\t\tself.pause();\n\t\t\t\t\t\t\tself._pauseTime = pauseTime; //so that when we resume(), it's starting from exactly the right spot (the pause() method uses the rawTime for the parent, but that may be a bit too far ahead)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (!tween._reversed) {\n\t\t\t\t\t\t\ttween.render((time - tween._startTime) * tween._timeScale, suppressEvents, force);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\ttween.render(((!tween._dirty) ? tween._totalDuration : tween.totalDuration()) - ((time - tween._startTime) * tween._timeScale), suppressEvents, force);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\ttween = next;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (self._onUpdate) if (!suppressEvents) {\n\t\t\t\tif (_lazyTweens.length) { //in case rendering caused any tweens to lazy-init, we should render them because typically when a timeline finishes, users expect things to have rendered fully. Imagine an onUpdate on a timeline that reports/checks tweened values.\n\t\t\t\t\t_lazyRender();\n\t\t\t\t}\n\t\t\t\tself._callback(\"onUpdate\");\n\t\t\t}\n\t\t\tif (callback) if (!self._locked) if (!self._gc) if (prevStart === self._startTime || prevTimeScale !== self._timeScale) if (self._time === 0 || totalDur >= self.totalDuration()) { //if one of the tweens that was rendered altered this timeline's startTime (like if an onComplete reversed the timeline), it probably isn't complete. If it is, don't worry, because whatever call altered the startTime would complete if it was necessary at the new time. The only exception is the timeScale property. Also check _gc because there's a chance that kill() could be called in an onUpdate\n\t\t\t\tif (isComplete) {\n\t\t\t\t\tif (_lazyTweens.length) { //in case rendering caused any tweens to lazy-init, we should render them because typically when a timeline finishes, users expect things to have rendered fully. Imagine an onComplete on a timeline that reports/checks tweened values.\n\t\t\t\t\t\t_lazyRender();\n\t\t\t\t\t}\n\t\t\t\t\tif (self._timeline.autoRemoveChildren) {\n\t\t\t\t\t\tself._enabled(false, false);\n\t\t\t\t\t}\n\t\t\t\t\tself._active = false;\n\t\t\t\t}\n\t\t\t\tif (!suppressEvents && self.vars[callback]) {\n\t\t\t\t\tself._callback(callback);\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\n\t\tp.getActive = function(nested, tweens, timelines) {\n\t\t\tvar a = [],\n\t\t\t\tall = this.getChildren(nested || (nested == null), tweens || (nested == null), !!timelines),\n\t\t\t\tcnt = 0,\n\t\t\t\tl = all.length,\n\t\t\t\ti, tween;\n\t\t\tfor (i = 0; i < l; i++) {\n\t\t\t\ttween = all[i];\n\t\t\t\tif (tween.isActive()) {\n\t\t\t\t\ta[cnt++] = tween;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn a;\n\t\t};\n\n\n\t\tp.getLabelAfter = function(time) {\n\t\t\tif (!time) if (time !== 0) { //faster than isNan()\n\t\t\t\ttime = this._time;\n\t\t\t}\n\t\t\tvar labels = this.getLabelsArray(),\n\t\t\t\tl = labels.length,\n\t\t\t\ti;\n\t\t\tfor (i = 0; i < l; i++) {\n\t\t\t\tif (labels[i].time > time) {\n\t\t\t\t\treturn labels[i].name;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn null;\n\t\t};\n\n\t\tp.getLabelBefore = function(time) {\n\t\t\tif (time == null) {\n\t\t\t\ttime = this._time;\n\t\t\t}\n\t\t\tvar labels = this.getLabelsArray(),\n\t\t\t\ti = labels.length;\n\t\t\twhile (--i > -1) {\n\t\t\t\tif (labels[i].time < time) {\n\t\t\t\t\treturn labels[i].name;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn null;\n\t\t};\n\n\t\tp.getLabelsArray = function() {\n\t\t\tvar a = [],\n\t\t\t\tcnt = 0,\n\t\t\t\tp;\n\t\t\tfor (p in this._labels) {\n\t\t\t\ta[cnt++] = {time:this._labels[p], name:p};\n\t\t\t}\n\t\t\ta.sort(function(a,b) {\n\t\t\t\treturn a.time - b.time;\n\t\t\t});\n\t\t\treturn a;\n\t\t};\n\n\t\tp.invalidate = function() {\n\t\t\tthis._locked = false; //unlock and set cycle in case invalidate() is called from inside an onRepeat\n\t\t\treturn _TimelineLite_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].prototype.invalidate.call(this);\n\t\t};\n\n\n//---- GETTERS / SETTERS -------------------------------------------------------------------------------------------------------\n\n\t\tp.progress = function(value, suppressEvents) {\n\t\t\treturn (!arguments.length) ? (this._time / this.duration()) || 0 : this.totalTime( this.duration() * ((this._yoyo && (this._cycle & 1) !== 0) ? 1 - value : value) + (this._cycle * (this._duration + this._repeatDelay)), suppressEvents);\n\t\t};\n\n\t\tp.totalProgress = function(value, suppressEvents) {\n\t\t\treturn (!arguments.length) ? (this._totalTime / this.totalDuration()) || 0 : this.totalTime( this.totalDuration() * value, suppressEvents);\n\t\t};\n\n\t\tp.totalDuration = function(value) {\n\t\t\tif (!arguments.length) {\n\t\t\t\tif (this._dirty) {\n\t\t\t\t\t_TimelineLite_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].prototype.totalDuration.call(this); //just forces refresh\n\t\t\t\t\t//Instead of Infinity, we use 999999999999 so that we can accommodate reverses.\n\t\t\t\t\tthis._totalDuration = (this._repeat === -1) ? 999999999999 : this._duration * (this._repeat + 1) + (this._repeatDelay * this._repeat);\n\t\t\t\t}\n\t\t\t\treturn this._totalDuration;\n\t\t\t}\n\t\t\treturn (this._repeat === -1 || !value) ? this : this.timeScale( this.totalDuration() / value );\n\t\t};\n\n\t\tp.time = function(value, suppressEvents) {\n\t\t\tif (!arguments.length) {\n\t\t\t\treturn this._time;\n\t\t\t}\n\t\t\tif (this._dirty) {\n\t\t\t\tthis.totalDuration();\n\t\t\t}\n\t\t\tvar duration = this._duration,\n\t\t\t\tcycle = this._cycle,\n\t\t\t\tcycleDur = cycle * (duration + this._repeatDelay);\n\t\t\tif (value > duration) {\n\t\t\t\tvalue = duration;\n\t\t\t}\n\t\t\treturn this.totalTime((this._yoyo && (cycle & 1)) ? duration - value + cycleDur : this._repeat ? value + cycleDur : value, suppressEvents);\n\t\t};\n\n\t\tp.repeat = function(value) {\n\t\t\tif (!arguments.length) {\n\t\t\t\treturn this._repeat;\n\t\t\t}\n\t\t\tthis._repeat = value;\n\t\t\treturn this._uncache(true);\n\t\t};\n\n\t\tp.repeatDelay = function(value) {\n\t\t\tif (!arguments.length) {\n\t\t\t\treturn this._repeatDelay;\n\t\t\t}\n\t\t\tthis._repeatDelay = value;\n\t\t\treturn this._uncache(true);\n\t\t};\n\n\t\tp.yoyo = function(value) {\n\t\t\tif (!arguments.length) {\n\t\t\t\treturn this._yoyo;\n\t\t\t}\n\t\t\tthis._yoyo = value;\n\t\t\treturn this;\n\t\t};\n\n\t\tp.currentLabel = function(value) {\n\t\t\tif (!arguments.length) {\n\t\t\t\treturn this.getLabelBefore(this._time + _tinyNum);\n\t\t\t}\n\t\t\treturn this.seek(value, true);\n\t\t};\n\t\t\n\t\treturn TimelineMax;\n\t\t\n\t}, true);\n\nvar TimelineMax = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"globals\"].TimelineMax;\n\n\n//# sourceURL=webpack:///./node_modules/gsap/TimelineMax.js?");

/***/ }),

/***/ "./node_modules/gsap/TweenLite.js":
/*!****************************************!*\
  !*** ./node_modules/gsap/TweenLite.js ***!
  \****************************************/
/*! exports provided: _gsScope, TweenLite, globals, default, SimpleTimeline, Animation, Ease, Linear, Power0, Power1, Power2, Power3, Power4, TweenPlugin, EventDispatcher */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* WEBPACK VAR INJECTION */(function(module, global) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"_gsScope\", function() { return _gsScope; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TweenLite\", function() { return TweenLite; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"globals\", function() { return globals; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"default\", function() { return TweenLite; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SimpleTimeline\", function() { return SimpleTimeline; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Animation\", function() { return Animation; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Ease\", function() { return Ease; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Linear\", function() { return Linear; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Power0\", function() { return Power0; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Power1\", function() { return Power1; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Power2\", function() { return Power2; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Power3\", function() { return Power3; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Power4\", function() { return Power4; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TweenPlugin\", function() { return TweenPlugin; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"EventDispatcher\", function() { return EventDispatcher; });\n/*!\n * VERSION: 2.1.3\n * DATE: 2019-05-17\n * UPDATES AND DOCS AT: http://greensock.com\n *\n * @license Copyright (c) 2008-2019, GreenSock. All rights reserved.\n * This work is subject to the terms at http://greensock.com/standard-license or for\n * Club GreenSock members, the software agreement that was issued with your membership.\n *\n * @author: Jack Doyle, jack@greensock.com\n */\n/* eslint-disable */\n\n/* ES6 changes:\n\t- declare and export _gsScope at top.\n\t- set var TweenLite = the result of the main function\n\t- export default TweenLite at the bottom\n\t- return TweenLite at the bottom of the main function\n\t- pass in _gsScope as the first parameter of the main function (which is actually at the bottom)\n\t- remove the \"export to multiple environments\" in Definition().\n */\nvar _gsScope = (typeof(window) !== \"undefined\") ? window : ( true && module.exports && typeof(global) !== \"undefined\") ? global : undefined || {};\n\nvar TweenLite = (function(window) {\n\n\t\t\"use strict\";\n\t\tvar _exports = {},\n\t\t\t_doc = window.document,\n\t\t\t_globals = window.GreenSockGlobals = window.GreenSockGlobals || window;\n\t\tif (_globals.TweenLite) {\n\t\t\treturn _globals.TweenLite; //in case the core set of classes is already loaded, don't instantiate twice.\n\t\t}\n\t\tvar _namespace = function(ns) {\n\t\t\t\tvar a = ns.split(\".\"),\n\t\t\t\t\tp = _globals, i;\n\t\t\t\tfor (i = 0; i < a.length; i++) {\n\t\t\t\t\tp[a[i]] = p = p[a[i]] || {};\n\t\t\t\t}\n\t\t\t\treturn p;\n\t\t\t},\n\t\t\tgs = _namespace(\"com.greensock\"),\n\t\t\t_tinyNum = 0.00000001,\n\t\t\t_slice = function(a) { //don't use Array.prototype.slice.call(target, 0) because that doesn't work in IE8 with a NodeList that's returned by querySelectorAll()\n\t\t\t\tvar b = [],\n\t\t\t\t\tl = a.length,\n\t\t\t\t\ti;\n\t\t\t\tfor (i = 0; i !== l; b.push(a[i++])) {}\n\t\t\t\treturn b;\n\t\t\t},\n\t\t\t_emptyFunc = function() {},\n\t\t\t_isArray = (function() { //works around issues in iframe environments where the Array global isn't shared, thus if the object originates in a different window/iframe, \"(obj instanceof Array)\" will evaluate false. We added some speed optimizations to avoid Object.prototype.toString.call() unless it's absolutely necessary because it's VERY slow (like 20x slower)\n\t\t\t\tvar toString = Object.prototype.toString,\n\t\t\t\t\tarray = toString.call([]);\n\t\t\t\treturn function(obj) {\n\t\t\t\t\treturn obj != null && (obj instanceof Array || (typeof(obj) === \"object\" && !!obj.push && toString.call(obj) === array));\n\t\t\t\t};\n\t\t\t}()),\n\t\t\ta, i, p, _ticker, _tickerActive,\n\t\t\t_defLookup = {},\n\n\t\t\t/**\n\t\t\t * @constructor\n\t\t\t * Defines a GreenSock class, optionally with an array of dependencies that must be instantiated first and passed into the definition.\n\t\t\t * This allows users to load GreenSock JS files in any order even if they have interdependencies (like CSSPlugin extends TweenPlugin which is\n\t\t\t * inside TweenLite.js, but if CSSPlugin is loaded first, it should wait to run its code until TweenLite.js loads and instantiates TweenPlugin\n\t\t\t * and then pass TweenPlugin to CSSPlugin's definition). This is all done automatically and internally.\n\t\t\t *\n\t\t\t * Every definition will be added to a \"com.greensock\" global object (typically window, but if a window.GreenSockGlobals object is found,\n\t\t\t * it will go there as of v1.7). For example, TweenLite will be found at window.com.greensock.TweenLite and since it's a global class that should be available anywhere,\n\t\t\t * it is ALSO referenced at window.TweenLite. However some classes aren't considered global, like the base com.greensock.core.Animation class, so\n\t\t\t * those will only be at the package like window.com.greensock.core.Animation. Again, if you define a GreenSockGlobals object on the window, everything\n\t\t\t * gets tucked neatly inside there instead of on the window directly. This allows you to do advanced things like load multiple versions of GreenSock\n\t\t\t * files and put them into distinct objects (imagine a banner ad uses a newer version but the main site uses an older one). In that case, you could\n\t\t\t * sandbox the banner one like:\n\t\t\t *\n\t\t\t * <script>\n\t\t\t *     var gs = window.GreenSockGlobals = {}; //the newer version we're about to load could now be referenced in a \"gs\" object, like gs.TweenLite.to(...). Use whatever alias you want as long as it's unique, \"gs\" or \"banner\" or whatever.\n\t\t\t * </script>\n\t\t\t * <script src=\"js/greensock/v1.7/TweenMax.js\"></script>\n\t\t\t * <script>\n\t\t\t *     window.GreenSockGlobals = window._gsQueue = window._gsDefine = null; //reset it back to null (along with the special _gsQueue variable) so that the next load of TweenMax affects the window and we can reference things directly like TweenLite.to(...)\n\t\t\t * </script>\n\t\t\t * <script src=\"js/greensock/v1.6/TweenMax.js\"></script>\n\t\t\t * <script>\n\t\t\t *     gs.TweenLite.to(...); //would use v1.7\n\t\t\t *     TweenLite.to(...); //would use v1.6\n\t\t\t * </script>\n\t\t\t *\n\t\t\t * @param {!string} ns The namespace of the class definition, leaving off \"com.greensock.\" as that's assumed. For example, \"TweenLite\" or \"plugins.CSSPlugin\" or \"easing.Back\".\n\t\t\t * @param {!Array.<string>} dependencies An array of dependencies (described as their namespaces minus \"com.greensock.\" prefix). For example [\"TweenLite\",\"plugins.TweenPlugin\",\"core.Animation\"]\n\t\t\t * @param {!function():Object} func The function that should be called and passed the resolved dependencies which will return the actual class for this definition.\n\t\t\t * @param {boolean=} global If true, the class will be added to the global scope (typically window unless you define a window.GreenSockGlobals object)\n\t\t\t */\n\t\t\tDefinition = function(ns, dependencies, func, global) {\n\t\t\t\tthis.sc = (_defLookup[ns]) ? _defLookup[ns].sc : []; //subclasses\n\t\t\t\t_defLookup[ns] = this;\n\t\t\t\tthis.gsClass = null;\n\t\t\t\tthis.func = func;\n\t\t\t\tvar _classes = [];\n\t\t\t\tthis.check = function(init) {\n\t\t\t\t\tvar i = dependencies.length,\n\t\t\t\t\t\tmissing = i,\n\t\t\t\t\t\tcur, a, n, cl;\n\t\t\t\t\twhile (--i > -1) {\n\t\t\t\t\t\tif ((cur = _defLookup[dependencies[i]] || new Definition(dependencies[i], [])).gsClass) {\n\t\t\t\t\t\t\t_classes[i] = cur.gsClass;\n\t\t\t\t\t\t\tmissing--;\n\t\t\t\t\t\t} else if (init) {\n\t\t\t\t\t\t\tcur.sc.push(this);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (missing === 0 && func) {\n\t\t\t\t\t\ta = (\"com.greensock.\" + ns).split(\".\");\n\t\t\t\t\t\tn = a.pop();\n\t\t\t\t\t\tcl = _namespace(a.join(\".\"))[n] = this.gsClass = func.apply(func, _classes);\n\n\t\t\t\t\t\t//exports to multiple environments\n\t\t\t\t\t\tif (global) {\n\t\t\t\t\t\t\t_globals[n] = _exports[n] = cl; //provides a way to avoid global namespace pollution. By default, the main classes like TweenLite, Power1, Strong, etc. are added to window unless a GreenSockGlobals is defined. So if you want to have things added to a custom object instead, just do something like window.GreenSockGlobals = {} before loading any GreenSock files. You can even set up an alias like window.GreenSockGlobals = windows.gs = {} so that you can access everything like gs.TweenLite. Also remember that ALL classes are added to the window.com.greensock object (in their respective packages, like com.greensock.easing.Power1, com.greensock.TweenLite, etc.)\n\t\t\t\t\t\t\t/*\n\t\t\t\t\t\t\tif (typeof(module) !== \"undefined\" && module.exports) { //node\n\t\t\t\t\t\t\t\tif (ns === moduleName) {\n\t\t\t\t\t\t\t\t\tmodule.exports = _exports[moduleName] = cl;\n\t\t\t\t\t\t\t\t\tfor (i in _exports) {\n\t\t\t\t\t\t\t\t\t\tcl[i] = _exports[i];\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t} else if (_exports[moduleName]) {\n\t\t\t\t\t\t\t\t\t_exports[moduleName][n] = cl;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t} else if (typeof(define) === \"function\" && define.amd){ //AMD\n\t\t\t\t\t\t\t\tdefine((window.GreenSockAMDPath ? window.GreenSockAMDPath + \"/\" : \"\") + ns.split(\".\").pop(), [], function() { return cl; });\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t*/\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfor (i = 0; i < this.sc.length; i++) {\n\t\t\t\t\t\t\tthis.sc[i].check();\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t};\n\t\t\t\tthis.check(true);\n\t\t\t},\n\n\t\t\t//used to create Definition instances (which basically registers a class that has dependencies).\n\t\t\t_gsDefine = window._gsDefine = function(ns, dependencies, func, global) {\n\t\t\t\treturn new Definition(ns, dependencies, func, global);\n\t\t\t},\n\n\t\t\t//a quick way to create a class that doesn't have any dependencies. Returns the class, but first registers it in the GreenSock namespace so that other classes can grab it (other classes might be dependent on the class).\n\t\t\t_class = gs._class = function(ns, func, global) {\n\t\t\t\tfunc = func || function() {};\n\t\t\t\t_gsDefine(ns, [], function(){ return func; }, global);\n\t\t\t\treturn func;\n\t\t\t};\n\n\t\t_gsDefine.globals = _globals;\n\n\n\n/*\n * ----------------------------------------------------------------\n * Ease\n * ----------------------------------------------------------------\n */\n\t\tvar _baseParams = [0, 0, 1, 1],\n\t\t\tEase = _class(\"easing.Ease\", function(func, extraParams, type, power) {\n\t\t\t\tthis._func = func;\n\t\t\t\tthis._type = type || 0;\n\t\t\t\tthis._power = power || 0;\n\t\t\t\tthis._params = extraParams ? _baseParams.concat(extraParams) : _baseParams;\n\t\t\t}, true),\n\t\t\t_easeMap = Ease.map = {},\n\t\t\t_easeReg = Ease.register = function(ease, names, types, create) {\n\t\t\t\tvar na = names.split(\",\"),\n\t\t\t\t\ti = na.length,\n\t\t\t\t\tta = (types || \"easeIn,easeOut,easeInOut\").split(\",\"),\n\t\t\t\t\te, name, j, type;\n\t\t\t\twhile (--i > -1) {\n\t\t\t\t\tname = na[i];\n\t\t\t\t\te = create ? _class(\"easing.\"+name, null, true) : gs.easing[name] || {};\n\t\t\t\t\tj = ta.length;\n\t\t\t\t\twhile (--j > -1) {\n\t\t\t\t\t\ttype = ta[j];\n\t\t\t\t\t\t_easeMap[name + \".\" + type] = _easeMap[type + name] = e[type] = ease.getRatio ? ease : ease[type] || new ease();\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\n\t\tp = Ease.prototype;\n\t\tp._calcEnd = false;\n\t\tp.getRatio = function(p) {\n\t\t\tif (this._func) {\n\t\t\t\tthis._params[0] = p;\n\t\t\t\treturn this._func.apply(null, this._params);\n\t\t\t}\n\t\t\tvar t = this._type,\n\t\t\t\tpw = this._power,\n\t\t\t\tr = (t === 1) ? 1 - p : (t === 2) ? p : (p < 0.5) ? p * 2 : (1 - p) * 2;\n\t\t\tif (pw === 1) {\n\t\t\t\tr *= r;\n\t\t\t} else if (pw === 2) {\n\t\t\t\tr *= r * r;\n\t\t\t} else if (pw === 3) {\n\t\t\t\tr *= r * r * r;\n\t\t\t} else if (pw === 4) {\n\t\t\t\tr *= r * r * r * r;\n\t\t\t}\n\t\t\treturn (t === 1) ? 1 - r : (t === 2) ? r : (p < 0.5) ? r / 2 : 1 - (r / 2);\n\t\t};\n\n\t\t//create all the standard eases like Linear, Quad, Cubic, Quart, Quint, Strong, Power0, Power1, Power2, Power3, and Power4 (each with easeIn, easeOut, and easeInOut)\n\t\ta = [\"Linear\",\"Quad\",\"Cubic\",\"Quart\",\"Quint,Strong\"];\n\t\ti = a.length;\n\t\twhile (--i > -1) {\n\t\t\tp = a[i]+\",Power\"+i;\n\t\t\t_easeReg(new Ease(null,null,1,i), p, \"easeOut\", true);\n\t\t\t_easeReg(new Ease(null,null,2,i), p, \"easeIn\" + ((i === 0) ? \",easeNone\" : \"\"));\n\t\t\t_easeReg(new Ease(null,null,3,i), p, \"easeInOut\");\n\t\t}\n\t\t_easeMap.linear = gs.easing.Linear.easeIn;\n\t\t_easeMap.swing = gs.easing.Quad.easeInOut; //for jQuery folks\n\n\n/*\n * ----------------------------------------------------------------\n * EventDispatcher\n * ----------------------------------------------------------------\n */\n\t\tvar EventDispatcher = _class(\"events.EventDispatcher\", function(target) {\n\t\t\tthis._listeners = {};\n\t\t\tthis._eventTarget = target || this;\n\t\t});\n\t\tp = EventDispatcher.prototype;\n\n\t\tp.addEventListener = function(type, callback, scope, useParam, priority) {\n\t\t\tpriority = priority || 0;\n\t\t\tvar list = this._listeners[type],\n\t\t\t\tindex = 0,\n\t\t\t\tlistener, i;\n\t\t\tif (this === _ticker && !_tickerActive) {\n\t\t\t\t_ticker.wake();\n\t\t\t}\n\t\t\tif (list == null) {\n\t\t\t\tthis._listeners[type] = list = [];\n\t\t\t}\n\t\t\ti = list.length;\n\t\t\twhile (--i > -1) {\n\t\t\t\tlistener = list[i];\n\t\t\t\tif (listener.c === callback && listener.s === scope) {\n\t\t\t\t\tlist.splice(i, 1);\n\t\t\t\t} else if (index === 0 && listener.pr < priority) {\n\t\t\t\t\tindex = i + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tlist.splice(index, 0, {c:callback, s:scope, up:useParam, pr:priority});\n\t\t};\n\n\t\tp.removeEventListener = function(type, callback) {\n\t\t\tvar list = this._listeners[type], i;\n\t\t\tif (list) {\n\t\t\t\ti = list.length;\n\t\t\t\twhile (--i > -1) {\n\t\t\t\t\tif (list[i].c === callback) {\n\t\t\t\t\t\tlist.splice(i, 1);\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\n\t\tp.dispatchEvent = function(type) {\n\t\t\tvar list = this._listeners[type],\n\t\t\t\ti, t, listener;\n\t\t\tif (list) {\n\t\t\t\ti = list.length;\n\t\t\t\tif (i > 1) {\n\t\t\t\t\tlist = list.slice(0); //in case addEventListener() is called from within a listener/callback (otherwise the index could change, resulting in a skip)\n\t\t\t\t}\n\t\t\t\tt = this._eventTarget;\n\t\t\t\twhile (--i > -1) {\n\t\t\t\t\tlistener = list[i];\n\t\t\t\t\tif (listener) {\n\t\t\t\t\t\tif (listener.up) {\n\t\t\t\t\t\t\tlistener.c.call(listener.s || t, {type:type, target:t});\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tlistener.c.call(listener.s || t);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\n\n/*\n * ----------------------------------------------------------------\n * Ticker\n * ----------------------------------------------------------------\n */\n \t\tvar _reqAnimFrame = window.requestAnimationFrame,\n\t\t\t_cancelAnimFrame = window.cancelAnimationFrame,\n\t\t\t_getTime = Date.now || function() {return new Date().getTime();},\n\t\t\t_lastUpdate = _getTime();\n\n\t\t//now try to determine the requestAnimationFrame and cancelAnimationFrame functions and if none are found, we'll use a setTimeout()/clearTimeout() polyfill.\n\t\ta = [\"ms\",\"moz\",\"webkit\",\"o\"];\n\t\ti = a.length;\n\t\twhile (--i > -1 && !_reqAnimFrame) {\n\t\t\t_reqAnimFrame = window[a[i] + \"RequestAnimationFrame\"];\n\t\t\t_cancelAnimFrame = window[a[i] + \"CancelAnimationFrame\"] || window[a[i] + \"CancelRequestAnimationFrame\"];\n\t\t}\n\n\t\t_class(\"Ticker\", function(fps, useRAF) {\n\t\t\tvar _self = this,\n\t\t\t\t_startTime = _getTime(),\n\t\t\t\t_useRAF = (useRAF !== false && _reqAnimFrame) ? \"auto\" : false,\n\t\t\t\t_lagThreshold = 500,\n\t\t\t\t_adjustedLag = 33,\n\t\t\t\t_tickWord = \"tick\", //helps reduce gc burden\n\t\t\t\t_fps, _req, _id, _gap, _nextTime,\n\t\t\t\t_tick = function(manual) {\n\t\t\t\t\tvar elapsed = _getTime() - _lastUpdate,\n\t\t\t\t\t\toverlap, dispatch;\n\t\t\t\t\tif (elapsed > _lagThreshold) {\n\t\t\t\t\t\t_startTime += elapsed - _adjustedLag;\n\t\t\t\t\t}\n\t\t\t\t\t_lastUpdate += elapsed;\n\t\t\t\t\t_self.time = (_lastUpdate - _startTime) / 1000;\n\t\t\t\t\toverlap = _self.time - _nextTime;\n\t\t\t\t\tif (!_fps || overlap > 0 || manual === true) {\n\t\t\t\t\t\t_self.frame++;\n\t\t\t\t\t\t_nextTime += overlap + (overlap >= _gap ? 0.004 : _gap - overlap);\n\t\t\t\t\t\tdispatch = true;\n\t\t\t\t\t}\n\t\t\t\t\tif (manual !== true) { //make sure the request is made before we dispatch the \"tick\" event so that timing is maintained. Otherwise, if processing the \"tick\" requires a bunch of time (like 15ms) and we're using a setTimeout() that's based on 16.7ms, it'd technically take 31.7ms between frames otherwise.\n\t\t\t\t\t\t_id = _req(_tick);\n\t\t\t\t\t}\n\t\t\t\t\tif (dispatch) {\n\t\t\t\t\t\t_self.dispatchEvent(_tickWord);\n\t\t\t\t\t}\n\t\t\t\t};\n\n\t\t\tEventDispatcher.call(_self);\n\t\t\t_self.time = _self.frame = 0;\n\t\t\t_self.tick = function() {\n\t\t\t\t_tick(true);\n\t\t\t};\n\n\t\t\t_self.lagSmoothing = function(threshold, adjustedLag) {\n\t\t\t\tif (!arguments.length) { //if lagSmoothing() is called with no arguments, treat it like a getter that returns a boolean indicating if it's enabled or not. This is purposely undocumented and is for internal use.\n\t\t\t\t\treturn (_lagThreshold < 1 / _tinyNum);\n\t\t\t\t}\n\t\t\t\t_lagThreshold = threshold || (1 / _tinyNum); //zero should be interpreted as basically unlimited\n\t\t\t\t_adjustedLag = Math.min(adjustedLag, _lagThreshold, 0);\n\t\t\t};\n\n\t\t\t_self.sleep = function() {\n\t\t\t\tif (_id == null) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tif (!_useRAF || !_cancelAnimFrame) {\n\t\t\t\t\tclearTimeout(_id);\n\t\t\t\t} else {\n\t\t\t\t\t_cancelAnimFrame(_id);\n\t\t\t\t}\n\t\t\t\t_req = _emptyFunc;\n\t\t\t\t_id = null;\n\t\t\t\tif (_self === _ticker) {\n\t\t\t\t\t_tickerActive = false;\n\t\t\t\t}\n\t\t\t};\n\n\t\t\t_self.wake = function(seamless) {\n\t\t\t\tif (_id !== null) {\n\t\t\t\t\t_self.sleep();\n\t\t\t\t} else if (seamless) {\n\t\t\t\t\t_startTime += -_lastUpdate + (_lastUpdate = _getTime());\n\t\t\t\t} else if (_self.frame > 10) { //don't trigger lagSmoothing if we're just waking up, and make sure that at least 10 frames have elapsed because of the iOS bug that we work around below with the 1.5-second setTimout().\n\t\t\t\t\t_lastUpdate = _getTime() - _lagThreshold + 5;\n\t\t\t\t}\n\t\t\t\t_req = (_fps === 0) ? _emptyFunc : (!_useRAF || !_reqAnimFrame) ? function(f) { return setTimeout(f, ((_nextTime - _self.time) * 1000 + 1) | 0); } : _reqAnimFrame;\n\t\t\t\tif (_self === _ticker) {\n\t\t\t\t\t_tickerActive = true;\n\t\t\t\t}\n\t\t\t\t_tick(2);\n\t\t\t};\n\n\t\t\t_self.fps = function(value) {\n\t\t\t\tif (!arguments.length) {\n\t\t\t\t\treturn _fps;\n\t\t\t\t}\n\t\t\t\t_fps = value;\n\t\t\t\t_gap = 1 / (_fps || 60);\n\t\t\t\t_nextTime = this.time + _gap;\n\t\t\t\t_self.wake();\n\t\t\t};\n\n\t\t\t_self.useRAF = function(value) {\n\t\t\t\tif (!arguments.length) {\n\t\t\t\t\treturn _useRAF;\n\t\t\t\t}\n\t\t\t\t_self.sleep();\n\t\t\t\t_useRAF = value;\n\t\t\t\t_self.fps(_fps);\n\t\t\t};\n\t\t\t_self.fps(fps);\n\n\t\t\t//a bug in iOS 6 Safari occasionally prevents the requestAnimationFrame from working initially, so we use a 1.5-second timeout that automatically falls back to setTimeout() if it senses this condition.\n\t\t\tsetTimeout(function() {\n\t\t\t\tif (_useRAF === \"auto\" && _self.frame < 5 && (_doc || {}).visibilityState !== \"hidden\") {\n\t\t\t\t\t_self.useRAF(false);\n\t\t\t\t}\n\t\t\t}, 1500);\n\t\t});\n\n\t\tp = gs.Ticker.prototype = new gs.events.EventDispatcher();\n\t\tp.constructor = gs.Ticker;\n\n\n/*\n * ----------------------------------------------------------------\n * Animation\n * ----------------------------------------------------------------\n */\n\t\tvar Animation = _class(\"core.Animation\", function(duration, vars) {\n\t\t\t\tthis.vars = vars = vars || {};\n\t\t\t\tthis._duration = this._totalDuration = duration || 0;\n\t\t\t\tthis._delay = Number(vars.delay) || 0;\n\t\t\t\tthis._timeScale = 1;\n\t\t\t\tthis._active = !!vars.immediateRender;\n\t\t\t\tthis.data = vars.data;\n\t\t\t\tthis._reversed = !!vars.reversed;\n\n\t\t\t\tif (!_rootTimeline) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tif (!_tickerActive) { //some browsers (like iOS 6 Safari) shut down JavaScript execution when the tab is disabled and they [occasionally] neglect to start up requestAnimationFrame again when returning - this code ensures that the engine starts up again properly.\n\t\t\t\t\t_ticker.wake();\n\t\t\t\t}\n\n\t\t\t\tvar tl = this.vars.useFrames ? _rootFramesTimeline : _rootTimeline;\n\t\t\t\ttl.add(this, tl._time);\n\n\t\t\t\tif (this.vars.paused) {\n\t\t\t\t\tthis.paused(true);\n\t\t\t\t}\n\t\t\t});\n\n\t\t_ticker = Animation.ticker = new gs.Ticker();\n\t\tp = Animation.prototype;\n\t\tp._dirty = p._gc = p._initted = p._paused = false;\n\t\tp._totalTime = p._time = 0;\n\t\tp._rawPrevTime = -1;\n\t\tp._next = p._last = p._onUpdate = p._timeline = p.timeline = null;\n\t\tp._paused = false;\n\n\n\t\t//some browsers (like iOS) occasionally drop the requestAnimationFrame event when the user switches to a different tab and then comes back again, so we use a 2-second setTimeout() to sense if/when that condition occurs and then wake() the ticker.\n\t\tvar _checkTimeout = function() {\n\t\t\t\tif (_tickerActive && _getTime() - _lastUpdate > 2000 && ((_doc || {}).visibilityState !== \"hidden\" || !_ticker.lagSmoothing())) { //note: if the tab is hidden, we should still wake if lagSmoothing has been disabled.\n\t\t\t\t\t_ticker.wake();\n\t\t\t\t}\n\t\t\t\tvar t = setTimeout(_checkTimeout, 2000);\n\t\t\t\tif (t.unref) {\n\t\t\t\t\t// allows a node process to exit even if the timeout’s callback hasn't been invoked. Without it, the node process could hang as this function is called every two seconds.\n\t\t\t\t\tt.unref();\n\t\t\t\t}\n\t\t\t};\n\t\t_checkTimeout();\n\n\n\t\tp.play = function(from, suppressEvents) {\n\t\t\tif (from != null) {\n\t\t\t\tthis.seek(from, suppressEvents);\n\t\t\t}\n\t\t\treturn this.reversed(false).paused(false);\n\t\t};\n\n\t\tp.pause = function(atTime, suppressEvents) {\n\t\t\tif (atTime != null) {\n\t\t\t\tthis.seek(atTime, suppressEvents);\n\t\t\t}\n\t\t\treturn this.paused(true);\n\t\t};\n\n\t\tp.resume = function(from, suppressEvents) {\n\t\t\tif (from != null) {\n\t\t\t\tthis.seek(from, suppressEvents);\n\t\t\t}\n\t\t\treturn this.paused(false);\n\t\t};\n\n\t\tp.seek = function(time, suppressEvents) {\n\t\t\treturn this.totalTime(Number(time), suppressEvents !== false);\n\t\t};\n\n\t\tp.restart = function(includeDelay, suppressEvents) {\n\t\t\treturn this.reversed(false).paused(false).totalTime(includeDelay ? -this._delay : 0, (suppressEvents !== false), true);\n\t\t};\n\n\t\tp.reverse = function(from, suppressEvents) {\n\t\t\tif (from != null) {\n\t\t\t\tthis.seek((from || this.totalDuration()), suppressEvents);\n\t\t\t}\n\t\t\treturn this.reversed(true).paused(false);\n\t\t};\n\n\t\tp.render = function(time, suppressEvents, force) {\n\t\t\t//stub - we override this method in subclasses.\n\t\t};\n\n\t\tp.invalidate = function() {\n\t\t\tthis._time = this._totalTime = 0;\n\t\t\tthis._initted = this._gc = false;\n\t\t\tthis._rawPrevTime = -1;\n\t\t\tif (this._gc || !this.timeline) {\n\t\t\t\tthis._enabled(true);\n\t\t\t}\n\t\t\treturn this;\n\t\t};\n\n\t\tp.isActive = function() {\n\t\t\tvar tl = this._timeline, //the 2 root timelines won't have a _timeline; they're always active.\n\t\t\t\tstartTime = this._startTime,\n\t\t\t\trawTime;\n\t\t\treturn (!tl || (!this._gc && !this._paused && tl.isActive() && (rawTime = tl.rawTime(true)) >= startTime && rawTime < startTime + this.totalDuration() / this._timeScale - _tinyNum));\n\t\t};\n\n\t\tp._enabled = function (enabled, ignoreTimeline) {\n\t\t\tif (!_tickerActive) {\n\t\t\t\t_ticker.wake();\n\t\t\t}\n\t\t\tthis._gc = !enabled;\n\t\t\tthis._active = this.isActive();\n\t\t\tif (ignoreTimeline !== true) {\n\t\t\t\tif (enabled && !this.timeline) {\n\t\t\t\t\tthis._timeline.add(this, this._startTime - this._delay);\n\t\t\t\t} else if (!enabled && this.timeline) {\n\t\t\t\t\tthis._timeline._remove(this, true);\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn false;\n\t\t};\n\n\n\t\tp._kill = function(vars, target) {\n\t\t\treturn this._enabled(false, false);\n\t\t};\n\n\t\tp.kill = function(vars, target) {\n\t\t\tthis._kill(vars, target);\n\t\t\treturn this;\n\t\t};\n\n\t\tp._uncache = function(includeSelf) {\n\t\t\tvar tween = includeSelf ? this : this.timeline;\n\t\t\twhile (tween) {\n\t\t\t\ttween._dirty = true;\n\t\t\t\ttween = tween.timeline;\n\t\t\t}\n\t\t\treturn this;\n\t\t};\n\n\t\tp._swapSelfInParams = function(params) {\n\t\t\tvar i = params.length,\n\t\t\t\tcopy = params.concat();\n\t\t\twhile (--i > -1) {\n\t\t\t\tif (params[i] === \"{self}\") {\n\t\t\t\t\tcopy[i] = this;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn copy;\n\t\t};\n\n\t\tp._callback = function(type) {\n\t\t\tvar v = this.vars,\n\t\t\t\tcallback = v[type],\n\t\t\t\tparams = v[type + \"Params\"],\n\t\t\t\tscope = v[type + \"Scope\"] || v.callbackScope || this,\n\t\t\t\tl = params ? params.length : 0;\n\t\t\tswitch (l) { //speed optimization; call() is faster than apply() so use it when there are only a few parameters (which is by far most common). Previously we simply did var v = this.vars; v[type].apply(v[type + \"Scope\"] || v.callbackScope || this, v[type + \"Params\"] || _blankArray);\n\t\t\t\tcase 0: callback.call(scope); break;\n\t\t\t\tcase 1: callback.call(scope, params[0]); break;\n\t\t\t\tcase 2: callback.call(scope, params[0], params[1]); break;\n\t\t\t\tdefault: callback.apply(scope, params);\n\t\t\t}\n\t\t};\n\n//----Animation getters/setters --------------------------------------------------------\n\n\t\tp.eventCallback = function(type, callback, params, scope) {\n\t\t\tif ((type || \"\").substr(0,2) === \"on\") {\n\t\t\t\tvar v = this.vars;\n\t\t\t\tif (arguments.length === 1) {\n\t\t\t\t\treturn v[type];\n\t\t\t\t}\n\t\t\t\tif (callback == null) {\n\t\t\t\t\tdelete v[type];\n\t\t\t\t} else {\n\t\t\t\t\tv[type] = callback;\n\t\t\t\t\tv[type + \"Params\"] = (_isArray(params) && params.join(\"\").indexOf(\"{self}\") !== -1) ? this._swapSelfInParams(params) : params;\n\t\t\t\t\tv[type + \"Scope\"] = scope;\n\t\t\t\t}\n\t\t\t\tif (type === \"onUpdate\") {\n\t\t\t\t\tthis._onUpdate = callback;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn this;\n\t\t};\n\n\t\tp.delay = function(value) {\n\t\t\tif (!arguments.length) {\n\t\t\t\treturn this._delay;\n\t\t\t}\n\t\t\tif (this._timeline.smoothChildTiming) {\n\t\t\t\tthis.startTime( this._startTime + value - this._delay );\n\t\t\t}\n\t\t\tthis._delay = value;\n\t\t\treturn this;\n\t\t};\n\n\t\tp.duration = function(value) {\n\t\t\tif (!arguments.length) {\n\t\t\t\tthis._dirty = false;\n\t\t\t\treturn this._duration;\n\t\t\t}\n\t\t\tthis._duration = this._totalDuration = value;\n\t\t\tthis._uncache(true); //true in case it's a TweenMax or TimelineMax that has a repeat - we'll need to refresh the totalDuration.\n\t\t\tif (this._timeline.smoothChildTiming) if (this._time > 0) if (this._time < this._duration) if (value !== 0) {\n\t\t\t\tthis.totalTime(this._totalTime * (value / this._duration), true);\n\t\t\t}\n\t\t\treturn this;\n\t\t};\n\n\t\tp.totalDuration = function(value) {\n\t\t\tthis._dirty = false;\n\t\t\treturn (!arguments.length) ? this._totalDuration : this.duration(value);\n\t\t};\n\n\t\tp.time = function(value, suppressEvents) {\n\t\t\tif (!arguments.length) {\n\t\t\t\treturn this._time;\n\t\t\t}\n\t\t\tif (this._dirty) {\n\t\t\t\tthis.totalDuration();\n\t\t\t}\n\t\t\treturn this.totalTime((value > this._duration) ? this._duration : value, suppressEvents);\n\t\t};\n\n\t\tp.totalTime = function(time, suppressEvents, uncapped) {\n\t\t\tif (!_tickerActive) {\n\t\t\t\t_ticker.wake();\n\t\t\t}\n\t\t\tif (!arguments.length) {\n\t\t\t\treturn this._totalTime;\n\t\t\t}\n\t\t\tif (this._timeline) {\n\t\t\t\tif (time < 0 && !uncapped) {\n\t\t\t\t\ttime += this.totalDuration();\n\t\t\t\t}\n\t\t\t\tif (this._timeline.smoothChildTiming) {\n\t\t\t\t\tif (this._dirty) {\n\t\t\t\t\t\tthis.totalDuration();\n\t\t\t\t\t}\n\t\t\t\t\tvar totalDuration = this._totalDuration,\n\t\t\t\t\t\ttl = this._timeline;\n\t\t\t\t\tif (time > totalDuration && !uncapped) {\n\t\t\t\t\t\ttime = totalDuration;\n\t\t\t\t\t}\n\t\t\t\t\tthis._startTime = (this._paused ? this._pauseTime : tl._time) - ((!this._reversed ? time : totalDuration - time) / this._timeScale);\n\t\t\t\t\tif (!tl._dirty) { //for performance improvement. If the parent's cache is already dirty, it already took care of marking the ancestors as dirty too, so skip the function call here.\n\t\t\t\t\t\tthis._uncache(false);\n\t\t\t\t\t}\n\t\t\t\t\t//in case any of the ancestor timelines had completed but should now be enabled, we should reset their totalTime() which will also ensure that they're lined up properly and enabled. Skip for animations that are on the root (wasteful). Example: a TimelineLite.exportRoot() is performed when there's a paused tween on the root, the export will not complete until that tween is unpaused, but imagine a child gets restarted later, after all [unpaused] tweens have completed. The startTime of that child would get pushed out, but one of the ancestors may have completed.\n\t\t\t\t\tif (tl._timeline) {\n\t\t\t\t\t\twhile (tl._timeline) {\n\t\t\t\t\t\t\tif (tl._timeline._time !== (tl._startTime + tl._totalTime) / tl._timeScale) {\n\t\t\t\t\t\t\t\ttl.totalTime(tl._totalTime, true);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\ttl = tl._timeline;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (this._gc) {\n\t\t\t\t\tthis._enabled(true, false);\n\t\t\t\t}\n\t\t\t\tif (this._totalTime !== time || this._duration === 0) {\n\t\t\t\t\tif (_lazyTweens.length) {\n\t\t\t\t\t\t_lazyRender();\n\t\t\t\t\t}\n\t\t\t\t\tthis.render(time, suppressEvents, false);\n\t\t\t\t\tif (_lazyTweens.length) { //in case rendering caused any tweens to lazy-init, we should render them because typically when someone calls seek() or time() or progress(), they expect an immediate render.\n\t\t\t\t\t\t_lazyRender();\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn this;\n\t\t};\n\n\t\tp.progress = p.totalProgress = function(value, suppressEvents) {\n\t\t\tvar duration = this.duration();\n\t\t\treturn (!arguments.length) ? (duration ? this._time / duration : this.ratio) : this.totalTime(duration * value, suppressEvents);\n\t\t};\n\n\t\tp.startTime = function(value) {\n\t\t\tif (!arguments.length) {\n\t\t\t\treturn this._startTime;\n\t\t\t}\n\t\t\tif (value !== this._startTime) {\n\t\t\t\tthis._startTime = value;\n\t\t\t\tif (this.timeline) if (this.timeline._sortChildren) {\n\t\t\t\t\tthis.timeline.add(this, value - this._delay); //ensures that any necessary re-sequencing of Animations in the timeline occurs to make sure the rendering order is correct.\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn this;\n\t\t};\n\n\t\tp.endTime = function(includeRepeats) {\n\t\t\treturn this._startTime + ((includeRepeats != false) ? this.totalDuration() : this.duration()) / this._timeScale;\n\t\t};\n\n\t\tp.timeScale = function(value) {\n\t\t\tif (!arguments.length) {\n\t\t\t\treturn this._timeScale;\n\t\t\t}\n\t\t\tvar pauseTime, t;\n\t\t\tvalue = value || _tinyNum; //can't allow zero because it'll throw the math off\n\t\t\tif (this._timeline && this._timeline.smoothChildTiming) {\n\t\t\t\tpauseTime = this._pauseTime;\n\t\t\t\tt = (pauseTime || pauseTime === 0) ? pauseTime : this._timeline.totalTime();\n\t\t\t\tthis._startTime = t - ((t - this._startTime) * this._timeScale / value);\n\t\t\t}\n\t\t\tthis._timeScale = value;\n\t\t\tt = this.timeline;\n\t\t\twhile (t && t.timeline) { //must update the duration/totalDuration of all ancestor timelines immediately in case in the middle of a render loop, one tween alters another tween's timeScale which shoves its startTime before 0, forcing the parent timeline to shift around and shiftChildren() which could affect that next tween's render (startTime). Doesn't matter for the root timeline though.\n\t\t\t\tt._dirty = true;\n\t\t\t\tt.totalDuration();\n\t\t\t\tt = t.timeline;\n\t\t\t}\n\t\t\treturn this;\n\t\t};\n\n\t\tp.reversed = function(value) {\n\t\t\tif (!arguments.length) {\n\t\t\t\treturn this._reversed;\n\t\t\t}\n\t\t\tif (value != this._reversed) {\n\t\t\t\tthis._reversed = value;\n\t\t\t\tthis.totalTime(((this._timeline && !this._timeline.smoothChildTiming) ? this.totalDuration() - this._totalTime : this._totalTime), true);\n\t\t\t}\n\t\t\treturn this;\n\t\t};\n\n\t\tp.paused = function(value) {\n\t\t\tif (!arguments.length) {\n\t\t\t\treturn this._paused;\n\t\t\t}\n\t\t\tvar tl = this._timeline,\n\t\t\t\traw, elapsed;\n\t\t\tif (value != this._paused) if (tl) {\n\t\t\t\tif (!_tickerActive && !value) {\n\t\t\t\t\t_ticker.wake();\n\t\t\t\t}\n\t\t\t\traw = tl.rawTime();\n\t\t\t\telapsed = raw - this._pauseTime;\n\t\t\t\tif (!value && tl.smoothChildTiming) {\n\t\t\t\t\tthis._startTime += elapsed;\n\t\t\t\t\tthis._uncache(false);\n\t\t\t\t}\n\t\t\t\tthis._pauseTime = value ? raw : null;\n\t\t\t\tthis._paused = value;\n\t\t\t\tthis._active = this.isActive();\n\t\t\t\tif (!value && elapsed !== 0 && this._initted && this.duration()) {\n\t\t\t\t\traw = tl.smoothChildTiming ? this._totalTime : (raw - this._startTime) / this._timeScale;\n\t\t\t\t\tthis.render(raw, (raw === this._totalTime), true); //in case the target's properties changed via some other tween or manual update by the user, we should force a render.\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (this._gc && !value) {\n\t\t\t\tthis._enabled(true, false);\n\t\t\t}\n\t\t\treturn this;\n\t\t};\n\n\n/*\n * ----------------------------------------------------------------\n * SimpleTimeline\n * ----------------------------------------------------------------\n */\n\t\tvar SimpleTimeline = _class(\"core.SimpleTimeline\", function(vars) {\n\t\t\tAnimation.call(this, 0, vars);\n\t\t\tthis.autoRemoveChildren = this.smoothChildTiming = true;\n\t\t});\n\n\t\tp = SimpleTimeline.prototype = new Animation();\n\t\tp.constructor = SimpleTimeline;\n\t\tp.kill()._gc = false;\n\t\tp._first = p._last = p._recent = null;\n\t\tp._sortChildren = false;\n\n\t\tp.add = p.insert = function(child, position, align, stagger) {\n\t\t\tvar prevTween, st;\n\t\t\tchild._startTime = Number(position || 0) + child._delay;\n\t\t\tif (child._paused) if (this !== child._timeline) { //we only adjust the _pauseTime if it wasn't in this timeline already. Remember, sometimes a tween will be inserted again into the same timeline when its startTime is changed so that the tweens in the TimelineLite/Max are re-ordered properly in the linked list (so everything renders in the proper order).\n\t\t\t\tchild._pauseTime = this.rawTime() - (child._timeline.rawTime() - child._pauseTime);\n\t\t\t}\n\t\t\tif (child.timeline) {\n\t\t\t\tchild.timeline._remove(child, true); //removes from existing timeline so that it can be properly added to this one.\n\t\t\t}\n\t\t\tchild.timeline = child._timeline = this;\n\t\t\tif (child._gc) {\n\t\t\t\tchild._enabled(true, true);\n\t\t\t}\n\t\t\tprevTween = this._last;\n\t\t\tif (this._sortChildren) {\n\t\t\t\tst = child._startTime;\n\t\t\t\twhile (prevTween && prevTween._startTime > st) {\n\t\t\t\t\tprevTween = prevTween._prev;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (prevTween) {\n\t\t\t\tchild._next = prevTween._next;\n\t\t\t\tprevTween._next = child;\n\t\t\t} else {\n\t\t\t\tchild._next = this._first;\n\t\t\t\tthis._first = child;\n\t\t\t}\n\t\t\tif (child._next) {\n\t\t\t\tchild._next._prev = child;\n\t\t\t} else {\n\t\t\t\tthis._last = child;\n\t\t\t}\n\t\t\tchild._prev = prevTween;\n\t\t\tthis._recent = child;\n\t\t\tif (this._timeline) {\n\t\t\t\tthis._uncache(true);\n\t\t\t}\n\t\t\treturn this;\n\t\t};\n\n\t\tp._remove = function(tween, skipDisable) {\n\t\t\tif (tween.timeline === this) {\n\t\t\t\tif (!skipDisable) {\n\t\t\t\t\ttween._enabled(false, true);\n\t\t\t\t}\n\n\t\t\t\tif (tween._prev) {\n\t\t\t\t\ttween._prev._next = tween._next;\n\t\t\t\t} else if (this._first === tween) {\n\t\t\t\t\tthis._first = tween._next;\n\t\t\t\t}\n\t\t\t\tif (tween._next) {\n\t\t\t\t\ttween._next._prev = tween._prev;\n\t\t\t\t} else if (this._last === tween) {\n\t\t\t\t\tthis._last = tween._prev;\n\t\t\t\t}\n\t\t\t\ttween._next = tween._prev = tween.timeline = null;\n\t\t\t\tif (tween === this._recent) {\n\t\t\t\t\tthis._recent = this._last;\n\t\t\t\t}\n\n\t\t\t\tif (this._timeline) {\n\t\t\t\t\tthis._uncache(true);\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn this;\n\t\t};\n\n\t\tp.render = function(time, suppressEvents, force) {\n\t\t\tvar tween = this._first,\n\t\t\t\tnext;\n\t\t\tthis._totalTime = this._time = this._rawPrevTime = time;\n\t\t\twhile (tween) {\n\t\t\t\tnext = tween._next; //record it here because the value could change after rendering...\n\t\t\t\tif (tween._active || (time >= tween._startTime && !tween._paused && !tween._gc)) {\n\t\t\t\t\tif (!tween._reversed) {\n\t\t\t\t\t\ttween.render((time - tween._startTime) * tween._timeScale, suppressEvents, force);\n\t\t\t\t\t} else {\n\t\t\t\t\t\ttween.render(((!tween._dirty) ? tween._totalDuration : tween.totalDuration()) - ((time - tween._startTime) * tween._timeScale), suppressEvents, force);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ttween = next;\n\t\t\t}\n\t\t};\n\n\t\tp.rawTime = function() {\n\t\t\tif (!_tickerActive) {\n\t\t\t\t_ticker.wake();\n\t\t\t}\n\t\t\treturn this._totalTime;\n\t\t};\n\n/*\n * ----------------------------------------------------------------\n * TweenLite\n * ----------------------------------------------------------------\n */\n\t\tvar TweenLite = _class(\"TweenLite\", function(target, duration, vars) {\n\t\t\t\tAnimation.call(this, duration, vars);\n\t\t\t\tthis.render = TweenLite.prototype.render; //speed optimization (avoid prototype lookup on this \"hot\" method)\n\n\t\t\t\tif (target == null) {\n\t\t\t\t\tthrow \"Cannot tween a null target.\";\n\t\t\t\t}\n\n\t\t\t\tthis.target = target = (typeof(target) !== \"string\") ? target : TweenLite.selector(target) || target;\n\n\t\t\t\tvar isSelector = (target.jquery || (target.length && target !== window && target[0] && (target[0] === window || (target[0].nodeType && target[0].style && !target.nodeType)))),\n\t\t\t\t\toverwrite = this.vars.overwrite,\n\t\t\t\t\ti, targ, targets;\n\n\t\t\t\tthis._overwrite = overwrite = (overwrite == null) ? _overwriteLookup[TweenLite.defaultOverwrite] : (typeof(overwrite) === \"number\") ? overwrite >> 0 : _overwriteLookup[overwrite];\n\n\t\t\t\tif ((isSelector || target instanceof Array || (target.push && _isArray(target))) && typeof(target[0]) !== \"number\") {\n\t\t\t\t\tthis._targets = targets = _slice(target);  //don't use Array.prototype.slice.call(target, 0) because that doesn't work in IE8 with a NodeList that's returned by querySelectorAll()\n\t\t\t\t\tthis._propLookup = [];\n\t\t\t\t\tthis._siblings = [];\n\t\t\t\t\tfor (i = 0; i < targets.length; i++) {\n\t\t\t\t\t\ttarg = targets[i];\n\t\t\t\t\t\tif (!targ) {\n\t\t\t\t\t\t\ttargets.splice(i--, 1);\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t} else if (typeof(targ) === \"string\") {\n\t\t\t\t\t\t\ttarg = targets[i--] = TweenLite.selector(targ); //in case it's an array of strings\n\t\t\t\t\t\t\tif (typeof(targ) === \"string\") {\n\t\t\t\t\t\t\t\ttargets.splice(i+1, 1); //to avoid an endless loop (can't imagine why the selector would return a string, but just in case)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t} else if (targ.length && targ !== window && targ[0] && (targ[0] === window || (targ[0].nodeType && targ[0].style && !targ.nodeType))) { //in case the user is passing in an array of selector objects (like jQuery objects), we need to check one more level and pull things out if necessary. Also note that <select> elements pass all the criteria regarding length and the first child having style, so we must also check to ensure the target isn't an HTML node itself.\n\t\t\t\t\t\t\ttargets.splice(i--, 1);\n\t\t\t\t\t\t\tthis._targets = targets = targets.concat(_slice(targ));\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tthis._siblings[i] = _register(targ, this, false);\n\t\t\t\t\t\tif (overwrite === 1) if (this._siblings[i].length > 1) {\n\t\t\t\t\t\t\t_applyOverwrite(targ, this, null, 1, this._siblings[i]);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t} else {\n\t\t\t\t\tthis._propLookup = {};\n\t\t\t\t\tthis._siblings = _register(target, this, false);\n\t\t\t\t\tif (overwrite === 1) if (this._siblings.length > 1) {\n\t\t\t\t\t\t_applyOverwrite(target, this, null, 1, this._siblings);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (this.vars.immediateRender || (duration === 0 && this._delay === 0 && this.vars.immediateRender !== false)) {\n\t\t\t\t\tthis._time = -_tinyNum; //forces a render without having to set the render() \"force\" parameter to true because we want to allow lazying by default (using the \"force\" parameter always forces an immediate full render)\n\t\t\t\t\tthis.render(Math.min(0, -this._delay)); //in case delay is negative\n\t\t\t\t}\n\t\t\t}, true),\n\t\t\t_isSelector = function(v) {\n\t\t\t\treturn (v && v.length && v !== window && v[0] && (v[0] === window || (v[0].nodeType && v[0].style && !v.nodeType))); //we cannot check \"nodeType\" if the target is window from within an iframe, otherwise it will trigger a security error in some browsers like Firefox.\n\t\t\t},\n\t\t\t_autoCSS = function(vars, target) {\n\t\t\t\tvar css = {},\n\t\t\t\t\tp;\n\t\t\t\tfor (p in vars) {\n\t\t\t\t\tif (!_reservedProps[p] && (!(p in target) || p === \"transform\" || p === \"x\" || p === \"y\" || p === \"width\" || p === \"height\" || p === \"className\" || p === \"border\") && (!_plugins[p] || (_plugins[p] && _plugins[p]._autoCSS))) { //note: <img> elements contain read-only \"x\" and \"y\" properties. We should also prioritize editing css width/height rather than the element's properties.\n\t\t\t\t\t\tcss[p] = vars[p];\n\t\t\t\t\t\tdelete vars[p];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tvars.css = css;\n\t\t\t};\n\n\t\tp = TweenLite.prototype = new Animation();\n\t\tp.constructor = TweenLite;\n\t\tp.kill()._gc = false;\n\n//----TweenLite defaults, overwrite management, and root updates ----------------------------------------------------\n\n\t\tp.ratio = 0;\n\t\tp._firstPT = p._targets = p._overwrittenProps = p._startAt = null;\n\t\tp._notifyPluginsOfEnabled = p._lazy = false;\n\n\t\tTweenLite.version = \"2.1.3\";\n\t\tTweenLite.defaultEase = p._ease = new Ease(null, null, 1, 1);\n\t\tTweenLite.defaultOverwrite = \"auto\";\n\t\tTweenLite.ticker = _ticker;\n\t\tTweenLite.autoSleep = 120;\n\t\tTweenLite.lagSmoothing = function(threshold, adjustedLag) {\n\t\t\t_ticker.lagSmoothing(threshold, adjustedLag);\n\t\t};\n\n\t\tTweenLite.selector = window.$ || window.jQuery || function(e) {\n\t\t\tvar selector = window.$ || window.jQuery;\n\t\t\tif (selector) {\n\t\t\t\tTweenLite.selector = selector;\n\t\t\t\treturn selector(e);\n\t\t\t}\n\t\t\tif (!_doc) { //in some dev environments (like Angular 6), GSAP gets loaded before the document is defined! So re-query it here if/when necessary.\n\t\t\t\t_doc = window.document;\n\t\t\t}\n\t\t\treturn (!_doc) ? e : (_doc.querySelectorAll ? _doc.querySelectorAll(e) : _doc.getElementById((e.charAt(0) === \"#\") ? e.substr(1) : e));\n\t\t};\n\n\t\tvar _lazyTweens = [],\n\t\t\t_lazyLookup = {},\n\t\t\t_numbersExp = /(?:(-|-=|\\+=)?\\d*\\.?\\d*(?:e[\\-+]?\\d+)?)[0-9]/ig,\n\t\t\t_relExp = /[\\+-]=-?[\\.\\d]/,\n\t\t\t//_nonNumbersExp = /(?:([\\-+](?!(\\d|=)))|[^\\d\\-+=e]|(e(?![\\-+][\\d])))+/ig,\n\t\t\t_setRatio = function(v) {\n\t\t\t\tvar pt = this._firstPT,\n\t\t\t\t\tmin = 0.000001,\n\t\t\t\t\tval;\n\t\t\t\twhile (pt) {\n\t\t\t\t\tval = !pt.blob ? pt.c * v + pt.s : (v === 1 && this.end != null) ? this.end : v ? this.join(\"\") : this.start;\n\t\t\t\t\tif (pt.m) {\n\t\t\t\t\t\tval = pt.m.call(this._tween, val, this._target || pt.t, this._tween);\n\t\t\t\t\t} else if (val < min) if (val > -min && !pt.blob) { //prevents issues with converting very small numbers to strings in the browser\n\t\t\t\t\t\tval = 0;\n\t\t\t\t\t}\n\t\t\t\t\tif (!pt.f) {\n\t\t\t\t\t\tpt.t[pt.p] = val;\n\t\t\t\t\t} else if (pt.fp) {\n\t\t\t\t\t\tpt.t[pt.p](pt.fp, val);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tpt.t[pt.p](val);\n\t\t\t\t\t}\n\t\t\t\t\tpt = pt._next;\n\t\t\t\t}\n\t\t\t},\n\t\t\t_blobRound = function(v) {\n\t\t\t\treturn (((v * 1000) | 0) / 1000) + \"\";\n\t\t\t},\n\t\t\t//compares two strings (start/end), finds the numbers that are different and spits back an array representing the whole value but with the changing values isolated as elements. For example, \"rgb(0,0,0)\" and \"rgb(100,50,0)\" would become [\"rgb(\", 0, \",\", 50, \",0)\"]. Notice it merges the parts that are identical (performance optimization). The array also has a linked list of PropTweens attached starting with _firstPT that contain the tweening data (t, p, s, c, f, etc.). It also stores the starting value as a \"start\" property so that we can revert to it if/when necessary, like when a tween rewinds fully. If the quantity of numbers differs between the start and end, it will always prioritize the end value(s). The pt parameter is optional - it's for a PropTween that will be appended to the end of the linked list and is typically for actually setting the value after all of the elements have been updated (with array.join(\"\")).\n\t\t\t_blobDif = function(start, end, filter, pt) {\n\t\t\t\tvar a = [],\n\t\t\t\t\tcharIndex = 0,\n\t\t\t\t\ts = \"\",\n\t\t\t\t\tcolor = 0,\n\t\t\t\t\tstartNums, endNums, num, i, l, nonNumbers, currentNum;\n\t\t\t\ta.start = start;\n\t\t\t\ta.end = end;\n\t\t\t\tstart = a[0] = start + \"\"; //ensure values are strings\n\t\t\t\tend = a[1] = end + \"\";\n\t\t\t\tif (filter) {\n\t\t\t\t\tfilter(a); //pass an array with the starting and ending values and let the filter do whatever it needs to the values.\n\t\t\t\t\tstart = a[0];\n\t\t\t\t\tend = a[1];\n\t\t\t\t}\n\t\t\t\ta.length = 0;\n\t\t\t\tstartNums = start.match(_numbersExp) || [];\n\t\t\t\tendNums = end.match(_numbersExp) || [];\n\t\t\t\tif (pt) {\n\t\t\t\t\tpt._next = null;\n\t\t\t\t\tpt.blob = 1;\n\t\t\t\t\ta._firstPT = a._applyPT = pt; //apply last in the linked list (which means inserting it first)\n\t\t\t\t}\n\t\t\t\tl = endNums.length;\n\t\t\t\tfor (i = 0; i < l; i++) {\n\t\t\t\t\tcurrentNum = endNums[i];\n\t\t\t\t\tnonNumbers = end.substr(charIndex, end.indexOf(currentNum, charIndex)-charIndex);\n\t\t\t\t\ts += (nonNumbers || !i) ? nonNumbers : \",\"; //note: SVG spec allows omission of comma/space when a negative sign is wedged between two numbers, like 2.5-5.3 instead of 2.5,-5.3 but when tweening, the negative value may switch to positive, so we insert the comma just in case.\n\t\t\t\t\tcharIndex += nonNumbers.length;\n\t\t\t\t\tif (color) { //sense rgba() values and round them.\n\t\t\t\t\t\tcolor = (color + 1) % 5;\n\t\t\t\t\t} else if (nonNumbers.substr(-5) === \"rgba(\") {\n\t\t\t\t\t\tcolor = 1;\n\t\t\t\t\t}\n\t\t\t\t\tif (currentNum === startNums[i] || startNums.length <= i) {\n\t\t\t\t\t\ts += currentNum;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif (s) {\n\t\t\t\t\t\t\ta.push(s);\n\t\t\t\t\t\t\ts = \"\";\n\t\t\t\t\t\t}\n\t\t\t\t\t\tnum = parseFloat(startNums[i]);\n\t\t\t\t\t\ta.push(num);\n\t\t\t\t\t\ta._firstPT = {_next: a._firstPT, t:a, p: a.length-1, s:num, c:((currentNum.charAt(1) === \"=\") ? parseInt(currentNum.charAt(0) + \"1\", 10) * parseFloat(currentNum.substr(2)) : (parseFloat(currentNum) - num)) || 0, f:0, m:(color && color < 4) ? Math.round : _blobRound}; //limiting to 3 decimal places and casting as a string can really help performance when array.join() is called!\n\t\t\t\t\t\t//note: we don't set _prev because we'll never need to remove individual PropTweens from this list.\n\t\t\t\t\t}\n\t\t\t\t\tcharIndex += currentNum.length;\n\t\t\t\t}\n\t\t\t\ts += end.substr(charIndex);\n\t\t\t\tif (s) {\n\t\t\t\t\ta.push(s);\n\t\t\t\t}\n\t\t\t\ta.setRatio = _setRatio;\n\t\t\t\tif (_relExp.test(end)) { //if the end string contains relative values, delete it so that on the final render (in _setRatio()), we don't actually set it to the string with += or -= characters (forces it to use the calculated value).\n\t\t\t\t\ta.end = null;\n\t\t\t\t}\n\t\t\t\treturn a;\n\t\t\t},\n\t\t\t//note: \"funcParam\" is only necessary for function-based getters/setters that require an extra parameter like getAttribute(\"width\") and setAttribute(\"width\", value). In this example, funcParam would be \"width\". Used by AttrPlugin for example.\n\t\t\t_addPropTween = function(target, prop, start, end, overwriteProp, mod, funcParam, stringFilter, index) {\n\t\t\t\tif (typeof(end) === \"function\") {\n\t\t\t\t\tend = end(index || 0, target);\n\t\t\t\t}\n\t\t\t\tvar type = typeof(target[prop]),\n\t\t\t\t\tgetterName = (type !== \"function\") ? \"\" : ((prop.indexOf(\"set\") || typeof(target[\"get\" + prop.substr(3)]) !== \"function\") ? prop : \"get\" + prop.substr(3)),\n\t\t\t\t\ts = (start !== \"get\") ? start : !getterName ? target[prop] : funcParam ? target[getterName](funcParam) : target[getterName](),\n\t\t\t\t\tisRelative = (typeof(end) === \"string\" && end.charAt(1) === \"=\"),\n\t\t\t\t\tpt = {t:target, p:prop, s:s, f:(type === \"function\"), pg:0, n:overwriteProp || prop, m:(!mod ? 0 : (typeof(mod) === \"function\") ? mod : Math.round), pr:0, c:isRelative ? parseInt(end.charAt(0) + \"1\", 10) * parseFloat(end.substr(2)) : (parseFloat(end) - s) || 0},\n\t\t\t\t\tblob;\n\n\t\t\t\tif (typeof(s) !== \"number\" || (typeof(end) !== \"number\" && !isRelative)) {\n\t\t\t\t\tif (funcParam || isNaN(s) || (!isRelative && isNaN(end)) || typeof(s) === \"boolean\" || typeof(end) === \"boolean\") {\n\t\t\t\t\t\t//a blob (string that has multiple numbers in it)\n\t\t\t\t\t\tpt.fp = funcParam;\n\t\t\t\t\t\tblob = _blobDif(s, (isRelative ? (parseFloat(pt.s) + pt.c) + (pt.s + \"\").replace(/[0-9\\-\\.]/g, \"\") : end), stringFilter || TweenLite.defaultStringFilter, pt);\n\t\t\t\t\t\tpt = {t: blob, p: \"setRatio\", s: 0, c: 1, f: 2, pg: 0, n: overwriteProp || prop, pr: 0, m: 0}; //\"2\" indicates it's a Blob property tween. Needed for RoundPropsPlugin for example.\n\t\t\t\t\t} else {\n\t\t\t\t\t\tpt.s = parseFloat(s);\n\t\t\t\t\t\tif (!isRelative) {\n\t\t\t\t\t\t\tpt.c = (parseFloat(end) - pt.s) || 0;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (pt.c) { //only add it to the linked list if there's a change.\n\t\t\t\t\tif ((pt._next = this._firstPT)) {\n\t\t\t\t\t\tpt._next._prev = pt;\n\t\t\t\t\t}\n\t\t\t\t\tthis._firstPT = pt;\n\t\t\t\t\treturn pt;\n\t\t\t\t}\n\t\t\t},\n\t\t\t_internals = TweenLite._internals = {isArray:_isArray, isSelector:_isSelector, lazyTweens:_lazyTweens, blobDif:_blobDif}, //gives us a way to expose certain private values to other GreenSock classes without contaminating tha main TweenLite object.\n\t\t\t_plugins = TweenLite._plugins = {},\n\t\t\t_tweenLookup = _internals.tweenLookup = {},\n\t\t\t_tweenLookupNum = 0,\n\t\t\t_reservedProps = _internals.reservedProps = {ease:1, delay:1, overwrite:1, onComplete:1, onCompleteParams:1, onCompleteScope:1, useFrames:1, runBackwards:1, startAt:1, onUpdate:1, onUpdateParams:1, onUpdateScope:1, onStart:1, onStartParams:1, onStartScope:1, onReverseComplete:1, onReverseCompleteParams:1, onReverseCompleteScope:1, onRepeat:1, onRepeatParams:1, onRepeatScope:1, easeParams:1, yoyo:1, immediateRender:1, repeat:1, repeatDelay:1, data:1, paused:1, reversed:1, autoCSS:1, lazy:1, onOverwrite:1, callbackScope:1, stringFilter:1, id:1, yoyoEase:1, stagger:1},\n\t\t\t_overwriteLookup = {none:0, all:1, auto:2, concurrent:3, allOnStart:4, preexisting:5, \"true\":1, \"false\":0},\n\t\t\t_rootFramesTimeline = Animation._rootFramesTimeline = new SimpleTimeline(),\n\t\t\t_rootTimeline = Animation._rootTimeline = new SimpleTimeline(),\n\t\t\t_nextGCFrame = 30,\n\t\t\t_lazyRender = _internals.lazyRender = function() {\n\t\t\t\tvar l = _lazyTweens.length,\n\t\t\t\t\ti, tween;\n\t\t\t\t_lazyLookup = {};\n\t\t\t\tfor (i = 0; i < l; i++) {\n\t\t\t\t\ttween = _lazyTweens[i];\n\t\t\t\t\tif (tween && tween._lazy !== false) {\n\t\t\t\t\t\ttween.render(tween._lazy[0], tween._lazy[1], true);\n\t\t\t\t\t\ttween._lazy = false;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t_lazyTweens.length = 0;\n\t\t\t};\n\n\t\t_rootTimeline._startTime = _ticker.time;\n\t\t_rootFramesTimeline._startTime = _ticker.frame;\n\t\t_rootTimeline._active = _rootFramesTimeline._active = true;\n\t\tsetTimeout(_lazyRender, 1); //on some mobile devices, there isn't a \"tick\" before code runs which means any lazy renders wouldn't run before the next official \"tick\".\n\n\t\tAnimation._updateRoot = TweenLite.render = function() {\n\t\t\t\tvar i, a, p;\n\t\t\t\tif (_lazyTweens.length) { //if code is run outside of the requestAnimationFrame loop, there may be tweens queued AFTER the engine refreshed, so we need to ensure any pending renders occur before we refresh again.\n\t\t\t\t\t_lazyRender();\n\t\t\t\t}\n\t\t\t\t_rootTimeline.render((_ticker.time - _rootTimeline._startTime) * _rootTimeline._timeScale, false, false);\n\t\t\t\t_rootFramesTimeline.render((_ticker.frame - _rootFramesTimeline._startTime) * _rootFramesTimeline._timeScale, false, false);\n\t\t\t\tif (_lazyTweens.length) {\n\t\t\t\t\t_lazyRender();\n\t\t\t\t}\n\t\t\t\tif (_ticker.frame >= _nextGCFrame) { //dump garbage every 120 frames or whatever the user sets TweenLite.autoSleep to\n\t\t\t\t\t_nextGCFrame = _ticker.frame + (parseInt(TweenLite.autoSleep, 10) || 120);\n\t\t\t\t\tfor (p in _tweenLookup) {\n\t\t\t\t\t\ta = _tweenLookup[p].tweens;\n\t\t\t\t\t\ti = a.length;\n\t\t\t\t\t\twhile (--i > -1) {\n\t\t\t\t\t\t\tif (a[i]._gc) {\n\t\t\t\t\t\t\t\ta.splice(i, 1);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (a.length === 0) {\n\t\t\t\t\t\t\tdelete _tweenLookup[p];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t//if there are no more tweens in the root timelines, or if they're all paused, make the _timer sleep to reduce load on the CPU slightly\n\t\t\t\t\tp = _rootTimeline._first;\n\t\t\t\t\tif (!p || p._paused) if (TweenLite.autoSleep && !_rootFramesTimeline._first && _ticker._listeners.tick.length === 1) {\n\t\t\t\t\t\twhile (p && p._paused) {\n\t\t\t\t\t\t\tp = p._next;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (!p) {\n\t\t\t\t\t\t\t_ticker.sleep();\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\n\t\t_ticker.addEventListener(\"tick\", Animation._updateRoot);\n\n\t\tvar _register = function(target, tween, scrub) {\n\t\t\t\tvar id = target._gsTweenID, a, i;\n\t\t\t\tif (!_tweenLookup[id || (target._gsTweenID = id = \"t\" + (_tweenLookupNum++))]) {\n\t\t\t\t\t_tweenLookup[id] = {target:target, tweens:[]};\n\t\t\t\t}\n\t\t\t\tif (tween) {\n\t\t\t\t\ta = _tweenLookup[id].tweens;\n\t\t\t\t\ta[(i = a.length)] = tween;\n\t\t\t\t\tif (scrub) {\n\t\t\t\t\t\twhile (--i > -1) {\n\t\t\t\t\t\t\tif (a[i] === tween) {\n\t\t\t\t\t\t\t\ta.splice(i, 1);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn _tweenLookup[id].tweens;\n\t\t\t},\n\t\t\t_onOverwrite = function(overwrittenTween, overwritingTween, target, killedProps) {\n\t\t\t\tvar func = overwrittenTween.vars.onOverwrite, r1, r2;\n\t\t\t\tif (func) {\n\t\t\t\t\tr1 = func(overwrittenTween, overwritingTween, target, killedProps);\n\t\t\t\t}\n\t\t\t\tfunc = TweenLite.onOverwrite;\n\t\t\t\tif (func) {\n\t\t\t\t\tr2 = func(overwrittenTween, overwritingTween, target, killedProps);\n\t\t\t\t}\n\t\t\t\treturn (r1 !== false && r2 !== false);\n\t\t\t},\n\t\t\t_applyOverwrite = function(target, tween, props, mode, siblings) {\n\t\t\t\tvar i, changed, curTween, l;\n\t\t\t\tif (mode === 1 || mode >= 4) {\n\t\t\t\t\tl = siblings.length;\n\t\t\t\t\tfor (i = 0; i < l; i++) {\n\t\t\t\t\t\tif ((curTween = siblings[i]) !== tween) {\n\t\t\t\t\t\t\tif (!curTween._gc) {\n\t\t\t\t\t\t\t\tif (curTween._kill(null, target, tween)) {\n\t\t\t\t\t\t\t\t\tchanged = true;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} else if (mode === 5) {\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn changed;\n\t\t\t\t}\n\t\t\t\t//NOTE: Add tiny amount to overcome floating point errors that can cause the startTime to be VERY slightly off (when a tween's time() is set for example)\n\t\t\t\tvar startTime = tween._startTime + _tinyNum,\n\t\t\t\t\toverlaps = [],\n\t\t\t\t\toCount = 0,\n\t\t\t\t\tzeroDur = (tween._duration === 0),\n\t\t\t\t\tglobalStart;\n\t\t\t\ti = siblings.length;\n\t\t\t\twhile (--i > -1) {\n\t\t\t\t\tif ((curTween = siblings[i]) === tween || curTween._gc || curTween._paused) {\n\t\t\t\t\t\t//ignore\n\t\t\t\t\t} else if (curTween._timeline !== tween._timeline) {\n\t\t\t\t\t\tglobalStart = globalStart || _checkOverlap(tween, 0, zeroDur);\n\t\t\t\t\t\tif (_checkOverlap(curTween, globalStart, zeroDur) === 0) {\n\t\t\t\t\t\t\toverlaps[oCount++] = curTween;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (curTween._startTime <= startTime) if (curTween._startTime + curTween.totalDuration() / curTween._timeScale > startTime) if (!((zeroDur || !curTween._initted) && startTime - curTween._startTime <= _tinyNum * 2)) {\n\t\t\t\t\t\toverlaps[oCount++] = curTween;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ti = oCount;\n\t\t\t\twhile (--i > -1) {\n\t\t\t\t\tcurTween = overlaps[i];\n\t\t\t\t\tl = curTween._firstPT; //we need to discern if there were property tweens originally; if they all get removed in the next line's _kill() call, the tween should be killed. See https://github.com/greensock/GreenSock-JS/issues/278\n\t\t\t\t\tif (mode === 2) if (curTween._kill(props, target, tween)) {\n\t\t\t\t\t\tchanged = true;\n\t\t\t\t\t}\n\t\t\t\t\tif (mode !== 2 || (!curTween._firstPT && curTween._initted && l)) {\n\t\t\t\t\t\tif (mode !== 2 && !_onOverwrite(curTween, tween)) {\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (curTween._enabled(false, false)) { //if all property tweens have been overwritten, kill the tween.\n\t\t\t\t\t\t\tchanged = true;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn changed;\n\t\t\t},\n\t\t\t_checkOverlap = function(tween, reference, zeroDur) {\n\t\t\t\tvar tl = tween._timeline,\n\t\t\t\t\tts = tl._timeScale,\n\t\t\t\t\tt = tween._startTime;\n\t\t\t\twhile (tl._timeline) {\n\t\t\t\t\tt += tl._startTime;\n\t\t\t\t\tts *= tl._timeScale;\n\t\t\t\t\tif (tl._paused) {\n\t\t\t\t\t\treturn -100;\n\t\t\t\t\t}\n\t\t\t\t\ttl = tl._timeline;\n\t\t\t\t}\n\t\t\t\tt /= ts;\n\t\t\t\treturn (t > reference) ? t - reference : ((zeroDur && t === reference) || (!tween._initted && t - reference < 2 * _tinyNum)) ? _tinyNum : ((t += tween.totalDuration() / tween._timeScale / ts) > reference + _tinyNum) ? 0 : t - reference - _tinyNum;\n\t\t\t};\n\n\n//---- TweenLite instance methods -----------------------------------------------------------------------------\n\n\t\tp._init = function() {\n\t\t\tvar v = this.vars,\n\t\t\t\top = this._overwrittenProps,\n\t\t\t\tdur = this._duration,\n\t\t\t\timmediate = !!v.immediateRender,\n\t\t\t\tease = v.ease,\n\t\t\t\tstartAt = this._startAt,\n\t\t\t\ti, initPlugins, pt, p, startVars, l;\n\t\t\tif (v.startAt) {\n\t\t\t\tif (startAt) {\n\t\t\t\t\tstartAt.render(-1, true); //if we've run a startAt previously (when the tween instantiated), we should revert it so that the values re-instantiate correctly particularly for relative tweens. Without this, a TweenLite.fromTo(obj, 1, {x:\"+=100\"}, {x:\"-=100\"}), for example, would actually jump to +=200 because the startAt would run twice, doubling the relative change.\n\t\t\t\t\tstartAt.kill();\n\t\t\t\t}\n\t\t\t\tstartVars = {};\n\t\t\t\tfor (p in v.startAt) { //copy the properties/values into a new object to avoid collisions, like var to = {x:0}, from = {x:500}; timeline.fromTo(e, 1, from, to).fromTo(e, 1, to, from);\n\t\t\t\t\tstartVars[p] = v.startAt[p];\n\t\t\t\t}\n\t\t\t\tstartVars.data = \"isStart\";\n\t\t\t\tstartVars.overwrite = false;\n\t\t\t\tstartVars.immediateRender = true;\n\t\t\t\tstartVars.lazy = (immediate && v.lazy !== false);\n\t\t\t\tstartVars.startAt = startVars.delay = null; //no nesting of startAt objects allowed (otherwise it could cause an infinite loop).\n\t\t\t\tstartVars.onUpdate = v.onUpdate;\n\t\t\t\tstartVars.onUpdateParams = v.onUpdateParams;\n\t\t\t\tstartVars.onUpdateScope = v.onUpdateScope || v.callbackScope || this;\n\t\t\t\tthis._startAt = TweenLite.to(this.target || {}, 0, startVars);\n\t\t\t\tif (immediate) {\n\t\t\t\t\tif (this._time > 0) {\n\t\t\t\t\t\tthis._startAt = null; //tweens that render immediately (like most from() and fromTo() tweens) shouldn't revert when their parent timeline's playhead goes backward past the startTime because the initial render could have happened anytime and it shouldn't be directly correlated to this tween's startTime. Imagine setting up a complex animation where the beginning states of various objects are rendered immediately but the tween doesn't happen for quite some time - if we revert to the starting values as soon as the playhead goes backward past the tween's startTime, it will throw things off visually. Reversion should only happen in TimelineLite/Max instances where immediateRender was false (which is the default in the convenience methods like from()).\n\t\t\t\t\t} else if (dur !== 0) {\n\t\t\t\t\t\treturn; //we skip initialization here so that overwriting doesn't occur until the tween actually begins. Otherwise, if you create several immediateRender:true tweens of the same target/properties to drop into a TimelineLite or TimelineMax, the last one created would overwrite the first ones because they didn't get placed into the timeline yet before the first render occurs and kicks in overwriting.\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else if (v.runBackwards && dur !== 0) {\n\t\t\t\t//from() tweens must be handled uniquely: their beginning values must be rendered but we don't want overwriting to occur yet (when time is still 0). Wait until the tween actually begins before doing all the routines like overwriting. At that time, we should render at the END of the tween to ensure that things initialize correctly (remember, from() tweens go backwards)\n\t\t\t\tif (startAt) {\n\t\t\t\t\tstartAt.render(-1, true);\n\t\t\t\t\tstartAt.kill();\n\t\t\t\t\tthis._startAt = null;\n\t\t\t\t} else {\n\t\t\t\t\tif (this._time !== 0) { //in rare cases (like if a from() tween runs and then is invalidate()-ed), immediateRender could be true but the initial forced-render gets skipped, so there's no need to force the render in this context when the _time is greater than 0\n\t\t\t\t\t\timmediate = false;\n\t\t\t\t\t}\n\t\t\t\t\tpt = {};\n\t\t\t\t\tfor (p in v) { //copy props into a new object and skip any reserved props, otherwise onComplete or onUpdate or onStart could fire. We should, however, permit autoCSS to go through.\n\t\t\t\t\t\tif (!_reservedProps[p] || p === \"autoCSS\") {\n\t\t\t\t\t\t\tpt[p] = v[p];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tpt.overwrite = 0;\n\t\t\t\t\tpt.data = \"isFromStart\"; //we tag the tween with as \"isFromStart\" so that if [inside a plugin] we need to only do something at the very END of a tween, we have a way of identifying this tween as merely the one that's setting the beginning values for a \"from()\" tween. For example, clearProps in CSSPlugin should only get applied at the very END of a tween and without this tag, from(...{height:100, clearProps:\"height\", delay:1}) would wipe the height at the beginning of the tween and after 1 second, it'd kick back in.\n\t\t\t\t\tpt.lazy = (immediate && v.lazy !== false);\n\t\t\t\t\tpt.immediateRender = immediate; //zero-duration tweens render immediately by default, but if we're not specifically instructed to render this tween immediately, we should skip this and merely _init() to record the starting values (rendering them immediately would push them to completion which is wasteful in that case - we'd have to render(-1) immediately after)\n\t\t\t\t\tthis._startAt = TweenLite.to(this.target, 0, pt);\n\t\t\t\t\tif (!immediate) {\n\t\t\t\t\t\tthis._startAt._init(); //ensures that the initial values are recorded\n\t\t\t\t\t\tthis._startAt._enabled(false); //no need to have the tween render on the next cycle. Disable it because we'll always manually control the renders of the _startAt tween.\n\t\t\t\t\t\tif (this.vars.immediateRender) {\n\t\t\t\t\t\t\tthis._startAt = null;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (this._time === 0) {\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tthis._ease = ease = (!ease) ? TweenLite.defaultEase : (ease instanceof Ease) ? ease : (typeof(ease) === \"function\") ? new Ease(ease, v.easeParams) : _easeMap[ease] || TweenLite.defaultEase;\n\t\t\tif (v.easeParams instanceof Array && ease.config) {\n\t\t\t\tthis._ease = ease.config.apply(ease, v.easeParams);\n\t\t\t}\n\t\t\tthis._easeType = this._ease._type;\n\t\t\tthis._easePower = this._ease._power;\n\t\t\tthis._firstPT = null;\n\n\t\t\tif (this._targets) {\n\t\t\t\tl = this._targets.length;\n\t\t\t\tfor (i = 0; i < l; i++) {\n\t\t\t\t\tif ( this._initProps( this._targets[i], (this._propLookup[i] = {}), this._siblings[i], (op ? op[i] : null), i) ) {\n\t\t\t\t\t\tinitPlugins = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tinitPlugins = this._initProps(this.target, this._propLookup, this._siblings, op, 0);\n\t\t\t}\n\n\t\t\tif (initPlugins) {\n\t\t\t\tTweenLite._onPluginEvent(\"_onInitAllProps\", this); //reorders the array in order of priority. Uses a static TweenPlugin method in order to minimize file size in TweenLite\n\t\t\t}\n\t\t\tif (op) if (!this._firstPT) if (typeof(this.target) !== \"function\") { //if all tweening properties have been overwritten, kill the tween. If the target is a function, it's probably a delayedCall so let it live.\n\t\t\t\tthis._enabled(false, false);\n\t\t\t}\n\t\t\tif (v.runBackwards) {\n\t\t\t\tpt = this._firstPT;\n\t\t\t\twhile (pt) {\n\t\t\t\t\tpt.s += pt.c;\n\t\t\t\t\tpt.c = -pt.c;\n\t\t\t\t\tpt = pt._next;\n\t\t\t\t}\n\t\t\t}\n\t\t\tthis._onUpdate = v.onUpdate;\n\t\t\tthis._initted = true;\n\t\t};\n\n\t\tp._initProps = function(target, propLookup, siblings, overwrittenProps, index) {\n\t\t\tvar p, i, initPlugins, plugin, pt, v;\n\t\t\tif (target == null) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tif (_lazyLookup[target._gsTweenID]) {\n\t\t\t\t_lazyRender(); //if other tweens of the same target have recently initted but haven't rendered yet, we've got to force the render so that the starting values are correct (imagine populating a timeline with a bunch of sequential tweens and then jumping to the end)\n\t\t\t}\n\n\t\t\tif (!this.vars.css) if (target.style) if (target !== window && target.nodeType) if (_plugins.css) if (this.vars.autoCSS !== false) { //it's so common to use TweenLite/Max to animate the css of DOM elements, we assume that if the target is a DOM element, that's what is intended (a convenience so that users don't have to wrap things in css:{}, although we still recommend it for a slight performance boost and better specificity). Note: we cannot check \"nodeType\" on the window inside an iframe.\n\t\t\t\t_autoCSS(this.vars, target);\n\t\t\t}\n\t\t\tfor (p in this.vars) {\n\t\t\t\tv = this.vars[p];\n\t\t\t\tif (_reservedProps[p]) {\n\t\t\t\t\tif (v) if ((v instanceof Array) || (v.push && _isArray(v))) if (v.join(\"\").indexOf(\"{self}\") !== -1) {\n\t\t\t\t\t\tthis.vars[p] = v = this._swapSelfInParams(v, this);\n\t\t\t\t\t}\n\n\t\t\t\t} else if (_plugins[p] && (plugin = new _plugins[p]())._onInitTween(target, this.vars[p], this, index)) {\n\n\t\t\t\t\t//t - target \t\t[object]\n\t\t\t\t\t//p - property \t\t[string]\n\t\t\t\t\t//s - start\t\t\t[number]\n\t\t\t\t\t//c - change\t\t[number]\n\t\t\t\t\t//f - isFunction\t[boolean]\n\t\t\t\t\t//n - name\t\t\t[string]\n\t\t\t\t\t//pg - isPlugin \t[boolean]\n\t\t\t\t\t//pr - priority\t\t[number]\n\t\t\t\t\t//m - mod           [function | 0]\n\t\t\t\t\tthis._firstPT = pt = {_next:this._firstPT, t:plugin, p:\"setRatio\", s:0, c:1, f:1, n:p, pg:1, pr:plugin._priority, m:0};\n\t\t\t\t\ti = plugin._overwriteProps.length;\n\t\t\t\t\twhile (--i > -1) {\n\t\t\t\t\t\tpropLookup[plugin._overwriteProps[i]] = this._firstPT;\n\t\t\t\t\t}\n\t\t\t\t\tif (plugin._priority || plugin._onInitAllProps) {\n\t\t\t\t\t\tinitPlugins = true;\n\t\t\t\t\t}\n\t\t\t\t\tif (plugin._onDisable || plugin._onEnable) {\n\t\t\t\t\t\tthis._notifyPluginsOfEnabled = true;\n\t\t\t\t\t}\n\t\t\t\t\tif (pt._next) {\n\t\t\t\t\t\tpt._next._prev = pt;\n\t\t\t\t\t}\n\n\t\t\t\t} else {\n\t\t\t\t\tpropLookup[p] = _addPropTween.call(this, target, p, \"get\", v, p, 0, null, this.vars.stringFilter, index);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (overwrittenProps) if (this._kill(overwrittenProps, target)) { //another tween may have tried to overwrite properties of this tween before init() was called (like if two tweens start at the same time, the one created second will run first)\n\t\t\t\treturn this._initProps(target, propLookup, siblings, overwrittenProps, index);\n\t\t\t}\n\t\t\tif (this._overwrite > 1) if (this._firstPT) if (siblings.length > 1) if (_applyOverwrite(target, this, propLookup, this._overwrite, siblings)) {\n\t\t\t\tthis._kill(propLookup, target);\n\t\t\t\treturn this._initProps(target, propLookup, siblings, overwrittenProps, index);\n\t\t\t}\n\t\t\tif (this._firstPT) if ((this.vars.lazy !== false && this._duration) || (this.vars.lazy && !this._duration)) { //zero duration tweens don't lazy render by default; everything else does.\n\t\t\t\t_lazyLookup[target._gsTweenID] = true;\n\t\t\t}\n\t\t\treturn initPlugins;\n\t\t};\n\n\t\tp.render = function(time, suppressEvents, force) {\n\t\t\tvar self = this,\n\t\t\t\tprevTime = self._time,\n\t\t\t\tduration = self._duration,\n\t\t\t\tprevRawPrevTime = self._rawPrevTime,\n\t\t\t\tisComplete, callback, pt, rawPrevTime;\n\t\t\tif (time >= duration - _tinyNum && time >= 0) { //to work around occasional floating point math artifacts.\n\t\t\t\tself._totalTime = self._time = duration;\n\t\t\t\tself.ratio = self._ease._calcEnd ? self._ease.getRatio(1) : 1;\n\t\t\t\tif (!self._reversed ) {\n\t\t\t\t\tisComplete = true;\n\t\t\t\t\tcallback = \"onComplete\";\n\t\t\t\t\tforce = (force || self._timeline.autoRemoveChildren); //otherwise, if the animation is unpaused/activated after it's already finished, it doesn't get removed from the parent timeline.\n\t\t\t\t}\n\t\t\t\tif (duration === 0) if (self._initted || !self.vars.lazy || force) { //zero-duration tweens are tricky because we must discern the momentum/direction of time in order to determine whether the starting values should be rendered or the ending values. If the \"playhead\" of its timeline goes past the zero-duration tween in the forward direction or lands directly on it, the end values should be rendered, but if the timeline's \"playhead\" moves past it in the backward direction (from a postitive time to a negative time), the starting values must be rendered.\n\t\t\t\t\tif (self._startTime === self._timeline._duration) { //if a zero-duration tween is at the VERY end of a timeline and that timeline renders at its end, it will typically add a tiny bit of cushion to the render time to prevent rounding errors from getting in the way of tweens rendering their VERY end. If we then reverse() that timeline, the zero-duration tween will trigger its onReverseComplete even though technically the playhead didn't pass over it again. It's a very specific edge case we must accommodate.\n\t\t\t\t\t\ttime = 0;\n\t\t\t\t\t}\n\t\t\t\t\tif (prevRawPrevTime < 0 || (time <= 0 && time >= -_tinyNum) || (prevRawPrevTime === _tinyNum && self.data !== \"isPause\")) if (prevRawPrevTime !== time) { //note: when this.data is \"isPause\", it's a callback added by addPause() on a timeline that we should not be triggered when LEAVING its exact start time. In other words, tl.addPause(1).play(1) shouldn't pause.\n\t\t\t\t\t\tforce = true;\n\t\t\t\t\t\tif (prevRawPrevTime > _tinyNum) {\n\t\t\t\t\t\t\tcallback = \"onReverseComplete\";\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tself._rawPrevTime = rawPrevTime = (!suppressEvents || time || prevRawPrevTime === time) ? time : _tinyNum; //when the playhead arrives at EXACTLY time 0 (right on top) of a zero-duration tween, we need to discern if events are suppressed so that when the playhead moves again (next time), it'll trigger the callback. If events are NOT suppressed, obviously the callback would be triggered in this render. Basically, the callback should fire either when the playhead ARRIVES or LEAVES this exact spot, not both. Imagine doing a timeline.seek(0) and there's a callback that sits at 0. Since events are suppressed on that seek() by default, nothing will fire, but when the playhead moves off of that position, the callback should fire. This behavior is what people intuitively expect. We set the _rawPrevTime to be a precise tiny number to indicate this scenario rather than using another property/variable which would increase memory usage. This technique is less readable, but more efficient.\n\t\t\t\t}\n\n\t\t\t} else if (time < _tinyNum) { //to work around occasional floating point math artifacts, round super small values to 0.\n\t\t\t\tself._totalTime = self._time = 0;\n\t\t\t\tself.ratio = self._ease._calcEnd ? self._ease.getRatio(0) : 0;\n\t\t\t\tif (prevTime !== 0 || (duration === 0 && prevRawPrevTime > 0)) {\n\t\t\t\t\tcallback = \"onReverseComplete\";\n\t\t\t\t\tisComplete = self._reversed;\n\t\t\t\t}\n\t\t\t\tif (time > -_tinyNum) {\n\t\t\t\t\ttime = 0;\n\t\t\t\t} else if (time < 0) {\n\t\t\t\t\tself._active = false;\n\t\t\t\t\tif (duration === 0) if (self._initted || !self.vars.lazy || force) { //zero-duration tweens are tricky because we must discern the momentum/direction of time in order to determine whether the starting values should be rendered or the ending values. If the \"playhead\" of its timeline goes past the zero-duration tween in the forward direction or lands directly on it, the end values should be rendered, but if the timeline's \"playhead\" moves past it in the backward direction (from a postitive time to a negative time), the starting values must be rendered.\n\t\t\t\t\t\tif (prevRawPrevTime >= 0 && !(prevRawPrevTime === _tinyNum && self.data === \"isPause\")) {\n\t\t\t\t\t\t\tforce = true;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tself._rawPrevTime = rawPrevTime = (!suppressEvents || time || prevRawPrevTime === time) ? time : _tinyNum; //when the playhead arrives at EXACTLY time 0 (right on top) of a zero-duration tween, we need to discern if events are suppressed so that when the playhead moves again (next time), it'll trigger the callback. If events are NOT suppressed, obviously the callback would be triggered in this render. Basically, the callback should fire either when the playhead ARRIVES or LEAVES this exact spot, not both. Imagine doing a timeline.seek(0) and there's a callback that sits at 0. Since events are suppressed on that seek() by default, nothing will fire, but when the playhead moves off of that position, the callback should fire. This behavior is what people intuitively expect. We set the _rawPrevTime to be a precise tiny number to indicate this scenario rather than using another property/variable which would increase memory usage. This technique is less readable, but more efficient.\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (!self._initted || (self._startAt && self._startAt.progress())) { //if we render the very beginning (time == 0) of a fromTo(), we must force the render (normal tweens wouldn't need to render at a time of 0 when the prevTime was also 0). This is also mandatory to make sure overwriting kicks in immediately. Also, we check progress() because if startAt has already rendered at its end, we should force a render at its beginning. Otherwise, if you put the playhead directly on top of where a fromTo({immediateRender:false}) starts, and then move it backwards, the from() won't revert its values.\n\t\t\t\t\tforce = true;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tself._totalTime = self._time = time;\n\n\t\t\t\tif (self._easeType) {\n\t\t\t\t\tvar r = time / duration, type = self._easeType, pow = self._easePower;\n\t\t\t\t\tif (type === 1 || (type === 3 && r >= 0.5)) {\n\t\t\t\t\t\tr = 1 - r;\n\t\t\t\t\t}\n\t\t\t\t\tif (type === 3) {\n\t\t\t\t\t\tr *= 2;\n\t\t\t\t\t}\n\t\t\t\t\tif (pow === 1) {\n\t\t\t\t\t\tr *= r;\n\t\t\t\t\t} else if (pow === 2) {\n\t\t\t\t\t\tr *= r * r;\n\t\t\t\t\t} else if (pow === 3) {\n\t\t\t\t\t\tr *= r * r * r;\n\t\t\t\t\t} else if (pow === 4) {\n\t\t\t\t\t\tr *= r * r * r * r;\n\t\t\t\t\t}\n\t\t\t\t\tself.ratio = (type === 1) ? 1 - r : (type === 2) ? r : (time / duration < 0.5) ? r / 2 : 1 - (r / 2);\n\t\t\t\t} else {\n\t\t\t\t\tself.ratio = self._ease.getRatio(time / duration);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (self._time === prevTime && !force) {\n\t\t\t\treturn;\n\t\t\t} else if (!self._initted) {\n\t\t\t\tself._init();\n\t\t\t\tif (!self._initted || self._gc) { //immediateRender tweens typically won't initialize until the playhead advances (_time is greater than 0) in order to ensure that overwriting occurs properly. Also, if all of the tweening properties have been overwritten (which would cause _gc to be true, as set in _init()), we shouldn't continue otherwise an onStart callback could be called for example.\n\t\t\t\t\treturn;\n\t\t\t\t} else if (!force && self._firstPT && ((self.vars.lazy !== false && self._duration) || (self.vars.lazy && !self._duration))) {\n\t\t\t\t\tself._time = self._totalTime = prevTime;\n\t\t\t\t\tself._rawPrevTime = prevRawPrevTime;\n\t\t\t\t\t_lazyTweens.push(self);\n\t\t\t\t\tself._lazy = [time, suppressEvents];\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t//_ease is initially set to defaultEase, so now that init() has run, _ease is set properly and we need to recalculate the ratio. Overall this is faster than using conditional logic earlier in the method to avoid having to set ratio twice because we only init() once but renderTime() gets called VERY frequently.\n\t\t\t\tif (self._time && !isComplete) {\n\t\t\t\t\tself.ratio = self._ease.getRatio(self._time / duration);\n\t\t\t\t} else if (isComplete && self._ease._calcEnd) {\n\t\t\t\t\tself.ratio = self._ease.getRatio((self._time === 0) ? 0 : 1);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (self._lazy !== false) { //in case a lazy render is pending, we should flush it because the new render is occurring now (imagine a lazy tween instantiating and then immediately the user calls tween.seek(tween.duration()), skipping to the end - the end render would be forced, and then if we didn't flush the lazy render, it'd fire AFTER the seek(), rendering it at the wrong time.\n\t\t\t\tself._lazy = false;\n\t\t\t}\n\t\t\tif (!self._active) if (!self._paused && self._time !== prevTime && time >= 0) {\n\t\t\t\tself._active = true;  //so that if the user renders a tween (as opposed to the timeline rendering it), the timeline is forced to re-render and align it with the proper time/frame on the next rendering cycle. Maybe the tween already finished but the user manually re-renders it as halfway done.\n\t\t\t}\n\t\t\tif (prevTime === 0) {\n\t\t\t\tif (self._startAt) {\n\t\t\t\t\tif (time >= 0) {\n\t\t\t\t\t\tself._startAt.render(time, true, force);\n\t\t\t\t\t} else if (!callback) {\n\t\t\t\t\t\tcallback = \"_dummyGS\"; //if no callback is defined, use a dummy value just so that the condition at the end evaluates as true because _startAt should render AFTER the normal render loop when the time is negative. We could handle this in a more intuitive way, of course, but the render loop is the MOST important thing to optimize, so this technique allows us to avoid adding extra conditional logic in a high-frequency area.\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (self.vars.onStart) if (self._time !== 0 || duration === 0) if (!suppressEvents) {\n\t\t\t\t\tself._callback(\"onStart\");\n\t\t\t\t}\n\t\t\t}\n\t\t\tpt = self._firstPT;\n\t\t\twhile (pt) {\n\t\t\t\tif (pt.f) {\n\t\t\t\t\tpt.t[pt.p](pt.c * self.ratio + pt.s);\n\t\t\t\t} else {\n\t\t\t\t\tpt.t[pt.p] = pt.c * self.ratio + pt.s;\n\t\t\t\t}\n\t\t\t\tpt = pt._next;\n\t\t\t}\n\n\t\t\tif (self._onUpdate) {\n\t\t\t\tif (time < 0) if (self._startAt && time !== -0.0001) { //if the tween is positioned at the VERY beginning (_startTime 0) of its parent timeline, it's illegal for the playhead to go back further, so we should not render the recorded startAt values.\n\t\t\t\t\tself._startAt.render(time, true, force); //note: for performance reasons, we tuck this conditional logic inside less traveled areas (most tweens don't have an onUpdate). We'd just have it at the end before the onComplete, but the values should be updated before any onUpdate is called, so we ALSO put it here and then if it's not called, we do so later near the onComplete.\n\t\t\t\t}\n\t\t\t\tif (!suppressEvents) if (self._time !== prevTime || isComplete || force) {\n\t\t\t\t\tself._callback(\"onUpdate\");\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (callback) if (!self._gc || force) { //check _gc because there's a chance that kill() could be called in an onUpdate\n\t\t\t\tif (time < 0 && self._startAt && !self._onUpdate && time !== -0.0001) { //-0.0001 is a special value that we use when looping back to the beginning of a repeated TimelineMax, in which case we shouldn't render the _startAt values.\n\t\t\t\t\tself._startAt.render(time, true, force);\n\t\t\t\t}\n\t\t\t\tif (isComplete) {\n\t\t\t\t\tif (self._timeline.autoRemoveChildren) {\n\t\t\t\t\t\tself._enabled(false, false);\n\t\t\t\t\t}\n\t\t\t\t\tself._active = false;\n\t\t\t\t}\n\t\t\t\tif (!suppressEvents && self.vars[callback]) {\n\t\t\t\t\tself._callback(callback);\n\t\t\t\t}\n\t\t\t\tif (duration === 0 && self._rawPrevTime === _tinyNum && rawPrevTime !== _tinyNum) { //the onComplete or onReverseComplete could trigger movement of the playhead and for zero-duration tweens (which must discern direction) that land directly back on their start time, we don't want to fire again on the next render. Think of several addPause()'s in a timeline that forces the playhead to a certain spot, but what if it's already paused and another tween is tweening the \"time\" of the timeline? Each time it moves [forward] past that spot, it would move back, and since suppressEvents is true, it'd reset _rawPrevTime to _tinyNum so that when it begins again, the callback would fire (so ultimately it could bounce back and forth during that tween). Again, this is a very uncommon scenario, but possible nonetheless.\n\t\t\t\t\tself._rawPrevTime = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\n\t\tp._kill = function(vars, target, overwritingTween) {\n\t\t\tif (vars === \"all\") {\n\t\t\t\tvars = null;\n\t\t\t}\n\t\t\tif (vars == null) if (target == null || target === this.target) {\n\t\t\t\tthis._lazy = false;\n\t\t\t\treturn this._enabled(false, false);\n\t\t\t}\n\t\t\ttarget = (typeof(target) !== \"string\") ? (target || this._targets || this.target) : TweenLite.selector(target) || target;\n\t\t\tvar simultaneousOverwrite = (overwritingTween && this._time && overwritingTween._startTime === this._startTime && this._timeline === overwritingTween._timeline),\n\t\t\t\tfirstPT = this._firstPT,\n\t\t\t\ti, overwrittenProps, p, pt, propLookup, changed, killProps, record, killed;\n\t\t\tif ((_isArray(target) || _isSelector(target)) && typeof(target[0]) !== \"number\") {\n\t\t\t\ti = target.length;\n\t\t\t\twhile (--i > -1) {\n\t\t\t\t\tif (this._kill(vars, target[i], overwritingTween)) {\n\t\t\t\t\t\tchanged = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (this._targets) {\n\t\t\t\t\ti = this._targets.length;\n\t\t\t\t\twhile (--i > -1) {\n\t\t\t\t\t\tif (target === this._targets[i]) {\n\t\t\t\t\t\t\tpropLookup = this._propLookup[i] || {};\n\t\t\t\t\t\t\tthis._overwrittenProps = this._overwrittenProps || [];\n\t\t\t\t\t\t\toverwrittenProps = this._overwrittenProps[i] = vars ? this._overwrittenProps[i] || {} : \"all\";\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else if (target !== this.target) {\n\t\t\t\t\treturn false;\n\t\t\t\t} else {\n\t\t\t\t\tpropLookup = this._propLookup;\n\t\t\t\t\toverwrittenProps = this._overwrittenProps = vars ? this._overwrittenProps || {} : \"all\";\n\t\t\t\t}\n\n\t\t\t\tif (propLookup) {\n\t\t\t\t\tkillProps = vars || propLookup;\n\t\t\t\t\trecord = (vars !== overwrittenProps && overwrittenProps !== \"all\" && vars !== propLookup && (typeof(vars) !== \"object\" || !vars._tempKill)); //_tempKill is a super-secret way to delete a particular tweening property but NOT have it remembered as an official overwritten property (like in BezierPlugin)\n\t\t\t\t\tif (overwritingTween && (TweenLite.onOverwrite || this.vars.onOverwrite)) {\n\t\t\t\t\t\tfor (p in killProps) {\n\t\t\t\t\t\t\tif (propLookup[p]) {\n\t\t\t\t\t\t\t\tif (!killed) {\n\t\t\t\t\t\t\t\t\tkilled = [];\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tkilled.push(p);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif ((killed || !vars) && !_onOverwrite(this, overwritingTween, target, killed)) { //if the onOverwrite returned false, that means the user wants to override the overwriting (cancel it).\n\t\t\t\t\t\t\treturn false;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tfor (p in killProps) {\n\t\t\t\t\t\tif ((pt = propLookup[p])) {\n\t\t\t\t\t\t\tif (simultaneousOverwrite) { //if another tween overwrites this one and they both start at exactly the same time, yet this tween has already rendered once (for example, at 0.001) because it's first in the queue, we should revert the values to where they were at 0 so that the starting values aren't contaminated on the overwriting tween.\n\t\t\t\t\t\t\t\tif (pt.f) {\n\t\t\t\t\t\t\t\t\tpt.t[pt.p](pt.s);\n\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\tpt.t[pt.p] = pt.s;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tchanged = true;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (pt.pg && pt.t._kill(killProps)) {\n\t\t\t\t\t\t\t\tchanged = true; //some plugins need to be notified so they can perform cleanup tasks first\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (!pt.pg || pt.t._overwriteProps.length === 0) {\n\t\t\t\t\t\t\t\tif (pt._prev) {\n\t\t\t\t\t\t\t\t\tpt._prev._next = pt._next;\n\t\t\t\t\t\t\t\t} else if (pt === this._firstPT) {\n\t\t\t\t\t\t\t\t\tthis._firstPT = pt._next;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tif (pt._next) {\n\t\t\t\t\t\t\t\t\tpt._next._prev = pt._prev;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tpt._next = pt._prev = null;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tdelete propLookup[p];\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (record) {\n\t\t\t\t\t\t\toverwrittenProps[p] = 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (!this._firstPT && this._initted && firstPT) { //if all tweening properties are killed, kill the tween. Without this line, if there's a tween with multiple targets and then you killTweensOf() each target individually, the tween would technically still remain active and fire its onComplete even though there aren't any more properties tweening.\n\t\t\t\t\t\tthis._enabled(false, false);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn changed;\n\t\t};\n\n\t\tp.invalidate = function() {\n\t\t\tif (this._notifyPluginsOfEnabled) {\n\t\t\t\tTweenLite._onPluginEvent(\"_onDisable\", this);\n\t\t\t}\n\t\t\tvar t = this._time;\n\t\t\tthis._firstPT = this._overwrittenProps = this._startAt = this._onUpdate = null;\n\t\t\tthis._notifyPluginsOfEnabled = this._active = this._lazy = false;\n\t\t\tthis._propLookup = (this._targets) ? {} : [];\n\t\t\tAnimation.prototype.invalidate.call(this);\n\t\t\tif (this.vars.immediateRender) {\n\t\t\t\tthis._time = -_tinyNum; //forces a render without having to set the render() \"force\" parameter to true because we want to allow lazying by default (using the \"force\" parameter always forces an immediate full render)\n\t\t\t\tthis.render(t, false, this.vars.lazy !== false);\n\t\t\t}\n\t\t\treturn this;\n\t\t};\n\n\t\tp._enabled = function(enabled, ignoreTimeline) {\n\t\t\tif (!_tickerActive) {\n\t\t\t\t_ticker.wake();\n\t\t\t}\n\t\t\tif (enabled && this._gc) {\n\t\t\t\tvar targets = this._targets,\n\t\t\t\t\ti;\n\t\t\t\tif (targets) {\n\t\t\t\t\ti = targets.length;\n\t\t\t\t\twhile (--i > -1) {\n\t\t\t\t\t\tthis._siblings[i] = _register(targets[i], this, true);\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tthis._siblings = _register(this.target, this, true);\n\t\t\t\t}\n\t\t\t}\n\t\t\tAnimation.prototype._enabled.call(this, enabled, ignoreTimeline);\n\t\t\tif (this._notifyPluginsOfEnabled) if (this._firstPT) {\n\t\t\t\treturn TweenLite._onPluginEvent((enabled ? \"_onEnable\" : \"_onDisable\"), this);\n\t\t\t}\n\t\t\treturn false;\n\t\t};\n\n\n//----TweenLite static methods -----------------------------------------------------\n\n\t\tTweenLite.to = function(target, duration, vars) {\n\t\t\treturn new TweenLite(target, duration, vars);\n\t\t};\n\n\t\tTweenLite.from = function(target, duration, vars) {\n\t\t\tvars.runBackwards = true;\n\t\t\tvars.immediateRender = (vars.immediateRender != false);\n\t\t\treturn new TweenLite(target, duration, vars);\n\t\t};\n\n\t\tTweenLite.fromTo = function(target, duration, fromVars, toVars) {\n\t\t\ttoVars.startAt = fromVars;\n\t\t\ttoVars.immediateRender = (toVars.immediateRender != false && fromVars.immediateRender != false);\n\t\t\treturn new TweenLite(target, duration, toVars);\n\t\t};\n\n\t\tTweenLite.delayedCall = function(delay, callback, params, scope, useFrames) {\n\t\t\treturn new TweenLite(callback, 0, {delay:delay, onComplete:callback, onCompleteParams:params, callbackScope:scope, onReverseComplete:callback, onReverseCompleteParams:params, immediateRender:false, lazy:false, useFrames:useFrames, overwrite:0});\n\t\t};\n\n\t\tTweenLite.set = function(target, vars) {\n\t\t\treturn new TweenLite(target, 0, vars);\n\t\t};\n\n\t\tTweenLite.getTweensOf = function(target, onlyActive) {\n\t\t\tif (target == null) { return []; }\n\t\t\ttarget = (typeof(target) !== \"string\") ? target : TweenLite.selector(target) || target;\n\t\t\tvar i, a, j, t;\n\t\t\tif ((_isArray(target) || _isSelector(target)) && typeof(target[0]) !== \"number\") {\n\t\t\t\ti = target.length;\n\t\t\t\ta = [];\n\t\t\t\twhile (--i > -1) {\n\t\t\t\t\ta = a.concat(TweenLite.getTweensOf(target[i], onlyActive));\n\t\t\t\t}\n\t\t\t\ti = a.length;\n\t\t\t\t//now get rid of any duplicates (tweens of arrays of objects could cause duplicates)\n\t\t\t\twhile (--i > -1) {\n\t\t\t\t\tt = a[i];\n\t\t\t\t\tj = i;\n\t\t\t\t\twhile (--j > -1) {\n\t\t\t\t\t\tif (t === a[j]) {\n\t\t\t\t\t\t\ta.splice(i, 1);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else if (target._gsTweenID) {\n\t\t\t\ta = _register(target).concat();\n\t\t\t\ti = a.length;\n\t\t\t\twhile (--i > -1) {\n\t\t\t\t\tif (a[i]._gc || (onlyActive && !a[i].isActive())) {\n\t\t\t\t\t\ta.splice(i, 1);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn a || [];\n\t\t};\n\n\t\tTweenLite.killTweensOf = TweenLite.killDelayedCallsTo = function(target, onlyActive, vars) {\n\t\t\tif (typeof(onlyActive) === \"object\") {\n\t\t\t\tvars = onlyActive; //for backwards compatibility (before \"onlyActive\" parameter was inserted)\n\t\t\t\tonlyActive = false;\n\t\t\t}\n\t\t\tvar a = TweenLite.getTweensOf(target, onlyActive),\n\t\t\t\ti = a.length;\n\t\t\twhile (--i > -1) {\n\t\t\t\ta[i]._kill(vars, target);\n\t\t\t}\n\t\t};\n\n\n\n/*\n * ----------------------------------------------------------------\n * TweenPlugin   (could easily be split out as a separate file/class, but included for ease of use (so that people don't need to include another script call before loading plugins which is easy to forget)\n * ----------------------------------------------------------------\n */\n\t\tvar TweenPlugin = _class(\"plugins.TweenPlugin\", function(props, priority) {\n\t\t\t\t\tthis._overwriteProps = (props || \"\").split(\",\");\n\t\t\t\t\tthis._propName = this._overwriteProps[0];\n\t\t\t\t\tthis._priority = priority || 0;\n\t\t\t\t\tthis._super = TweenPlugin.prototype;\n\t\t\t\t}, true);\n\n\t\tp = TweenPlugin.prototype;\n\t\tTweenPlugin.version = \"1.19.0\";\n\t\tTweenPlugin.API = 2;\n\t\tp._firstPT = null;\n\t\tp._addTween = _addPropTween;\n\t\tp.setRatio = _setRatio;\n\n\t\tp._kill = function(lookup) {\n\t\t\tvar a = this._overwriteProps,\n\t\t\t\tpt = this._firstPT,\n\t\t\t\ti;\n\t\t\tif (lookup[this._propName] != null) {\n\t\t\t\tthis._overwriteProps = [];\n\t\t\t} else {\n\t\t\t\ti = a.length;\n\t\t\t\twhile (--i > -1) {\n\t\t\t\t\tif (lookup[a[i]] != null) {\n\t\t\t\t\t\ta.splice(i, 1);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\twhile (pt) {\n\t\t\t\tif (lookup[pt.n] != null) {\n\t\t\t\t\tif (pt._next) {\n\t\t\t\t\t\tpt._next._prev = pt._prev;\n\t\t\t\t\t}\n\t\t\t\t\tif (pt._prev) {\n\t\t\t\t\t\tpt._prev._next = pt._next;\n\t\t\t\t\t\tpt._prev = null;\n\t\t\t\t\t} else if (this._firstPT === pt) {\n\t\t\t\t\t\tthis._firstPT = pt._next;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tpt = pt._next;\n\t\t\t}\n\t\t\treturn false;\n\t\t};\n\n\t\tp._mod = p._roundProps = function(lookup) {\n\t\t\tvar pt = this._firstPT,\n\t\t\t\tval;\n\t\t\twhile (pt) {\n\t\t\t\tval = lookup[this._propName] || (pt.n != null && lookup[ pt.n.split(this._propName + \"_\").join(\"\") ]);\n\t\t\t\tif (val && typeof(val) === \"function\") { //some properties that are very plugin-specific add a prefix named after the _propName plus an underscore, so we need to ignore that extra stuff here.\n\t\t\t\t\tif (pt.f === 2) {\n\t\t\t\t\t\tpt.t._applyPT.m = val;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tpt.m = val;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tpt = pt._next;\n\t\t\t}\n\t\t};\n\n\t\tTweenLite._onPluginEvent = function(type, tween) {\n\t\t\tvar pt = tween._firstPT,\n\t\t\t\tchanged, pt2, first, last, next;\n\t\t\tif (type === \"_onInitAllProps\") {\n\t\t\t\t//sorts the PropTween linked list in order of priority because some plugins need to render earlier/later than others, like MotionBlurPlugin applies its effects after all x/y/alpha tweens have rendered on each frame.\n\t\t\t\twhile (pt) {\n\t\t\t\t\tnext = pt._next;\n\t\t\t\t\tpt2 = first;\n\t\t\t\t\twhile (pt2 && pt2.pr > pt.pr) {\n\t\t\t\t\t\tpt2 = pt2._next;\n\t\t\t\t\t}\n\t\t\t\t\tif ((pt._prev = pt2 ? pt2._prev : last)) {\n\t\t\t\t\t\tpt._prev._next = pt;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tfirst = pt;\n\t\t\t\t\t}\n\t\t\t\t\tif ((pt._next = pt2)) {\n\t\t\t\t\t\tpt2._prev = pt;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tlast = pt;\n\t\t\t\t\t}\n\t\t\t\t\tpt = next;\n\t\t\t\t}\n\t\t\t\tpt = tween._firstPT = first;\n\t\t\t}\n\t\t\twhile (pt) {\n\t\t\t\tif (pt.pg) if (typeof(pt.t[type]) === \"function\") if (pt.t[type]()) {\n\t\t\t\t\tchanged = true;\n\t\t\t\t}\n\t\t\t\tpt = pt._next;\n\t\t\t}\n\t\t\treturn changed;\n\t\t};\n\n\t\tTweenPlugin.activate = function(plugins) {\n\t\t\tvar i = plugins.length;\n\t\t\twhile (--i > -1) {\n\t\t\t\tif (plugins[i].API === TweenPlugin.API) {\n\t\t\t\t\t_plugins[(new plugins[i]())._propName] = plugins[i];\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn true;\n\t\t};\n\n\t\t//provides a more concise way to define plugins that have no dependencies besides TweenPlugin and TweenLite, wrapping common boilerplate stuff into one function (added in 1.9.0). You don't NEED to use this to define a plugin - the old way still works and can be useful in certain (rare) situations.\n\t\t_gsDefine.plugin = function(config) {\n\t\t\tif (!config || !config.propName || !config.init || !config.API) { throw \"illegal plugin definition.\"; }\n\t\t\tvar propName = config.propName,\n\t\t\t\tpriority = config.priority || 0,\n\t\t\t\toverwriteProps = config.overwriteProps,\n\t\t\t\tmap = {init:\"_onInitTween\", set:\"setRatio\", kill:\"_kill\", round:\"_mod\", mod:\"_mod\", initAll:\"_onInitAllProps\"},\n\t\t\t\tPlugin = _class(\"plugins.\" + propName.charAt(0).toUpperCase() + propName.substr(1) + \"Plugin\",\n\t\t\t\t\tfunction() {\n\t\t\t\t\t\tTweenPlugin.call(this, propName, priority);\n\t\t\t\t\t\tthis._overwriteProps = overwriteProps || [];\n\t\t\t\t\t}, (config.global === true)),\n\t\t\t\tp = Plugin.prototype = new TweenPlugin(propName),\n\t\t\t\tprop;\n\t\t\tp.constructor = Plugin;\n\t\t\tPlugin.API = config.API;\n\t\t\tfor (prop in map) {\n\t\t\t\tif (typeof(config[prop]) === \"function\") {\n\t\t\t\t\tp[map[prop]] = config[prop];\n\t\t\t\t}\n\t\t\t}\n\t\t\tPlugin.version = config.version;\n\t\t\tTweenPlugin.activate([Plugin]);\n\t\t\treturn Plugin;\n\t\t};\n\n\n\t\t//now run through all the dependencies discovered and if any are missing, log that to the console as a warning. This is why it's best to have TweenLite load last - it can check all the dependencies for you.\n\t\ta = window._gsQueue;\n\t\tif (a) {\n\t\t\tfor (i = 0; i < a.length; i++) {\n\t\t\t\ta[i]();\n\t\t\t}\n\t\t\tfor (p in _defLookup) {\n\t\t\t\tif (!_defLookup[p].func) {\n\t\t\t\t\twindow.console.log(\"GSAP encountered missing dependency: \" + p);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t_tickerActive = false; //ensures that the first official animation forces a ticker.tick() to update the time when it is instantiated\n\n\t\treturn TweenLite;\n\n})(_gsScope, \"TweenLite\");\n\nvar globals = _gsScope.GreenSockGlobals;\nvar nonGlobals = globals.com.greensock;\n\nvar SimpleTimeline = nonGlobals.core.SimpleTimeline;\nvar Animation = nonGlobals.core.Animation;\nvar Ease = globals.Ease;\nvar Linear = globals.Linear;\nvar Power0 = Linear;\nvar Power1 = globals.Power1;\nvar Power2 = globals.Power2;\nvar Power3 = globals.Power3;\nvar Power4 = globals.Power4;\nvar TweenPlugin = globals.TweenPlugin;\nvar EventDispatcher = nonGlobals.events.EventDispatcher;\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../webpack/buildin/harmony-module.js */ \"./node_modules/webpack/buildin/harmony-module.js\")(module), __webpack_require__(/*! ./../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\")))\n\n//# sourceURL=webpack:///./node_modules/gsap/TweenLite.js?");

/***/ }),

/***/ "./node_modules/gsap/TweenMax.js":
/*!***************************************!*\
  !*** ./node_modules/gsap/TweenMax.js ***!
  \***************************************/
/*! exports provided: TweenMax, default, TweenLite, TimelineLite, TimelineMax, CSSPlugin, AttrPlugin, BezierPlugin, DirectionalRotationPlugin, RoundPropsPlugin, TweenPlugin, Ease, Power0, Power1, Power2, Power3, Power4, Linear, Back, Elastic, Bounce, RoughEase, SlowMo, SteppedEase, Circ, Expo, Sine, ExpoScaleEase */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TweenMax\", function() { return TweenMax; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"default\", function() { return TweenMax; });\n/* harmony import */ var _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./TweenLite.js */ \"./node_modules/gsap/TweenLite.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TweenLite\", function() { return _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TweenPlugin\", function() { return _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"TweenPlugin\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Ease\", function() { return _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Ease\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Power0\", function() { return _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Power0\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Power1\", function() { return _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Power1\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Power2\", function() { return _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Power2\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Power3\", function() { return _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Power3\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Power4\", function() { return _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Power4\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Linear\", function() { return _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Linear\"]; });\n\n/* harmony import */ var _TweenMaxBase_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./TweenMaxBase.js */ \"./node_modules/gsap/TweenMaxBase.js\");\n/* harmony import */ var _CSSPlugin_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./CSSPlugin.js */ \"./node_modules/gsap/CSSPlugin.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"CSSPlugin\", function() { return _CSSPlugin_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"]; });\n\n/* harmony import */ var _AttrPlugin_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./AttrPlugin.js */ \"./node_modules/gsap/AttrPlugin.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AttrPlugin\", function() { return _AttrPlugin_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"]; });\n\n/* harmony import */ var _RoundPropsPlugin_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./RoundPropsPlugin.js */ \"./node_modules/gsap/RoundPropsPlugin.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"RoundPropsPlugin\", function() { return _RoundPropsPlugin_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"]; });\n\n/* harmony import */ var _DirectionalRotationPlugin_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./DirectionalRotationPlugin.js */ \"./node_modules/gsap/DirectionalRotationPlugin.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DirectionalRotationPlugin\", function() { return _DirectionalRotationPlugin_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"]; });\n\n/* harmony import */ var _TimelineLite_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./TimelineLite.js */ \"./node_modules/gsap/TimelineLite.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TimelineLite\", function() { return _TimelineLite_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"]; });\n\n/* harmony import */ var _TimelineMax_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./TimelineMax.js */ \"./node_modules/gsap/TimelineMax.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TimelineMax\", function() { return _TimelineMax_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"]; });\n\n/* harmony import */ var _BezierPlugin_js__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./BezierPlugin.js */ \"./node_modules/gsap/BezierPlugin.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"BezierPlugin\", function() { return _BezierPlugin_js__WEBPACK_IMPORTED_MODULE_8__[\"default\"]; });\n\n/* harmony import */ var _EasePack_js__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./EasePack.js */ \"./node_modules/gsap/EasePack.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Back\", function() { return _EasePack_js__WEBPACK_IMPORTED_MODULE_9__[\"Back\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Elastic\", function() { return _EasePack_js__WEBPACK_IMPORTED_MODULE_9__[\"Elastic\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Bounce\", function() { return _EasePack_js__WEBPACK_IMPORTED_MODULE_9__[\"Bounce\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"RoughEase\", function() { return _EasePack_js__WEBPACK_IMPORTED_MODULE_9__[\"RoughEase\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SlowMo\", function() { return _EasePack_js__WEBPACK_IMPORTED_MODULE_9__[\"SlowMo\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SteppedEase\", function() { return _EasePack_js__WEBPACK_IMPORTED_MODULE_9__[\"SteppedEase\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Circ\", function() { return _EasePack_js__WEBPACK_IMPORTED_MODULE_9__[\"Circ\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Expo\", function() { return _EasePack_js__WEBPACK_IMPORTED_MODULE_9__[\"Expo\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Sine\", function() { return _EasePack_js__WEBPACK_IMPORTED_MODULE_9__[\"Sine\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ExpoScaleEase\", function() { return _EasePack_js__WEBPACK_IMPORTED_MODULE_9__[\"ExpoScaleEase\"]; });\n\n/*!\n * VERSION: 2.1.3\n * DATE: 2019-05-17\n * UPDATES AND DOCS AT: http://greensock.com\n *\n * @license Copyright (c) 2008-2019, GreenSock. All rights reserved.\n * This work is subject to the terms at http://greensock.com/standard-license or for\n * Club GreenSock members, the software agreement that was issued with your membership.\n * \n * @author: Jack Doyle, jack@greensock.com\n **/\n/* eslint-disable */\n\n\n\n\n\n\n\n\n\n\n\n\n//the following two lines are designed to prevent tree shaking of the classes that were historically included with TweenMax (otherwise, folks would have to reference CSSPlugin, for example, to ensure their CSS-related animations worked)\nvar TweenMax = _TweenMaxBase_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"];\nTweenMax._autoActivated = [_TimelineLite_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"], _TimelineMax_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"], _CSSPlugin_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"], _AttrPlugin_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"], _BezierPlugin_js__WEBPACK_IMPORTED_MODULE_8__[\"default\"], _RoundPropsPlugin_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"], _DirectionalRotationPlugin_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"], _EasePack_js__WEBPACK_IMPORTED_MODULE_9__[\"Back\"], _EasePack_js__WEBPACK_IMPORTED_MODULE_9__[\"Elastic\"], _EasePack_js__WEBPACK_IMPORTED_MODULE_9__[\"Bounce\"], _EasePack_js__WEBPACK_IMPORTED_MODULE_9__[\"RoughEase\"], _EasePack_js__WEBPACK_IMPORTED_MODULE_9__[\"SlowMo\"], _EasePack_js__WEBPACK_IMPORTED_MODULE_9__[\"SteppedEase\"], _EasePack_js__WEBPACK_IMPORTED_MODULE_9__[\"Circ\"], _EasePack_js__WEBPACK_IMPORTED_MODULE_9__[\"Expo\"], _EasePack_js__WEBPACK_IMPORTED_MODULE_9__[\"Sine\"], _EasePack_js__WEBPACK_IMPORTED_MODULE_9__[\"ExpoScaleEase\"]];\n\n\n\n\n\n//# sourceURL=webpack:///./node_modules/gsap/TweenMax.js?");

/***/ }),

/***/ "./node_modules/gsap/TweenMaxBase.js":
/*!*******************************************!*\
  !*** ./node_modules/gsap/TweenMaxBase.js ***!
  \*******************************************/
/*! exports provided: TweenMax, TweenMaxBase, default, TweenLite, Ease, Power0, Power1, Power2, Power3, Power4, Linear */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TweenMax\", function() { return TweenMax; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TweenMaxBase\", function() { return TweenMaxBase; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"default\", function() { return TweenMax; });\n/* harmony import */ var _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./TweenLite.js */ \"./node_modules/gsap/TweenLite.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TweenLite\", function() { return _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Ease\", function() { return _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Ease\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Power0\", function() { return _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Power0\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Power1\", function() { return _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Power1\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Power2\", function() { return _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Power2\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Power3\", function() { return _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Power3\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Power4\", function() { return _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Power4\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Linear\", function() { return _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Linear\"]; });\n\n/*!\n * VERSION: 2.1.3\n * DATE: 2019-05-17\n * UPDATES AND DOCS AT: http://greensock.com\n *\n * @license Copyright (c) 2008-2019, GreenSock. All rights reserved.\n * This work is subject to the terms at http://greensock.com/standard-license or for\n * Club GreenSock members, the software agreement that was issued with your membership.\n * \n * @author: Jack Doyle, jack@greensock.com\n **/\n/* eslint-disable */\n\n\n\n\n_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"_gsScope\"]._gsDefine(\"TweenMax\", [\"core.Animation\",\"core.SimpleTimeline\",\"TweenLite\"], function() {\n\n\t\tvar _slice = function(a) { //don't use [].slice because that doesn't work in IE8 with a NodeList that's returned by querySelectorAll()\n\t\t\t\tvar b = [],\n\t\t\t\t\tl = a.length,\n\t\t\t\t\ti;\n\t\t\t\tfor (i = 0; i !== l; b.push(a[i++]));\n\t\t\t\treturn b;\n\t\t\t},\n\t\t\t_applyCycle = function(vars, targets, i) {\n\t\t\t\tvar alt = vars.cycle,\n\t\t\t\t\tp, val;\n\t\t\t\tfor (p in alt) {\n\t\t\t\t\tval = alt[p];\n\t\t\t\t\tvars[p] = (typeof(val) === \"function\") ? val(i, targets[i], targets) : val[i % val.length];\n\t\t\t\t}\n\t\t\t\tdelete vars.cycle;\n\t\t\t},\n\t\t\t//for distributing values across an array. Can accept a number, a function or (most commonly) a function which can contain the following properties: {base, amount, from, ease, grid, axis, length, each}. Returns a function that expects the following parameters: index, target, array. Recognizes the following\n\t\t\t_distribute = function(v) {\n\t\t\t\tif (typeof(v) === \"function\") {\n\t\t\t\t\treturn v;\n\t\t\t\t}\n\t\t\t\tvar vars = (typeof(v) === \"object\") ? v : {each:v}, //n:1 is just to indicate v was a number; we leverage that later to set v according to the length we get. If a number is passed in, we treat it like the old stagger value where 0.1, for example, would mean that things would be distributed with 0.1 between each element in the array rather than a total \"amount\" that's chunked out among them all.\n\t\t\t\t\tease = vars.ease,\n\t\t\t\t\tfrom = vars.from || 0,\n\t\t\t\t\tbase = vars.base || 0,\n\t\t\t\t\tcache = {},\n\t\t\t\t\tisFromKeyword = isNaN(from),\n\t\t\t\t\taxis = vars.axis,\n\t\t\t\t\tratio = {center:0.5, end:1}[from] || 0;\n\t\t\t\treturn function(i, target, a) {\n\t\t\t\t\tvar l = (a || vars).length,\n\t\t\t\t\t\tdistances = cache[l],\n\t\t\t\t\t\toriginX, originY, x, y, d, j, max, min, wrap;\n\t\t\t\t\tif (!distances) {\n\t\t\t\t\t\twrap = (vars.grid === \"auto\") ? 0 : (vars.grid || [Infinity])[0];\n\t\t\t\t\t\tif (!wrap) {\n\t\t\t\t\t\t\tmax = -Infinity;\n\t\t\t\t\t\t\twhile (max < (max = a[wrap++].getBoundingClientRect().left) && wrap < l) { }\n\t\t\t\t\t\t\twrap--;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tdistances = cache[l] = [];\n\t\t\t\t\t\toriginX = isFromKeyword ? (Math.min(wrap, l) * ratio) - 0.5 : from % wrap;\n\t\t\t\t\t\toriginY = isFromKeyword ? l * ratio / wrap - 0.5 : (from / wrap) | 0;\n\t\t\t\t\t\tmax = 0;\n\t\t\t\t\t\tmin = Infinity;\n\t\t\t\t\t\tfor (j = 0; j < l; j++) {\n\t\t\t\t\t\t\tx = (j % wrap) - originX;\n\t\t\t\t\t\t\ty = originY - ((j / wrap) | 0);\n\t\t\t\t\t\t\tdistances[j] = d = !axis ? Math.sqrt(x * x + y * y) : Math.abs((axis === \"y\") ? y : x);\n\t\t\t\t\t\t\tif (d > max) {\n\t\t\t\t\t\t\t\tmax = d;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (d < min) {\n\t\t\t\t\t\t\t\tmin = d;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tdistances.max = max - min;\n\t\t\t\t\t\tdistances.min = min;\n\t\t\t\t\t\tdistances.v = l = vars.amount || (vars.each * (wrap > l ? l - 1 : !axis ? Math.max(wrap, l / wrap) : axis === \"y\" ? l / wrap : wrap)) || 0;\n\t\t\t\t\t\tdistances.b = (l < 0) ? base - l : base;\n\t\t\t\t\t}\n\t\t\t\t\tl = (distances[i] - distances.min) / distances.max;\n\t\t\t\t\treturn distances.b + (ease ? ease.getRatio(l) : l) * distances.v;\n\t\t\t\t};\n\t\t\t},\n\t\t\tTweenMax = function(target, duration, vars) {\n\t\t\t\t_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].call(this, target, duration, vars);\n\t\t\t\tthis._cycle = 0;\n\t\t\t\tthis._yoyo = (this.vars.yoyo === true || !!this.vars.yoyoEase);\n\t\t\t\tthis._repeat = this.vars.repeat || 0;\n\t\t\t\tthis._repeatDelay = this.vars.repeatDelay || 0;\n\t\t\t\tif (this._repeat) {\n\t\t\t\t\tthis._uncache(true); //ensures that if there is any repeat, the totalDuration will get recalculated to accurately report it.\n\t\t\t\t}\n\t\t\t\tthis.render = TweenMax.prototype.render; //speed optimization (avoid prototype lookup on this \"hot\" method)\n\t\t\t},\n\t\t\t_tinyNum = 0.00000001,\n\t\t\tTweenLiteInternals = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]._internals,\n\t\t\t_isSelector = TweenLiteInternals.isSelector,\n\t\t\t_isArray = TweenLiteInternals.isArray,\n\t\t\tp = TweenMax.prototype = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].to({}, 0.1, {}),\n\t\t\t_blankArray = [];\n\n\t\tTweenMax.version = \"2.1.3\";\n\t\tp.constructor = TweenMax;\n\t\tp.kill()._gc = false;\n\t\tTweenMax.killTweensOf = TweenMax.killDelayedCallsTo = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].killTweensOf;\n\t\tTweenMax.getTweensOf = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].getTweensOf;\n\t\tTweenMax.lagSmoothing = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].lagSmoothing;\n\t\tTweenMax.ticker = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].ticker;\n\t\tTweenMax.render = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].render;\n\t\tTweenMax.distribute = _distribute;\n\n\t\tp.invalidate = function() {\n\t\t\tthis._yoyo = (this.vars.yoyo === true || !!this.vars.yoyoEase);\n\t\t\tthis._repeat = this.vars.repeat || 0;\n\t\t\tthis._repeatDelay = this.vars.repeatDelay || 0;\n\t\t\tthis._yoyoEase = null;\n\t\t\tthis._uncache(true);\n\t\t\treturn _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].prototype.invalidate.call(this);\n\t\t};\n\n\t\tp.updateTo = function(vars, resetDuration) {\n\t\t\tvar self = this,\n\t\t\t\tcurRatio = self.ratio,\n\t\t\t\timmediate = self.vars.immediateRender || vars.immediateRender,\n\t\t\t\tp;\n\t\t\tif (resetDuration && self._startTime < self._timeline._time) {\n\t\t\t\tself._startTime = self._timeline._time;\n\t\t\t\tself._uncache(false);\n\t\t\t\tif (self._gc) {\n\t\t\t\t\tself._enabled(true, false);\n\t\t\t\t} else {\n\t\t\t\t\tself._timeline.insert(self, self._startTime - self._delay); //ensures that any necessary re-sequencing of Animations in the timeline occurs to make sure the rendering order is correct.\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor (p in vars) {\n\t\t\t\tself.vars[p] = vars[p];\n\t\t\t}\n\t\t\tif (self._initted || immediate) {\n\t\t\t\tif (resetDuration) {\n\t\t\t\t\tself._initted = false;\n\t\t\t\t\tif (immediate) {\n\t\t\t\t\t\tself.render(0, true, true);\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tif (self._gc) {\n\t\t\t\t\t\tself._enabled(true, false);\n\t\t\t\t\t}\n\t\t\t\t\tif (self._notifyPluginsOfEnabled && self._firstPT) {\n\t\t\t\t\t\t_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]._onPluginEvent(\"_onDisable\", self); //in case a plugin like MotionBlur must perform some cleanup tasks\n\t\t\t\t\t}\n\t\t\t\t\tif (self._time / self._duration > 0.998) { //if the tween has finished (or come extremely close to finishing), we just need to rewind it to 0 and then render it again at the end which forces it to re-initialize (parsing the new vars). We allow tweens that are close to finishing (but haven't quite finished) to work this way too because otherwise, the values are so small when determining where to project the starting values that binary math issues creep in and can make the tween appear to render incorrectly when run backwards.\n\t\t\t\t\t\tvar prevTime = self._totalTime;\n\t\t\t\t\t\tself.render(0, true, false);\n\t\t\t\t\t\tself._initted = false;\n\t\t\t\t\t\tself.render(prevTime, true, false);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tself._initted = false;\n\t\t\t\t\t\tself._init();\n\t\t\t\t\t\tif (self._time > 0 || immediate) {\n\t\t\t\t\t\t\tvar inv = 1 / (1 - curRatio),\n\t\t\t\t\t\t\t\tpt = self._firstPT, endValue;\n\t\t\t\t\t\t\twhile (pt) {\n\t\t\t\t\t\t\t\tendValue = pt.s + pt.c;\n\t\t\t\t\t\t\t\tpt.c *= inv;\n\t\t\t\t\t\t\t\tpt.s = endValue - pt.c;\n\t\t\t\t\t\t\t\tpt = pt._next;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn self;\n\t\t};\n\n\t\tp.render = function(time, suppressEvents, force) {\n\t\t\tif (!this._initted) if (this._duration === 0 && this.vars.repeat) { //zero duration tweens that render immediately have render() called from TweenLite's constructor, before TweenMax's constructor has finished setting _repeat, _repeatDelay, and _yoyo which are critical in determining totalDuration() so we need to call invalidate() which is a low-kb way to get those set properly.\n\t\t\t\tthis.invalidate();\n\t\t\t}\n\t\t\tvar self = this,\n\t\t\t\ttotalDur = (!self._dirty) ? self._totalDuration : self.totalDuration(),\n\t\t\t\tprevTime = self._time,\n\t\t\t\tprevTotalTime = self._totalTime,\n\t\t\t\tprevCycle = self._cycle,\n\t\t\t\tduration = self._duration,\n\t\t\t\tprevRawPrevTime = self._rawPrevTime,\n\t\t\t\tisComplete, callback, pt, cycleDuration, r, type, pow, rawPrevTime, yoyoEase;\n\t\t\tif (time >= totalDur - _tinyNum && time >= 0) { //to work around occasional floating point math artifacts.\n\t\t\t\tself._totalTime = totalDur;\n\t\t\t\tself._cycle = self._repeat;\n\t\t\t\tif (self._yoyo && (self._cycle & 1) !== 0) {\n\t\t\t\t\tself._time = 0;\n\t\t\t\t\tself.ratio = self._ease._calcEnd ? self._ease.getRatio(0) : 0;\n\t\t\t\t} else {\n\t\t\t\t\tself._time = duration;\n\t\t\t\t\tself.ratio = self._ease._calcEnd ? self._ease.getRatio(1) : 1;\n\t\t\t\t}\n\t\t\t\tif (!self._reversed) {\n\t\t\t\t\tisComplete = true;\n\t\t\t\t\tcallback = \"onComplete\";\n\t\t\t\t\tforce = (force || self._timeline.autoRemoveChildren); //otherwise, if the animation is unpaused/activated after it's already finished, it doesn't get removed from the parent timeline.\n\t\t\t\t}\n\t\t\t\tif (duration === 0) if (self._initted || !self.vars.lazy || force) { //zero-duration tweens are tricky because we must discern the momentum/direction of time in order to determine whether the starting values should be rendered or the ending values. If the \"playhead\" of its timeline goes past the zero-duration tween in the forward direction or lands directly on it, the end values should be rendered, but if the timeline's \"playhead\" moves past it in the backward direction (from a postitive time to a negative time), the starting values must be rendered.\n\t\t\t\t\tif (self._startTime === self._timeline._duration) { //if a zero-duration tween is at the VERY end of a timeline and that timeline renders at its end, it will typically add a tiny bit of cushion to the render time to prevent rounding errors from getting in the way of tweens rendering their VERY end. If we then reverse() that timeline, the zero-duration tween will trigger its onReverseComplete even though technically the playhead didn't pass over it again. It's a very specific edge case we must accommodate.\n\t\t\t\t\t\ttime = 0;\n\t\t\t\t\t}\n\t\t\t\t\tif (prevRawPrevTime < 0 || (time <= 0 && time >= -_tinyNum) || (prevRawPrevTime === _tinyNum && self.data !== \"isPause\")) if (prevRawPrevTime !== time) { //note: when this.data is \"isPause\", it's a callback added by addPause() on a timeline that we should not be triggered when LEAVING its exact start time. In other words, tl.addPause(1).play(1) shouldn't pause.\n\t\t\t\t\t\tforce = true;\n\t\t\t\t\t\tif (prevRawPrevTime > _tinyNum) {\n\t\t\t\t\t\t\tcallback = \"onReverseComplete\";\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tself._rawPrevTime = rawPrevTime = (!suppressEvents || time || prevRawPrevTime === time) ? time : _tinyNum; //when the playhead arrives at EXACTLY time 0 (right on top) of a zero-duration tween, we need to discern if events are suppressed so that when the playhead moves again (next time), it'll trigger the callback. If events are NOT suppressed, obviously the callback would be triggered in this render. Basically, the callback should fire either when the playhead ARRIVES or LEAVES this exact spot, not both. Imagine doing a timeline.seek(0) and there's a callback that sits at 0. Since events are suppressed on that seek() by default, nothing will fire, but when the playhead moves off of that position, the callback should fire. This behavior is what people intuitively expect. We set the _rawPrevTime to be a precise tiny number to indicate this scenario rather than using another property/variable which would increase memory usage. This technique is less readable, but more efficient.\n\t\t\t\t}\n\n\t\t\t} else if (time < _tinyNum) { //to work around occasional floating point math artifacts, round super small values to 0.\n\t\t\t\tself._totalTime = self._time = self._cycle = 0;\n\t\t\t\tself.ratio = self._ease._calcEnd ? self._ease.getRatio(0) : 0;\n\t\t\t\tif (prevTotalTime !== 0 || (duration === 0 && prevRawPrevTime > 0)) {\n\t\t\t\t\tcallback = \"onReverseComplete\";\n\t\t\t\t\tisComplete = self._reversed;\n\t\t\t\t}\n\t\t\t\tif (time > -_tinyNum) {\n\t\t\t\t\ttime = 0;\n\t\t\t\t} else if (time < 0) {\n\t\t\t\t\tself._active = false;\n\t\t\t\t\tif (duration === 0) if (self._initted || !self.vars.lazy || force) { //zero-duration tweens are tricky because we must discern the momentum/direction of time in order to determine whether the starting values should be rendered or the ending values. If the \"playhead\" of its timeline goes past the zero-duration tween in the forward direction or lands directly on it, the end values should be rendered, but if the timeline's \"playhead\" moves past it in the backward direction (from a postitive time to a negative time), the starting values must be rendered.\n\t\t\t\t\t\tif (prevRawPrevTime >= 0) {\n\t\t\t\t\t\t\tforce = true;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tself._rawPrevTime = rawPrevTime = (!suppressEvents || time || prevRawPrevTime === time) ? time : _tinyNum; //when the playhead arrives at EXACTLY time 0 (right on top) of a zero-duration tween, we need to discern if events are suppressed so that when the playhead moves again (next time), it'll trigger the callback. If events are NOT suppressed, obviously the callback would be triggered in this render. Basically, the callback should fire either when the playhead ARRIVES or LEAVES this exact spot, not both. Imagine doing a timeline.seek(0) and there's a callback that sits at 0. Since events are suppressed on that seek() by default, nothing will fire, but when the playhead moves off of that position, the callback should fire. This behavior is what people intuitively expect. We set the _rawPrevTime to be a precise tiny number to indicate this scenario rather than using another property/variable which would increase memory usage. This technique is less readable, but more efficient.\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (!self._initted) { //if we render the very beginning (time == 0) of a fromTo(), we must force the render (normal tweens wouldn't need to render at a time of 0 when the prevTime was also 0). This is also mandatory to make sure overwriting kicks in immediately.\n\t\t\t\t\tforce = true;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tself._totalTime = self._time = time;\n\t\t\t\tif (self._repeat !== 0) {\n\t\t\t\t\tcycleDuration = duration + self._repeatDelay;\n\t\t\t\t\tself._cycle = (self._totalTime / cycleDuration) >> 0; //originally _totalTime % cycleDuration but floating point errors caused problems, so I normalized it. (4 % 0.8 should be 0 but some browsers report it as 0.79999999!)\n\t\t\t\t\tif (self._cycle !== 0) if (self._cycle === self._totalTime / cycleDuration && prevTotalTime <= time) {\n\t\t\t\t\t\tself._cycle--; //otherwise when rendered exactly at the end time, it will act as though it is repeating (at the beginning)\n\t\t\t\t\t}\n\t\t\t\t\tself._time = self._totalTime - (self._cycle * cycleDuration);\n\t\t\t\t\tif (self._yoyo) if ((self._cycle & 1) !== 0) {\n\t\t\t\t\t\tself._time = duration - self._time;\n\t\t\t\t\t\tyoyoEase = self._yoyoEase || self.vars.yoyoEase; //note: we don't set this._yoyoEase in _init() like we do other properties because it's TweenMax-specific and doing it here allows us to optimize performance (most tweens don't have a yoyoEase). Note that we also must skip the this.ratio calculation further down right after we _init() in this function, because we're doing it here.\n\t\t\t\t\t\tif (yoyoEase) {\n\t\t\t\t\t\t\tif (!self._yoyoEase) {\n\t\t\t\t\t\t\t\tif (yoyoEase === true && !self._initted) { //if it's not initted and yoyoEase is true, this._ease won't have been populated yet so we must discern it here.\n\t\t\t\t\t\t\t\t\tyoyoEase = self.vars.ease;\n\t\t\t\t\t\t\t\t\tself._yoyoEase = yoyoEase = !yoyoEase ? _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].defaultEase : (yoyoEase instanceof _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Ease\"]) ? yoyoEase : (typeof(yoyoEase) === \"function\") ? new _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Ease\"](yoyoEase, self.vars.easeParams) : _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Ease\"].map[yoyoEase] || _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].defaultEase;\n\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\tself._yoyoEase = yoyoEase = (yoyoEase === true) ? self._ease : (yoyoEase instanceof _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Ease\"]) ? yoyoEase : _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Ease\"].map[yoyoEase];\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tself.ratio = yoyoEase ? 1 - yoyoEase.getRatio((duration - self._time) / duration) : 0;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (self._time > duration) {\n\t\t\t\t\t\tself._time = duration;\n\t\t\t\t\t} else if (self._time < 0) {\n\t\t\t\t\t\tself._time = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (self._easeType && !yoyoEase) {\n\t\t\t\t\tr = self._time / duration;\n\t\t\t\t\ttype = self._easeType;\n\t\t\t\t\tpow = self._easePower;\n\t\t\t\t\tif (type === 1 || (type === 3 && r >= 0.5)) {\n\t\t\t\t\t\tr = 1 - r;\n\t\t\t\t\t}\n\t\t\t\t\tif (type === 3) {\n\t\t\t\t\t\tr *= 2;\n\t\t\t\t\t}\n\t\t\t\t\tif (pow === 1) {\n\t\t\t\t\t\tr *= r;\n\t\t\t\t\t} else if (pow === 2) {\n\t\t\t\t\t\tr *= r * r;\n\t\t\t\t\t} else if (pow === 3) {\n\t\t\t\t\t\tr *= r * r * r;\n\t\t\t\t\t} else if (pow === 4) {\n\t\t\t\t\t\tr *= r * r * r * r;\n\t\t\t\t\t}\n\t\t\t\t\tself.ratio = (type === 1) ? 1 - r : (type === 2) ? r : (self._time / duration < 0.5) ? r / 2 : 1 - (r / 2);\n\n\t\t\t\t} else if (!yoyoEase) {\n\t\t\t\t\tself.ratio = self._ease.getRatio(self._time / duration);\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tif (prevTime === self._time && !force && prevCycle === self._cycle) {\n\t\t\t\tif (prevTotalTime !== self._totalTime) if (self._onUpdate) if (!suppressEvents) { //so that onUpdate fires even during the repeatDelay - as long as the totalTime changed, we should trigger onUpdate.\n\t\t\t\t\tself._callback(\"onUpdate\");\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t} else if (!self._initted) {\n\t\t\t\tself._init();\n\t\t\t\tif (!self._initted || self._gc) { //immediateRender tweens typically won't initialize until the playhead advances (_time is greater than 0) in order to ensure that overwriting occurs properly. Also, if all of the tweening properties have been overwritten (which would cause _gc to be true, as set in _init()), we shouldn't continue otherwise an onStart callback could be called for example.\n\t\t\t\t\treturn;\n\t\t\t\t} else if (!force && self._firstPT && ((self.vars.lazy !== false && self._duration) || (self.vars.lazy && !self._duration))) { //we stick it in the queue for rendering at the very end of the tick - this is a performance optimization because browsers invalidate styles and force a recalculation if you read, write, and then read style data (so it's better to read/read/read/write/write/write than read/write/read/write/read/write). The down side, of course, is that usually you WANT things to render immediately because you may have code running right after that which depends on the change. Like imagine running TweenLite.set(...) and then immediately after that, creating a nother tween that animates the same property to another value; the starting values of that 2nd tween wouldn't be accurate if lazy is true.\n\t\t\t\t\tself._time = prevTime;\n\t\t\t\t\tself._totalTime = prevTotalTime;\n\t\t\t\t\tself._rawPrevTime = prevRawPrevTime;\n\t\t\t\t\tself._cycle = prevCycle;\n\t\t\t\t\tTweenLiteInternals.lazyTweens.push(self);\n\t\t\t\t\tself._lazy = [time, suppressEvents];\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t//_ease is initially set to defaultEase, so now that init() has run, _ease is set properly and we need to recalculate the ratio. Overall this is faster than using conditional logic earlier in the method to avoid having to set ratio twice because we only init() once but renderTime() gets called VERY frequently.\n\t\t\t\tif (self._time && !isComplete && !yoyoEase) {\n\t\t\t\t\tself.ratio = self._ease.getRatio(self._time / duration);\n\t\t\t\t} else if (isComplete && this._ease._calcEnd && !yoyoEase) {\n\t\t\t\t\tself.ratio = self._ease.getRatio((self._time === 0) ? 0 : 1);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (self._lazy !== false) {\n\t\t\t\tself._lazy = false;\n\t\t\t}\n\n\t\t\tif (!self._active) if (!self._paused && self._time !== prevTime && time >= 0) {\n\t\t\t\tself._active = true; //so that if the user renders a tween (as opposed to the timeline rendering it), the timeline is forced to re-render and align it with the proper time/frame on the next rendering cycle. Maybe the tween already finished but the user manually re-renders it as halfway done.\n\t\t\t}\n\t\t\tif (prevTotalTime === 0) {\n\t\t\t\tif (self._initted === 2 && time > 0) {\n\t\t\t\t\tself._init(); //will just apply overwriting since _initted of (2) means it was a from() tween that had immediateRender:true\n\t\t\t\t}\n\t\t\t\tif (self._startAt) {\n\t\t\t\t\tif (time >= 0) {\n\t\t\t\t\t\tself._startAt.render(time, true, force);\n\t\t\t\t\t} else if (!callback) {\n\t\t\t\t\t\tcallback = \"_dummyGS\"; //if no callback is defined, use a dummy value just so that the condition at the end evaluates as true because _startAt should render AFTER the normal render loop when the time is negative. We could handle this in a more intuitive way, of course, but the render loop is the MOST important thing to optimize, so this technique allows us to avoid adding extra conditional logic in a high-frequency area.\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (self.vars.onStart) if (self._totalTime !== 0 || duration === 0) if (!suppressEvents) {\n\t\t\t\t\tself._callback(\"onStart\");\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tpt = self._firstPT;\n\t\t\twhile (pt) {\n\t\t\t\tif (pt.f) {\n\t\t\t\t\tpt.t[pt.p](pt.c * self.ratio + pt.s);\n\t\t\t\t} else {\n\t\t\t\t\tpt.t[pt.p] = pt.c * self.ratio + pt.s;\n\t\t\t\t}\n\t\t\t\tpt = pt._next;\n\t\t\t}\n\n\t\t\tif (self._onUpdate) {\n\t\t\t\tif (time < 0) if (self._startAt && self._startTime) { //if the tween is positioned at the VERY beginning (_startTime 0) of its parent timeline, it's illegal for the playhead to go back further, so we should not render the recorded startAt values.\n\t\t\t\t\tself._startAt.render(time, true, force); //note: for performance reasons, we tuck this conditional logic inside less traveled areas (most tweens don't have an onUpdate). We'd just have it at the end before the onComplete, but the values should be updated before any onUpdate is called, so we ALSO put it here and then if it's not called, we do so later near the onComplete.\n\t\t\t\t}\n\t\t\t\tif (!suppressEvents) if (self._totalTime !== prevTotalTime || callback) {\n\t\t\t\t\tself._callback(\"onUpdate\");\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (self._cycle !== prevCycle) if (!suppressEvents) if (!self._gc) if (self.vars.onRepeat) {\n\t\t\t\tself._callback(\"onRepeat\");\n\t\t\t}\n\t\t\tif (callback) if (!self._gc || force) { //check gc because there's a chance that kill() could be called in an onUpdate\n\t\t\t\tif (time < 0 && self._startAt && !self._onUpdate && self._startTime) { //if the tween is positioned at the VERY beginning (_startTime 0) of its parent timeline, it's illegal for the playhead to go back further, so we should not render the recorded startAt values.\n\t\t\t\t\tself._startAt.render(time, true, force);\n\t\t\t\t}\n\t\t\t\tif (isComplete) {\n\t\t\t\t\tif (self._timeline.autoRemoveChildren) {\n\t\t\t\t\t\tself._enabled(false, false);\n\t\t\t\t\t}\n\t\t\t\t\tself._active = false;\n\t\t\t\t}\n\t\t\t\tif (!suppressEvents && self.vars[callback]) {\n\t\t\t\t\tself._callback(callback);\n\t\t\t\t}\n\t\t\t\tif (duration === 0 && self._rawPrevTime === _tinyNum && rawPrevTime !== _tinyNum) { //the onComplete or onReverseComplete could trigger movement of the playhead and for zero-duration tweens (which must discern direction) that land directly back on their start time, we don't want to fire again on the next render. Think of several addPause()'s in a timeline that forces the playhead to a certain spot, but what if it's already paused and another tween is tweening the \"time\" of the timeline? Each time it moves [forward] past that spot, it would move back, and since suppressEvents is true, it'd reset _rawPrevTime to _tinyNum so that when it begins again, the callback would fire (so ultimately it could bounce back and forth during that tween). Again, this is a very uncommon scenario, but possible nonetheless.\n\t\t\t\t\tself._rawPrevTime = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\n//---- STATIC FUNCTIONS -----------------------------------------------------------------------------------------------------------\n\n\t\tTweenMax.to = function(target, duration, vars) {\n\t\t\treturn new TweenMax(target, duration, vars);\n\t\t};\n\n\t\tTweenMax.from = function(target, duration, vars) {\n\t\t\tvars.runBackwards = true;\n\t\t\tvars.immediateRender = (vars.immediateRender != false);\n\t\t\treturn new TweenMax(target, duration, vars);\n\t\t};\n\n\t\tTweenMax.fromTo = function(target, duration, fromVars, toVars) {\n\t\t\ttoVars.startAt = fromVars;\n\t\t\ttoVars.immediateRender = (toVars.immediateRender != false && fromVars.immediateRender != false);\n\t\t\treturn new TweenMax(target, duration, toVars);\n\t\t};\n\n\t\tTweenMax.staggerTo = TweenMax.allTo = function(targets, duration, vars, stagger, onCompleteAll, onCompleteAllParams, onCompleteAllScope) {\n\t\t\tvar a = [],\n\t\t\t\tstaggerFunc = _distribute(vars.stagger || stagger),\n\t\t\t\tcycle = vars.cycle,\n\t\t\t\tfromCycle = (vars.startAt || _blankArray).cycle,\n\t\t\t\tl, copy, i, p;\n\t\t\tif (!_isArray(targets)) {\n\t\t\t\tif (typeof(targets) === \"string\") {\n\t\t\t\t\ttargets = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].selector(targets) || targets;\n\t\t\t\t}\n\t\t\t\tif (_isSelector(targets)) {\n\t\t\t\t\ttargets = _slice(targets);\n\t\t\t\t}\n\t\t\t}\n\t\t\ttargets = targets || [];\n\t\t\tl = targets.length - 1;\n\t\t\tfor (i = 0; i <= l; i++) {\n\t\t\t\tcopy = {};\n\t\t\t\tfor (p in vars) {\n\t\t\t\t\tcopy[p] = vars[p];\n\t\t\t\t}\n\t\t\t\tif (cycle) {\n\t\t\t\t\t_applyCycle(copy, targets, i);\n\t\t\t\t\tif (copy.duration != null) {\n\t\t\t\t\t\tduration = copy.duration;\n\t\t\t\t\t\tdelete copy.duration;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (fromCycle) {\n\t\t\t\t\tfromCycle = copy.startAt = {};\n\t\t\t\t\tfor (p in vars.startAt) {\n\t\t\t\t\t\tfromCycle[p] = vars.startAt[p];\n\t\t\t\t\t}\n\t\t\t\t\t_applyCycle(copy.startAt, targets, i);\n\t\t\t\t}\n\t\t\t\tcopy.delay = staggerFunc(i, targets[i], targets) + (copy.delay || 0);\n\t\t\t\tif (i === l && onCompleteAll) {\n\t\t\t\t\tcopy.onComplete = function() {\n\t\t\t\t\t\tif (vars.onComplete) {\n\t\t\t\t\t\t\tvars.onComplete.apply(vars.onCompleteScope || this, arguments);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tonCompleteAll.apply(onCompleteAllScope || vars.callbackScope || this, onCompleteAllParams || _blankArray);\n\t\t\t\t\t};\n\t\t\t\t}\n\t\t\t\ta[i] = new TweenMax(targets[i], duration, copy);\n\t\t\t}\n\t\t\treturn a;\n\t\t};\n\n\t\tTweenMax.staggerFrom = TweenMax.allFrom = function(targets, duration, vars, stagger, onCompleteAll, onCompleteAllParams, onCompleteAllScope) {\n\t\t\tvars.runBackwards = true;\n\t\t\tvars.immediateRender = (vars.immediateRender != false);\n\t\t\treturn TweenMax.staggerTo(targets, duration, vars, stagger, onCompleteAll, onCompleteAllParams, onCompleteAllScope);\n\t\t};\n\n\t\tTweenMax.staggerFromTo = TweenMax.allFromTo = function(targets, duration, fromVars, toVars, stagger, onCompleteAll, onCompleteAllParams, onCompleteAllScope) {\n\t\t\ttoVars.startAt = fromVars;\n\t\t\ttoVars.immediateRender = (toVars.immediateRender != false && fromVars.immediateRender != false);\n\t\t\treturn TweenMax.staggerTo(targets, duration, toVars, stagger, onCompleteAll, onCompleteAllParams, onCompleteAllScope);\n\t\t};\n\n\t\tTweenMax.delayedCall = function(delay, callback, params, scope, useFrames) {\n\t\t\treturn new TweenMax(callback, 0, {delay:delay, onComplete:callback, onCompleteParams:params, callbackScope:scope, onReverseComplete:callback, onReverseCompleteParams:params, immediateRender:false, useFrames:useFrames, overwrite:0});\n\t\t};\n\n\t\tTweenMax.set = function(target, vars) {\n\t\t\treturn new TweenMax(target, 0, vars);\n\t\t};\n\n\t\tTweenMax.isTweening = function(target) {\n\t\t\treturn (_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].getTweensOf(target, true).length > 0);\n\t\t};\n\n\t\tvar _getChildrenOf = function(timeline, includeTimelines) {\n\t\t\t\tvar a = [],\n\t\t\t\t\tcnt = 0,\n\t\t\t\t\ttween = timeline._first;\n\t\t\t\twhile (tween) {\n\t\t\t\t\tif (tween instanceof _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]) {\n\t\t\t\t\t\ta[cnt++] = tween;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif (includeTimelines) {\n\t\t\t\t\t\t\ta[cnt++] = tween;\n\t\t\t\t\t\t}\n\t\t\t\t\t\ta = a.concat(_getChildrenOf(tween, includeTimelines));\n\t\t\t\t\t\tcnt = a.length;\n\t\t\t\t\t}\n\t\t\t\t\ttween = tween._next;\n\t\t\t\t}\n\t\t\t\treturn a;\n\t\t\t},\n\t\t\tgetAllTweens = TweenMax.getAllTweens = function(includeTimelines) {\n\t\t\t\treturn _getChildrenOf(_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Animation\"]._rootTimeline, includeTimelines).concat( _getChildrenOf(_TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Animation\"]._rootFramesTimeline, includeTimelines) );\n\t\t\t};\n\n\t\tTweenMax.killAll = function(complete, tweens, delayedCalls, timelines) {\n\t\t\tif (tweens == null) {\n\t\t\t\ttweens = true;\n\t\t\t}\n\t\t\tif (delayedCalls == null) {\n\t\t\t\tdelayedCalls = true;\n\t\t\t}\n\t\t\tvar a = getAllTweens((timelines != false)),\n\t\t\t\tl = a.length,\n\t\t\t\tallTrue = (tweens && delayedCalls && timelines),\n\t\t\t\tisDC, tween, i;\n\t\t\tfor (i = 0; i < l; i++) {\n\t\t\t\ttween = a[i];\n\t\t\t\tif (allTrue || (tween instanceof _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"SimpleTimeline\"]) || ((isDC = (tween.target === tween.vars.onComplete)) && delayedCalls) || (tweens && !isDC)) {\n\t\t\t\t\tif (complete) {\n\t\t\t\t\t\ttween.totalTime(tween._reversed ? 0 : tween.totalDuration());\n\t\t\t\t\t} else {\n\t\t\t\t\t\ttween._enabled(false, false);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\n\t\tTweenMax.killChildTweensOf = function(parent, complete) {\n\t\t\tif (parent == null) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tvar tl = TweenLiteInternals.tweenLookup,\n\t\t\t\ta, curParent, p, i, l;\n\t\t\tif (typeof(parent) === \"string\") {\n\t\t\t\tparent = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].selector(parent) || parent;\n\t\t\t}\n\t\t\tif (_isSelector(parent)) {\n\t\t\t\tparent = _slice(parent);\n\t\t\t}\n\t\t\tif (_isArray(parent)) {\n\t\t\t\ti = parent.length;\n\t\t\t\twhile (--i > -1) {\n\t\t\t\t\tTweenMax.killChildTweensOf(parent[i], complete);\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t}\n\t\t\ta = [];\n\t\t\tfor (p in tl) {\n\t\t\t\tcurParent = tl[p].target.parentNode;\n\t\t\t\twhile (curParent) {\n\t\t\t\t\tif (curParent === parent) {\n\t\t\t\t\t\ta = a.concat(tl[p].tweens);\n\t\t\t\t\t}\n\t\t\t\t\tcurParent = curParent.parentNode;\n\t\t\t\t}\n\t\t\t}\n\t\t\tl = a.length;\n\t\t\tfor (i = 0; i < l; i++) {\n\t\t\t\tif (complete) {\n\t\t\t\t\ta[i].totalTime(a[i].totalDuration());\n\t\t\t\t}\n\t\t\t\ta[i]._enabled(false, false);\n\t\t\t}\n\t\t};\n\n\t\tvar _changePause = function(pause, tweens, delayedCalls, timelines) {\n\t\t\ttweens = (tweens !== false);\n\t\t\tdelayedCalls = (delayedCalls !== false);\n\t\t\ttimelines = (timelines !== false);\n\t\t\tvar a = getAllTweens(timelines),\n\t\t\t\tallTrue = (tweens && delayedCalls && timelines),\n\t\t\t\ti = a.length,\n\t\t\t\tisDC, tween;\n\t\t\twhile (--i > -1) {\n\t\t\t\ttween = a[i];\n\t\t\t\tif (allTrue || (tween instanceof _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"SimpleTimeline\"]) || ((isDC = (tween.target === tween.vars.onComplete)) && delayedCalls) || (tweens && !isDC)) {\n\t\t\t\t\ttween.paused(pause);\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\n\t\tTweenMax.pauseAll = function(tweens, delayedCalls, timelines) {\n\t\t\t_changePause(true, tweens, delayedCalls, timelines);\n\t\t};\n\n\t\tTweenMax.resumeAll = function(tweens, delayedCalls, timelines) {\n\t\t\t_changePause(false, tweens, delayedCalls, timelines);\n\t\t};\n\n\t\tTweenMax.globalTimeScale = function(value) {\n\t\t\tvar tl = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Animation\"]._rootTimeline,\n\t\t\t\tt = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].ticker.time;\n\t\t\tif (!arguments.length) {\n\t\t\t\treturn tl._timeScale;\n\t\t\t}\n\t\t\tvalue = value || _tinyNum; //can't allow zero because it'll throw the math off\n\t\t\ttl._startTime = t - ((t - tl._startTime) * tl._timeScale / value);\n\t\t\ttl = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Animation\"]._rootFramesTimeline;\n\t\t\tt = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].ticker.frame;\n\t\t\ttl._startTime = t - ((t - tl._startTime) * tl._timeScale / value);\n\t\t\ttl._timeScale = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Animation\"]._rootTimeline._timeScale = value;\n\t\t\treturn value;\n\t\t};\n\n\n//---- GETTERS / SETTERS ----------------------------------------------------------------------------------------------------------\n\n\t\tp.progress = function(value, suppressEvents) {\n\t\t\treturn (!arguments.length) ? (this.duration() ? this._time / this._duration : this.ratio) : this.totalTime( this.duration() * ((this._yoyo && (this._cycle & 1) !== 0) ? 1 - value : value) + (this._cycle * (this._duration + this._repeatDelay)), suppressEvents);\n\t\t};\n\n\t\tp.totalProgress = function(value, suppressEvents) {\n\t\t\treturn (!arguments.length) ? this._totalTime / this.totalDuration() : this.totalTime( this.totalDuration() * value, suppressEvents);\n\t\t};\n\n\t\tp.time = function(value, suppressEvents) {\n\t\t\tif (!arguments.length) {\n\t\t\t\treturn this._time;\n\t\t\t}\n\t\t\tif (this._dirty) {\n\t\t\t\tthis.totalDuration();\n\t\t\t}\n\t\t\tvar duration = this._duration,\n\t\t\t\tcycle = this._cycle,\n\t\t\t\tcycleDur = cycle * (duration + this._repeatDelay);\n\t\t\tif (value > duration) {\n\t\t\t\tvalue = duration;\n\t\t\t}\n\t\t\treturn this.totalTime((this._yoyo && (cycle & 1)) ? duration - value + cycleDur : this._repeat ? value + cycleDur : value, suppressEvents);\n\t\t};\n\n\t\tp.duration = function(value) {\n\t\t\tif (!arguments.length) {\n\t\t\t\treturn this._duration; //don't set _dirty = false because there could be repeats that haven't been factored into the _totalDuration yet. Otherwise, if you create a repeated TweenMax and then immediately check its duration(), it would cache the value and the totalDuration would not be correct, thus repeats wouldn't take effect.\n\t\t\t}\n\t\t\treturn _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"Animation\"].prototype.duration.call(this, value);\n\t\t};\n\n\t\tp.totalDuration = function(value) {\n\t\t\tif (!arguments.length) {\n\t\t\t\tif (this._dirty) {\n\t\t\t\t\t//instead of Infinity, we use 999999999999 so that we can accommodate reverses\n\t\t\t\t\tthis._totalDuration = (this._repeat === -1) ? 999999999999 : this._duration * (this._repeat + 1) + (this._repeatDelay * this._repeat);\n\t\t\t\t\tthis._dirty = false;\n\t\t\t\t}\n\t\t\t\treturn this._totalDuration;\n\t\t\t}\n\t\t\treturn (this._repeat === -1) ? this : this.duration( (value - (this._repeat * this._repeatDelay)) / (this._repeat + 1) );\n\t\t};\n\n\t\tp.repeat = function(value) {\n\t\t\tif (!arguments.length) {\n\t\t\t\treturn this._repeat;\n\t\t\t}\n\t\t\tthis._repeat = value;\n\t\t\treturn this._uncache(true);\n\t\t};\n\n\t\tp.repeatDelay = function(value) {\n\t\t\tif (!arguments.length) {\n\t\t\t\treturn this._repeatDelay;\n\t\t\t}\n\t\t\tthis._repeatDelay = value;\n\t\t\treturn this._uncache(true);\n\t\t};\n\n\t\tp.yoyo = function(value) {\n\t\t\tif (!arguments.length) {\n\t\t\t\treturn this._yoyo;\n\t\t\t}\n\t\t\tthis._yoyo = value;\n\t\t\treturn this;\n\t\t};\n\n\n\t\treturn TweenMax;\n\n\t}, true);\n\nvar TweenMax = _TweenLite_js__WEBPACK_IMPORTED_MODULE_0__[\"globals\"].TweenMax;\nvar TweenMaxBase = TweenMax;\n\n\n\n\n//# sourceURL=webpack:///./node_modules/gsap/TweenMaxBase.js?");

/***/ }),

/***/ "./node_modules/ieee754/index.js":
/*!***************************************!*\
  !*** ./node_modules/ieee754/index.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("exports.read = function (buffer, offset, isLE, mLen, nBytes) {\n  var e, m\n  var eLen = (nBytes * 8) - mLen - 1\n  var eMax = (1 << eLen) - 1\n  var eBias = eMax >> 1\n  var nBits = -7\n  var i = isLE ? (nBytes - 1) : 0\n  var d = isLE ? -1 : 1\n  var s = buffer[offset + i]\n\n  i += d\n\n  e = s & ((1 << (-nBits)) - 1)\n  s >>= (-nBits)\n  nBits += eLen\n  for (; nBits > 0; e = (e * 256) + buffer[offset + i], i += d, nBits -= 8) {}\n\n  m = e & ((1 << (-nBits)) - 1)\n  e >>= (-nBits)\n  nBits += mLen\n  for (; nBits > 0; m = (m * 256) + buffer[offset + i], i += d, nBits -= 8) {}\n\n  if (e === 0) {\n    e = 1 - eBias\n  } else if (e === eMax) {\n    return m ? NaN : ((s ? -1 : 1) * Infinity)\n  } else {\n    m = m + Math.pow(2, mLen)\n    e = e - eBias\n  }\n  return (s ? -1 : 1) * m * Math.pow(2, e - mLen)\n}\n\nexports.write = function (buffer, value, offset, isLE, mLen, nBytes) {\n  var e, m, c\n  var eLen = (nBytes * 8) - mLen - 1\n  var eMax = (1 << eLen) - 1\n  var eBias = eMax >> 1\n  var rt = (mLen === 23 ? Math.pow(2, -24) - Math.pow(2, -77) : 0)\n  var i = isLE ? 0 : (nBytes - 1)\n  var d = isLE ? 1 : -1\n  var s = value < 0 || (value === 0 && 1 / value < 0) ? 1 : 0\n\n  value = Math.abs(value)\n\n  if (isNaN(value) || value === Infinity) {\n    m = isNaN(value) ? 1 : 0\n    e = eMax\n  } else {\n    e = Math.floor(Math.log(value) / Math.LN2)\n    if (value * (c = Math.pow(2, -e)) < 1) {\n      e--\n      c *= 2\n    }\n    if (e + eBias >= 1) {\n      value += rt / c\n    } else {\n      value += rt * Math.pow(2, 1 - eBias)\n    }\n    if (value * c >= 2) {\n      e++\n      c /= 2\n    }\n\n    if (e + eBias >= eMax) {\n      m = 0\n      e = eMax\n    } else if (e + eBias >= 1) {\n      m = ((value * c) - 1) * Math.pow(2, mLen)\n      e = e + eBias\n    } else {\n      m = value * Math.pow(2, eBias - 1) * Math.pow(2, mLen)\n      e = 0\n    }\n  }\n\n  for (; mLen >= 8; buffer[offset + i] = m & 0xff, i += d, m /= 256, mLen -= 8) {}\n\n  e = (e << mLen) | m\n  eLen += mLen\n  for (; eLen > 0; buffer[offset + i] = e & 0xff, i += d, e /= 256, eLen -= 8) {}\n\n  buffer[offset + i - d] |= s * 128\n}\n\n\n//# sourceURL=webpack:///./node_modules/ieee754/index.js?");

/***/ }),

/***/ "./node_modules/isarray/index.js":
/*!***************************************!*\
  !*** ./node_modules/isarray/index.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("var toString = {}.toString;\n\nmodule.exports = Array.isArray || function (arr) {\n  return toString.call(arr) == '[object Array]';\n};\n\n\n//# sourceURL=webpack:///./node_modules/isarray/index.js?");

/***/ }),

/***/ "./node_modules/node-libs-browser/mock/empty.js":
/*!******************************************************!*\
  !*** ./node_modules/node-libs-browser/mock/empty.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("\n\n//# sourceURL=webpack:///./node_modules/node-libs-browser/mock/empty.js?");

/***/ }),

/***/ "./node_modules/process/browser.js":
/*!*****************************************!*\
  !*** ./node_modules/process/browser.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// shim for using process in browser\nvar process = module.exports = {};\n\n// cached from whatever global is present so that test runners that stub it\n// don't break things.  But we need to wrap it in a try catch in case it is\n// wrapped in strict mode code which doesn't define any globals.  It's inside a\n// function because try/catches deoptimize in certain engines.\n\nvar cachedSetTimeout;\nvar cachedClearTimeout;\n\nfunction defaultSetTimout() {\n    throw new Error('setTimeout has not been defined');\n}\nfunction defaultClearTimeout () {\n    throw new Error('clearTimeout has not been defined');\n}\n(function () {\n    try {\n        if (typeof setTimeout === 'function') {\n            cachedSetTimeout = setTimeout;\n        } else {\n            cachedSetTimeout = defaultSetTimout;\n        }\n    } catch (e) {\n        cachedSetTimeout = defaultSetTimout;\n    }\n    try {\n        if (typeof clearTimeout === 'function') {\n            cachedClearTimeout = clearTimeout;\n        } else {\n            cachedClearTimeout = defaultClearTimeout;\n        }\n    } catch (e) {\n        cachedClearTimeout = defaultClearTimeout;\n    }\n} ())\nfunction runTimeout(fun) {\n    if (cachedSetTimeout === setTimeout) {\n        //normal enviroments in sane situations\n        return setTimeout(fun, 0);\n    }\n    // if setTimeout wasn't available but was latter defined\n    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {\n        cachedSetTimeout = setTimeout;\n        return setTimeout(fun, 0);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedSetTimeout(fun, 0);\n    } catch(e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally\n            return cachedSetTimeout.call(null, fun, 0);\n        } catch(e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error\n            return cachedSetTimeout.call(this, fun, 0);\n        }\n    }\n\n\n}\nfunction runClearTimeout(marker) {\n    if (cachedClearTimeout === clearTimeout) {\n        //normal enviroments in sane situations\n        return clearTimeout(marker);\n    }\n    // if clearTimeout wasn't available but was latter defined\n    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {\n        cachedClearTimeout = clearTimeout;\n        return clearTimeout(marker);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedClearTimeout(marker);\n    } catch (e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally\n            return cachedClearTimeout.call(null, marker);\n        } catch (e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.\n            // Some versions of I.E. have different rules for clearTimeout vs setTimeout\n            return cachedClearTimeout.call(this, marker);\n        }\n    }\n\n\n\n}\nvar queue = [];\nvar draining = false;\nvar currentQueue;\nvar queueIndex = -1;\n\nfunction cleanUpNextTick() {\n    if (!draining || !currentQueue) {\n        return;\n    }\n    draining = false;\n    if (currentQueue.length) {\n        queue = currentQueue.concat(queue);\n    } else {\n        queueIndex = -1;\n    }\n    if (queue.length) {\n        drainQueue();\n    }\n}\n\nfunction drainQueue() {\n    if (draining) {\n        return;\n    }\n    var timeout = runTimeout(cleanUpNextTick);\n    draining = true;\n\n    var len = queue.length;\n    while(len) {\n        currentQueue = queue;\n        queue = [];\n        while (++queueIndex < len) {\n            if (currentQueue) {\n                currentQueue[queueIndex].run();\n            }\n        }\n        queueIndex = -1;\n        len = queue.length;\n    }\n    currentQueue = null;\n    draining = false;\n    runClearTimeout(timeout);\n}\n\nprocess.nextTick = function (fun) {\n    var args = new Array(arguments.length - 1);\n    if (arguments.length > 1) {\n        for (var i = 1; i < arguments.length; i++) {\n            args[i - 1] = arguments[i];\n        }\n    }\n    queue.push(new Item(fun, args));\n    if (queue.length === 1 && !draining) {\n        runTimeout(drainQueue);\n    }\n};\n\n// v8 likes predictible objects\nfunction Item(fun, array) {\n    this.fun = fun;\n    this.array = array;\n}\nItem.prototype.run = function () {\n    this.fun.apply(null, this.array);\n};\nprocess.title = 'browser';\nprocess.browser = true;\nprocess.env = {};\nprocess.argv = [];\nprocess.version = ''; // empty string to avoid regexp issues\nprocess.versions = {};\n\nfunction noop() {}\n\nprocess.on = noop;\nprocess.addListener = noop;\nprocess.once = noop;\nprocess.off = noop;\nprocess.removeListener = noop;\nprocess.removeAllListeners = noop;\nprocess.emit = noop;\nprocess.prependListener = noop;\nprocess.prependOnceListener = noop;\n\nprocess.listeners = function (name) { return [] }\n\nprocess.binding = function (name) {\n    throw new Error('process.binding is not supported');\n};\n\nprocess.cwd = function () { return '/' };\nprocess.chdir = function (dir) {\n    throw new Error('process.chdir is not supported');\n};\nprocess.umask = function() { return 0; };\n\n\n//# sourceURL=webpack:///./node_modules/process/browser.js?");

/***/ }),

/***/ "./node_modules/setimmediate/setImmediate.js":
/*!***************************************************!*\
  !*** ./node_modules/setimmediate/setImmediate.js ***!
  \***************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(global, process) {(function (global, undefined) {\n    \"use strict\";\n\n    if (global.setImmediate) {\n        return;\n    }\n\n    var nextHandle = 1; // Spec says greater than zero\n    var tasksByHandle = {};\n    var currentlyRunningATask = false;\n    var doc = global.document;\n    var registerImmediate;\n\n    function setImmediate(callback) {\n      // Callback can either be a function or a string\n      if (typeof callback !== \"function\") {\n        callback = new Function(\"\" + callback);\n      }\n      // Copy function arguments\n      var args = new Array(arguments.length - 1);\n      for (var i = 0; i < args.length; i++) {\n          args[i] = arguments[i + 1];\n      }\n      // Store and register the task\n      var task = { callback: callback, args: args };\n      tasksByHandle[nextHandle] = task;\n      registerImmediate(nextHandle);\n      return nextHandle++;\n    }\n\n    function clearImmediate(handle) {\n        delete tasksByHandle[handle];\n    }\n\n    function run(task) {\n        var callback = task.callback;\n        var args = task.args;\n        switch (args.length) {\n        case 0:\n            callback();\n            break;\n        case 1:\n            callback(args[0]);\n            break;\n        case 2:\n            callback(args[0], args[1]);\n            break;\n        case 3:\n            callback(args[0], args[1], args[2]);\n            break;\n        default:\n            callback.apply(undefined, args);\n            break;\n        }\n    }\n\n    function runIfPresent(handle) {\n        // From the spec: \"Wait until any invocations of this algorithm started before this one have completed.\"\n        // So if we're currently running a task, we'll need to delay this invocation.\n        if (currentlyRunningATask) {\n            // Delay by doing a setTimeout. setImmediate was tried instead, but in Firefox 7 it generated a\n            // \"too much recursion\" error.\n            setTimeout(runIfPresent, 0, handle);\n        } else {\n            var task = tasksByHandle[handle];\n            if (task) {\n                currentlyRunningATask = true;\n                try {\n                    run(task);\n                } finally {\n                    clearImmediate(handle);\n                    currentlyRunningATask = false;\n                }\n            }\n        }\n    }\n\n    function installNextTickImplementation() {\n        registerImmediate = function(handle) {\n            process.nextTick(function () { runIfPresent(handle); });\n        };\n    }\n\n    function canUsePostMessage() {\n        // The test against `importScripts` prevents this implementation from being installed inside a web worker,\n        // where `global.postMessage` means something completely different and can't be used for this purpose.\n        if (global.postMessage && !global.importScripts) {\n            var postMessageIsAsynchronous = true;\n            var oldOnMessage = global.onmessage;\n            global.onmessage = function() {\n                postMessageIsAsynchronous = false;\n            };\n            global.postMessage(\"\", \"*\");\n            global.onmessage = oldOnMessage;\n            return postMessageIsAsynchronous;\n        }\n    }\n\n    function installPostMessageImplementation() {\n        // Installs an event handler on `global` for the `message` event: see\n        // * https://developer.mozilla.org/en/DOM/window.postMessage\n        // * http://www.whatwg.org/specs/web-apps/current-work/multipage/comms.html#crossDocumentMessages\n\n        var messagePrefix = \"setImmediate$\" + Math.random() + \"$\";\n        var onGlobalMessage = function(event) {\n            if (event.source === global &&\n                typeof event.data === \"string\" &&\n                event.data.indexOf(messagePrefix) === 0) {\n                runIfPresent(+event.data.slice(messagePrefix.length));\n            }\n        };\n\n        if (global.addEventListener) {\n            global.addEventListener(\"message\", onGlobalMessage, false);\n        } else {\n            global.attachEvent(\"onmessage\", onGlobalMessage);\n        }\n\n        registerImmediate = function(handle) {\n            global.postMessage(messagePrefix + handle, \"*\");\n        };\n    }\n\n    function installMessageChannelImplementation() {\n        var channel = new MessageChannel();\n        channel.port1.onmessage = function(event) {\n            var handle = event.data;\n            runIfPresent(handle);\n        };\n\n        registerImmediate = function(handle) {\n            channel.port2.postMessage(handle);\n        };\n    }\n\n    function installReadyStateChangeImplementation() {\n        var html = doc.documentElement;\n        registerImmediate = function(handle) {\n            // Create a <script> element; its readystatechange event will be fired asynchronously once it is inserted\n            // into the document. Do so, thus queuing up the task. Remember to clean up once it's been called.\n            var script = doc.createElement(\"script\");\n            script.onreadystatechange = function () {\n                runIfPresent(handle);\n                script.onreadystatechange = null;\n                html.removeChild(script);\n                script = null;\n            };\n            html.appendChild(script);\n        };\n    }\n\n    function installSetTimeoutImplementation() {\n        registerImmediate = function(handle) {\n            setTimeout(runIfPresent, 0, handle);\n        };\n    }\n\n    // If supported, we should attach to the prototype of global, since that is where setTimeout et al. live.\n    var attachTo = Object.getPrototypeOf && Object.getPrototypeOf(global);\n    attachTo = attachTo && attachTo.setTimeout ? attachTo : global;\n\n    // Don't get fooled by e.g. browserify environments.\n    if ({}.toString.call(global.process) === \"[object process]\") {\n        // For Node.js before 0.9\n        installNextTickImplementation();\n\n    } else if (canUsePostMessage()) {\n        // For non-IE10 modern browsers\n        installPostMessageImplementation();\n\n    } else if (global.MessageChannel) {\n        // For web workers, where supported\n        installMessageChannelImplementation();\n\n    } else if (doc && \"onreadystatechange\" in doc.createElement(\"script\")) {\n        // For IE 6–8\n        installReadyStateChangeImplementation();\n\n    } else {\n        // For older browsers\n        installSetTimeoutImplementation();\n    }\n\n    attachTo.setImmediate = setImmediate;\n    attachTo.clearImmediate = clearImmediate;\n}(typeof self === \"undefined\" ? typeof global === \"undefined\" ? this : global : self));\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\"), __webpack_require__(/*! ./../process/browser.js */ \"./node_modules/process/browser.js\")))\n\n//# sourceURL=webpack:///./node_modules/setimmediate/setImmediate.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/NeuralNetwork.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/NeuralNetwork.js ***!
  \*****************************************************************************/
/*! exports provided: NeuralNetwork */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"NeuralNetwork\", function() { return NeuralNetwork; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var _common_getModelUris__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./common/getModelUris */ \"./node_modules/tfjs-image-recognition-base/build/es6/common/getModelUris.js\");\n/* harmony import */ var _dom__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./dom */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/index.js\");\n/* harmony import */ var _env__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./env */ \"./node_modules/tfjs-image-recognition-base/build/es6/env/index.js\");\n\r\n\r\n\r\n\r\n\r\nvar NeuralNetwork = /** @class */ (function () {\r\n    function NeuralNetwork(_name) {\r\n        this._name = _name;\r\n        this._params = undefined;\r\n        this._paramMappings = [];\r\n    }\r\n    Object.defineProperty(NeuralNetwork.prototype, \"params\", {\r\n        get: function () { return this._params; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(NeuralNetwork.prototype, \"paramMappings\", {\r\n        get: function () { return this._paramMappings; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(NeuralNetwork.prototype, \"isLoaded\", {\r\n        get: function () { return !!this.params; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    NeuralNetwork.prototype.getParamFromPath = function (paramPath) {\r\n        var _a = this.traversePropertyPath(paramPath), obj = _a.obj, objProp = _a.objProp;\r\n        return obj[objProp];\r\n    };\r\n    NeuralNetwork.prototype.reassignParamFromPath = function (paramPath, tensor) {\r\n        var _a = this.traversePropertyPath(paramPath), obj = _a.obj, objProp = _a.objProp;\r\n        obj[objProp].dispose();\r\n        obj[objProp] = tensor;\r\n    };\r\n    NeuralNetwork.prototype.getParamList = function () {\r\n        var _this = this;\r\n        return this._paramMappings.map(function (_a) {\r\n            var paramPath = _a.paramPath;\r\n            return ({\r\n                path: paramPath,\r\n                tensor: _this.getParamFromPath(paramPath)\r\n            });\r\n        });\r\n    };\r\n    NeuralNetwork.prototype.getTrainableParams = function () {\r\n        return this.getParamList().filter(function (param) { return param.tensor instanceof _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"Variable\"]; });\r\n    };\r\n    NeuralNetwork.prototype.getFrozenParams = function () {\r\n        return this.getParamList().filter(function (param) { return !(param.tensor instanceof _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"Variable\"]); });\r\n    };\r\n    NeuralNetwork.prototype.variable = function () {\r\n        var _this = this;\r\n        this.getFrozenParams().forEach(function (_a) {\r\n            var path = _a.path, tensor = _a.tensor;\r\n            _this.reassignParamFromPath(path, tensor.variable());\r\n        });\r\n    };\r\n    NeuralNetwork.prototype.freeze = function () {\r\n        var _this = this;\r\n        this.getTrainableParams().forEach(function (_a) {\r\n            var path = _a.path, variable = _a.tensor;\r\n            var tensor = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tensor\"](variable.dataSync());\r\n            variable.dispose();\r\n            _this.reassignParamFromPath(path, tensor);\r\n        });\r\n    };\r\n    NeuralNetwork.prototype.dispose = function (throwOnRedispose) {\r\n        if (throwOnRedispose === void 0) { throwOnRedispose = true; }\r\n        this.getParamList().forEach(function (param) {\r\n            if (throwOnRedispose && param.tensor.isDisposed) {\r\n                throw new Error(\"param tensor has already been disposed for path \" + param.path);\r\n            }\r\n            param.tensor.dispose();\r\n        });\r\n        this._params = undefined;\r\n    };\r\n    NeuralNetwork.prototype.serializeParams = function () {\r\n        return new Float32Array(this.getParamList()\r\n            .map(function (_a) {\r\n            var tensor = _a.tensor;\r\n            return Array.from(tensor.dataSync());\r\n        })\r\n            .reduce(function (flat, arr) { return flat.concat(arr); }));\r\n    };\r\n    NeuralNetwork.prototype.load = function (weightsOrUrl) {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0:\r\n                        if (weightsOrUrl instanceof Float32Array) {\r\n                            this.extractWeights(weightsOrUrl);\r\n                            return [2 /*return*/];\r\n                        }\r\n                        return [4 /*yield*/, this.loadFromUri(weightsOrUrl)];\r\n                    case 1:\r\n                        _a.sent();\r\n                        return [2 /*return*/];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    NeuralNetwork.prototype.loadFromUri = function (uri) {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var weightMap;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0:\r\n                        if (uri && typeof uri !== 'string') {\r\n                            throw new Error(this._name + \".loadFromUri - expected model uri\");\r\n                        }\r\n                        return [4 /*yield*/, Object(_dom__WEBPACK_IMPORTED_MODULE_3__[\"loadWeightMap\"])(uri, this.getDefaultModelName())];\r\n                    case 1:\r\n                        weightMap = _a.sent();\r\n                        this.loadFromWeightMap(weightMap);\r\n                        return [2 /*return*/];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    NeuralNetwork.prototype.loadFromDisk = function (filePath) {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var readFile, _a, manifestUri, modelBaseUri, fetchWeightsFromDisk, loadWeights, manifest, _b, _c, weightMap;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_d) {\r\n                switch (_d.label) {\r\n                    case 0:\r\n                        if (filePath && typeof filePath !== 'string') {\r\n                            throw new Error(this._name + \".loadFromDisk - expected model file path\");\r\n                        }\r\n                        readFile = _env__WEBPACK_IMPORTED_MODULE_4__[\"env\"].getEnv().readFile;\r\n                        _a = Object(_common_getModelUris__WEBPACK_IMPORTED_MODULE_2__[\"getModelUris\"])(filePath, this.getDefaultModelName()), manifestUri = _a.manifestUri, modelBaseUri = _a.modelBaseUri;\r\n                        fetchWeightsFromDisk = function (filePaths) { return Promise.all(filePaths.map(function (filePath) { return readFile(filePath).then(function (buf) { return buf.buffer; }); })); };\r\n                        loadWeights = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"io\"].weightsLoaderFactory(fetchWeightsFromDisk);\r\n                        _c = (_b = JSON).parse;\r\n                        return [4 /*yield*/, readFile(manifestUri)];\r\n                    case 1:\r\n                        manifest = _c.apply(_b, [(_d.sent()).toString()]);\r\n                        return [4 /*yield*/, loadWeights(manifest, modelBaseUri)];\r\n                    case 2:\r\n                        weightMap = _d.sent();\r\n                        this.loadFromWeightMap(weightMap);\r\n                        return [2 /*return*/];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    NeuralNetwork.prototype.loadFromWeightMap = function (weightMap) {\r\n        var _a = this.extractParamsFromWeigthMap(weightMap), paramMappings = _a.paramMappings, params = _a.params;\r\n        this._paramMappings = paramMappings;\r\n        this._params = params;\r\n    };\r\n    NeuralNetwork.prototype.extractWeights = function (weights) {\r\n        var _a = this.extractParams(weights), paramMappings = _a.paramMappings, params = _a.params;\r\n        this._paramMappings = paramMappings;\r\n        this._params = params;\r\n    };\r\n    NeuralNetwork.prototype.traversePropertyPath = function (paramPath) {\r\n        if (!this.params) {\r\n            throw new Error(\"traversePropertyPath - model has no loaded params\");\r\n        }\r\n        var result = paramPath.split('/').reduce(function (res, objProp) {\r\n            if (!res.nextObj.hasOwnProperty(objProp)) {\r\n                throw new Error(\"traversePropertyPath - object does not have property \" + objProp + \", for path \" + paramPath);\r\n            }\r\n            return { obj: res.nextObj, objProp: objProp, nextObj: res.nextObj[objProp] };\r\n        }, { nextObj: this.params });\r\n        var obj = result.obj, objProp = result.objProp;\r\n        if (!obj || !objProp || !(obj[objProp] instanceof _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"Tensor\"])) {\r\n            throw new Error(\"traversePropertyPath - parameter is not a tensor, for path \" + paramPath);\r\n        }\r\n        return { obj: obj, objProp: objProp };\r\n    };\r\n    return NeuralNetwork;\r\n}());\r\n\r\n//# sourceMappingURL=NeuralNetwork.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/NeuralNetwork.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/classes/BoundingBox.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/classes/BoundingBox.js ***!
  \***********************************************************************************/
/*! exports provided: BoundingBox */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"BoundingBox\", function() { return BoundingBox; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _Box__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Box */ \"./node_modules/tfjs-image-recognition-base/build/es6/classes/Box.js\");\n\r\n\r\nvar BoundingBox = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(BoundingBox, _super);\r\n    function BoundingBox(left, top, right, bottom, allowNegativeDimensions) {\r\n        if (allowNegativeDimensions === void 0) { allowNegativeDimensions = false; }\r\n        return _super.call(this, { left: left, top: top, right: right, bottom: bottom }, allowNegativeDimensions) || this;\r\n    }\r\n    return BoundingBox;\r\n}(_Box__WEBPACK_IMPORTED_MODULE_1__[\"Box\"]));\r\n\r\n//# sourceMappingURL=BoundingBox.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/classes/BoundingBox.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/classes/Box.js":
/*!***************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/classes/Box.js ***!
  \***************************************************************************/
/*! exports provided: Box */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Box\", function() { return Box; });\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils */ \"./node_modules/tfjs-image-recognition-base/build/es6/utils/index.js\");\n/* harmony import */ var _Point__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Point */ \"./node_modules/tfjs-image-recognition-base/build/es6/classes/Point.js\");\n\r\n\r\nvar Box = /** @class */ (function () {\r\n    function Box(_box, allowNegativeDimensions) {\r\n        if (allowNegativeDimensions === void 0) { allowNegativeDimensions = true; }\r\n        var box = (_box || {});\r\n        var isBbox = [box.left, box.top, box.right, box.bottom].every(_utils__WEBPACK_IMPORTED_MODULE_0__[\"isValidNumber\"]);\r\n        var isRect = [box.x, box.y, box.width, box.height].every(_utils__WEBPACK_IMPORTED_MODULE_0__[\"isValidNumber\"]);\r\n        if (!isRect && !isBbox) {\r\n            throw new Error(\"Box.constructor - expected box to be IBoundingBox | IRect, instead have \" + JSON.stringify(box));\r\n        }\r\n        var _a = isRect\r\n            ? [box.x, box.y, box.width, box.height]\r\n            : [box.left, box.top, box.right - box.left, box.bottom - box.top], x = _a[0], y = _a[1], width = _a[2], height = _a[3];\r\n        Box.assertIsValidBox({ x: x, y: y, width: width, height: height }, 'Box.constructor', allowNegativeDimensions);\r\n        this._x = x;\r\n        this._y = y;\r\n        this._width = width;\r\n        this._height = height;\r\n    }\r\n    Box.isRect = function (rect) {\r\n        return !!rect && [rect.x, rect.y, rect.width, rect.height].every(_utils__WEBPACK_IMPORTED_MODULE_0__[\"isValidNumber\"]);\r\n    };\r\n    Box.assertIsValidBox = function (box, callee, allowNegativeDimensions) {\r\n        if (allowNegativeDimensions === void 0) { allowNegativeDimensions = false; }\r\n        if (!Box.isRect(box)) {\r\n            throw new Error(callee + \" - invalid box: \" + JSON.stringify(box) + \", expected object with properties x, y, width, height\");\r\n        }\r\n        if (!allowNegativeDimensions && (box.width < 0 || box.height < 0)) {\r\n            throw new Error(callee + \" - width (\" + box.width + \") and height (\" + box.height + \") must be positive numbers\");\r\n        }\r\n    };\r\n    Object.defineProperty(Box.prototype, \"x\", {\r\n        get: function () { return this._x; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"y\", {\r\n        get: function () { return this._y; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"width\", {\r\n        get: function () { return this._width; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"height\", {\r\n        get: function () { return this._height; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"left\", {\r\n        get: function () { return this.x; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"top\", {\r\n        get: function () { return this.y; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"right\", {\r\n        get: function () { return this.x + this.width; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"bottom\", {\r\n        get: function () { return this.y + this.height; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"area\", {\r\n        get: function () { return this.width * this.height; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"topLeft\", {\r\n        get: function () { return new _Point__WEBPACK_IMPORTED_MODULE_1__[\"Point\"](this.left, this.top); },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"topRight\", {\r\n        get: function () { return new _Point__WEBPACK_IMPORTED_MODULE_1__[\"Point\"](this.right, this.top); },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"bottomLeft\", {\r\n        get: function () { return new _Point__WEBPACK_IMPORTED_MODULE_1__[\"Point\"](this.left, this.bottom); },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"bottomRight\", {\r\n        get: function () { return new _Point__WEBPACK_IMPORTED_MODULE_1__[\"Point\"](this.right, this.bottom); },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Box.prototype.round = function () {\r\n        var _a = [this.x, this.y, this.width, this.height]\r\n            .map(function (val) { return Math.round(val); }), x = _a[0], y = _a[1], width = _a[2], height = _a[3];\r\n        return new Box({ x: x, y: y, width: width, height: height });\r\n    };\r\n    Box.prototype.floor = function () {\r\n        var _a = [this.x, this.y, this.width, this.height]\r\n            .map(function (val) { return Math.floor(val); }), x = _a[0], y = _a[1], width = _a[2], height = _a[3];\r\n        return new Box({ x: x, y: y, width: width, height: height });\r\n    };\r\n    Box.prototype.toSquare = function () {\r\n        var _a = this, x = _a.x, y = _a.y, width = _a.width, height = _a.height;\r\n        var diff = Math.abs(width - height);\r\n        if (width < height) {\r\n            x -= (diff / 2);\r\n            width += diff;\r\n        }\r\n        if (height < width) {\r\n            y -= (diff / 2);\r\n            height += diff;\r\n        }\r\n        return new Box({ x: x, y: y, width: width, height: height });\r\n    };\r\n    Box.prototype.rescale = function (s) {\r\n        var scaleX = Object(_utils__WEBPACK_IMPORTED_MODULE_0__[\"isDimensions\"])(s) ? s.width : s;\r\n        var scaleY = Object(_utils__WEBPACK_IMPORTED_MODULE_0__[\"isDimensions\"])(s) ? s.height : s;\r\n        return new Box({\r\n            x: this.x * scaleX,\r\n            y: this.y * scaleY,\r\n            width: this.width * scaleX,\r\n            height: this.height * scaleY\r\n        });\r\n    };\r\n    Box.prototype.pad = function (padX, padY) {\r\n        var _a = [\r\n            this.x - (padX / 2),\r\n            this.y - (padY / 2),\r\n            this.width + padX,\r\n            this.height + padY\r\n        ], x = _a[0], y = _a[1], width = _a[2], height = _a[3];\r\n        return new Box({ x: x, y: y, width: width, height: height });\r\n    };\r\n    Box.prototype.clipAtImageBorders = function (imgWidth, imgHeight) {\r\n        var _a = this, x = _a.x, y = _a.y, right = _a.right, bottom = _a.bottom;\r\n        var clippedX = Math.max(x, 0);\r\n        var clippedY = Math.max(y, 0);\r\n        var newWidth = right - clippedX;\r\n        var newHeight = bottom - clippedY;\r\n        var clippedWidth = Math.min(newWidth, imgWidth - clippedX);\r\n        var clippedHeight = Math.min(newHeight, imgHeight - clippedY);\r\n        return (new Box({ x: clippedX, y: clippedY, width: clippedWidth, height: clippedHeight })).floor();\r\n    };\r\n    Box.prototype.shift = function (sx, sy) {\r\n        var _a = this, width = _a.width, height = _a.height;\r\n        var x = this.x + sx;\r\n        var y = this.y + sy;\r\n        return new Box({ x: x, y: y, width: width, height: height });\r\n    };\r\n    Box.prototype.padAtBorders = function (imageHeight, imageWidth) {\r\n        var w = this.width + 1;\r\n        var h = this.height + 1;\r\n        var dx = 1;\r\n        var dy = 1;\r\n        var edx = w;\r\n        var edy = h;\r\n        var x = this.left;\r\n        var y = this.top;\r\n        var ex = this.right;\r\n        var ey = this.bottom;\r\n        if (ex > imageWidth) {\r\n            edx = -ex + imageWidth + w;\r\n            ex = imageWidth;\r\n        }\r\n        if (ey > imageHeight) {\r\n            edy = -ey + imageHeight + h;\r\n            ey = imageHeight;\r\n        }\r\n        if (x < 1) {\r\n            edy = 2 - x;\r\n            x = 1;\r\n        }\r\n        if (y < 1) {\r\n            edy = 2 - y;\r\n            y = 1;\r\n        }\r\n        return { dy: dy, edy: edy, dx: dx, edx: edx, y: y, ey: ey, x: x, ex: ex, w: w, h: h };\r\n    };\r\n    Box.prototype.calibrate = function (region) {\r\n        return new Box({\r\n            left: this.left + (region.left * this.width),\r\n            top: this.top + (region.top * this.height),\r\n            right: this.right + (region.right * this.width),\r\n            bottom: this.bottom + (region.bottom * this.height)\r\n        }).toSquare().round();\r\n    };\r\n    return Box;\r\n}());\r\n\r\n//# sourceMappingURL=Box.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/classes/Box.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/classes/Dimensions.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/classes/Dimensions.js ***!
  \**********************************************************************************/
/*! exports provided: Dimensions */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Dimensions\", function() { return Dimensions; });\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils */ \"./node_modules/tfjs-image-recognition-base/build/es6/utils/index.js\");\n\r\nvar Dimensions = /** @class */ (function () {\r\n    function Dimensions(width, height) {\r\n        if (!Object(_utils__WEBPACK_IMPORTED_MODULE_0__[\"isValidNumber\"])(width) || !Object(_utils__WEBPACK_IMPORTED_MODULE_0__[\"isValidNumber\"])(height)) {\r\n            throw new Error(\"Dimensions.constructor - expected width and height to be valid numbers, instead have \" + JSON.stringify({ width: width, height: height }));\r\n        }\r\n        this._width = width;\r\n        this._height = height;\r\n    }\r\n    Object.defineProperty(Dimensions.prototype, \"width\", {\r\n        get: function () { return this._width; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Dimensions.prototype, \"height\", {\r\n        get: function () { return this._height; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Dimensions.prototype.reverse = function () {\r\n        return new Dimensions(1 / this.width, 1 / this.height);\r\n    };\r\n    return Dimensions;\r\n}());\r\n\r\n//# sourceMappingURL=Dimensions.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/classes/Dimensions.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/classes/LabeledBox.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/classes/LabeledBox.js ***!
  \**********************************************************************************/
/*! exports provided: LabeledBox */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"LabeledBox\", function() { return LabeledBox; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _Box__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Box */ \"./node_modules/tfjs-image-recognition-base/build/es6/classes/Box.js\");\n/* harmony import */ var _utils_index__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/index */ \"./node_modules/tfjs-image-recognition-base/build/es6/utils/index.js\");\n\r\n\r\n\r\nvar LabeledBox = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(LabeledBox, _super);\r\n    function LabeledBox(box, label) {\r\n        var _this = _super.call(this, box) || this;\r\n        _this._label = label;\r\n        return _this;\r\n    }\r\n    LabeledBox.assertIsValidLabeledBox = function (box, callee) {\r\n        _Box__WEBPACK_IMPORTED_MODULE_1__[\"Box\"].assertIsValidBox(box, callee);\r\n        if (!Object(_utils_index__WEBPACK_IMPORTED_MODULE_2__[\"isValidNumber\"])(box.label)) {\r\n            throw new Error(callee + \" - expected property label (\" + box.label + \") to be a number\");\r\n        }\r\n    };\r\n    Object.defineProperty(LabeledBox.prototype, \"label\", {\r\n        get: function () { return this._label; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    return LabeledBox;\r\n}(_Box__WEBPACK_IMPORTED_MODULE_1__[\"Box\"]));\r\n\r\n//# sourceMappingURL=LabeledBox.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/classes/LabeledBox.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/classes/ObjectDetection.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/classes/ObjectDetection.js ***!
  \***************************************************************************************/
/*! exports provided: ObjectDetection */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ObjectDetection\", function() { return ObjectDetection; });\n/* harmony import */ var _Box__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Box */ \"./node_modules/tfjs-image-recognition-base/build/es6/classes/Box.js\");\n/* harmony import */ var _Dimensions__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Dimensions */ \"./node_modules/tfjs-image-recognition-base/build/es6/classes/Dimensions.js\");\n\r\n\r\nvar ObjectDetection = /** @class */ (function () {\r\n    function ObjectDetection(score, classScore, className, relativeBox, imageDims) {\r\n        this._imageDims = new _Dimensions__WEBPACK_IMPORTED_MODULE_1__[\"Dimensions\"](imageDims.width, imageDims.height);\r\n        this._score = score;\r\n        this._classScore = classScore;\r\n        this._className = className;\r\n        this._box = new _Box__WEBPACK_IMPORTED_MODULE_0__[\"Box\"](relativeBox).rescale(this._imageDims);\r\n    }\r\n    Object.defineProperty(ObjectDetection.prototype, \"score\", {\r\n        get: function () { return this._score; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(ObjectDetection.prototype, \"classScore\", {\r\n        get: function () { return this._classScore; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(ObjectDetection.prototype, \"className\", {\r\n        get: function () { return this._className; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(ObjectDetection.prototype, \"box\", {\r\n        get: function () { return this._box; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(ObjectDetection.prototype, \"imageDims\", {\r\n        get: function () { return this._imageDims; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(ObjectDetection.prototype, \"imageWidth\", {\r\n        get: function () { return this.imageDims.width; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(ObjectDetection.prototype, \"imageHeight\", {\r\n        get: function () { return this.imageDims.height; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(ObjectDetection.prototype, \"relativeBox\", {\r\n        get: function () { return new _Box__WEBPACK_IMPORTED_MODULE_0__[\"Box\"](this._box).rescale(this.imageDims.reverse()); },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    ObjectDetection.prototype.forSize = function (width, height) {\r\n        return new ObjectDetection(this.score, this.classScore, this.className, this.relativeBox, { width: width, height: height });\r\n    };\r\n    return ObjectDetection;\r\n}());\r\n\r\n//# sourceMappingURL=ObjectDetection.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/classes/ObjectDetection.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/classes/Point.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/classes/Point.js ***!
  \*****************************************************************************/
/*! exports provided: Point */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Point\", function() { return Point; });\nvar Point = /** @class */ (function () {\r\n    function Point(x, y) {\r\n        this._x = x;\r\n        this._y = y;\r\n    }\r\n    Object.defineProperty(Point.prototype, \"x\", {\r\n        get: function () { return this._x; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Point.prototype, \"y\", {\r\n        get: function () { return this._y; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Point.prototype.add = function (pt) {\r\n        return new Point(this.x + pt.x, this.y + pt.y);\r\n    };\r\n    Point.prototype.sub = function (pt) {\r\n        return new Point(this.x - pt.x, this.y - pt.y);\r\n    };\r\n    Point.prototype.mul = function (pt) {\r\n        return new Point(this.x * pt.x, this.y * pt.y);\r\n    };\r\n    Point.prototype.div = function (pt) {\r\n        return new Point(this.x / pt.x, this.y / pt.y);\r\n    };\r\n    Point.prototype.abs = function () {\r\n        return new Point(Math.abs(this.x), Math.abs(this.y));\r\n    };\r\n    Point.prototype.magnitude = function () {\r\n        return Math.sqrt(Math.pow(this.x, 2) + Math.pow(this.y, 2));\r\n    };\r\n    Point.prototype.floor = function () {\r\n        return new Point(Math.floor(this.x), Math.floor(this.y));\r\n    };\r\n    return Point;\r\n}());\r\n\r\n//# sourceMappingURL=Point.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/classes/Point.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/classes/PredictedBox.js":
/*!************************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/classes/PredictedBox.js ***!
  \************************************************************************************/
/*! exports provided: PredictedBox */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PredictedBox\", function() { return PredictedBox; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils */ \"./node_modules/tfjs-image-recognition-base/build/es6/utils/index.js\");\n/* harmony import */ var _LabeledBox__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./LabeledBox */ \"./node_modules/tfjs-image-recognition-base/build/es6/classes/LabeledBox.js\");\n\r\n\r\n\r\nvar PredictedBox = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(PredictedBox, _super);\r\n    function PredictedBox(box, label, score, classScore) {\r\n        var _this = _super.call(this, box, label) || this;\r\n        _this._score = score;\r\n        _this._classScore = classScore;\r\n        return _this;\r\n    }\r\n    PredictedBox.assertIsValidPredictedBox = function (box, callee) {\r\n        _LabeledBox__WEBPACK_IMPORTED_MODULE_2__[\"LabeledBox\"].assertIsValidLabeledBox(box, callee);\r\n        if (!Object(_utils__WEBPACK_IMPORTED_MODULE_1__[\"isValidProbablitiy\"])(box.score)\r\n            || !Object(_utils__WEBPACK_IMPORTED_MODULE_1__[\"isValidProbablitiy\"])(box.classScore)) {\r\n            throw new Error(callee + \" - expected properties score (\" + box.score + \") and (\" + box.classScore + \") to be a number between [0, 1]\");\r\n        }\r\n    };\r\n    Object.defineProperty(PredictedBox.prototype, \"score\", {\r\n        get: function () { return this._score; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(PredictedBox.prototype, \"classScore\", {\r\n        get: function () { return this._classScore; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    return PredictedBox;\r\n}(_LabeledBox__WEBPACK_IMPORTED_MODULE_2__[\"LabeledBox\"]));\r\n\r\n//# sourceMappingURL=PredictedBox.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/classes/PredictedBox.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/classes/Rect.js":
/*!****************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/classes/Rect.js ***!
  \****************************************************************************/
/*! exports provided: Rect */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Rect\", function() { return Rect; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _Box__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Box */ \"./node_modules/tfjs-image-recognition-base/build/es6/classes/Box.js\");\n\r\n\r\nvar Rect = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(Rect, _super);\r\n    function Rect(x, y, width, height, allowNegativeDimensions) {\r\n        if (allowNegativeDimensions === void 0) { allowNegativeDimensions = false; }\r\n        return _super.call(this, { x: x, y: y, width: width, height: height }, allowNegativeDimensions) || this;\r\n    }\r\n    return Rect;\r\n}(_Box__WEBPACK_IMPORTED_MODULE_1__[\"Box\"]));\r\n\r\n//# sourceMappingURL=Rect.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/classes/Rect.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/classes/index.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/classes/index.js ***!
  \*****************************************************************************/
/*! exports provided: BoundingBox, Box, Dimensions, LabeledBox, ObjectDetection, Point, PredictedBox, Rect */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _BoundingBox__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./BoundingBox */ \"./node_modules/tfjs-image-recognition-base/build/es6/classes/BoundingBox.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"BoundingBox\", function() { return _BoundingBox__WEBPACK_IMPORTED_MODULE_0__[\"BoundingBox\"]; });\n\n/* harmony import */ var _Box__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Box */ \"./node_modules/tfjs-image-recognition-base/build/es6/classes/Box.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Box\", function() { return _Box__WEBPACK_IMPORTED_MODULE_1__[\"Box\"]; });\n\n/* harmony import */ var _Dimensions__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Dimensions */ \"./node_modules/tfjs-image-recognition-base/build/es6/classes/Dimensions.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Dimensions\", function() { return _Dimensions__WEBPACK_IMPORTED_MODULE_2__[\"Dimensions\"]; });\n\n/* harmony import */ var _LabeledBox__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./LabeledBox */ \"./node_modules/tfjs-image-recognition-base/build/es6/classes/LabeledBox.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"LabeledBox\", function() { return _LabeledBox__WEBPACK_IMPORTED_MODULE_3__[\"LabeledBox\"]; });\n\n/* harmony import */ var _ObjectDetection__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ObjectDetection */ \"./node_modules/tfjs-image-recognition-base/build/es6/classes/ObjectDetection.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ObjectDetection\", function() { return _ObjectDetection__WEBPACK_IMPORTED_MODULE_4__[\"ObjectDetection\"]; });\n\n/* harmony import */ var _Point__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Point */ \"./node_modules/tfjs-image-recognition-base/build/es6/classes/Point.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Point\", function() { return _Point__WEBPACK_IMPORTED_MODULE_5__[\"Point\"]; });\n\n/* harmony import */ var _PredictedBox__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./PredictedBox */ \"./node_modules/tfjs-image-recognition-base/build/es6/classes/PredictedBox.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PredictedBox\", function() { return _PredictedBox__WEBPACK_IMPORTED_MODULE_6__[\"PredictedBox\"]; });\n\n/* harmony import */ var _Rect__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Rect */ \"./node_modules/tfjs-image-recognition-base/build/es6/classes/Rect.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Rect\", function() { return _Rect__WEBPACK_IMPORTED_MODULE_7__[\"Rect\"]; });\n\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/classes/index.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/common/convLayer.js":
/*!********************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/common/convLayer.js ***!
  \********************************************************************************/
/*! exports provided: convLayer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"convLayer\", function() { return convLayer; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n\r\nfunction convLayer(x, params, padding, withRelu) {\r\n    if (padding === void 0) { padding = 'same'; }\r\n    if (withRelu === void 0) { withRelu = false; }\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () {\r\n        var out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"conv2d\"](x, params.filters, [1, 1], padding), params.bias);\r\n        return withRelu ? _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"relu\"](out) : out;\r\n    });\r\n}\r\n//# sourceMappingURL=convLayer.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/common/convLayer.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/common/disposeUnusedWeightTensors.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/common/disposeUnusedWeightTensors.js ***!
  \*************************************************************************************************/
/*! exports provided: disposeUnusedWeightTensors */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"disposeUnusedWeightTensors\", function() { return disposeUnusedWeightTensors; });\nfunction disposeUnusedWeightTensors(weightMap, paramMappings) {\r\n    Object.keys(weightMap).forEach(function (path) {\r\n        if (!paramMappings.some(function (pm) { return pm.originalPath === path; })) {\r\n            weightMap[path].dispose();\r\n        }\r\n    });\r\n}\r\n//# sourceMappingURL=disposeUnusedWeightTensors.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/common/disposeUnusedWeightTensors.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/common/extractConvParamsFactory.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/common/extractConvParamsFactory.js ***!
  \***********************************************************************************************/
/*! exports provided: extractConvParamsFactory */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractConvParamsFactory\", function() { return extractConvParamsFactory; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n\r\nfunction extractConvParamsFactory(extractWeights, paramMappings) {\r\n    return function (channelsIn, channelsOut, filterSize, mappedPrefix) {\r\n        var filters = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tensor4d\"](extractWeights(channelsIn * channelsOut * filterSize * filterSize), [filterSize, filterSize, channelsIn, channelsOut]);\r\n        var bias = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tensor1d\"](extractWeights(channelsOut));\r\n        paramMappings.push({ paramPath: mappedPrefix + \"/filters\" }, { paramPath: mappedPrefix + \"/bias\" });\r\n        return { filters: filters, bias: bias };\r\n    };\r\n}\r\n//# sourceMappingURL=extractConvParamsFactory.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/common/extractConvParamsFactory.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/common/extractFCParamsFactory.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/common/extractFCParamsFactory.js ***!
  \*********************************************************************************************/
/*! exports provided: extractFCParamsFactory */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractFCParamsFactory\", function() { return extractFCParamsFactory; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n\r\nfunction extractFCParamsFactory(extractWeights, paramMappings) {\r\n    return function (channelsIn, channelsOut, mappedPrefix) {\r\n        var fc_weights = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tensor2d\"](extractWeights(channelsIn * channelsOut), [channelsIn, channelsOut]);\r\n        var fc_bias = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tensor1d\"](extractWeights(channelsOut));\r\n        paramMappings.push({ paramPath: mappedPrefix + \"/weights\" }, { paramPath: mappedPrefix + \"/bias\" });\r\n        return {\r\n            weights: fc_weights,\r\n            bias: fc_bias\r\n        };\r\n    };\r\n}\r\n//# sourceMappingURL=extractFCParamsFactory.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/common/extractFCParamsFactory.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/common/extractSeparableConvParamsFactory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/common/extractSeparableConvParamsFactory.js ***!
  \********************************************************************************************************/
/*! exports provided: extractSeparableConvParamsFactory, loadSeparableConvParamsFactory */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractSeparableConvParamsFactory\", function() { return extractSeparableConvParamsFactory; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"loadSeparableConvParamsFactory\", function() { return loadSeparableConvParamsFactory; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var _types__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./types */ \"./node_modules/tfjs-image-recognition-base/build/es6/common/types.js\");\n\r\n\r\nfunction extractSeparableConvParamsFactory(extractWeights, paramMappings) {\r\n    return function (channelsIn, channelsOut, mappedPrefix) {\r\n        var depthwise_filter = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tensor4d\"](extractWeights(3 * 3 * channelsIn), [3, 3, channelsIn, 1]);\r\n        var pointwise_filter = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tensor4d\"](extractWeights(channelsIn * channelsOut), [1, 1, channelsIn, channelsOut]);\r\n        var bias = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tensor1d\"](extractWeights(channelsOut));\r\n        paramMappings.push({ paramPath: mappedPrefix + \"/depthwise_filter\" }, { paramPath: mappedPrefix + \"/pointwise_filter\" }, { paramPath: mappedPrefix + \"/bias\" });\r\n        return new _types__WEBPACK_IMPORTED_MODULE_1__[\"SeparableConvParams\"](depthwise_filter, pointwise_filter, bias);\r\n    };\r\n}\r\nfunction loadSeparableConvParamsFactory(extractWeightEntry) {\r\n    return function (prefix) {\r\n        var depthwise_filter = extractWeightEntry(prefix + \"/depthwise_filter\", 4);\r\n        var pointwise_filter = extractWeightEntry(prefix + \"/pointwise_filter\", 4);\r\n        var bias = extractWeightEntry(prefix + \"/bias\", 1);\r\n        return new _types__WEBPACK_IMPORTED_MODULE_1__[\"SeparableConvParams\"](depthwise_filter, pointwise_filter, bias);\r\n    };\r\n}\r\n//# sourceMappingURL=extractSeparableConvParamsFactory.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/common/extractSeparableConvParamsFactory.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/common/extractWeightEntryFactory.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/common/extractWeightEntryFactory.js ***!
  \************************************************************************************************/
/*! exports provided: extractWeightEntryFactory */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractWeightEntryFactory\", function() { return extractWeightEntryFactory; });\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils */ \"./node_modules/tfjs-image-recognition-base/build/es6/utils/index.js\");\n\r\nfunction extractWeightEntryFactory(weightMap, paramMappings) {\r\n    return function (originalPath, paramRank, mappedPath) {\r\n        var tensor = weightMap[originalPath];\r\n        if (!Object(_utils__WEBPACK_IMPORTED_MODULE_0__[\"isTensor\"])(tensor, paramRank)) {\r\n            throw new Error(\"expected weightMap[\" + originalPath + \"] to be a Tensor\" + paramRank + \"D, instead have \" + tensor);\r\n        }\r\n        paramMappings.push({ originalPath: originalPath, paramPath: mappedPath || originalPath });\r\n        return tensor;\r\n    };\r\n}\r\n//# sourceMappingURL=extractWeightEntryFactory.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/common/extractWeightEntryFactory.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/common/extractWeightsFactory.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/common/extractWeightsFactory.js ***!
  \********************************************************************************************/
/*! exports provided: extractWeightsFactory */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractWeightsFactory\", function() { return extractWeightsFactory; });\nfunction extractWeightsFactory(weights) {\r\n    var remainingWeights = weights;\r\n    function extractWeights(numWeights) {\r\n        var ret = remainingWeights.slice(0, numWeights);\r\n        remainingWeights = remainingWeights.slice(numWeights);\r\n        return ret;\r\n    }\r\n    function getRemainingWeights() {\r\n        return remainingWeights;\r\n    }\r\n    return {\r\n        extractWeights: extractWeights,\r\n        getRemainingWeights: getRemainingWeights\r\n    };\r\n}\r\n//# sourceMappingURL=extractWeightsFactory.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/common/extractWeightsFactory.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/common/getModelUris.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/common/getModelUris.js ***!
  \***********************************************************************************/
/*! exports provided: getModelUris */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getModelUris\", function() { return getModelUris; });\nfunction getModelUris(uri, defaultModelName) {\r\n    var defaultManifestFilename = defaultModelName + \"-weights_manifest.json\";\r\n    if (!uri) {\r\n        return {\r\n            modelBaseUri: '',\r\n            manifestUri: defaultManifestFilename\r\n        };\r\n    }\r\n    if (uri === '/') {\r\n        return {\r\n            modelBaseUri: '/',\r\n            manifestUri: \"/\" + defaultManifestFilename\r\n        };\r\n    }\r\n    var protocol = uri.startsWith('http://') ? 'http://' : uri.startsWith('https://') ? 'https://' : '';\r\n    uri = uri.replace(protocol, '');\r\n    var parts = uri.split('/').filter(function (s) { return s; });\r\n    var manifestFile = uri.endsWith('.json')\r\n        ? parts[parts.length - 1]\r\n        : defaultManifestFilename;\r\n    var modelBaseUri = protocol + (uri.endsWith('.json') ? parts.slice(0, parts.length - 1) : parts).join('/');\r\n    modelBaseUri = uri.startsWith('/') ? \"/\" + modelBaseUri : modelBaseUri;\r\n    return {\r\n        modelBaseUri: modelBaseUri,\r\n        manifestUri: modelBaseUri === '/' ? \"/\" + manifestFile : modelBaseUri + \"/\" + manifestFile\r\n    };\r\n}\r\n//# sourceMappingURL=getModelUris.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/common/getModelUris.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/common/index.js":
/*!****************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/common/index.js ***!
  \****************************************************************************/
/*! exports provided: convLayer, disposeUnusedWeightTensors, extractConvParamsFactory, extractFCParamsFactory, extractSeparableConvParamsFactory, loadSeparableConvParamsFactory, extractWeightEntryFactory, extractWeightsFactory, getModelUris, SeparableConvParams */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _convLayer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./convLayer */ \"./node_modules/tfjs-image-recognition-base/build/es6/common/convLayer.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"convLayer\", function() { return _convLayer__WEBPACK_IMPORTED_MODULE_0__[\"convLayer\"]; });\n\n/* harmony import */ var _disposeUnusedWeightTensors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./disposeUnusedWeightTensors */ \"./node_modules/tfjs-image-recognition-base/build/es6/common/disposeUnusedWeightTensors.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"disposeUnusedWeightTensors\", function() { return _disposeUnusedWeightTensors__WEBPACK_IMPORTED_MODULE_1__[\"disposeUnusedWeightTensors\"]; });\n\n/* harmony import */ var _extractConvParamsFactory__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./extractConvParamsFactory */ \"./node_modules/tfjs-image-recognition-base/build/es6/common/extractConvParamsFactory.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extractConvParamsFactory\", function() { return _extractConvParamsFactory__WEBPACK_IMPORTED_MODULE_2__[\"extractConvParamsFactory\"]; });\n\n/* harmony import */ var _extractFCParamsFactory__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./extractFCParamsFactory */ \"./node_modules/tfjs-image-recognition-base/build/es6/common/extractFCParamsFactory.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extractFCParamsFactory\", function() { return _extractFCParamsFactory__WEBPACK_IMPORTED_MODULE_3__[\"extractFCParamsFactory\"]; });\n\n/* harmony import */ var _extractSeparableConvParamsFactory__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./extractSeparableConvParamsFactory */ \"./node_modules/tfjs-image-recognition-base/build/es6/common/extractSeparableConvParamsFactory.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extractSeparableConvParamsFactory\", function() { return _extractSeparableConvParamsFactory__WEBPACK_IMPORTED_MODULE_4__[\"extractSeparableConvParamsFactory\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadSeparableConvParamsFactory\", function() { return _extractSeparableConvParamsFactory__WEBPACK_IMPORTED_MODULE_4__[\"loadSeparableConvParamsFactory\"]; });\n\n/* harmony import */ var _extractWeightEntryFactory__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./extractWeightEntryFactory */ \"./node_modules/tfjs-image-recognition-base/build/es6/common/extractWeightEntryFactory.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extractWeightEntryFactory\", function() { return _extractWeightEntryFactory__WEBPACK_IMPORTED_MODULE_5__[\"extractWeightEntryFactory\"]; });\n\n/* harmony import */ var _extractWeightsFactory__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./extractWeightsFactory */ \"./node_modules/tfjs-image-recognition-base/build/es6/common/extractWeightsFactory.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extractWeightsFactory\", function() { return _extractWeightsFactory__WEBPACK_IMPORTED_MODULE_6__[\"extractWeightsFactory\"]; });\n\n/* harmony import */ var _getModelUris__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./getModelUris */ \"./node_modules/tfjs-image-recognition-base/build/es6/common/getModelUris.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"getModelUris\", function() { return _getModelUris__WEBPACK_IMPORTED_MODULE_7__[\"getModelUris\"]; });\n\n/* harmony import */ var _types__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./types */ \"./node_modules/tfjs-image-recognition-base/build/es6/common/types.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SeparableConvParams\", function() { return _types__WEBPACK_IMPORTED_MODULE_8__[\"SeparableConvParams\"]; });\n\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/common/index.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/common/types.js":
/*!****************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/common/types.js ***!
  \****************************************************************************/
/*! exports provided: SeparableConvParams */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"SeparableConvParams\", function() { return SeparableConvParams; });\nvar SeparableConvParams = /** @class */ (function () {\r\n    function SeparableConvParams(depthwise_filter, pointwise_filter, bias) {\r\n        this.depthwise_filter = depthwise_filter;\r\n        this.pointwise_filter = pointwise_filter;\r\n        this.bias = bias;\r\n    }\r\n    return SeparableConvParams;\r\n}());\r\n\r\n//# sourceMappingURL=types.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/common/types.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/dom/NetInput.js":
/*!****************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/dom/NetInput.js ***!
  \****************************************************************************/
/*! exports provided: NetInput */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"NetInput\", function() { return NetInput; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var _env__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../env */ \"./node_modules/tfjs-image-recognition-base/build/es6/env/index.js\");\n/* harmony import */ var _ops_padToSquare__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../ops/padToSquare */ \"./node_modules/tfjs-image-recognition-base/build/es6/ops/padToSquare.js\");\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils */ \"./node_modules/tfjs-image-recognition-base/build/es6/utils/index.js\");\n/* harmony import */ var _createCanvas__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./createCanvas */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/createCanvas.js\");\n/* harmony import */ var _imageToSquare__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./imageToSquare */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/imageToSquare.js\");\n\r\n\r\n\r\n\r\n\r\n\r\nvar NetInput = /** @class */ (function () {\r\n    function NetInput(inputs, treatAsBatchInput) {\r\n        var _this = this;\r\n        if (treatAsBatchInput === void 0) { treatAsBatchInput = false; }\r\n        this._imageTensors = [];\r\n        this._canvases = [];\r\n        this._treatAsBatchInput = false;\r\n        this._inputDimensions = [];\r\n        if (!Array.isArray(inputs)) {\r\n            throw new Error(\"NetInput.constructor - expected inputs to be an Array of TResolvedNetInput or to be instanceof tf.Tensor4D, instead have \" + inputs);\r\n        }\r\n        this._treatAsBatchInput = treatAsBatchInput;\r\n        this._batchSize = inputs.length;\r\n        inputs.forEach(function (input, idx) {\r\n            if (Object(_utils__WEBPACK_IMPORTED_MODULE_3__[\"isTensor3D\"])(input)) {\r\n                _this._imageTensors[idx] = input;\r\n                _this._inputDimensions[idx] = input.shape;\r\n                return;\r\n            }\r\n            if (Object(_utils__WEBPACK_IMPORTED_MODULE_3__[\"isTensor4D\"])(input)) {\r\n                var batchSize = input.shape[0];\r\n                if (batchSize !== 1) {\r\n                    throw new Error(\"NetInput - tf.Tensor4D with batchSize \" + batchSize + \" passed, but not supported in input array\");\r\n                }\r\n                _this._imageTensors[idx] = input;\r\n                _this._inputDimensions[idx] = input.shape.slice(1);\r\n                return;\r\n            }\r\n            var canvas = input instanceof _env__WEBPACK_IMPORTED_MODULE_1__[\"env\"].getEnv().Canvas ? input : Object(_createCanvas__WEBPACK_IMPORTED_MODULE_4__[\"createCanvasFromMedia\"])(input);\r\n            _this._canvases[idx] = canvas;\r\n            _this._inputDimensions[idx] = [canvas.height, canvas.width, 3];\r\n        });\r\n    }\r\n    Object.defineProperty(NetInput.prototype, \"imageTensors\", {\r\n        get: function () {\r\n            return this._imageTensors;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(NetInput.prototype, \"canvases\", {\r\n        get: function () {\r\n            return this._canvases;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(NetInput.prototype, \"isBatchInput\", {\r\n        get: function () {\r\n            return this.batchSize > 1 || this._treatAsBatchInput;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(NetInput.prototype, \"batchSize\", {\r\n        get: function () {\r\n            return this._batchSize;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(NetInput.prototype, \"inputDimensions\", {\r\n        get: function () {\r\n            return this._inputDimensions;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(NetInput.prototype, \"inputSize\", {\r\n        get: function () {\r\n            return this._inputSize;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(NetInput.prototype, \"reshapedInputDimensions\", {\r\n        get: function () {\r\n            var _this = this;\r\n            return Object(_utils__WEBPACK_IMPORTED_MODULE_3__[\"range\"])(this.batchSize, 0, 1).map(function (_, batchIdx) { return _this.getReshapedInputDimensions(batchIdx); });\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    NetInput.prototype.getInput = function (batchIdx) {\r\n        return this.canvases[batchIdx] || this.imageTensors[batchIdx];\r\n    };\r\n    NetInput.prototype.getInputDimensions = function (batchIdx) {\r\n        return this._inputDimensions[batchIdx];\r\n    };\r\n    NetInput.prototype.getInputHeight = function (batchIdx) {\r\n        return this._inputDimensions[batchIdx][0];\r\n    };\r\n    NetInput.prototype.getInputWidth = function (batchIdx) {\r\n        return this._inputDimensions[batchIdx][1];\r\n    };\r\n    NetInput.prototype.getReshapedInputDimensions = function (batchIdx) {\r\n        if (typeof this.inputSize !== 'number') {\r\n            throw new Error('getReshapedInputDimensions - inputSize not set, toBatchTensor has not been called yet');\r\n        }\r\n        var width = this.getInputWidth(batchIdx);\r\n        var height = this.getInputHeight(batchIdx);\r\n        return Object(_utils__WEBPACK_IMPORTED_MODULE_3__[\"computeReshapedDimensions\"])({ width: width, height: height }, this.inputSize);\r\n    };\r\n    /**\r\n     * Create a batch tensor from all input canvases and tensors\r\n     * with size [batchSize, inputSize, inputSize, 3].\r\n     *\r\n     * @param inputSize Height and width of the tensor.\r\n     * @param isCenterImage (optional, default: false) If true, add an equal amount of padding on\r\n     * both sides of the minor dimension oof the image.\r\n     * @returns The batch tensor.\r\n     */\r\n    NetInput.prototype.toBatchTensor = function (inputSize, isCenterInputs) {\r\n        var _this = this;\r\n        if (isCenterInputs === void 0) { isCenterInputs = true; }\r\n        this._inputSize = inputSize;\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () {\r\n            var inputTensors = Object(_utils__WEBPACK_IMPORTED_MODULE_3__[\"range\"])(_this.batchSize, 0, 1).map(function (batchIdx) {\r\n                var input = _this.getInput(batchIdx);\r\n                if (input instanceof _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"Tensor\"]) {\r\n                    var imgTensor = Object(_utils__WEBPACK_IMPORTED_MODULE_3__[\"isTensor4D\"])(input) ? input : input.expandDims();\r\n                    imgTensor = Object(_ops_padToSquare__WEBPACK_IMPORTED_MODULE_2__[\"padToSquare\"])(imgTensor, isCenterInputs);\r\n                    if (imgTensor.shape[1] !== inputSize || imgTensor.shape[2] !== inputSize) {\r\n                        imgTensor = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"image\"].resizeBilinear(imgTensor, [inputSize, inputSize]);\r\n                    }\r\n                    return imgTensor.as3D(inputSize, inputSize, 3);\r\n                }\r\n                if (input instanceof _env__WEBPACK_IMPORTED_MODULE_1__[\"env\"].getEnv().Canvas) {\r\n                    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"browser\"].fromPixels(Object(_imageToSquare__WEBPACK_IMPORTED_MODULE_5__[\"imageToSquare\"])(input, inputSize, isCenterInputs));\r\n                }\r\n                throw new Error(\"toBatchTensor - at batchIdx \" + batchIdx + \", expected input to be instanceof tf.Tensor or instanceof HTMLCanvasElement, instead have \" + input);\r\n            });\r\n            var batchTensor = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"stack\"](inputTensors.map(function (t) { return t.toFloat(); })).as4D(_this.batchSize, inputSize, inputSize, 3);\r\n            return batchTensor;\r\n        });\r\n    };\r\n    return NetInput;\r\n}());\r\n\r\n//# sourceMappingURL=NetInput.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/dom/NetInput.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/dom/awaitMediaLoaded.js":
/*!************************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/dom/awaitMediaLoaded.js ***!
  \************************************************************************************/
/*! exports provided: awaitMediaLoaded */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"awaitMediaLoaded\", function() { return awaitMediaLoaded; });\n/* harmony import */ var _env__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../env */ \"./node_modules/tfjs-image-recognition-base/build/es6/env/index.js\");\n/* harmony import */ var _isMediaLoaded__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./isMediaLoaded */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/isMediaLoaded.js\");\n\r\n\r\nfunction awaitMediaLoaded(media) {\r\n    return new Promise(function (resolve, reject) {\r\n        if (media instanceof _env__WEBPACK_IMPORTED_MODULE_0__[\"env\"].getEnv().Canvas || Object(_isMediaLoaded__WEBPACK_IMPORTED_MODULE_1__[\"isMediaLoaded\"])(media)) {\r\n            return resolve();\r\n        }\r\n        function onLoad(e) {\r\n            if (!e.currentTarget)\r\n                return;\r\n            e.currentTarget.removeEventListener('load', onLoad);\r\n            e.currentTarget.removeEventListener('error', onError);\r\n            resolve(e);\r\n        }\r\n        function onError(e) {\r\n            if (!e.currentTarget)\r\n                return;\r\n            e.currentTarget.removeEventListener('load', onLoad);\r\n            e.currentTarget.removeEventListener('error', onError);\r\n            reject(e);\r\n        }\r\n        media.addEventListener('load', onLoad);\r\n        media.addEventListener('error', onError);\r\n    });\r\n}\r\n//# sourceMappingURL=awaitMediaLoaded.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/dom/awaitMediaLoaded.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/dom/bufferToImage.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/dom/bufferToImage.js ***!
  \*********************************************************************************/
/*! exports provided: bufferToImage */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"bufferToImage\", function() { return bufferToImage; });\n/* harmony import */ var _env__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../env */ \"./node_modules/tfjs-image-recognition-base/build/es6/env/index.js\");\n\r\nfunction bufferToImage(buf) {\r\n    return new Promise(function (resolve, reject) {\r\n        if (!(buf instanceof Blob)) {\r\n            return reject('bufferToImage - expected buf to be of type: Blob');\r\n        }\r\n        var reader = new FileReader();\r\n        reader.onload = function () {\r\n            if (typeof reader.result !== 'string') {\r\n                return reject('bufferToImage - expected reader.result to be a string, in onload');\r\n            }\r\n            var img = _env__WEBPACK_IMPORTED_MODULE_0__[\"env\"].getEnv().createImageElement();\r\n            img.onload = function () { return resolve(img); };\r\n            img.onerror = reject;\r\n            img.src = reader.result;\r\n        };\r\n        reader.onerror = reject;\r\n        reader.readAsDataURL(buf);\r\n    });\r\n}\r\n//# sourceMappingURL=bufferToImage.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/dom/bufferToImage.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/dom/createCanvas.js":
/*!********************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/dom/createCanvas.js ***!
  \********************************************************************************/
/*! exports provided: createCanvas, createCanvasFromMedia */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"createCanvas\", function() { return createCanvas; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"createCanvasFromMedia\", function() { return createCanvasFromMedia; });\n/* harmony import */ var _env__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../env */ \"./node_modules/tfjs-image-recognition-base/build/es6/env/index.js\");\n/* harmony import */ var _getContext2dOrThrow__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./getContext2dOrThrow */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/getContext2dOrThrow.js\");\n/* harmony import */ var _getMediaDimensions__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./getMediaDimensions */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/getMediaDimensions.js\");\n/* harmony import */ var _isMediaLoaded__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./isMediaLoaded */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/isMediaLoaded.js\");\n\r\n\r\n\r\n\r\nfunction createCanvas(_a) {\r\n    var width = _a.width, height = _a.height;\r\n    var createCanvasElement = _env__WEBPACK_IMPORTED_MODULE_0__[\"env\"].getEnv().createCanvasElement;\r\n    var canvas = createCanvasElement();\r\n    canvas.width = width;\r\n    canvas.height = height;\r\n    return canvas;\r\n}\r\nfunction createCanvasFromMedia(media, dims) {\r\n    var ImageData = _env__WEBPACK_IMPORTED_MODULE_0__[\"env\"].getEnv().ImageData;\r\n    if (!(media instanceof ImageData) && !Object(_isMediaLoaded__WEBPACK_IMPORTED_MODULE_3__[\"isMediaLoaded\"])(media)) {\r\n        throw new Error('createCanvasFromMedia - media has not finished loading yet');\r\n    }\r\n    var _a = dims || Object(_getMediaDimensions__WEBPACK_IMPORTED_MODULE_2__[\"getMediaDimensions\"])(media), width = _a.width, height = _a.height;\r\n    var canvas = createCanvas({ width: width, height: height });\r\n    if (media instanceof ImageData) {\r\n        Object(_getContext2dOrThrow__WEBPACK_IMPORTED_MODULE_1__[\"getContext2dOrThrow\"])(canvas).putImageData(media, 0, 0);\r\n    }\r\n    else {\r\n        Object(_getContext2dOrThrow__WEBPACK_IMPORTED_MODULE_1__[\"getContext2dOrThrow\"])(canvas).drawImage(media, 0, 0, width, height);\r\n    }\r\n    return canvas;\r\n}\r\n//# sourceMappingURL=createCanvas.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/dom/createCanvas.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/dom/fetchImage.js":
/*!******************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/dom/fetchImage.js ***!
  \******************************************************************************/
/*! exports provided: fetchImage */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"fetchImage\", function() { return fetchImage; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _bufferToImage__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./bufferToImage */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/bufferToImage.js\");\n/* harmony import */ var _fetchOrThrow__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./fetchOrThrow */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/fetchOrThrow.js\");\n\r\n\r\n\r\nfunction fetchImage(uri) {\r\n    return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n        var res, blob;\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n            switch (_a.label) {\r\n                case 0: return [4 /*yield*/, Object(_fetchOrThrow__WEBPACK_IMPORTED_MODULE_2__[\"fetchOrThrow\"])(uri)];\r\n                case 1:\r\n                    res = _a.sent();\r\n                    return [4 /*yield*/, (res).blob()];\r\n                case 2:\r\n                    blob = _a.sent();\r\n                    if (!blob.type.startsWith('image/')) {\r\n                        throw new Error(\"fetchImage - expected blob type to be of type image/*, instead have: \" + blob.type + \", for url: \" + res.url);\r\n                    }\r\n                    return [2 /*return*/, Object(_bufferToImage__WEBPACK_IMPORTED_MODULE_1__[\"bufferToImage\"])(blob)];\r\n            }\r\n        });\r\n    });\r\n}\r\n//# sourceMappingURL=fetchImage.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/dom/fetchImage.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/dom/fetchJson.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/dom/fetchJson.js ***!
  \*****************************************************************************/
/*! exports provided: fetchJson */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"fetchJson\", function() { return fetchJson; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _fetchOrThrow__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./fetchOrThrow */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/fetchOrThrow.js\");\n\r\n\r\nfunction fetchJson(uri) {\r\n    return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n            switch (_a.label) {\r\n                case 0: return [4 /*yield*/, Object(_fetchOrThrow__WEBPACK_IMPORTED_MODULE_1__[\"fetchOrThrow\"])(uri)];\r\n                case 1: return [2 /*return*/, (_a.sent()).json()];\r\n            }\r\n        });\r\n    });\r\n}\r\n//# sourceMappingURL=fetchJson.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/dom/fetchJson.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/dom/fetchNetWeights.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/dom/fetchNetWeights.js ***!
  \***********************************************************************************/
/*! exports provided: fetchNetWeights */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"fetchNetWeights\", function() { return fetchNetWeights; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _fetchOrThrow__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./fetchOrThrow */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/fetchOrThrow.js\");\n\r\n\r\nfunction fetchNetWeights(uri) {\r\n    return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n        var _a;\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n            switch (_b.label) {\r\n                case 0:\r\n                    _a = Float32Array.bind;\r\n                    return [4 /*yield*/, Object(_fetchOrThrow__WEBPACK_IMPORTED_MODULE_1__[\"fetchOrThrow\"])(uri)];\r\n                case 1: return [4 /*yield*/, (_b.sent()).arrayBuffer()];\r\n                case 2: return [2 /*return*/, new (_a.apply(Float32Array, [void 0, _b.sent()]))()];\r\n            }\r\n        });\r\n    });\r\n}\r\n//# sourceMappingURL=fetchNetWeights.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/dom/fetchNetWeights.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/dom/fetchOrThrow.js":
/*!********************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/dom/fetchOrThrow.js ***!
  \********************************************************************************/
/*! exports provided: fetchOrThrow */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"fetchOrThrow\", function() { return fetchOrThrow; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _env__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../env */ \"./node_modules/tfjs-image-recognition-base/build/es6/env/index.js\");\n\r\n\r\nfunction fetchOrThrow(url, init) {\r\n    return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n        var fetch, res;\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n            switch (_a.label) {\r\n                case 0:\r\n                    fetch = _env__WEBPACK_IMPORTED_MODULE_1__[\"env\"].getEnv().fetch;\r\n                    return [4 /*yield*/, fetch(url, init)];\r\n                case 1:\r\n                    res = _a.sent();\r\n                    if (!(res.status < 400)) {\r\n                        throw new Error(\"failed to fetch: (\" + res.status + \") \" + res.statusText + \", from url: \" + res.url);\r\n                    }\r\n                    return [2 /*return*/, res];\r\n            }\r\n        });\r\n    });\r\n}\r\n//# sourceMappingURL=fetchOrThrow.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/dom/fetchOrThrow.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/dom/getContext2dOrThrow.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/dom/getContext2dOrThrow.js ***!
  \***************************************************************************************/
/*! exports provided: getContext2dOrThrow */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getContext2dOrThrow\", function() { return getContext2dOrThrow; });\n/* harmony import */ var _env__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../env */ \"./node_modules/tfjs-image-recognition-base/build/es6/env/index.js\");\n/* harmony import */ var _resolveInput__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./resolveInput */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/resolveInput.js\");\n\r\n\r\nfunction getContext2dOrThrow(canvasArg) {\r\n    var _a = _env__WEBPACK_IMPORTED_MODULE_0__[\"env\"].getEnv(), Canvas = _a.Canvas, CanvasRenderingContext2D = _a.CanvasRenderingContext2D;\r\n    if (canvasArg instanceof CanvasRenderingContext2D) {\r\n        return canvasArg;\r\n    }\r\n    var canvas = Object(_resolveInput__WEBPACK_IMPORTED_MODULE_1__[\"resolveInput\"])(canvasArg);\r\n    if (!(canvas instanceof Canvas)) {\r\n        throw new Error('resolveContext2d - expected canvas to be of instance of Canvas');\r\n    }\r\n    var ctx = canvas.getContext('2d');\r\n    if (!ctx) {\r\n        throw new Error('resolveContext2d - canvas 2d context is null');\r\n    }\r\n    return ctx;\r\n}\r\n//# sourceMappingURL=getContext2dOrThrow.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/dom/getContext2dOrThrow.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/dom/getMediaDimensions.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/dom/getMediaDimensions.js ***!
  \**************************************************************************************/
/*! exports provided: getMediaDimensions */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getMediaDimensions\", function() { return getMediaDimensions; });\n/* harmony import */ var _classes_Dimensions__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../classes/Dimensions */ \"./node_modules/tfjs-image-recognition-base/build/es6/classes/Dimensions.js\");\n/* harmony import */ var _env__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../env */ \"./node_modules/tfjs-image-recognition-base/build/es6/env/index.js\");\n\r\n\r\nfunction getMediaDimensions(input) {\r\n    var _a = _env__WEBPACK_IMPORTED_MODULE_1__[\"env\"].getEnv(), Image = _a.Image, Video = _a.Video;\r\n    if (input instanceof Image) {\r\n        return new _classes_Dimensions__WEBPACK_IMPORTED_MODULE_0__[\"Dimensions\"](input.naturalWidth, input.naturalHeight);\r\n    }\r\n    if (input instanceof Video) {\r\n        return new _classes_Dimensions__WEBPACK_IMPORTED_MODULE_0__[\"Dimensions\"](input.videoWidth, input.videoHeight);\r\n    }\r\n    return new _classes_Dimensions__WEBPACK_IMPORTED_MODULE_0__[\"Dimensions\"](input.width, input.height);\r\n}\r\n//# sourceMappingURL=getMediaDimensions.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/dom/getMediaDimensions.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/dom/imageTensorToCanvas.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/dom/imageTensorToCanvas.js ***!
  \***************************************************************************************/
/*! exports provided: imageTensorToCanvas */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"imageTensorToCanvas\", function() { return imageTensorToCanvas; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var _env__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../env */ \"./node_modules/tfjs-image-recognition-base/build/es6/env/index.js\");\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../utils */ \"./node_modules/tfjs-image-recognition-base/build/es6/utils/index.js\");\n\r\n\r\n\r\n\r\nfunction imageTensorToCanvas(imgTensor, canvas) {\r\n    return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n        var targetCanvas, _a, height, width, numChannels, imgTensor3D;\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n            switch (_b.label) {\r\n                case 0:\r\n                    targetCanvas = canvas || _env__WEBPACK_IMPORTED_MODULE_2__[\"env\"].getEnv().createCanvasElement();\r\n                    _a = imgTensor.shape.slice(Object(_utils__WEBPACK_IMPORTED_MODULE_3__[\"isTensor4D\"])(imgTensor) ? 1 : 0), height = _a[0], width = _a[1], numChannels = _a[2];\r\n                    imgTensor3D = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tidy\"](function () { return imgTensor.as3D(height, width, numChannels).toInt(); });\r\n                    return [4 /*yield*/, _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"browser\"].toPixels(imgTensor3D, targetCanvas)];\r\n                case 1:\r\n                    _b.sent();\r\n                    imgTensor3D.dispose();\r\n                    return [2 /*return*/, targetCanvas];\r\n            }\r\n        });\r\n    });\r\n}\r\n//# sourceMappingURL=imageTensorToCanvas.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/dom/imageTensorToCanvas.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/dom/imageToSquare.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/dom/imageToSquare.js ***!
  \*********************************************************************************/
/*! exports provided: imageToSquare */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"imageToSquare\", function() { return imageToSquare; });\n/* harmony import */ var _env__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../env */ \"./node_modules/tfjs-image-recognition-base/build/es6/env/index.js\");\n/* harmony import */ var _createCanvas__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./createCanvas */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/createCanvas.js\");\n/* harmony import */ var _getContext2dOrThrow__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./getContext2dOrThrow */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/getContext2dOrThrow.js\");\n/* harmony import */ var _getMediaDimensions__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./getMediaDimensions */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/getMediaDimensions.js\");\n\r\n\r\n\r\n\r\nfunction imageToSquare(input, inputSize, centerImage) {\r\n    if (centerImage === void 0) { centerImage = false; }\r\n    var _a = _env__WEBPACK_IMPORTED_MODULE_0__[\"env\"].getEnv(), Image = _a.Image, Canvas = _a.Canvas;\r\n    if (!(input instanceof Image || input instanceof Canvas)) {\r\n        throw new Error('imageToSquare - expected arg0 to be HTMLImageElement | HTMLCanvasElement');\r\n    }\r\n    var dims = Object(_getMediaDimensions__WEBPACK_IMPORTED_MODULE_3__[\"getMediaDimensions\"])(input);\r\n    var scale = inputSize / Math.max(dims.height, dims.width);\r\n    var width = scale * dims.width;\r\n    var height = scale * dims.height;\r\n    var targetCanvas = Object(_createCanvas__WEBPACK_IMPORTED_MODULE_1__[\"createCanvas\"])({ width: inputSize, height: inputSize });\r\n    var inputCanvas = input instanceof Canvas ? input : Object(_createCanvas__WEBPACK_IMPORTED_MODULE_1__[\"createCanvasFromMedia\"])(input);\r\n    var offset = Math.abs(width - height) / 2;\r\n    var dx = centerImage && width < height ? offset : 0;\r\n    var dy = centerImage && height < width ? offset : 0;\r\n    Object(_getContext2dOrThrow__WEBPACK_IMPORTED_MODULE_2__[\"getContext2dOrThrow\"])(targetCanvas).drawImage(inputCanvas, dx, dy, width, height);\r\n    return targetCanvas;\r\n}\r\n//# sourceMappingURL=imageToSquare.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/dom/imageToSquare.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/dom/index.js":
/*!*************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/dom/index.js ***!
  \*************************************************************************/
/*! exports provided: awaitMediaLoaded, bufferToImage, createCanvas, createCanvasFromMedia, fetchImage, fetchJson, fetchNetWeights, fetchOrThrow, getContext2dOrThrow, getMediaDimensions, imageTensorToCanvas, imageToSquare, isMediaElement, isMediaLoaded, loadWeightMap, matchDimensions, NetInput, resolveInput, toNetInput */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _awaitMediaLoaded__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./awaitMediaLoaded */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/awaitMediaLoaded.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"awaitMediaLoaded\", function() { return _awaitMediaLoaded__WEBPACK_IMPORTED_MODULE_0__[\"awaitMediaLoaded\"]; });\n\n/* harmony import */ var _bufferToImage__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./bufferToImage */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/bufferToImage.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"bufferToImage\", function() { return _bufferToImage__WEBPACK_IMPORTED_MODULE_1__[\"bufferToImage\"]; });\n\n/* harmony import */ var _createCanvas__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./createCanvas */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/createCanvas.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"createCanvas\", function() { return _createCanvas__WEBPACK_IMPORTED_MODULE_2__[\"createCanvas\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"createCanvasFromMedia\", function() { return _createCanvas__WEBPACK_IMPORTED_MODULE_2__[\"createCanvasFromMedia\"]; });\n\n/* harmony import */ var _fetchImage__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./fetchImage */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/fetchImage.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"fetchImage\", function() { return _fetchImage__WEBPACK_IMPORTED_MODULE_3__[\"fetchImage\"]; });\n\n/* harmony import */ var _fetchJson__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./fetchJson */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/fetchJson.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"fetchJson\", function() { return _fetchJson__WEBPACK_IMPORTED_MODULE_4__[\"fetchJson\"]; });\n\n/* harmony import */ var _fetchNetWeights__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./fetchNetWeights */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/fetchNetWeights.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"fetchNetWeights\", function() { return _fetchNetWeights__WEBPACK_IMPORTED_MODULE_5__[\"fetchNetWeights\"]; });\n\n/* harmony import */ var _fetchOrThrow__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./fetchOrThrow */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/fetchOrThrow.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"fetchOrThrow\", function() { return _fetchOrThrow__WEBPACK_IMPORTED_MODULE_6__[\"fetchOrThrow\"]; });\n\n/* harmony import */ var _getContext2dOrThrow__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./getContext2dOrThrow */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/getContext2dOrThrow.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"getContext2dOrThrow\", function() { return _getContext2dOrThrow__WEBPACK_IMPORTED_MODULE_7__[\"getContext2dOrThrow\"]; });\n\n/* harmony import */ var _getMediaDimensions__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./getMediaDimensions */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/getMediaDimensions.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"getMediaDimensions\", function() { return _getMediaDimensions__WEBPACK_IMPORTED_MODULE_8__[\"getMediaDimensions\"]; });\n\n/* harmony import */ var _imageTensorToCanvas__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./imageTensorToCanvas */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/imageTensorToCanvas.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"imageTensorToCanvas\", function() { return _imageTensorToCanvas__WEBPACK_IMPORTED_MODULE_9__[\"imageTensorToCanvas\"]; });\n\n/* harmony import */ var _imageToSquare__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./imageToSquare */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/imageToSquare.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"imageToSquare\", function() { return _imageToSquare__WEBPACK_IMPORTED_MODULE_10__[\"imageToSquare\"]; });\n\n/* harmony import */ var _isMediaElement__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./isMediaElement */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/isMediaElement.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isMediaElement\", function() { return _isMediaElement__WEBPACK_IMPORTED_MODULE_11__[\"isMediaElement\"]; });\n\n/* harmony import */ var _isMediaLoaded__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./isMediaLoaded */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/isMediaLoaded.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isMediaLoaded\", function() { return _isMediaLoaded__WEBPACK_IMPORTED_MODULE_12__[\"isMediaLoaded\"]; });\n\n/* harmony import */ var _loadWeightMap__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./loadWeightMap */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/loadWeightMap.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadWeightMap\", function() { return _loadWeightMap__WEBPACK_IMPORTED_MODULE_13__[\"loadWeightMap\"]; });\n\n/* harmony import */ var _matchDimensions__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./matchDimensions */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/matchDimensions.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"matchDimensions\", function() { return _matchDimensions__WEBPACK_IMPORTED_MODULE_14__[\"matchDimensions\"]; });\n\n/* harmony import */ var _NetInput__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./NetInput */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/NetInput.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"NetInput\", function() { return _NetInput__WEBPACK_IMPORTED_MODULE_15__[\"NetInput\"]; });\n\n/* harmony import */ var _resolveInput__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./resolveInput */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/resolveInput.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"resolveInput\", function() { return _resolveInput__WEBPACK_IMPORTED_MODULE_16__[\"resolveInput\"]; });\n\n/* harmony import */ var _toNetInput__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./toNetInput */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/toNetInput.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"toNetInput\", function() { return _toNetInput__WEBPACK_IMPORTED_MODULE_17__[\"toNetInput\"]; });\n\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/dom/index.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/dom/isMediaElement.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/dom/isMediaElement.js ***!
  \**********************************************************************************/
/*! exports provided: isMediaElement */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isMediaElement\", function() { return isMediaElement; });\n/* harmony import */ var _env__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../env */ \"./node_modules/tfjs-image-recognition-base/build/es6/env/index.js\");\n\r\nfunction isMediaElement(input) {\r\n    var _a = _env__WEBPACK_IMPORTED_MODULE_0__[\"env\"].getEnv(), Image = _a.Image, Canvas = _a.Canvas, Video = _a.Video;\r\n    return input instanceof Image\r\n        || input instanceof Canvas\r\n        || input instanceof Video;\r\n}\r\n//# sourceMappingURL=isMediaElement.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/dom/isMediaElement.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/dom/isMediaLoaded.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/dom/isMediaLoaded.js ***!
  \*********************************************************************************/
/*! exports provided: isMediaLoaded */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isMediaLoaded\", function() { return isMediaLoaded; });\n/* harmony import */ var _env__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../env */ \"./node_modules/tfjs-image-recognition-base/build/es6/env/index.js\");\n\r\nfunction isMediaLoaded(media) {\r\n    var _a = _env__WEBPACK_IMPORTED_MODULE_0__[\"env\"].getEnv(), Image = _a.Image, Video = _a.Video;\r\n    return (media instanceof Image && media.complete)\r\n        || (media instanceof Video && media.readyState >= 3);\r\n}\r\n//# sourceMappingURL=isMediaLoaded.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/dom/isMediaLoaded.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/dom/loadWeightMap.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/dom/loadWeightMap.js ***!
  \*********************************************************************************/
/*! exports provided: loadWeightMap */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"loadWeightMap\", function() { return loadWeightMap; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var _common_getModelUris__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/getModelUris */ \"./node_modules/tfjs-image-recognition-base/build/es6/common/getModelUris.js\");\n/* harmony import */ var _fetchJson__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./fetchJson */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/fetchJson.js\");\n\r\n\r\n\r\n\r\nfunction loadWeightMap(uri, defaultModelName) {\r\n    return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n        var _a, manifestUri, modelBaseUri, manifest;\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n            switch (_b.label) {\r\n                case 0:\r\n                    _a = Object(_common_getModelUris__WEBPACK_IMPORTED_MODULE_2__[\"getModelUris\"])(uri, defaultModelName), manifestUri = _a.manifestUri, modelBaseUri = _a.modelBaseUri;\r\n                    return [4 /*yield*/, Object(_fetchJson__WEBPACK_IMPORTED_MODULE_3__[\"fetchJson\"])(manifestUri)];\r\n                case 1:\r\n                    manifest = _b.sent();\r\n                    return [2 /*return*/, _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"io\"].loadWeights(manifest, modelBaseUri)];\r\n            }\r\n        });\r\n    });\r\n}\r\n//# sourceMappingURL=loadWeightMap.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/dom/loadWeightMap.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/dom/matchDimensions.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/dom/matchDimensions.js ***!
  \***********************************************************************************/
/*! exports provided: matchDimensions */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"matchDimensions\", function() { return matchDimensions; });\n/* harmony import */ var _getMediaDimensions__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./getMediaDimensions */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/getMediaDimensions.js\");\n\r\nfunction matchDimensions(input, reference, useMediaDimensions) {\r\n    if (useMediaDimensions === void 0) { useMediaDimensions = false; }\r\n    var _a = useMediaDimensions\r\n        ? Object(_getMediaDimensions__WEBPACK_IMPORTED_MODULE_0__[\"getMediaDimensions\"])(reference)\r\n        : reference, width = _a.width, height = _a.height;\r\n    input.width = width;\r\n    input.height = height;\r\n    return { width: width, height: height };\r\n}\r\n//# sourceMappingURL=matchDimensions.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/dom/matchDimensions.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/dom/resolveInput.js":
/*!********************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/dom/resolveInput.js ***!
  \********************************************************************************/
/*! exports provided: resolveInput */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"resolveInput\", function() { return resolveInput; });\n/* harmony import */ var _env__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../env */ \"./node_modules/tfjs-image-recognition-base/build/es6/env/index.js\");\n\r\nfunction resolveInput(arg) {\r\n    if (!_env__WEBPACK_IMPORTED_MODULE_0__[\"env\"].isNodejs() && typeof arg === 'string') {\r\n        return document.getElementById(arg);\r\n    }\r\n    return arg;\r\n}\r\n//# sourceMappingURL=resolveInput.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/dom/resolveInput.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/dom/toNetInput.js":
/*!******************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/dom/toNetInput.js ***!
  \******************************************************************************/
/*! exports provided: toNetInput */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"toNetInput\", function() { return toNetInput; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils */ \"./node_modules/tfjs-image-recognition-base/build/es6/utils/index.js\");\n/* harmony import */ var _awaitMediaLoaded__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./awaitMediaLoaded */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/awaitMediaLoaded.js\");\n/* harmony import */ var _isMediaElement__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./isMediaElement */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/isMediaElement.js\");\n/* harmony import */ var _NetInput__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./NetInput */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/NetInput.js\");\n/* harmony import */ var _resolveInput__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./resolveInput */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/resolveInput.js\");\n\r\n\r\n\r\n\r\n\r\n\r\n/**\r\n * Validates the input to make sure, they are valid net inputs and awaits all media elements\r\n * to be finished loading.\r\n *\r\n * @param input The input, which can be a media element or an array of different media elements.\r\n * @returns A NetInput instance, which can be passed into one of the neural networks.\r\n */\r\nfunction toNetInput(inputs) {\r\n    return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n        var inputArgArray, getIdxHint, inputArray;\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n            switch (_a.label) {\r\n                case 0:\r\n                    if (inputs instanceof _NetInput__WEBPACK_IMPORTED_MODULE_4__[\"NetInput\"]) {\r\n                        return [2 /*return*/, inputs];\r\n                    }\r\n                    inputArgArray = Array.isArray(inputs)\r\n                        ? inputs\r\n                        : [inputs];\r\n                    if (!inputArgArray.length) {\r\n                        throw new Error('toNetInput - empty array passed as input');\r\n                    }\r\n                    getIdxHint = function (idx) { return Array.isArray(inputs) ? \" at input index \" + idx + \":\" : ''; };\r\n                    inputArray = inputArgArray.map(_resolveInput__WEBPACK_IMPORTED_MODULE_5__[\"resolveInput\"]);\r\n                    inputArray.forEach(function (input, i) {\r\n                        if (!Object(_isMediaElement__WEBPACK_IMPORTED_MODULE_3__[\"isMediaElement\"])(input) && !Object(_utils__WEBPACK_IMPORTED_MODULE_1__[\"isTensor3D\"])(input) && !Object(_utils__WEBPACK_IMPORTED_MODULE_1__[\"isTensor4D\"])(input)) {\r\n                            if (typeof inputArgArray[i] === 'string') {\r\n                                throw new Error(\"toNetInput -\" + getIdxHint(i) + \" string passed, but could not resolve HTMLElement for element id \" + inputArgArray[i]);\r\n                            }\r\n                            throw new Error(\"toNetInput -\" + getIdxHint(i) + \" expected media to be of type HTMLImageElement | HTMLVideoElement | HTMLCanvasElement | tf.Tensor3D, or to be an element id\");\r\n                        }\r\n                        if (Object(_utils__WEBPACK_IMPORTED_MODULE_1__[\"isTensor4D\"])(input)) {\r\n                            // if tf.Tensor4D is passed in the input array, the batch size has to be 1\r\n                            var batchSize = input.shape[0];\r\n                            if (batchSize !== 1) {\r\n                                throw new Error(\"toNetInput -\" + getIdxHint(i) + \" tf.Tensor4D with batchSize \" + batchSize + \" passed, but not supported in input array\");\r\n                            }\r\n                        }\r\n                    });\r\n                    // wait for all media elements being loaded\r\n                    return [4 /*yield*/, Promise.all(inputArray.map(function (input) { return Object(_isMediaElement__WEBPACK_IMPORTED_MODULE_3__[\"isMediaElement\"])(input) && Object(_awaitMediaLoaded__WEBPACK_IMPORTED_MODULE_2__[\"awaitMediaLoaded\"])(input); }))];\r\n                case 1:\r\n                    // wait for all media elements being loaded\r\n                    _a.sent();\r\n                    return [2 /*return*/, new _NetInput__WEBPACK_IMPORTED_MODULE_4__[\"NetInput\"](inputArray, Array.isArray(inputs))];\r\n            }\r\n        });\r\n    });\r\n}\r\n//# sourceMappingURL=toNetInput.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/dom/toNetInput.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/draw/DrawBox.js":
/*!****************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/draw/DrawBox.js ***!
  \****************************************************************************/
/*! exports provided: DrawBoxOptions, DrawBox */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DrawBoxOptions\", function() { return DrawBoxOptions; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DrawBox\", function() { return DrawBox; });\n/* harmony import */ var _classes__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../classes */ \"./node_modules/tfjs-image-recognition-base/build/es6/classes/index.js\");\n/* harmony import */ var _dom_getContext2dOrThrow__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../dom/getContext2dOrThrow */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/getContext2dOrThrow.js\");\n/* harmony import */ var _DrawTextField__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./DrawTextField */ \"./node_modules/tfjs-image-recognition-base/build/es6/draw/DrawTextField.js\");\n\r\n\r\n\r\nvar DrawBoxOptions = /** @class */ (function () {\r\n    function DrawBoxOptions(options) {\r\n        if (options === void 0) { options = {}; }\r\n        var boxColor = options.boxColor, lineWidth = options.lineWidth, label = options.label, drawLabelOptions = options.drawLabelOptions;\r\n        this.boxColor = boxColor || 'rgba(0, 0, 255, 1)';\r\n        this.lineWidth = lineWidth || 2;\r\n        this.label = label;\r\n        var defaultDrawLabelOptions = {\r\n            anchorPosition: _DrawTextField__WEBPACK_IMPORTED_MODULE_2__[\"AnchorPosition\"].BOTTOM_LEFT,\r\n            backgroundColor: this.boxColor\r\n        };\r\n        this.drawLabelOptions = new _DrawTextField__WEBPACK_IMPORTED_MODULE_2__[\"DrawTextFieldOptions\"](Object.assign({}, defaultDrawLabelOptions, drawLabelOptions));\r\n    }\r\n    return DrawBoxOptions;\r\n}());\r\n\r\nvar DrawBox = /** @class */ (function () {\r\n    function DrawBox(box, options) {\r\n        if (options === void 0) { options = {}; }\r\n        this.box = new _classes__WEBPACK_IMPORTED_MODULE_0__[\"Box\"](box);\r\n        this.options = new DrawBoxOptions(options);\r\n    }\r\n    DrawBox.prototype.draw = function (canvasArg) {\r\n        var ctx = Object(_dom_getContext2dOrThrow__WEBPACK_IMPORTED_MODULE_1__[\"getContext2dOrThrow\"])(canvasArg);\r\n        var _a = this.options, boxColor = _a.boxColor, lineWidth = _a.lineWidth;\r\n        var _b = this.box, x = _b.x, y = _b.y, width = _b.width, height = _b.height;\r\n        ctx.strokeStyle = boxColor;\r\n        ctx.lineWidth = lineWidth;\r\n        ctx.strokeRect(x, y, width, height);\r\n        var label = this.options.label;\r\n        if (label) {\r\n            new _DrawTextField__WEBPACK_IMPORTED_MODULE_2__[\"DrawTextField\"]([label], { x: x - (lineWidth / 2), y: y }, this.options.drawLabelOptions).draw(canvasArg);\r\n        }\r\n    };\r\n    return DrawBox;\r\n}());\r\n\r\n//# sourceMappingURL=DrawBox.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/draw/DrawBox.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/draw/DrawTextField.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/draw/DrawTextField.js ***!
  \**********************************************************************************/
/*! exports provided: AnchorPosition, DrawTextFieldOptions, DrawTextField */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"AnchorPosition\", function() { return AnchorPosition; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DrawTextFieldOptions\", function() { return DrawTextFieldOptions; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"DrawTextField\", function() { return DrawTextField; });\n/* harmony import */ var _dom_getContext2dOrThrow__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../dom/getContext2dOrThrow */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/getContext2dOrThrow.js\");\n/* harmony import */ var _dom_resolveInput__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../dom/resolveInput */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/resolveInput.js\");\n\r\n\r\nvar AnchorPosition;\r\n(function (AnchorPosition) {\r\n    AnchorPosition[\"TOP_LEFT\"] = \"TOP_LEFT\";\r\n    AnchorPosition[\"TOP_RIGHT\"] = \"TOP_RIGHT\";\r\n    AnchorPosition[\"BOTTOM_LEFT\"] = \"BOTTOM_LEFT\";\r\n    AnchorPosition[\"BOTTOM_RIGHT\"] = \"BOTTOM_RIGHT\";\r\n})(AnchorPosition || (AnchorPosition = {}));\r\nvar DrawTextFieldOptions = /** @class */ (function () {\r\n    function DrawTextFieldOptions(options) {\r\n        if (options === void 0) { options = {}; }\r\n        var anchorPosition = options.anchorPosition, backgroundColor = options.backgroundColor, fontColor = options.fontColor, fontSize = options.fontSize, fontStyle = options.fontStyle, padding = options.padding;\r\n        this.anchorPosition = anchorPosition || AnchorPosition.TOP_LEFT;\r\n        this.backgroundColor = backgroundColor || 'rgba(0, 0, 0, 0.5)';\r\n        this.fontColor = fontColor || 'rgba(255, 255, 255, 1)';\r\n        this.fontSize = fontSize || 14;\r\n        this.fontStyle = fontStyle || 'Georgia';\r\n        this.padding = padding || 4;\r\n    }\r\n    return DrawTextFieldOptions;\r\n}());\r\n\r\nvar DrawTextField = /** @class */ (function () {\r\n    function DrawTextField(text, anchor, options) {\r\n        if (options === void 0) { options = {}; }\r\n        this.text = typeof text === 'string'\r\n            ? [text]\r\n            : (text instanceof DrawTextField ? text.text : text);\r\n        this.anchor = anchor;\r\n        this.options = new DrawTextFieldOptions(options);\r\n    }\r\n    DrawTextField.prototype.measureWidth = function (ctx) {\r\n        var padding = this.options.padding;\r\n        return this.text.map(function (l) { return ctx.measureText(l).width; }).reduce(function (w0, w1) { return w0 < w1 ? w1 : w0; }, 0) + (2 * padding);\r\n    };\r\n    DrawTextField.prototype.measureHeight = function () {\r\n        var _a = this.options, fontSize = _a.fontSize, padding = _a.padding;\r\n        return this.text.length * fontSize + (2 * padding);\r\n    };\r\n    DrawTextField.prototype.getUpperLeft = function (ctx, canvasDims) {\r\n        var anchorPosition = this.options.anchorPosition;\r\n        var isShiftLeft = anchorPosition === AnchorPosition.BOTTOM_RIGHT || anchorPosition === AnchorPosition.TOP_RIGHT;\r\n        var isShiftTop = anchorPosition === AnchorPosition.BOTTOM_LEFT || anchorPosition === AnchorPosition.BOTTOM_RIGHT;\r\n        var textFieldWidth = this.measureWidth(ctx);\r\n        var textFieldHeight = this.measureHeight();\r\n        var x = (isShiftLeft ? this.anchor.x - textFieldWidth : this.anchor.x);\r\n        var y = isShiftTop ? this.anchor.y - textFieldHeight : this.anchor.y;\r\n        // adjust anchor if text box exceeds canvas borders\r\n        if (canvasDims) {\r\n            var width = canvasDims.width, height = canvasDims.height;\r\n            var newX = Math.max(Math.min(x, width - textFieldWidth), 0);\r\n            var newY = Math.max(Math.min(y, height - textFieldHeight), 0);\r\n            return { x: newX, y: newY };\r\n        }\r\n        return { x: x, y: y };\r\n    };\r\n    DrawTextField.prototype.draw = function (canvasArg) {\r\n        var canvas = Object(_dom_resolveInput__WEBPACK_IMPORTED_MODULE_1__[\"resolveInput\"])(canvasArg);\r\n        var ctx = Object(_dom_getContext2dOrThrow__WEBPACK_IMPORTED_MODULE_0__[\"getContext2dOrThrow\"])(canvas);\r\n        var _a = this.options, backgroundColor = _a.backgroundColor, fontColor = _a.fontColor, fontSize = _a.fontSize, fontStyle = _a.fontStyle, padding = _a.padding;\r\n        ctx.font = fontSize + \"px \" + fontStyle;\r\n        var maxTextWidth = this.measureWidth(ctx);\r\n        var textHeight = this.measureHeight();\r\n        ctx.fillStyle = backgroundColor;\r\n        var upperLeft = this.getUpperLeft(ctx, canvas);\r\n        ctx.fillRect(upperLeft.x, upperLeft.y, maxTextWidth, textHeight);\r\n        ctx.fillStyle = fontColor;\r\n        this.text.forEach(function (textLine, i) {\r\n            var x = padding + upperLeft.x;\r\n            var y = padding + upperLeft.y + ((i + 1) * fontSize);\r\n            ctx.fillText(textLine, x, y);\r\n        });\r\n    };\r\n    return DrawTextField;\r\n}());\r\n\r\n//# sourceMappingURL=DrawTextField.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/draw/DrawTextField.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/draw/index.js":
/*!**************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/draw/index.js ***!
  \**************************************************************************/
/*! exports provided: DrawBoxOptions, DrawBox, AnchorPosition, DrawTextFieldOptions, DrawTextField */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _DrawBox__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./DrawBox */ \"./node_modules/tfjs-image-recognition-base/build/es6/draw/DrawBox.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DrawBoxOptions\", function() { return _DrawBox__WEBPACK_IMPORTED_MODULE_0__[\"DrawBoxOptions\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DrawBox\", function() { return _DrawBox__WEBPACK_IMPORTED_MODULE_0__[\"DrawBox\"]; });\n\n/* harmony import */ var _DrawTextField__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./DrawTextField */ \"./node_modules/tfjs-image-recognition-base/build/es6/draw/DrawTextField.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"AnchorPosition\", function() { return _DrawTextField__WEBPACK_IMPORTED_MODULE_1__[\"AnchorPosition\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DrawTextFieldOptions\", function() { return _DrawTextField__WEBPACK_IMPORTED_MODULE_1__[\"DrawTextFieldOptions\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"DrawTextField\", function() { return _DrawTextField__WEBPACK_IMPORTED_MODULE_1__[\"DrawTextField\"]; });\n\n\r\n\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/draw/index.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/env/createBrowserEnv.js":
/*!************************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/env/createBrowserEnv.js ***!
  \************************************************************************************/
/*! exports provided: createBrowserEnv */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"createBrowserEnv\", function() { return createBrowserEnv; });\nfunction createBrowserEnv() {\r\n    var fetch = window['fetch'] || function () {\r\n        throw new Error('fetch - missing fetch implementation for browser environment');\r\n    };\r\n    var readFile = function () {\r\n        throw new Error('readFile - filesystem not available for browser environment');\r\n    };\r\n    return {\r\n        Canvas: HTMLCanvasElement,\r\n        CanvasRenderingContext2D: CanvasRenderingContext2D,\r\n        Image: HTMLImageElement,\r\n        ImageData: ImageData,\r\n        Video: HTMLVideoElement,\r\n        createCanvasElement: function () { return document.createElement('canvas'); },\r\n        createImageElement: function () { return document.createElement('img'); },\r\n        fetch: fetch,\r\n        readFile: readFile\r\n    };\r\n}\r\n//# sourceMappingURL=createBrowserEnv.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/env/createBrowserEnv.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/env/createFileSystem.js":
/*!************************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/env/createFileSystem.js ***!
  \************************************************************************************/
/*! exports provided: createFileSystem */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"createFileSystem\", function() { return createFileSystem; });\nfunction createFileSystem(fs) {\r\n    var requireFsError = '';\r\n    if (!fs) {\r\n        try {\r\n            fs = __webpack_require__(/*! fs */ \"./node_modules/node-libs-browser/mock/empty.js\");\r\n        }\r\n        catch (err) {\r\n            requireFsError = err.toString();\r\n        }\r\n    }\r\n    var readFile = fs\r\n        ? function (filePath) {\r\n            return new Promise(function (res, rej) {\r\n                fs.readFile(filePath, function (err, buffer) {\r\n                    return err ? rej(err) : res(buffer);\r\n                });\r\n            });\r\n        }\r\n        : function () {\r\n            throw new Error(\"readFile - failed to require fs in nodejs environment with error: \" + requireFsError);\r\n        };\r\n    return {\r\n        readFile: readFile\r\n    };\r\n}\r\n//# sourceMappingURL=createFileSystem.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/env/createFileSystem.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/env/createNodejsEnv.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/env/createNodejsEnv.js ***!
  \***********************************************************************************/
/*! exports provided: createNodejsEnv */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* WEBPACK VAR INJECTION */(function(global) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"createNodejsEnv\", function() { return createNodejsEnv; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _createFileSystem__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./createFileSystem */ \"./node_modules/tfjs-image-recognition-base/build/es6/env/createFileSystem.js\");\n\r\n\r\nfunction createNodejsEnv() {\r\n    var Canvas = global['Canvas'] || global['HTMLCanvasElement'];\r\n    var Image = global['Image'] || global['HTMLImageElement'];\r\n    var createCanvasElement = function () {\r\n        if (Canvas) {\r\n            return new Canvas();\r\n        }\r\n        throw new Error('createCanvasElement - missing Canvas implementation for nodejs environment');\r\n    };\r\n    var createImageElement = function () {\r\n        if (Image) {\r\n            return new Image();\r\n        }\r\n        throw new Error('createImageElement - missing Image implementation for nodejs environment');\r\n    };\r\n    var fetch = global['fetch'] || function () {\r\n        throw new Error('fetch - missing fetch implementation for nodejs environment');\r\n    };\r\n    var fileSystem = Object(_createFileSystem__WEBPACK_IMPORTED_MODULE_1__[\"createFileSystem\"])();\r\n    return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__assign\"])({ Canvas: Canvas || /** @class */ (function () {\r\n            function Canvas() {\r\n            }\r\n            return Canvas;\r\n        }()), CanvasRenderingContext2D: global['CanvasRenderingContext2D'] || /** @class */ (function () {\r\n            function class_1() {\r\n            }\r\n            return class_1;\r\n        }()), Image: Image || /** @class */ (function () {\r\n            function Image() {\r\n            }\r\n            return Image;\r\n        }()), ImageData: global['ImageData'] || /** @class */ (function () {\r\n            function class_2() {\r\n            }\r\n            return class_2;\r\n        }()), Video: global['HTMLVideoElement'] || /** @class */ (function () {\r\n            function class_3() {\r\n            }\r\n            return class_3;\r\n        }()), createCanvasElement: createCanvasElement,\r\n        createImageElement: createImageElement,\r\n        fetch: fetch }, fileSystem);\r\n}\r\n//# sourceMappingURL=createNodejsEnv.js.map\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\")))\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/env/createNodejsEnv.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/env/index.js":
/*!*************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/env/index.js ***!
  \*************************************************************************/
/*! exports provided: env */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"env\", function() { return env; });\n/* harmony import */ var _createBrowserEnv__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./createBrowserEnv */ \"./node_modules/tfjs-image-recognition-base/build/es6/env/createBrowserEnv.js\");\n/* harmony import */ var _createFileSystem__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./createFileSystem */ \"./node_modules/tfjs-image-recognition-base/build/es6/env/createFileSystem.js\");\n/* harmony import */ var _createNodejsEnv__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./createNodejsEnv */ \"./node_modules/tfjs-image-recognition-base/build/es6/env/createNodejsEnv.js\");\n/* harmony import */ var _isBrowser__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./isBrowser */ \"./node_modules/tfjs-image-recognition-base/build/es6/env/isBrowser.js\");\n/* harmony import */ var _isNodejs__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./isNodejs */ \"./node_modules/tfjs-image-recognition-base/build/es6/env/isNodejs.js\");\n\r\n\r\n\r\n\r\n\r\nvar environment;\r\nfunction getEnv() {\r\n    if (!environment) {\r\n        throw new Error('getEnv - environment is not defined, check isNodejs() and isBrowser()');\r\n    }\r\n    return environment;\r\n}\r\nfunction setEnv(env) {\r\n    environment = env;\r\n}\r\nfunction initialize() {\r\n    // check for isBrowser() first to prevent electron renderer process\r\n    // to be initialized with wrong environment due to isNodejs() returning true\r\n    if (Object(_isBrowser__WEBPACK_IMPORTED_MODULE_3__[\"isBrowser\"])()) {\r\n        setEnv(Object(_createBrowserEnv__WEBPACK_IMPORTED_MODULE_0__[\"createBrowserEnv\"])());\r\n    }\r\n    if (Object(_isNodejs__WEBPACK_IMPORTED_MODULE_4__[\"isNodejs\"])()) {\r\n        setEnv(Object(_createNodejsEnv__WEBPACK_IMPORTED_MODULE_2__[\"createNodejsEnv\"])());\r\n    }\r\n}\r\nfunction monkeyPatch(env) {\r\n    if (!environment) {\r\n        initialize();\r\n    }\r\n    if (!environment) {\r\n        throw new Error('monkeyPatch - environment is not defined, check isNodejs() and isBrowser()');\r\n    }\r\n    var _a = env.Canvas, Canvas = _a === void 0 ? environment.Canvas : _a, _b = env.Image, Image = _b === void 0 ? environment.Image : _b;\r\n    environment.Canvas = Canvas;\r\n    environment.Image = Image;\r\n    environment.createCanvasElement = env.createCanvasElement || (function () { return new Canvas(); });\r\n    environment.createImageElement = env.createImageElement || (function () { return new Image(); });\r\n    environment.ImageData = env.ImageData || environment.ImageData;\r\n    environment.Video = env.Video || environment.Video;\r\n    environment.fetch = env.fetch || environment.fetch;\r\n    environment.readFile = env.readFile || environment.readFile;\r\n}\r\nvar env = {\r\n    getEnv: getEnv,\r\n    setEnv: setEnv,\r\n    initialize: initialize,\r\n    createBrowserEnv: _createBrowserEnv__WEBPACK_IMPORTED_MODULE_0__[\"createBrowserEnv\"],\r\n    createFileSystem: _createFileSystem__WEBPACK_IMPORTED_MODULE_1__[\"createFileSystem\"],\r\n    createNodejsEnv: _createNodejsEnv__WEBPACK_IMPORTED_MODULE_2__[\"createNodejsEnv\"],\r\n    monkeyPatch: monkeyPatch,\r\n    isBrowser: _isBrowser__WEBPACK_IMPORTED_MODULE_3__[\"isBrowser\"],\r\n    isNodejs: _isNodejs__WEBPACK_IMPORTED_MODULE_4__[\"isNodejs\"]\r\n};\r\ninitialize();\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/env/index.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/env/isBrowser.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/env/isBrowser.js ***!
  \*****************************************************************************/
/*! exports provided: isBrowser */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isBrowser\", function() { return isBrowser; });\nfunction isBrowser() {\r\n    return typeof window === 'object'\r\n        && typeof document !== 'undefined'\r\n        && typeof HTMLImageElement !== 'undefined'\r\n        && typeof HTMLCanvasElement !== 'undefined'\r\n        && typeof HTMLVideoElement !== 'undefined'\r\n        && typeof ImageData !== 'undefined'\r\n        && typeof CanvasRenderingContext2D !== 'undefined';\r\n}\r\n//# sourceMappingURL=isBrowser.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/env/isBrowser.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/env/isNodejs.js":
/*!****************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/env/isNodejs.js ***!
  \****************************************************************************/
/*! exports provided: isNodejs */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* WEBPACK VAR INJECTION */(function(global, process) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isNodejs\", function() { return isNodejs; });\nfunction isNodejs() {\r\n    return typeof global === 'object'\r\n        && \"function\" === 'function'\r\n        && typeof module !== 'undefined'\r\n        // issues with gatsby.js: module.exports is undefined\r\n        // && !!module.exports\r\n        && typeof process !== 'undefined' && !!process.version;\r\n}\r\n//# sourceMappingURL=isNodejs.js.map\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\"), __webpack_require__(/*! ./../../../../process/browser.js */ \"./node_modules/process/browser.js\")))\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/env/isNodejs.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/index.js":
/*!*********************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/index.js ***!
  \*********************************************************************/
/*! exports provided: env, isTensor, isTensor1D, isTensor2D, isTensor3D, isTensor4D, isFloat, isEven, round, isDimensions, computeReshapedDimensions, getCenterPoint, range, isValidNumber, isValidProbablitiy, NeuralNetwork, draw, TfjsImageRecognitionBase, BoundingBox, Box, Dimensions, LabeledBox, ObjectDetection, Point, PredictedBox, Rect, awaitMediaLoaded, bufferToImage, createCanvas, createCanvasFromMedia, fetchImage, fetchJson, fetchNetWeights, fetchOrThrow, getContext2dOrThrow, getMediaDimensions, imageTensorToCanvas, imageToSquare, isMediaElement, isMediaLoaded, loadWeightMap, matchDimensions, NetInput, resolveInput, toNetInput, iou, minBbox, nonMaxSuppression, normalize, padToSquare, shuffleArray, sigmoid, inverseSigmoid */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _draw__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./draw */ \"./node_modules/tfjs-image-recognition-base/build/es6/draw/index.js\");\n/* harmony reexport (module object) */ __webpack_require__.d(__webpack_exports__, \"draw\", function() { return _draw__WEBPACK_IMPORTED_MODULE_0__; });\n/* harmony import */ var _tfjsImageRecognitionBase__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./tfjsImageRecognitionBase */ \"./node_modules/tfjs-image-recognition-base/build/es6/tfjsImageRecognitionBase.js\");\n/* harmony reexport (module object) */ __webpack_require__.d(__webpack_exports__, \"TfjsImageRecognitionBase\", function() { return _tfjsImageRecognitionBase__WEBPACK_IMPORTED_MODULE_1__; });\n/* harmony import */ var _classes_index__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./classes/index */ \"./node_modules/tfjs-image-recognition-base/build/es6/classes/index.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"BoundingBox\", function() { return _classes_index__WEBPACK_IMPORTED_MODULE_2__[\"BoundingBox\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Box\", function() { return _classes_index__WEBPACK_IMPORTED_MODULE_2__[\"Box\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Dimensions\", function() { return _classes_index__WEBPACK_IMPORTED_MODULE_2__[\"Dimensions\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"LabeledBox\", function() { return _classes_index__WEBPACK_IMPORTED_MODULE_2__[\"LabeledBox\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"ObjectDetection\", function() { return _classes_index__WEBPACK_IMPORTED_MODULE_2__[\"ObjectDetection\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Point\", function() { return _classes_index__WEBPACK_IMPORTED_MODULE_2__[\"Point\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"PredictedBox\", function() { return _classes_index__WEBPACK_IMPORTED_MODULE_2__[\"PredictedBox\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"Rect\", function() { return _classes_index__WEBPACK_IMPORTED_MODULE_2__[\"Rect\"]; });\n\n/* harmony import */ var _dom_index__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./dom/index */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/index.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"awaitMediaLoaded\", function() { return _dom_index__WEBPACK_IMPORTED_MODULE_3__[\"awaitMediaLoaded\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"bufferToImage\", function() { return _dom_index__WEBPACK_IMPORTED_MODULE_3__[\"bufferToImage\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"createCanvas\", function() { return _dom_index__WEBPACK_IMPORTED_MODULE_3__[\"createCanvas\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"createCanvasFromMedia\", function() { return _dom_index__WEBPACK_IMPORTED_MODULE_3__[\"createCanvasFromMedia\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"fetchImage\", function() { return _dom_index__WEBPACK_IMPORTED_MODULE_3__[\"fetchImage\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"fetchJson\", function() { return _dom_index__WEBPACK_IMPORTED_MODULE_3__[\"fetchJson\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"fetchNetWeights\", function() { return _dom_index__WEBPACK_IMPORTED_MODULE_3__[\"fetchNetWeights\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"fetchOrThrow\", function() { return _dom_index__WEBPACK_IMPORTED_MODULE_3__[\"fetchOrThrow\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"getContext2dOrThrow\", function() { return _dom_index__WEBPACK_IMPORTED_MODULE_3__[\"getContext2dOrThrow\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"getMediaDimensions\", function() { return _dom_index__WEBPACK_IMPORTED_MODULE_3__[\"getMediaDimensions\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"imageTensorToCanvas\", function() { return _dom_index__WEBPACK_IMPORTED_MODULE_3__[\"imageTensorToCanvas\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"imageToSquare\", function() { return _dom_index__WEBPACK_IMPORTED_MODULE_3__[\"imageToSquare\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isMediaElement\", function() { return _dom_index__WEBPACK_IMPORTED_MODULE_3__[\"isMediaElement\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isMediaLoaded\", function() { return _dom_index__WEBPACK_IMPORTED_MODULE_3__[\"isMediaLoaded\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadWeightMap\", function() { return _dom_index__WEBPACK_IMPORTED_MODULE_3__[\"loadWeightMap\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"matchDimensions\", function() { return _dom_index__WEBPACK_IMPORTED_MODULE_3__[\"matchDimensions\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"NetInput\", function() { return _dom_index__WEBPACK_IMPORTED_MODULE_3__[\"NetInput\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"resolveInput\", function() { return _dom_index__WEBPACK_IMPORTED_MODULE_3__[\"resolveInput\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"toNetInput\", function() { return _dom_index__WEBPACK_IMPORTED_MODULE_3__[\"toNetInput\"]; });\n\n/* harmony import */ var _env_index__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./env/index */ \"./node_modules/tfjs-image-recognition-base/build/es6/env/index.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"env\", function() { return _env_index__WEBPACK_IMPORTED_MODULE_4__[\"env\"]; });\n\n/* harmony import */ var _ops_index__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ops/index */ \"./node_modules/tfjs-image-recognition-base/build/es6/ops/index.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"iou\", function() { return _ops_index__WEBPACK_IMPORTED_MODULE_5__[\"iou\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"minBbox\", function() { return _ops_index__WEBPACK_IMPORTED_MODULE_5__[\"minBbox\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"nonMaxSuppression\", function() { return _ops_index__WEBPACK_IMPORTED_MODULE_5__[\"nonMaxSuppression\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"normalize\", function() { return _ops_index__WEBPACK_IMPORTED_MODULE_5__[\"normalize\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"padToSquare\", function() { return _ops_index__WEBPACK_IMPORTED_MODULE_5__[\"padToSquare\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"shuffleArray\", function() { return _ops_index__WEBPACK_IMPORTED_MODULE_5__[\"shuffleArray\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"sigmoid\", function() { return _ops_index__WEBPACK_IMPORTED_MODULE_5__[\"sigmoid\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"inverseSigmoid\", function() { return _ops_index__WEBPACK_IMPORTED_MODULE_5__[\"inverseSigmoid\"]; });\n\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./utils */ \"./node_modules/tfjs-image-recognition-base/build/es6/utils/index.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isTensor\", function() { return _utils__WEBPACK_IMPORTED_MODULE_6__[\"isTensor\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isTensor1D\", function() { return _utils__WEBPACK_IMPORTED_MODULE_6__[\"isTensor1D\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isTensor2D\", function() { return _utils__WEBPACK_IMPORTED_MODULE_6__[\"isTensor2D\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isTensor3D\", function() { return _utils__WEBPACK_IMPORTED_MODULE_6__[\"isTensor3D\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isTensor4D\", function() { return _utils__WEBPACK_IMPORTED_MODULE_6__[\"isTensor4D\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isFloat\", function() { return _utils__WEBPACK_IMPORTED_MODULE_6__[\"isFloat\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isEven\", function() { return _utils__WEBPACK_IMPORTED_MODULE_6__[\"isEven\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"round\", function() { return _utils__WEBPACK_IMPORTED_MODULE_6__[\"round\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isDimensions\", function() { return _utils__WEBPACK_IMPORTED_MODULE_6__[\"isDimensions\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"computeReshapedDimensions\", function() { return _utils__WEBPACK_IMPORTED_MODULE_6__[\"computeReshapedDimensions\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"getCenterPoint\", function() { return _utils__WEBPACK_IMPORTED_MODULE_6__[\"getCenterPoint\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"range\", function() { return _utils__WEBPACK_IMPORTED_MODULE_6__[\"range\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isValidNumber\", function() { return _utils__WEBPACK_IMPORTED_MODULE_6__[\"isValidNumber\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"isValidProbablitiy\", function() { return _utils__WEBPACK_IMPORTED_MODULE_6__[\"isValidProbablitiy\"]; });\n\n/* harmony import */ var _NeuralNetwork__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./NeuralNetwork */ \"./node_modules/tfjs-image-recognition-base/build/es6/NeuralNetwork.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"NeuralNetwork\", function() { return _NeuralNetwork__WEBPACK_IMPORTED_MODULE_7__[\"NeuralNetwork\"]; });\n\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n// modules, which are not to be reexported\r\n\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/index.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/ops/index.js":
/*!*************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/ops/index.js ***!
  \*************************************************************************/
/*! exports provided: iou, minBbox, nonMaxSuppression, normalize, padToSquare, shuffleArray, sigmoid, inverseSigmoid */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"sigmoid\", function() { return sigmoid; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"inverseSigmoid\", function() { return inverseSigmoid; });\n/* harmony import */ var _iou__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./iou */ \"./node_modules/tfjs-image-recognition-base/build/es6/ops/iou.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"iou\", function() { return _iou__WEBPACK_IMPORTED_MODULE_0__[\"iou\"]; });\n\n/* harmony import */ var _minBbox__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./minBbox */ \"./node_modules/tfjs-image-recognition-base/build/es6/ops/minBbox.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"minBbox\", function() { return _minBbox__WEBPACK_IMPORTED_MODULE_1__[\"minBbox\"]; });\n\n/* harmony import */ var _nonMaxSuppression__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./nonMaxSuppression */ \"./node_modules/tfjs-image-recognition-base/build/es6/ops/nonMaxSuppression.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"nonMaxSuppression\", function() { return _nonMaxSuppression__WEBPACK_IMPORTED_MODULE_2__[\"nonMaxSuppression\"]; });\n\n/* harmony import */ var _normalize__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./normalize */ \"./node_modules/tfjs-image-recognition-base/build/es6/ops/normalize.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"normalize\", function() { return _normalize__WEBPACK_IMPORTED_MODULE_3__[\"normalize\"]; });\n\n/* harmony import */ var _padToSquare__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./padToSquare */ \"./node_modules/tfjs-image-recognition-base/build/es6/ops/padToSquare.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"padToSquare\", function() { return _padToSquare__WEBPACK_IMPORTED_MODULE_4__[\"padToSquare\"]; });\n\n/* harmony import */ var _shuffleArray__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./shuffleArray */ \"./node_modules/tfjs-image-recognition-base/build/es6/ops/shuffleArray.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"shuffleArray\", function() { return _shuffleArray__WEBPACK_IMPORTED_MODULE_5__[\"shuffleArray\"]; });\n\n\r\n\r\n\r\n\r\n\r\n\r\nfunction sigmoid(x) {\r\n    return 1 / (1 + Math.exp(-x));\r\n}\r\nfunction inverseSigmoid(x) {\r\n    return Math.log(x / (1 - x));\r\n}\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/ops/index.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/ops/iou.js":
/*!***********************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/ops/iou.js ***!
  \***********************************************************************/
/*! exports provided: iou */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"iou\", function() { return iou; });\nfunction iou(box1, box2, isIOU) {\r\n    if (isIOU === void 0) { isIOU = true; }\r\n    var width = Math.max(0.0, Math.min(box1.right, box2.right) - Math.max(box1.left, box2.left));\r\n    var height = Math.max(0.0, Math.min(box1.bottom, box2.bottom) - Math.max(box1.top, box2.top));\r\n    var interSection = width * height;\r\n    return isIOU\r\n        ? interSection / (box1.area + box2.area - interSection)\r\n        : interSection / Math.min(box1.area, box2.area);\r\n}\r\n//# sourceMappingURL=iou.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/ops/iou.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/ops/minBbox.js":
/*!***************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/ops/minBbox.js ***!
  \***************************************************************************/
/*! exports provided: minBbox */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"minBbox\", function() { return minBbox; });\n/* harmony import */ var _classes__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../classes */ \"./node_modules/tfjs-image-recognition-base/build/es6/classes/index.js\");\n\r\nfunction minBbox(pts) {\r\n    var xs = pts.map(function (pt) { return pt.x; });\r\n    var ys = pts.map(function (pt) { return pt.y; });\r\n    var minX = xs.reduce(function (min, x) { return x < min ? x : min; }, Infinity);\r\n    var minY = ys.reduce(function (min, y) { return y < min ? y : min; }, Infinity);\r\n    var maxX = xs.reduce(function (max, x) { return max < x ? x : max; }, 0);\r\n    var maxY = ys.reduce(function (max, y) { return max < y ? y : max; }, 0);\r\n    return new _classes__WEBPACK_IMPORTED_MODULE_0__[\"BoundingBox\"](minX, minY, maxX, maxY);\r\n}\r\n//# sourceMappingURL=minBbox.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/ops/minBbox.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/ops/nonMaxSuppression.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/ops/nonMaxSuppression.js ***!
  \*************************************************************************************/
/*! exports provided: nonMaxSuppression */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"nonMaxSuppression\", function() { return nonMaxSuppression; });\n/* harmony import */ var _iou__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./iou */ \"./node_modules/tfjs-image-recognition-base/build/es6/ops/iou.js\");\n\r\nfunction nonMaxSuppression(boxes, scores, iouThreshold, isIOU) {\r\n    if (isIOU === void 0) { isIOU = true; }\r\n    var indicesSortedByScore = scores\r\n        .map(function (score, boxIndex) { return ({ score: score, boxIndex: boxIndex }); })\r\n        .sort(function (c1, c2) { return c1.score - c2.score; })\r\n        .map(function (c) { return c.boxIndex; });\r\n    var pick = [];\r\n    var _loop_1 = function () {\r\n        var curr = indicesSortedByScore.pop();\r\n        pick.push(curr);\r\n        var indices = indicesSortedByScore;\r\n        var outputs = [];\r\n        for (var i = 0; i < indices.length; i++) {\r\n            var idx = indices[i];\r\n            var currBox = boxes[curr];\r\n            var idxBox = boxes[idx];\r\n            outputs.push(Object(_iou__WEBPACK_IMPORTED_MODULE_0__[\"iou\"])(currBox, idxBox, isIOU));\r\n        }\r\n        indicesSortedByScore = indicesSortedByScore.filter(function (_, j) { return outputs[j] <= iouThreshold; });\r\n    };\r\n    while (indicesSortedByScore.length > 0) {\r\n        _loop_1();\r\n    }\r\n    return pick;\r\n}\r\n//# sourceMappingURL=nonMaxSuppression.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/ops/nonMaxSuppression.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/ops/normalize.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/ops/normalize.js ***!
  \*****************************************************************************/
/*! exports provided: normalize */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"normalize\", function() { return normalize; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n\r\n\r\nfunction normalize(x, meanRgb) {\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tidy\"](function () {\r\n        var r = meanRgb[0], g = meanRgb[1], b = meanRgb[2];\r\n        var avg_r = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"fill\"](Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__spreadArrays\"])(x.shape.slice(0, 3), [1]), r);\r\n        var avg_g = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"fill\"](Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__spreadArrays\"])(x.shape.slice(0, 3), [1]), g);\r\n        var avg_b = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"fill\"](Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__spreadArrays\"])(x.shape.slice(0, 3), [1]), b);\r\n        var avg_rgb = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"concat\"]([avg_r, avg_g, avg_b], 3);\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"sub\"](x, avg_rgb);\r\n    });\r\n}\r\n//# sourceMappingURL=normalize.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/ops/normalize.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/ops/padToSquare.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/ops/padToSquare.js ***!
  \*******************************************************************************/
/*! exports provided: padToSquare */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"padToSquare\", function() { return padToSquare; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n\r\n/**\r\n * Pads the smaller dimension of an image tensor with zeros, such that width === height.\r\n *\r\n * @param imgTensor The image tensor.\r\n * @param isCenterImage (optional, default: false) If true, add an equal amount of padding on\r\n * both sides of the minor dimension oof the image.\r\n * @returns The padded tensor with width === height.\r\n */\r\nfunction padToSquare(imgTensor, isCenterImage) {\r\n    if (isCenterImage === void 0) { isCenterImage = false; }\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () {\r\n        var _a = imgTensor.shape.slice(1), height = _a[0], width = _a[1];\r\n        if (height === width) {\r\n            return imgTensor;\r\n        }\r\n        var dimDiff = Math.abs(height - width);\r\n        var paddingAmount = Math.round(dimDiff * (isCenterImage ? 0.5 : 1));\r\n        var paddingAxis = height > width ? 2 : 1;\r\n        var createPaddingTensor = function (paddingAmount) {\r\n            var paddingTensorShape = imgTensor.shape.slice();\r\n            paddingTensorShape[paddingAxis] = paddingAmount;\r\n            return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"fill\"](paddingTensorShape, 0);\r\n        };\r\n        var paddingTensorAppend = createPaddingTensor(paddingAmount);\r\n        var remainingPaddingAmount = dimDiff - paddingTensorAppend.shape[paddingAxis];\r\n        var paddingTensorPrepend = isCenterImage && remainingPaddingAmount\r\n            ? createPaddingTensor(remainingPaddingAmount)\r\n            : null;\r\n        var tensorsToStack = [\r\n            paddingTensorPrepend,\r\n            imgTensor,\r\n            paddingTensorAppend\r\n        ]\r\n            .filter(function (t) { return !!t; })\r\n            .map(function (t) { return t.toFloat(); });\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"concat\"](tensorsToStack, paddingAxis);\r\n    });\r\n}\r\n//# sourceMappingURL=padToSquare.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/ops/padToSquare.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/ops/shuffleArray.js":
/*!********************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/ops/shuffleArray.js ***!
  \********************************************************************************/
/*! exports provided: shuffleArray */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"shuffleArray\", function() { return shuffleArray; });\nfunction shuffleArray(inputArray) {\r\n    var array = inputArray.slice();\r\n    for (var i = array.length - 1; i > 0; i--) {\r\n        var j = Math.floor(Math.random() * (i + 1));\r\n        var x = array[i];\r\n        array[i] = array[j];\r\n        array[j] = x;\r\n    }\r\n    return array;\r\n}\r\n//# sourceMappingURL=shuffleArray.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/ops/shuffleArray.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/tfjsImageRecognitionBase.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/tfjsImageRecognitionBase.js ***!
  \****************************************************************************************/
/*! exports provided: convLayer, disposeUnusedWeightTensors, extractConvParamsFactory, extractFCParamsFactory, extractSeparableConvParamsFactory, loadSeparableConvParamsFactory, extractWeightEntryFactory, extractWeightsFactory, getModelUris, SeparableConvParams, TinyYolov2, TinyYolov2SizeType, TinyYolov2Options, validateConfig */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _common__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./common */ \"./node_modules/tfjs-image-recognition-base/build/es6/common/index.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"convLayer\", function() { return _common__WEBPACK_IMPORTED_MODULE_0__[\"convLayer\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"disposeUnusedWeightTensors\", function() { return _common__WEBPACK_IMPORTED_MODULE_0__[\"disposeUnusedWeightTensors\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extractConvParamsFactory\", function() { return _common__WEBPACK_IMPORTED_MODULE_0__[\"extractConvParamsFactory\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extractFCParamsFactory\", function() { return _common__WEBPACK_IMPORTED_MODULE_0__[\"extractFCParamsFactory\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extractSeparableConvParamsFactory\", function() { return _common__WEBPACK_IMPORTED_MODULE_0__[\"extractSeparableConvParamsFactory\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"loadSeparableConvParamsFactory\", function() { return _common__WEBPACK_IMPORTED_MODULE_0__[\"loadSeparableConvParamsFactory\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extractWeightEntryFactory\", function() { return _common__WEBPACK_IMPORTED_MODULE_0__[\"extractWeightEntryFactory\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"extractWeightsFactory\", function() { return _common__WEBPACK_IMPORTED_MODULE_0__[\"extractWeightsFactory\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"getModelUris\", function() { return _common__WEBPACK_IMPORTED_MODULE_0__[\"getModelUris\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"SeparableConvParams\", function() { return _common__WEBPACK_IMPORTED_MODULE_0__[\"SeparableConvParams\"]; });\n\n/* harmony import */ var _tinyYolov2_index__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./tinyYolov2/index */ \"./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/index.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TinyYolov2\", function() { return _tinyYolov2_index__WEBPACK_IMPORTED_MODULE_1__[\"TinyYolov2\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TinyYolov2SizeType\", function() { return _tinyYolov2_index__WEBPACK_IMPORTED_MODULE_1__[\"TinyYolov2SizeType\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TinyYolov2Options\", function() { return _tinyYolov2_index__WEBPACK_IMPORTED_MODULE_1__[\"TinyYolov2Options\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"validateConfig\", function() { return _tinyYolov2_index__WEBPACK_IMPORTED_MODULE_1__[\"validateConfig\"]; });\n\n\r\n\r\n//# sourceMappingURL=tfjsImageRecognitionBase.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/tfjsImageRecognitionBase.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/TinyYolov2.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/TinyYolov2.js ***!
  \*************************************************************************************/
/*! exports provided: TinyYolov2 */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TinyYolov2\", function() { return TinyYolov2; });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var _classes_BoundingBox__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../classes/BoundingBox */ \"./node_modules/tfjs-image-recognition-base/build/es6/classes/BoundingBox.js\");\n/* harmony import */ var _classes_ObjectDetection__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../classes/ObjectDetection */ \"./node_modules/tfjs-image-recognition-base/build/es6/classes/ObjectDetection.js\");\n/* harmony import */ var _common__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common */ \"./node_modules/tfjs-image-recognition-base/build/es6/common/index.js\");\n/* harmony import */ var _dom__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../dom */ \"./node_modules/tfjs-image-recognition-base/build/es6/dom/index.js\");\n/* harmony import */ var _NeuralNetwork__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../NeuralNetwork */ \"./node_modules/tfjs-image-recognition-base/build/es6/NeuralNetwork.js\");\n/* harmony import */ var _ops__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../ops */ \"./node_modules/tfjs-image-recognition-base/build/es6/ops/index.js\");\n/* harmony import */ var _ops_nonMaxSuppression__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../ops/nonMaxSuppression */ \"./node_modules/tfjs-image-recognition-base/build/es6/ops/nonMaxSuppression.js\");\n/* harmony import */ var _ops_normalize__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../ops/normalize */ \"./node_modules/tfjs-image-recognition-base/build/es6/ops/normalize.js\");\n/* harmony import */ var _config__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./config */ \"./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/config.js\");\n/* harmony import */ var _convWithBatchNorm__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./convWithBatchNorm */ \"./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/convWithBatchNorm.js\");\n/* harmony import */ var _depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./depthwiseSeparableConv */ \"./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/depthwiseSeparableConv.js\");\n/* harmony import */ var _extractParams__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./extractParams */ \"./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/extractParams.js\");\n/* harmony import */ var _extractParamsFromWeigthMap__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./extractParamsFromWeigthMap */ \"./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/extractParamsFromWeigthMap.js\");\n/* harmony import */ var _leaky__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./leaky */ \"./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/leaky.js\");\n/* harmony import */ var _TinyYolov2Options__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./TinyYolov2Options */ \"./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/TinyYolov2Options.js\");\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nvar TinyYolov2 = /** @class */ (function (_super) {\r\n    Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__extends\"])(TinyYolov2, _super);\r\n    function TinyYolov2(config) {\r\n        var _this = _super.call(this, 'TinyYolov2') || this;\r\n        Object(_config__WEBPACK_IMPORTED_MODULE_10__[\"validateConfig\"])(config);\r\n        _this._config = config;\r\n        return _this;\r\n    }\r\n    Object.defineProperty(TinyYolov2.prototype, \"config\", {\r\n        get: function () {\r\n            return this._config;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(TinyYolov2.prototype, \"withClassScores\", {\r\n        get: function () {\r\n            return this.config.withClassScores || this.config.classes.length > 1;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(TinyYolov2.prototype, \"boxEncodingSize\", {\r\n        get: function () {\r\n            return 5 + (this.withClassScores ? this.config.classes.length : 0);\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    TinyYolov2.prototype.runTinyYolov2 = function (x, params) {\r\n        var out = Object(_convWithBatchNorm__WEBPACK_IMPORTED_MODULE_11__[\"convWithBatchNorm\"])(x, params.conv0);\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"maxPool\"](out, [2, 2], [2, 2], 'same');\r\n        out = Object(_convWithBatchNorm__WEBPACK_IMPORTED_MODULE_11__[\"convWithBatchNorm\"])(out, params.conv1);\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"maxPool\"](out, [2, 2], [2, 2], 'same');\r\n        out = Object(_convWithBatchNorm__WEBPACK_IMPORTED_MODULE_11__[\"convWithBatchNorm\"])(out, params.conv2);\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"maxPool\"](out, [2, 2], [2, 2], 'same');\r\n        out = Object(_convWithBatchNorm__WEBPACK_IMPORTED_MODULE_11__[\"convWithBatchNorm\"])(out, params.conv3);\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"maxPool\"](out, [2, 2], [2, 2], 'same');\r\n        out = Object(_convWithBatchNorm__WEBPACK_IMPORTED_MODULE_11__[\"convWithBatchNorm\"])(out, params.conv4);\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"maxPool\"](out, [2, 2], [2, 2], 'same');\r\n        out = Object(_convWithBatchNorm__WEBPACK_IMPORTED_MODULE_11__[\"convWithBatchNorm\"])(out, params.conv5);\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"maxPool\"](out, [2, 2], [1, 1], 'same');\r\n        out = Object(_convWithBatchNorm__WEBPACK_IMPORTED_MODULE_11__[\"convWithBatchNorm\"])(out, params.conv6);\r\n        out = Object(_convWithBatchNorm__WEBPACK_IMPORTED_MODULE_11__[\"convWithBatchNorm\"])(out, params.conv7);\r\n        return Object(_common__WEBPACK_IMPORTED_MODULE_4__[\"convLayer\"])(out, params.conv8, 'valid', false);\r\n    };\r\n    TinyYolov2.prototype.runMobilenet = function (x, params) {\r\n        var out = this.config.isFirstLayerConv2d\r\n            ? Object(_leaky__WEBPACK_IMPORTED_MODULE_15__[\"leaky\"])(Object(_common__WEBPACK_IMPORTED_MODULE_4__[\"convLayer\"])(x, params.conv0, 'valid', false))\r\n            : Object(_depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_12__[\"depthwiseSeparableConv\"])(x, params.conv0);\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"maxPool\"](out, [2, 2], [2, 2], 'same');\r\n        out = Object(_depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_12__[\"depthwiseSeparableConv\"])(out, params.conv1);\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"maxPool\"](out, [2, 2], [2, 2], 'same');\r\n        out = Object(_depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_12__[\"depthwiseSeparableConv\"])(out, params.conv2);\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"maxPool\"](out, [2, 2], [2, 2], 'same');\r\n        out = Object(_depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_12__[\"depthwiseSeparableConv\"])(out, params.conv3);\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"maxPool\"](out, [2, 2], [2, 2], 'same');\r\n        out = Object(_depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_12__[\"depthwiseSeparableConv\"])(out, params.conv4);\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"maxPool\"](out, [2, 2], [2, 2], 'same');\r\n        out = Object(_depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_12__[\"depthwiseSeparableConv\"])(out, params.conv5);\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"maxPool\"](out, [2, 2], [1, 1], 'same');\r\n        out = params.conv6 ? Object(_depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_12__[\"depthwiseSeparableConv\"])(out, params.conv6) : out;\r\n        out = params.conv7 ? Object(_depthwiseSeparableConv__WEBPACK_IMPORTED_MODULE_12__[\"depthwiseSeparableConv\"])(out, params.conv7) : out;\r\n        return Object(_common__WEBPACK_IMPORTED_MODULE_4__[\"convLayer\"])(out, params.conv8, 'valid', false);\r\n    };\r\n    TinyYolov2.prototype.forwardInput = function (input, inputSize) {\r\n        var _this = this;\r\n        var params = this.params;\r\n        if (!params) {\r\n            throw new Error('TinyYolov2 - load model before inference');\r\n        }\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tidy\"](function () {\r\n            var batchTensor = input.toBatchTensor(inputSize, false).toFloat();\r\n            batchTensor = _this.config.meanRgb\r\n                ? Object(_ops_normalize__WEBPACK_IMPORTED_MODULE_9__[\"normalize\"])(batchTensor, _this.config.meanRgb)\r\n                : batchTensor;\r\n            batchTensor = batchTensor.div(_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"scalar\"](256));\r\n            return _this.config.withSeparableConvs\r\n                ? _this.runMobilenet(batchTensor, params)\r\n                : _this.runTinyYolov2(batchTensor, params);\r\n        });\r\n    };\r\n    TinyYolov2.prototype.forward = function (input, inputSize) {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var _a;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this.forwardInput;\r\n                        return [4 /*yield*/, Object(_dom__WEBPACK_IMPORTED_MODULE_5__[\"toNetInput\"])(input)];\r\n                    case 1: return [4 /*yield*/, _a.apply(this, [_b.sent(), inputSize])];\r\n                    case 2: return [2 /*return*/, _b.sent()];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    TinyYolov2.prototype.detect = function (input, forwardParams) {\r\n        if (forwardParams === void 0) { forwardParams = {}; }\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var _a, inputSize, scoreThreshold, netInput, out, out0, inputDimensions, results, boxes, scores, classScores, classNames, indices, detections;\r\n            var _this = this;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = new _TinyYolov2Options__WEBPACK_IMPORTED_MODULE_16__[\"TinyYolov2Options\"](forwardParams), inputSize = _a.inputSize, scoreThreshold = _a.scoreThreshold;\r\n                        return [4 /*yield*/, Object(_dom__WEBPACK_IMPORTED_MODULE_5__[\"toNetInput\"])(input)];\r\n                    case 1:\r\n                        netInput = _b.sent();\r\n                        return [4 /*yield*/, this.forwardInput(netInput, inputSize)];\r\n                    case 2:\r\n                        out = _b.sent();\r\n                        out0 = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tidy\"](function () { return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"unstack\"](out)[0].expandDims(); });\r\n                        inputDimensions = {\r\n                            width: netInput.getInputWidth(0),\r\n                            height: netInput.getInputHeight(0)\r\n                        };\r\n                        return [4 /*yield*/, this.extractBoxes(out0, netInput.getReshapedInputDimensions(0), scoreThreshold)];\r\n                    case 3:\r\n                        results = _b.sent();\r\n                        out.dispose();\r\n                        out0.dispose();\r\n                        boxes = results.map(function (res) { return res.box; });\r\n                        scores = results.map(function (res) { return res.score; });\r\n                        classScores = results.map(function (res) { return res.classScore; });\r\n                        classNames = results.map(function (res) { return _this.config.classes[res.label]; });\r\n                        indices = Object(_ops_nonMaxSuppression__WEBPACK_IMPORTED_MODULE_8__[\"nonMaxSuppression\"])(boxes.map(function (box) { return box.rescale(inputSize); }), scores, this.config.iouThreshold, true);\r\n                        detections = indices.map(function (idx) {\r\n                            return new _classes_ObjectDetection__WEBPACK_IMPORTED_MODULE_3__[\"ObjectDetection\"](scores[idx], classScores[idx], classNames[idx], boxes[idx], inputDimensions);\r\n                        });\r\n                        return [2 /*return*/, detections];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    TinyYolov2.prototype.getDefaultModelName = function () {\r\n        return '';\r\n    };\r\n    TinyYolov2.prototype.extractParamsFromWeigthMap = function (weightMap) {\r\n        return Object(_extractParamsFromWeigthMap__WEBPACK_IMPORTED_MODULE_14__[\"extractParamsFromWeigthMap\"])(weightMap, this.config);\r\n    };\r\n    TinyYolov2.prototype.extractParams = function (weights) {\r\n        var filterSizes = this.config.filterSizes || TinyYolov2.DEFAULT_FILTER_SIZES;\r\n        var numFilters = filterSizes ? filterSizes.length : undefined;\r\n        if (numFilters !== 7 && numFilters !== 8 && numFilters !== 9) {\r\n            throw new Error(\"TinyYolov2 - expected 7 | 8 | 9 convolutional filters, but found \" + numFilters + \" filterSizes in config\");\r\n        }\r\n        return Object(_extractParams__WEBPACK_IMPORTED_MODULE_13__[\"extractParams\"])(weights, this.config, this.boxEncodingSize, filterSizes);\r\n    };\r\n    TinyYolov2.prototype.extractBoxes = function (outputTensor, inputBlobDimensions, scoreThreshold) {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var width, height, inputSize, correctionFactorX, correctionFactorY, numCells, numBoxes, _a, boxesTensor, scoresTensor, classScoresTensor, results, scoresData, boxesData, row, col, anchor, score, ctX, ctY, width_1, height_1, x, y, pos, _b, classScore, label, _c;\r\n            var _this = this;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_d) {\r\n                switch (_d.label) {\r\n                    case 0:\r\n                        width = inputBlobDimensions.width, height = inputBlobDimensions.height;\r\n                        inputSize = Math.max(width, height);\r\n                        correctionFactorX = inputSize / width;\r\n                        correctionFactorY = inputSize / height;\r\n                        numCells = outputTensor.shape[1];\r\n                        numBoxes = this.config.anchors.length;\r\n                        _a = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"tidy\"](function () {\r\n                            var reshaped = outputTensor.reshape([numCells, numCells, numBoxes, _this.boxEncodingSize]);\r\n                            var boxes = reshaped.slice([0, 0, 0, 0], [numCells, numCells, numBoxes, 4]);\r\n                            var scores = reshaped.slice([0, 0, 0, 4], [numCells, numCells, numBoxes, 1]);\r\n                            var classScores = _this.withClassScores\r\n                                ? _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"softmax\"](reshaped.slice([0, 0, 0, 5], [numCells, numCells, numBoxes, _this.config.classes.length]), 3)\r\n                                : _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_1__[\"scalar\"](0);\r\n                            return [boxes, scores, classScores];\r\n                        }), boxesTensor = _a[0], scoresTensor = _a[1], classScoresTensor = _a[2];\r\n                        results = [];\r\n                        return [4 /*yield*/, scoresTensor.array()];\r\n                    case 1:\r\n                        scoresData = _d.sent();\r\n                        return [4 /*yield*/, boxesTensor.array()];\r\n                    case 2:\r\n                        boxesData = _d.sent();\r\n                        row = 0;\r\n                        _d.label = 3;\r\n                    case 3:\r\n                        if (!(row < numCells)) return [3 /*break*/, 12];\r\n                        col = 0;\r\n                        _d.label = 4;\r\n                    case 4:\r\n                        if (!(col < numCells)) return [3 /*break*/, 11];\r\n                        anchor = 0;\r\n                        _d.label = 5;\r\n                    case 5:\r\n                        if (!(anchor < numBoxes)) return [3 /*break*/, 10];\r\n                        score = Object(_ops__WEBPACK_IMPORTED_MODULE_7__[\"sigmoid\"])(scoresData[row][col][anchor][0]);\r\n                        if (!(!scoreThreshold || score > scoreThreshold)) return [3 /*break*/, 9];\r\n                        ctX = ((col + Object(_ops__WEBPACK_IMPORTED_MODULE_7__[\"sigmoid\"])(boxesData[row][col][anchor][0])) / numCells) * correctionFactorX;\r\n                        ctY = ((row + Object(_ops__WEBPACK_IMPORTED_MODULE_7__[\"sigmoid\"])(boxesData[row][col][anchor][1])) / numCells) * correctionFactorY;\r\n                        width_1 = ((Math.exp(boxesData[row][col][anchor][2]) * this.config.anchors[anchor].x) / numCells) * correctionFactorX;\r\n                        height_1 = ((Math.exp(boxesData[row][col][anchor][3]) * this.config.anchors[anchor].y) / numCells) * correctionFactorY;\r\n                        x = (ctX - (width_1 / 2));\r\n                        y = (ctY - (height_1 / 2));\r\n                        pos = { row: row, col: col, anchor: anchor };\r\n                        if (!this.withClassScores) return [3 /*break*/, 7];\r\n                        return [4 /*yield*/, this.extractPredictedClass(classScoresTensor, pos)];\r\n                    case 6:\r\n                        _c = _d.sent();\r\n                        return [3 /*break*/, 8];\r\n                    case 7:\r\n                        _c = { classScore: 1, label: 0 };\r\n                        _d.label = 8;\r\n                    case 8:\r\n                        _b = _c, classScore = _b.classScore, label = _b.label;\r\n                        results.push(Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__assign\"])({ box: new _classes_BoundingBox__WEBPACK_IMPORTED_MODULE_2__[\"BoundingBox\"](x, y, x + width_1, y + height_1), score: score, classScore: score * classScore, label: label }, pos));\r\n                        _d.label = 9;\r\n                    case 9:\r\n                        anchor++;\r\n                        return [3 /*break*/, 5];\r\n                    case 10:\r\n                        col++;\r\n                        return [3 /*break*/, 4];\r\n                    case 11:\r\n                        row++;\r\n                        return [3 /*break*/, 3];\r\n                    case 12:\r\n                        boxesTensor.dispose();\r\n                        scoresTensor.dispose();\r\n                        classScoresTensor.dispose();\r\n                        return [2 /*return*/, results];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    TinyYolov2.prototype.extractPredictedClass = function (classesTensor, pos) {\r\n        return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__awaiter\"])(this, void 0, void 0, function () {\r\n            var row, col, anchor, classesData;\r\n            return Object(tslib__WEBPACK_IMPORTED_MODULE_0__[\"__generator\"])(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0:\r\n                        row = pos.row, col = pos.col, anchor = pos.anchor;\r\n                        return [4 /*yield*/, classesTensor.array()];\r\n                    case 1:\r\n                        classesData = _a.sent();\r\n                        return [2 /*return*/, Array(this.config.classes.length).fill(0)\r\n                                .map(function (_, i) { return classesData[row][col][anchor][i]; })\r\n                                .map(function (classScore, label) { return ({\r\n                                classScore: classScore,\r\n                                label: label\r\n                            }); })\r\n                                .reduce(function (max, curr) { return max.classScore > curr.classScore ? max : curr; })];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    TinyYolov2.DEFAULT_FILTER_SIZES = [\r\n        3, 16, 32, 64, 128, 256, 512, 1024, 1024\r\n    ];\r\n    return TinyYolov2;\r\n}(_NeuralNetwork__WEBPACK_IMPORTED_MODULE_6__[\"NeuralNetwork\"]));\r\n\r\n//# sourceMappingURL=TinyYolov2.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/TinyYolov2.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/TinyYolov2Options.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/TinyYolov2Options.js ***!
  \********************************************************************************************/
/*! exports provided: TinyYolov2SizeType, TinyYolov2Options */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TinyYolov2SizeType\", function() { return TinyYolov2SizeType; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TinyYolov2Options\", function() { return TinyYolov2Options; });\nvar TinyYolov2SizeType;\r\n(function (TinyYolov2SizeType) {\r\n    TinyYolov2SizeType[TinyYolov2SizeType[\"XS\"] = 224] = \"XS\";\r\n    TinyYolov2SizeType[TinyYolov2SizeType[\"SM\"] = 320] = \"SM\";\r\n    TinyYolov2SizeType[TinyYolov2SizeType[\"MD\"] = 416] = \"MD\";\r\n    TinyYolov2SizeType[TinyYolov2SizeType[\"LG\"] = 608] = \"LG\";\r\n})(TinyYolov2SizeType || (TinyYolov2SizeType = {}));\r\nvar TinyYolov2Options = /** @class */ (function () {\r\n    function TinyYolov2Options(_a) {\r\n        var _b = _a === void 0 ? {} : _a, inputSize = _b.inputSize, scoreThreshold = _b.scoreThreshold;\r\n        this._name = 'TinyYolov2Options';\r\n        this._inputSize = inputSize || 416;\r\n        this._scoreThreshold = scoreThreshold || 0.5;\r\n        if (typeof this._inputSize !== 'number' || this._inputSize % 32 !== 0) {\r\n            throw new Error(this._name + \" - expected inputSize to be a number divisible by 32\");\r\n        }\r\n        if (typeof this._scoreThreshold !== 'number' || this._scoreThreshold <= 0 || this._scoreThreshold >= 1) {\r\n            throw new Error(this._name + \" - expected scoreThreshold to be a number between 0 and 1\");\r\n        }\r\n    }\r\n    Object.defineProperty(TinyYolov2Options.prototype, \"inputSize\", {\r\n        get: function () { return this._inputSize; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(TinyYolov2Options.prototype, \"scoreThreshold\", {\r\n        get: function () { return this._scoreThreshold; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    return TinyYolov2Options;\r\n}());\r\n\r\n//# sourceMappingURL=TinyYolov2Options.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/TinyYolov2Options.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/config.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/config.js ***!
  \*********************************************************************************/
/*! exports provided: validateConfig */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"validateConfig\", function() { return validateConfig; });\nvar isNumber = function (arg) { return typeof arg === 'number'; };\r\nfunction validateConfig(config) {\r\n    if (!config) {\r\n        throw new Error(\"invalid config: \" + config);\r\n    }\r\n    if (typeof config.withSeparableConvs !== 'boolean') {\r\n        throw new Error(\"config.withSeparableConvs has to be a boolean, have: \" + config.withSeparableConvs);\r\n    }\r\n    if (!isNumber(config.iouThreshold) || config.iouThreshold < 0 || config.iouThreshold > 1.0) {\r\n        throw new Error(\"config.iouThreshold has to be a number between [0, 1], have: \" + config.iouThreshold);\r\n    }\r\n    if (!Array.isArray(config.classes)\r\n        || !config.classes.length\r\n        || !config.classes.every(function (c) { return typeof c === 'string'; })) {\r\n        throw new Error(\"config.classes has to be an array class names: string[], have: \" + JSON.stringify(config.classes));\r\n    }\r\n    if (!Array.isArray(config.anchors)\r\n        || !config.anchors.length\r\n        || !config.anchors.map(function (a) { return a || {}; }).every(function (a) { return isNumber(a.x) && isNumber(a.y); })) {\r\n        throw new Error(\"config.anchors has to be an array of { x: number, y: number }, have: \" + JSON.stringify(config.anchors));\r\n    }\r\n    if (config.meanRgb && (!Array.isArray(config.meanRgb)\r\n        || config.meanRgb.length !== 3\r\n        || !config.meanRgb.every(isNumber))) {\r\n        throw new Error(\"config.meanRgb has to be an array of shape [number, number, number], have: \" + JSON.stringify(config.meanRgb));\r\n    }\r\n}\r\n//# sourceMappingURL=config.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/config.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/convWithBatchNorm.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/convWithBatchNorm.js ***!
  \********************************************************************************************/
/*! exports provided: convWithBatchNorm */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"convWithBatchNorm\", function() { return convWithBatchNorm; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var _leaky__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./leaky */ \"./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/leaky.js\");\n\r\n\r\nfunction convWithBatchNorm(x, params) {\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () {\r\n        var out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"pad\"](x, [[0, 0], [1, 1], [1, 1], [0, 0]]);\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"conv2d\"](out, params.conv.filters, [1, 1], 'valid');\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"sub\"](out, params.bn.sub);\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"mul\"](out, params.bn.truediv);\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](out, params.conv.bias);\r\n        return Object(_leaky__WEBPACK_IMPORTED_MODULE_1__[\"leaky\"])(out);\r\n    });\r\n}\r\n//# sourceMappingURL=convWithBatchNorm.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/convWithBatchNorm.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/depthwiseSeparableConv.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/depthwiseSeparableConv.js ***!
  \*************************************************************************************************/
/*! exports provided: depthwiseSeparableConv */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"depthwiseSeparableConv\", function() { return depthwiseSeparableConv; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var _leaky__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./leaky */ \"./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/leaky.js\");\n\r\n\r\nfunction depthwiseSeparableConv(x, params) {\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () {\r\n        var out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"pad\"](x, [[0, 0], [1, 1], [1, 1], [0, 0]]);\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"separableConv2d\"](out, params.depthwise_filter, params.pointwise_filter, [1, 1], 'valid');\r\n        out = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](out, params.bias);\r\n        return Object(_leaky__WEBPACK_IMPORTED_MODULE_1__[\"leaky\"])(out);\r\n    });\r\n}\r\n//# sourceMappingURL=depthwiseSeparableConv.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/depthwiseSeparableConv.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/extractParams.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/extractParams.js ***!
  \****************************************************************************************/
/*! exports provided: extractParams */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractParams\", function() { return extractParams; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var _common__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common */ \"./node_modules/tfjs-image-recognition-base/build/es6/common/index.js\");\n/* harmony import */ var _common_extractSeparableConvParamsFactory__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/extractSeparableConvParamsFactory */ \"./node_modules/tfjs-image-recognition-base/build/es6/common/extractSeparableConvParamsFactory.js\");\n/* harmony import */ var _common_extractWeightsFactory__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common/extractWeightsFactory */ \"./node_modules/tfjs-image-recognition-base/build/es6/common/extractWeightsFactory.js\");\n\r\n\r\n\r\n\r\nfunction extractorsFactory(extractWeights, paramMappings) {\r\n    var extractConvParams = Object(_common__WEBPACK_IMPORTED_MODULE_1__[\"extractConvParamsFactory\"])(extractWeights, paramMappings);\r\n    function extractBatchNormParams(size, mappedPrefix) {\r\n        var sub = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tensor1d\"](extractWeights(size));\r\n        var truediv = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tensor1d\"](extractWeights(size));\r\n        paramMappings.push({ paramPath: mappedPrefix + \"/sub\" }, { paramPath: mappedPrefix + \"/truediv\" });\r\n        return { sub: sub, truediv: truediv };\r\n    }\r\n    function extractConvWithBatchNormParams(channelsIn, channelsOut, mappedPrefix) {\r\n        var conv = extractConvParams(channelsIn, channelsOut, 3, mappedPrefix + \"/conv\");\r\n        var bn = extractBatchNormParams(channelsOut, mappedPrefix + \"/bn\");\r\n        return { conv: conv, bn: bn };\r\n    }\r\n    var extractSeparableConvParams = Object(_common_extractSeparableConvParamsFactory__WEBPACK_IMPORTED_MODULE_2__[\"extractSeparableConvParamsFactory\"])(extractWeights, paramMappings);\r\n    return {\r\n        extractConvParams: extractConvParams,\r\n        extractConvWithBatchNormParams: extractConvWithBatchNormParams,\r\n        extractSeparableConvParams: extractSeparableConvParams\r\n    };\r\n}\r\nfunction extractParams(weights, config, boxEncodingSize, filterSizes) {\r\n    var _a = Object(_common_extractWeightsFactory__WEBPACK_IMPORTED_MODULE_3__[\"extractWeightsFactory\"])(weights), extractWeights = _a.extractWeights, getRemainingWeights = _a.getRemainingWeights;\r\n    var paramMappings = [];\r\n    var _b = extractorsFactory(extractWeights, paramMappings), extractConvParams = _b.extractConvParams, extractConvWithBatchNormParams = _b.extractConvWithBatchNormParams, extractSeparableConvParams = _b.extractSeparableConvParams;\r\n    var params;\r\n    if (config.withSeparableConvs) {\r\n        var s0 = filterSizes[0], s1 = filterSizes[1], s2 = filterSizes[2], s3 = filterSizes[3], s4 = filterSizes[4], s5 = filterSizes[5], s6 = filterSizes[6], s7 = filterSizes[7], s8 = filterSizes[8];\r\n        var conv0 = config.isFirstLayerConv2d\r\n            ? extractConvParams(s0, s1, 3, 'conv0')\r\n            : extractSeparableConvParams(s0, s1, 'conv0');\r\n        var conv1 = extractSeparableConvParams(s1, s2, 'conv1');\r\n        var conv2 = extractSeparableConvParams(s2, s3, 'conv2');\r\n        var conv3 = extractSeparableConvParams(s3, s4, 'conv3');\r\n        var conv4 = extractSeparableConvParams(s4, s5, 'conv4');\r\n        var conv5 = extractSeparableConvParams(s5, s6, 'conv5');\r\n        var conv6 = s7 ? extractSeparableConvParams(s6, s7, 'conv6') : undefined;\r\n        var conv7 = s8 ? extractSeparableConvParams(s7, s8, 'conv7') : undefined;\r\n        var conv8 = extractConvParams(s8 || s7 || s6, 5 * boxEncodingSize, 1, 'conv8');\r\n        params = { conv0: conv0, conv1: conv1, conv2: conv2, conv3: conv3, conv4: conv4, conv5: conv5, conv6: conv6, conv7: conv7, conv8: conv8 };\r\n    }\r\n    else {\r\n        var s0 = filterSizes[0], s1 = filterSizes[1], s2 = filterSizes[2], s3 = filterSizes[3], s4 = filterSizes[4], s5 = filterSizes[5], s6 = filterSizes[6], s7 = filterSizes[7], s8 = filterSizes[8];\r\n        var conv0 = extractConvWithBatchNormParams(s0, s1, 'conv0');\r\n        var conv1 = extractConvWithBatchNormParams(s1, s2, 'conv1');\r\n        var conv2 = extractConvWithBatchNormParams(s2, s3, 'conv2');\r\n        var conv3 = extractConvWithBatchNormParams(s3, s4, 'conv3');\r\n        var conv4 = extractConvWithBatchNormParams(s4, s5, 'conv4');\r\n        var conv5 = extractConvWithBatchNormParams(s5, s6, 'conv5');\r\n        var conv6 = extractConvWithBatchNormParams(s6, s7, 'conv6');\r\n        var conv7 = extractConvWithBatchNormParams(s7, s8, 'conv7');\r\n        var conv8 = extractConvParams(s8, 5 * boxEncodingSize, 1, 'conv8');\r\n        params = { conv0: conv0, conv1: conv1, conv2: conv2, conv3: conv3, conv4: conv4, conv5: conv5, conv6: conv6, conv7: conv7, conv8: conv8 };\r\n    }\r\n    if (getRemainingWeights().length !== 0) {\r\n        throw new Error(\"weights remaing after extract: \" + getRemainingWeights().length);\r\n    }\r\n    return { params: params, paramMappings: paramMappings };\r\n}\r\n//# sourceMappingURL=extractParams.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/extractParams.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/extractParamsFromWeigthMap.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/extractParamsFromWeigthMap.js ***!
  \*****************************************************************************************************/
/*! exports provided: extractParamsFromWeigthMap */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractParamsFromWeigthMap\", function() { return extractParamsFromWeigthMap; });\n/* harmony import */ var _common_disposeUnusedWeightTensors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/disposeUnusedWeightTensors */ \"./node_modules/tfjs-image-recognition-base/build/es6/common/disposeUnusedWeightTensors.js\");\n/* harmony import */ var _common_extractSeparableConvParamsFactory__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/extractSeparableConvParamsFactory */ \"./node_modules/tfjs-image-recognition-base/build/es6/common/extractSeparableConvParamsFactory.js\");\n/* harmony import */ var _common_extractWeightEntryFactory__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/extractWeightEntryFactory */ \"./node_modules/tfjs-image-recognition-base/build/es6/common/extractWeightEntryFactory.js\");\n\r\n\r\n\r\nfunction extractorsFactory(weightMap, paramMappings) {\r\n    var extractWeightEntry = Object(_common_extractWeightEntryFactory__WEBPACK_IMPORTED_MODULE_2__[\"extractWeightEntryFactory\"])(weightMap, paramMappings);\r\n    function extractBatchNormParams(prefix) {\r\n        var sub = extractWeightEntry(prefix + \"/sub\", 1);\r\n        var truediv = extractWeightEntry(prefix + \"/truediv\", 1);\r\n        return { sub: sub, truediv: truediv };\r\n    }\r\n    function extractConvParams(prefix) {\r\n        var filters = extractWeightEntry(prefix + \"/filters\", 4);\r\n        var bias = extractWeightEntry(prefix + \"/bias\", 1);\r\n        return { filters: filters, bias: bias };\r\n    }\r\n    function extractConvWithBatchNormParams(prefix) {\r\n        var conv = extractConvParams(prefix + \"/conv\");\r\n        var bn = extractBatchNormParams(prefix + \"/bn\");\r\n        return { conv: conv, bn: bn };\r\n    }\r\n    var extractSeparableConvParams = Object(_common_extractSeparableConvParamsFactory__WEBPACK_IMPORTED_MODULE_1__[\"loadSeparableConvParamsFactory\"])(extractWeightEntry);\r\n    return {\r\n        extractConvParams: extractConvParams,\r\n        extractConvWithBatchNormParams: extractConvWithBatchNormParams,\r\n        extractSeparableConvParams: extractSeparableConvParams\r\n    };\r\n}\r\nfunction extractParamsFromWeigthMap(weightMap, config) {\r\n    var paramMappings = [];\r\n    var _a = extractorsFactory(weightMap, paramMappings), extractConvParams = _a.extractConvParams, extractConvWithBatchNormParams = _a.extractConvWithBatchNormParams, extractSeparableConvParams = _a.extractSeparableConvParams;\r\n    var params;\r\n    if (config.withSeparableConvs) {\r\n        var numFilters = (config.filterSizes && config.filterSizes.length || 9);\r\n        params = {\r\n            conv0: config.isFirstLayerConv2d ? extractConvParams('conv0') : extractSeparableConvParams('conv0'),\r\n            conv1: extractSeparableConvParams('conv1'),\r\n            conv2: extractSeparableConvParams('conv2'),\r\n            conv3: extractSeparableConvParams('conv3'),\r\n            conv4: extractSeparableConvParams('conv4'),\r\n            conv5: extractSeparableConvParams('conv5'),\r\n            conv6: numFilters > 7 ? extractSeparableConvParams('conv6') : undefined,\r\n            conv7: numFilters > 8 ? extractSeparableConvParams('conv7') : undefined,\r\n            conv8: extractConvParams('conv8')\r\n        };\r\n    }\r\n    else {\r\n        params = {\r\n            conv0: extractConvWithBatchNormParams('conv0'),\r\n            conv1: extractConvWithBatchNormParams('conv1'),\r\n            conv2: extractConvWithBatchNormParams('conv2'),\r\n            conv3: extractConvWithBatchNormParams('conv3'),\r\n            conv4: extractConvWithBatchNormParams('conv4'),\r\n            conv5: extractConvWithBatchNormParams('conv5'),\r\n            conv6: extractConvWithBatchNormParams('conv6'),\r\n            conv7: extractConvWithBatchNormParams('conv7'),\r\n            conv8: extractConvParams('conv8')\r\n        };\r\n    }\r\n    Object(_common_disposeUnusedWeightTensors__WEBPACK_IMPORTED_MODULE_0__[\"disposeUnusedWeightTensors\"])(weightMap, paramMappings);\r\n    return { params: params, paramMappings: paramMappings };\r\n}\r\n//# sourceMappingURL=extractParamsFromWeigthMap.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/extractParamsFromWeigthMap.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/index.js":
/*!********************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/index.js ***!
  \********************************************************************************/
/*! exports provided: TinyYolov2, TinyYolov2SizeType, TinyYolov2Options, validateConfig */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _TinyYolov2__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./TinyYolov2 */ \"./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/TinyYolov2.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TinyYolov2\", function() { return _TinyYolov2__WEBPACK_IMPORTED_MODULE_0__[\"TinyYolov2\"]; });\n\n/* harmony import */ var _TinyYolov2Options__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./TinyYolov2Options */ \"./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/TinyYolov2Options.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TinyYolov2SizeType\", function() { return _TinyYolov2Options__WEBPACK_IMPORTED_MODULE_1__[\"TinyYolov2SizeType\"]; });\n\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"TinyYolov2Options\", function() { return _TinyYolov2Options__WEBPACK_IMPORTED_MODULE_1__[\"TinyYolov2Options\"]; });\n\n/* harmony import */ var _config__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./config */ \"./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/config.js\");\n/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, \"validateConfig\", function() { return _config__WEBPACK_IMPORTED_MODULE_2__[\"validateConfig\"]; });\n\n\r\n\r\n\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/index.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/leaky.js":
/*!********************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/leaky.js ***!
  \********************************************************************************/
/*! exports provided: leaky */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"leaky\", function() { return leaky; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n\r\nfunction leaky(x) {\r\n    return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"tidy\"](function () {\r\n        var min = _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"mul\"](x, _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"scalar\"](0.10000000149011612));\r\n        return _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"add\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"relu\"](_tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"sub\"](x, min)), min);\r\n        //return tf.maximum(x, min)\r\n    });\r\n}\r\n//# sourceMappingURL=leaky.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/tinyYolov2/leaky.js?");

/***/ }),

/***/ "./node_modules/tfjs-image-recognition-base/build/es6/utils/index.js":
/*!***************************************************************************!*\
  !*** ./node_modules/tfjs-image-recognition-base/build/es6/utils/index.js ***!
  \***************************************************************************/
/*! exports provided: isTensor, isTensor1D, isTensor2D, isTensor3D, isTensor4D, isFloat, isEven, round, isDimensions, computeReshapedDimensions, getCenterPoint, range, isValidNumber, isValidProbablitiy */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isTensor\", function() { return isTensor; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isTensor1D\", function() { return isTensor1D; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isTensor2D\", function() { return isTensor2D; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isTensor3D\", function() { return isTensor3D; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isTensor4D\", function() { return isTensor4D; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isFloat\", function() { return isFloat; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isEven\", function() { return isEven; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"round\", function() { return round; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isDimensions\", function() { return isDimensions; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"computeReshapedDimensions\", function() { return computeReshapedDimensions; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getCenterPoint\", function() { return getCenterPoint; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"range\", function() { return range; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isValidNumber\", function() { return isValidNumber; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isValidProbablitiy\", function() { return isValidProbablitiy; });\n/* harmony import */ var _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js\");\n/* harmony import */ var _classes_Dimensions__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../classes/Dimensions */ \"./node_modules/tfjs-image-recognition-base/build/es6/classes/Dimensions.js\");\n/* harmony import */ var _classes_Point__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../classes/Point */ \"./node_modules/tfjs-image-recognition-base/build/es6/classes/Point.js\");\n\r\n\r\n\r\nfunction isTensor(tensor, dim) {\r\n    return tensor instanceof _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__[\"Tensor\"] && tensor.shape.length === dim;\r\n}\r\nfunction isTensor1D(tensor) {\r\n    return isTensor(tensor, 1);\r\n}\r\nfunction isTensor2D(tensor) {\r\n    return isTensor(tensor, 2);\r\n}\r\nfunction isTensor3D(tensor) {\r\n    return isTensor(tensor, 3);\r\n}\r\nfunction isTensor4D(tensor) {\r\n    return isTensor(tensor, 4);\r\n}\r\nfunction isFloat(num) {\r\n    return num % 1 !== 0;\r\n}\r\nfunction isEven(num) {\r\n    return num % 2 === 0;\r\n}\r\nfunction round(num, prec) {\r\n    if (prec === void 0) { prec = 2; }\r\n    var f = Math.pow(10, prec);\r\n    return Math.floor(num * f) / f;\r\n}\r\nfunction isDimensions(obj) {\r\n    return obj && obj.width && obj.height;\r\n}\r\nfunction computeReshapedDimensions(_a, inputSize) {\r\n    var width = _a.width, height = _a.height;\r\n    var scale = inputSize / Math.max(height, width);\r\n    return new _classes_Dimensions__WEBPACK_IMPORTED_MODULE_1__[\"Dimensions\"](Math.round(width * scale), Math.round(height * scale));\r\n}\r\nfunction getCenterPoint(pts) {\r\n    return pts.reduce(function (sum, pt) { return sum.add(pt); }, new _classes_Point__WEBPACK_IMPORTED_MODULE_2__[\"Point\"](0, 0))\r\n        .div(new _classes_Point__WEBPACK_IMPORTED_MODULE_2__[\"Point\"](pts.length, pts.length));\r\n}\r\nfunction range(num, start, step) {\r\n    return Array(num).fill(0).map(function (_, i) { return start + (i * step); });\r\n}\r\nfunction isValidNumber(num) {\r\n    return !!num && num !== Infinity && num !== -Infinity && !isNaN(num) || num === 0;\r\n}\r\nfunction isValidProbablitiy(num) {\r\n    return isValidNumber(num) && 0 <= num && num <= 1.0;\r\n}\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/tfjs-image-recognition-base/build/es6/utils/index.js?");

/***/ }),

/***/ "./node_modules/timers-browserify/main.js":
/*!************************************************!*\
  !*** ./node_modules/timers-browserify/main.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(global) {var scope = (typeof global !== \"undefined\" && global) ||\n            (typeof self !== \"undefined\" && self) ||\n            window;\nvar apply = Function.prototype.apply;\n\n// DOM APIs, for completeness\n\nexports.setTimeout = function() {\n  return new Timeout(apply.call(setTimeout, scope, arguments), clearTimeout);\n};\nexports.setInterval = function() {\n  return new Timeout(apply.call(setInterval, scope, arguments), clearInterval);\n};\nexports.clearTimeout =\nexports.clearInterval = function(timeout) {\n  if (timeout) {\n    timeout.close();\n  }\n};\n\nfunction Timeout(id, clearFn) {\n  this._id = id;\n  this._clearFn = clearFn;\n}\nTimeout.prototype.unref = Timeout.prototype.ref = function() {};\nTimeout.prototype.close = function() {\n  this._clearFn.call(scope, this._id);\n};\n\n// Does not start the time, just sets up the members needed.\nexports.enroll = function(item, msecs) {\n  clearTimeout(item._idleTimeoutId);\n  item._idleTimeout = msecs;\n};\n\nexports.unenroll = function(item) {\n  clearTimeout(item._idleTimeoutId);\n  item._idleTimeout = -1;\n};\n\nexports._unrefActive = exports.active = function(item) {\n  clearTimeout(item._idleTimeoutId);\n\n  var msecs = item._idleTimeout;\n  if (msecs >= 0) {\n    item._idleTimeoutId = setTimeout(function onTimeout() {\n      if (item._onTimeout)\n        item._onTimeout();\n    }, msecs);\n  }\n};\n\n// setimmediate attaches itself to the global object\n__webpack_require__(/*! setimmediate */ \"./node_modules/setimmediate/setImmediate.js\");\n// On some exotic environments, it's not clear which object `setimmediate` was\n// able to install onto.  Search each possibility in the same order as the\n// `setimmediate` library.\nexports.setImmediate = (typeof self !== \"undefined\" && self.setImmediate) ||\n                       (typeof global !== \"undefined\" && global.setImmediate) ||\n                       (this && this.setImmediate);\nexports.clearImmediate = (typeof self !== \"undefined\" && self.clearImmediate) ||\n                         (typeof global !== \"undefined\" && global.clearImmediate) ||\n                         (this && this.clearImmediate);\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\")))\n\n//# sourceURL=webpack:///./node_modules/timers-browserify/main.js?");

/***/ }),

/***/ "./node_modules/tslib/tslib.es6.js":
/*!*****************************************!*\
  !*** ./node_modules/tslib/tslib.es6.js ***!
  \*****************************************/
/*! exports provided: __extends, __assign, __rest, __decorate, __param, __metadata, __awaiter, __generator, __exportStar, __values, __read, __spread, __spreadArrays, __await, __asyncGenerator, __asyncDelegator, __asyncValues, __makeTemplateObject, __importStar, __importDefault */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"__extends\", function() { return __extends; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"__assign\", function() { return __assign; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"__rest\", function() { return __rest; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"__decorate\", function() { return __decorate; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"__param\", function() { return __param; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"__metadata\", function() { return __metadata; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"__awaiter\", function() { return __awaiter; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"__generator\", function() { return __generator; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"__exportStar\", function() { return __exportStar; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"__values\", function() { return __values; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"__read\", function() { return __read; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"__spread\", function() { return __spread; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"__spreadArrays\", function() { return __spreadArrays; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"__await\", function() { return __await; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"__asyncGenerator\", function() { return __asyncGenerator; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"__asyncDelegator\", function() { return __asyncDelegator; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"__asyncValues\", function() { return __asyncValues; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"__makeTemplateObject\", function() { return __makeTemplateObject; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"__importStar\", function() { return __importStar; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"__importDefault\", function() { return __importDefault; });\n/*! *****************************************************************************\r\nCopyright (c) Microsoft Corporation. All rights reserved.\r\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use\r\nthis file except in compliance with the License. You may obtain a copy of the\r\nLicense at http://www.apache.org/licenses/LICENSE-2.0\r\n\r\nTHIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\r\nKIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED\r\nWARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,\r\nMERCHANTABLITY OR NON-INFRINGEMENT.\r\n\r\nSee the Apache Version 2.0 License for specific language governing permissions\r\nand limitations under the License.\r\n***************************************************************************** */\r\n/* global Reflect, Promise */\r\n\r\nvar extendStatics = function(d, b) {\r\n    extendStatics = Object.setPrototypeOf ||\r\n        ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\r\n        function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\r\n    return extendStatics(d, b);\r\n};\r\n\r\nfunction __extends(d, b) {\r\n    extendStatics(d, b);\r\n    function __() { this.constructor = d; }\r\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\r\n}\r\n\r\nvar __assign = function() {\r\n    __assign = Object.assign || function __assign(t) {\r\n        for (var s, i = 1, n = arguments.length; i < n; i++) {\r\n            s = arguments[i];\r\n            for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];\r\n        }\r\n        return t;\r\n    }\r\n    return __assign.apply(this, arguments);\r\n}\r\n\r\nfunction __rest(s, e) {\r\n    var t = {};\r\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\r\n        t[p] = s[p];\r\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\r\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\r\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\r\n                t[p[i]] = s[p[i]];\r\n        }\r\n    return t;\r\n}\r\n\r\nfunction __decorate(decorators, target, key, desc) {\r\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\r\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\r\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\r\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\r\n}\r\n\r\nfunction __param(paramIndex, decorator) {\r\n    return function (target, key) { decorator(target, key, paramIndex); }\r\n}\r\n\r\nfunction __metadata(metadataKey, metadataValue) {\r\n    if (typeof Reflect === \"object\" && typeof Reflect.metadata === \"function\") return Reflect.metadata(metadataKey, metadataValue);\r\n}\r\n\r\nfunction __awaiter(thisArg, _arguments, P, generator) {\r\n    return new (P || (P = Promise))(function (resolve, reject) {\r\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\r\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\r\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\r\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\r\n    });\r\n}\r\n\r\nfunction __generator(thisArg, body) {\r\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\r\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\r\n    function verb(n) { return function (v) { return step([n, v]); }; }\r\n    function step(op) {\r\n        if (f) throw new TypeError(\"Generator is already executing.\");\r\n        while (_) try {\r\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\r\n            if (y = 0, t) op = [op[0] & 2, t.value];\r\n            switch (op[0]) {\r\n                case 0: case 1: t = op; break;\r\n                case 4: _.label++; return { value: op[1], done: false };\r\n                case 5: _.label++; y = op[1]; op = [0]; continue;\r\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\r\n                default:\r\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\r\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\r\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\r\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\r\n                    if (t[2]) _.ops.pop();\r\n                    _.trys.pop(); continue;\r\n            }\r\n            op = body.call(thisArg, _);\r\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\r\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\r\n    }\r\n}\r\n\r\nfunction __exportStar(m, exports) {\r\n    for (var p in m) if (!exports.hasOwnProperty(p)) exports[p] = m[p];\r\n}\r\n\r\nfunction __values(o) {\r\n    var m = typeof Symbol === \"function\" && o[Symbol.iterator], i = 0;\r\n    if (m) return m.call(o);\r\n    return {\r\n        next: function () {\r\n            if (o && i >= o.length) o = void 0;\r\n            return { value: o && o[i++], done: !o };\r\n        }\r\n    };\r\n}\r\n\r\nfunction __read(o, n) {\r\n    var m = typeof Symbol === \"function\" && o[Symbol.iterator];\r\n    if (!m) return o;\r\n    var i = m.call(o), r, ar = [], e;\r\n    try {\r\n        while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);\r\n    }\r\n    catch (error) { e = { error: error }; }\r\n    finally {\r\n        try {\r\n            if (r && !r.done && (m = i[\"return\"])) m.call(i);\r\n        }\r\n        finally { if (e) throw e.error; }\r\n    }\r\n    return ar;\r\n}\r\n\r\nfunction __spread() {\r\n    for (var ar = [], i = 0; i < arguments.length; i++)\r\n        ar = ar.concat(__read(arguments[i]));\r\n    return ar;\r\n}\r\n\r\nfunction __spreadArrays() {\r\n    for (var s = 0, i = 0, il = arguments.length; i < il; i++) s += arguments[i].length;\r\n    for (var r = Array(s), k = 0, i = 0; i < il; i++)\r\n        for (var a = arguments[i], j = 0, jl = a.length; j < jl; j++, k++)\r\n            r[k] = a[j];\r\n    return r;\r\n};\r\n\r\nfunction __await(v) {\r\n    return this instanceof __await ? (this.v = v, this) : new __await(v);\r\n}\r\n\r\nfunction __asyncGenerator(thisArg, _arguments, generator) {\r\n    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\r\n    var g = generator.apply(thisArg, _arguments || []), i, q = [];\r\n    return i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i;\r\n    function verb(n) { if (g[n]) i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; }\r\n    function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }\r\n    function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r); }\r\n    function fulfill(value) { resume(\"next\", value); }\r\n    function reject(value) { resume(\"throw\", value); }\r\n    function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }\r\n}\r\n\r\nfunction __asyncDelegator(o) {\r\n    var i, p;\r\n    return i = {}, verb(\"next\"), verb(\"throw\", function (e) { throw e; }), verb(\"return\"), i[Symbol.iterator] = function () { return this; }, i;\r\n    function verb(n, f) { i[n] = o[n] ? function (v) { return (p = !p) ? { value: __await(o[n](v)), done: n === \"return\" } : f ? f(v) : v; } : f; }\r\n}\r\n\r\nfunction __asyncValues(o) {\r\n    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\r\n    var m = o[Symbol.asyncIterator], i;\r\n    return m ? m.call(o) : (o = typeof __values === \"function\" ? __values(o) : o[Symbol.iterator](), i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i);\r\n    function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }\r\n    function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }\r\n}\r\n\r\nfunction __makeTemplateObject(cooked, raw) {\r\n    if (Object.defineProperty) { Object.defineProperty(cooked, \"raw\", { value: raw }); } else { cooked.raw = raw; }\r\n    return cooked;\r\n};\r\n\r\nfunction __importStar(mod) {\r\n    if (mod && mod.__esModule) return mod;\r\n    var result = {};\r\n    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];\r\n    result.default = mod;\r\n    return result;\r\n}\r\n\r\nfunction __importDefault(mod) {\r\n    return (mod && mod.__esModule) ? mod : { default: mod };\r\n}\r\n\n\n//# sourceURL=webpack:///./node_modules/tslib/tslib.es6.js?");

/***/ }),

/***/ "./node_modules/underscore/underscore.js":
/*!***********************************************!*\
  !*** ./node_modules/underscore/underscore.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(global, module) {var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;//     Underscore.js 1.9.1\n//     http://underscorejs.org\n//     (c) 2009-2018 Jeremy Ashkenas, DocumentCloud and Investigative Reporters & Editors\n//     Underscore may be freely distributed under the MIT license.\n\n(function() {\n\n  // Baseline setup\n  // --------------\n\n  // Establish the root object, `window` (`self`) in the browser, `global`\n  // on the server, or `this` in some virtual machines. We use `self`\n  // instead of `window` for `WebWorker` support.\n  var root = typeof self == 'object' && self.self === self && self ||\n            typeof global == 'object' && global.global === global && global ||\n            this ||\n            {};\n\n  // Save the previous value of the `_` variable.\n  var previousUnderscore = root._;\n\n  // Save bytes in the minified (but not gzipped) version:\n  var ArrayProto = Array.prototype, ObjProto = Object.prototype;\n  var SymbolProto = typeof Symbol !== 'undefined' ? Symbol.prototype : null;\n\n  // Create quick reference variables for speed access to core prototypes.\n  var push = ArrayProto.push,\n      slice = ArrayProto.slice,\n      toString = ObjProto.toString,\n      hasOwnProperty = ObjProto.hasOwnProperty;\n\n  // All **ECMAScript 5** native function implementations that we hope to use\n  // are declared here.\n  var nativeIsArray = Array.isArray,\n      nativeKeys = Object.keys,\n      nativeCreate = Object.create;\n\n  // Naked function reference for surrogate-prototype-swapping.\n  var Ctor = function(){};\n\n  // Create a safe reference to the Underscore object for use below.\n  var _ = function(obj) {\n    if (obj instanceof _) return obj;\n    if (!(this instanceof _)) return new _(obj);\n    this._wrapped = obj;\n  };\n\n  // Export the Underscore object for **Node.js**, with\n  // backwards-compatibility for their old module API. If we're in\n  // the browser, add `_` as a global object.\n  // (`nodeType` is checked to ensure that `module`\n  // and `exports` are not HTML elements.)\n  if ( true && !exports.nodeType) {\n    if ( true && !module.nodeType && module.exports) {\n      exports = module.exports = _;\n    }\n    exports._ = _;\n  } else {\n    root._ = _;\n  }\n\n  // Current version.\n  _.VERSION = '1.9.1';\n\n  // Internal function that returns an efficient (for current engines) version\n  // of the passed-in callback, to be repeatedly applied in other Underscore\n  // functions.\n  var optimizeCb = function(func, context, argCount) {\n    if (context === void 0) return func;\n    switch (argCount == null ? 3 : argCount) {\n      case 1: return function(value) {\n        return func.call(context, value);\n      };\n      // The 2-argument case is omitted because we’re not using it.\n      case 3: return function(value, index, collection) {\n        return func.call(context, value, index, collection);\n      };\n      case 4: return function(accumulator, value, index, collection) {\n        return func.call(context, accumulator, value, index, collection);\n      };\n    }\n    return function() {\n      return func.apply(context, arguments);\n    };\n  };\n\n  var builtinIteratee;\n\n  // An internal function to generate callbacks that can be applied to each\n  // element in a collection, returning the desired result — either `identity`,\n  // an arbitrary callback, a property matcher, or a property accessor.\n  var cb = function(value, context, argCount) {\n    if (_.iteratee !== builtinIteratee) return _.iteratee(value, context);\n    if (value == null) return _.identity;\n    if (_.isFunction(value)) return optimizeCb(value, context, argCount);\n    if (_.isObject(value) && !_.isArray(value)) return _.matcher(value);\n    return _.property(value);\n  };\n\n  // External wrapper for our callback generator. Users may customize\n  // `_.iteratee` if they want additional predicate/iteratee shorthand styles.\n  // This abstraction hides the internal-only argCount argument.\n  _.iteratee = builtinIteratee = function(value, context) {\n    return cb(value, context, Infinity);\n  };\n\n  // Some functions take a variable number of arguments, or a few expected\n  // arguments at the beginning and then a variable number of values to operate\n  // on. This helper accumulates all remaining arguments past the function’s\n  // argument length (or an explicit `startIndex`), into an array that becomes\n  // the last argument. Similar to ES6’s \"rest parameter\".\n  var restArguments = function(func, startIndex) {\n    startIndex = startIndex == null ? func.length - 1 : +startIndex;\n    return function() {\n      var length = Math.max(arguments.length - startIndex, 0),\n          rest = Array(length),\n          index = 0;\n      for (; index < length; index++) {\n        rest[index] = arguments[index + startIndex];\n      }\n      switch (startIndex) {\n        case 0: return func.call(this, rest);\n        case 1: return func.call(this, arguments[0], rest);\n        case 2: return func.call(this, arguments[0], arguments[1], rest);\n      }\n      var args = Array(startIndex + 1);\n      for (index = 0; index < startIndex; index++) {\n        args[index] = arguments[index];\n      }\n      args[startIndex] = rest;\n      return func.apply(this, args);\n    };\n  };\n\n  // An internal function for creating a new object that inherits from another.\n  var baseCreate = function(prototype) {\n    if (!_.isObject(prototype)) return {};\n    if (nativeCreate) return nativeCreate(prototype);\n    Ctor.prototype = prototype;\n    var result = new Ctor;\n    Ctor.prototype = null;\n    return result;\n  };\n\n  var shallowProperty = function(key) {\n    return function(obj) {\n      return obj == null ? void 0 : obj[key];\n    };\n  };\n\n  var has = function(obj, path) {\n    return obj != null && hasOwnProperty.call(obj, path);\n  }\n\n  var deepGet = function(obj, path) {\n    var length = path.length;\n    for (var i = 0; i < length; i++) {\n      if (obj == null) return void 0;\n      obj = obj[path[i]];\n    }\n    return length ? obj : void 0;\n  };\n\n  // Helper for collection methods to determine whether a collection\n  // should be iterated as an array or as an object.\n  // Related: http://people.mozilla.org/~jorendorff/es6-draft.html#sec-tolength\n  // Avoids a very nasty iOS 8 JIT bug on ARM-64. #2094\n  var MAX_ARRAY_INDEX = Math.pow(2, 53) - 1;\n  var getLength = shallowProperty('length');\n  var isArrayLike = function(collection) {\n    var length = getLength(collection);\n    return typeof length == 'number' && length >= 0 && length <= MAX_ARRAY_INDEX;\n  };\n\n  // Collection Functions\n  // --------------------\n\n  // The cornerstone, an `each` implementation, aka `forEach`.\n  // Handles raw objects in addition to array-likes. Treats all\n  // sparse array-likes as if they were dense.\n  _.each = _.forEach = function(obj, iteratee, context) {\n    iteratee = optimizeCb(iteratee, context);\n    var i, length;\n    if (isArrayLike(obj)) {\n      for (i = 0, length = obj.length; i < length; i++) {\n        iteratee(obj[i], i, obj);\n      }\n    } else {\n      var keys = _.keys(obj);\n      for (i = 0, length = keys.length; i < length; i++) {\n        iteratee(obj[keys[i]], keys[i], obj);\n      }\n    }\n    return obj;\n  };\n\n  // Return the results of applying the iteratee to each element.\n  _.map = _.collect = function(obj, iteratee, context) {\n    iteratee = cb(iteratee, context);\n    var keys = !isArrayLike(obj) && _.keys(obj),\n        length = (keys || obj).length,\n        results = Array(length);\n    for (var index = 0; index < length; index++) {\n      var currentKey = keys ? keys[index] : index;\n      results[index] = iteratee(obj[currentKey], currentKey, obj);\n    }\n    return results;\n  };\n\n  // Create a reducing function iterating left or right.\n  var createReduce = function(dir) {\n    // Wrap code that reassigns argument variables in a separate function than\n    // the one that accesses `arguments.length` to avoid a perf hit. (#1991)\n    var reducer = function(obj, iteratee, memo, initial) {\n      var keys = !isArrayLike(obj) && _.keys(obj),\n          length = (keys || obj).length,\n          index = dir > 0 ? 0 : length - 1;\n      if (!initial) {\n        memo = obj[keys ? keys[index] : index];\n        index += dir;\n      }\n      for (; index >= 0 && index < length; index += dir) {\n        var currentKey = keys ? keys[index] : index;\n        memo = iteratee(memo, obj[currentKey], currentKey, obj);\n      }\n      return memo;\n    };\n\n    return function(obj, iteratee, memo, context) {\n      var initial = arguments.length >= 3;\n      return reducer(obj, optimizeCb(iteratee, context, 4), memo, initial);\n    };\n  };\n\n  // **Reduce** builds up a single result from a list of values, aka `inject`,\n  // or `foldl`.\n  _.reduce = _.foldl = _.inject = createReduce(1);\n\n  // The right-associative version of reduce, also known as `foldr`.\n  _.reduceRight = _.foldr = createReduce(-1);\n\n  // Return the first value which passes a truth test. Aliased as `detect`.\n  _.find = _.detect = function(obj, predicate, context) {\n    var keyFinder = isArrayLike(obj) ? _.findIndex : _.findKey;\n    var key = keyFinder(obj, predicate, context);\n    if (key !== void 0 && key !== -1) return obj[key];\n  };\n\n  // Return all the elements that pass a truth test.\n  // Aliased as `select`.\n  _.filter = _.select = function(obj, predicate, context) {\n    var results = [];\n    predicate = cb(predicate, context);\n    _.each(obj, function(value, index, list) {\n      if (predicate(value, index, list)) results.push(value);\n    });\n    return results;\n  };\n\n  // Return all the elements for which a truth test fails.\n  _.reject = function(obj, predicate, context) {\n    return _.filter(obj, _.negate(cb(predicate)), context);\n  };\n\n  // Determine whether all of the elements match a truth test.\n  // Aliased as `all`.\n  _.every = _.all = function(obj, predicate, context) {\n    predicate = cb(predicate, context);\n    var keys = !isArrayLike(obj) && _.keys(obj),\n        length = (keys || obj).length;\n    for (var index = 0; index < length; index++) {\n      var currentKey = keys ? keys[index] : index;\n      if (!predicate(obj[currentKey], currentKey, obj)) return false;\n    }\n    return true;\n  };\n\n  // Determine if at least one element in the object matches a truth test.\n  // Aliased as `any`.\n  _.some = _.any = function(obj, predicate, context) {\n    predicate = cb(predicate, context);\n    var keys = !isArrayLike(obj) && _.keys(obj),\n        length = (keys || obj).length;\n    for (var index = 0; index < length; index++) {\n      var currentKey = keys ? keys[index] : index;\n      if (predicate(obj[currentKey], currentKey, obj)) return true;\n    }\n    return false;\n  };\n\n  // Determine if the array or object contains a given item (using `===`).\n  // Aliased as `includes` and `include`.\n  _.contains = _.includes = _.include = function(obj, item, fromIndex, guard) {\n    if (!isArrayLike(obj)) obj = _.values(obj);\n    if (typeof fromIndex != 'number' || guard) fromIndex = 0;\n    return _.indexOf(obj, item, fromIndex) >= 0;\n  };\n\n  // Invoke a method (with arguments) on every item in a collection.\n  _.invoke = restArguments(function(obj, path, args) {\n    var contextPath, func;\n    if (_.isFunction(path)) {\n      func = path;\n    } else if (_.isArray(path)) {\n      contextPath = path.slice(0, -1);\n      path = path[path.length - 1];\n    }\n    return _.map(obj, function(context) {\n      var method = func;\n      if (!method) {\n        if (contextPath && contextPath.length) {\n          context = deepGet(context, contextPath);\n        }\n        if (context == null) return void 0;\n        method = context[path];\n      }\n      return method == null ? method : method.apply(context, args);\n    });\n  });\n\n  // Convenience version of a common use case of `map`: fetching a property.\n  _.pluck = function(obj, key) {\n    return _.map(obj, _.property(key));\n  };\n\n  // Convenience version of a common use case of `filter`: selecting only objects\n  // containing specific `key:value` pairs.\n  _.where = function(obj, attrs) {\n    return _.filter(obj, _.matcher(attrs));\n  };\n\n  // Convenience version of a common use case of `find`: getting the first object\n  // containing specific `key:value` pairs.\n  _.findWhere = function(obj, attrs) {\n    return _.find(obj, _.matcher(attrs));\n  };\n\n  // Return the maximum element (or element-based computation).\n  _.max = function(obj, iteratee, context) {\n    var result = -Infinity, lastComputed = -Infinity,\n        value, computed;\n    if (iteratee == null || typeof iteratee == 'number' && typeof obj[0] != 'object' && obj != null) {\n      obj = isArrayLike(obj) ? obj : _.values(obj);\n      for (var i = 0, length = obj.length; i < length; i++) {\n        value = obj[i];\n        if (value != null && value > result) {\n          result = value;\n        }\n      }\n    } else {\n      iteratee = cb(iteratee, context);\n      _.each(obj, function(v, index, list) {\n        computed = iteratee(v, index, list);\n        if (computed > lastComputed || computed === -Infinity && result === -Infinity) {\n          result = v;\n          lastComputed = computed;\n        }\n      });\n    }\n    return result;\n  };\n\n  // Return the minimum element (or element-based computation).\n  _.min = function(obj, iteratee, context) {\n    var result = Infinity, lastComputed = Infinity,\n        value, computed;\n    if (iteratee == null || typeof iteratee == 'number' && typeof obj[0] != 'object' && obj != null) {\n      obj = isArrayLike(obj) ? obj : _.values(obj);\n      for (var i = 0, length = obj.length; i < length; i++) {\n        value = obj[i];\n        if (value != null && value < result) {\n          result = value;\n        }\n      }\n    } else {\n      iteratee = cb(iteratee, context);\n      _.each(obj, function(v, index, list) {\n        computed = iteratee(v, index, list);\n        if (computed < lastComputed || computed === Infinity && result === Infinity) {\n          result = v;\n          lastComputed = computed;\n        }\n      });\n    }\n    return result;\n  };\n\n  // Shuffle a collection.\n  _.shuffle = function(obj) {\n    return _.sample(obj, Infinity);\n  };\n\n  // Sample **n** random values from a collection using the modern version of the\n  // [Fisher-Yates shuffle](http://en.wikipedia.org/wiki/Fisher–Yates_shuffle).\n  // If **n** is not specified, returns a single random element.\n  // The internal `guard` argument allows it to work with `map`.\n  _.sample = function(obj, n, guard) {\n    if (n == null || guard) {\n      if (!isArrayLike(obj)) obj = _.values(obj);\n      return obj[_.random(obj.length - 1)];\n    }\n    var sample = isArrayLike(obj) ? _.clone(obj) : _.values(obj);\n    var length = getLength(sample);\n    n = Math.max(Math.min(n, length), 0);\n    var last = length - 1;\n    for (var index = 0; index < n; index++) {\n      var rand = _.random(index, last);\n      var temp = sample[index];\n      sample[index] = sample[rand];\n      sample[rand] = temp;\n    }\n    return sample.slice(0, n);\n  };\n\n  // Sort the object's values by a criterion produced by an iteratee.\n  _.sortBy = function(obj, iteratee, context) {\n    var index = 0;\n    iteratee = cb(iteratee, context);\n    return _.pluck(_.map(obj, function(value, key, list) {\n      return {\n        value: value,\n        index: index++,\n        criteria: iteratee(value, key, list)\n      };\n    }).sort(function(left, right) {\n      var a = left.criteria;\n      var b = right.criteria;\n      if (a !== b) {\n        if (a > b || a === void 0) return 1;\n        if (a < b || b === void 0) return -1;\n      }\n      return left.index - right.index;\n    }), 'value');\n  };\n\n  // An internal function used for aggregate \"group by\" operations.\n  var group = function(behavior, partition) {\n    return function(obj, iteratee, context) {\n      var result = partition ? [[], []] : {};\n      iteratee = cb(iteratee, context);\n      _.each(obj, function(value, index) {\n        var key = iteratee(value, index, obj);\n        behavior(result, value, key);\n      });\n      return result;\n    };\n  };\n\n  // Groups the object's values by a criterion. Pass either a string attribute\n  // to group by, or a function that returns the criterion.\n  _.groupBy = group(function(result, value, key) {\n    if (has(result, key)) result[key].push(value); else result[key] = [value];\n  });\n\n  // Indexes the object's values by a criterion, similar to `groupBy`, but for\n  // when you know that your index values will be unique.\n  _.indexBy = group(function(result, value, key) {\n    result[key] = value;\n  });\n\n  // Counts instances of an object that group by a certain criterion. Pass\n  // either a string attribute to count by, or a function that returns the\n  // criterion.\n  _.countBy = group(function(result, value, key) {\n    if (has(result, key)) result[key]++; else result[key] = 1;\n  });\n\n  var reStrSymbol = /[^\\ud800-\\udfff]|[\\ud800-\\udbff][\\udc00-\\udfff]|[\\ud800-\\udfff]/g;\n  // Safely create a real, live array from anything iterable.\n  _.toArray = function(obj) {\n    if (!obj) return [];\n    if (_.isArray(obj)) return slice.call(obj);\n    if (_.isString(obj)) {\n      // Keep surrogate pair characters together\n      return obj.match(reStrSymbol);\n    }\n    if (isArrayLike(obj)) return _.map(obj, _.identity);\n    return _.values(obj);\n  };\n\n  // Return the number of elements in an object.\n  _.size = function(obj) {\n    if (obj == null) return 0;\n    return isArrayLike(obj) ? obj.length : _.keys(obj).length;\n  };\n\n  // Split a collection into two arrays: one whose elements all satisfy the given\n  // predicate, and one whose elements all do not satisfy the predicate.\n  _.partition = group(function(result, value, pass) {\n    result[pass ? 0 : 1].push(value);\n  }, true);\n\n  // Array Functions\n  // ---------------\n\n  // Get the first element of an array. Passing **n** will return the first N\n  // values in the array. Aliased as `head` and `take`. The **guard** check\n  // allows it to work with `_.map`.\n  _.first = _.head = _.take = function(array, n, guard) {\n    if (array == null || array.length < 1) return n == null ? void 0 : [];\n    if (n == null || guard) return array[0];\n    return _.initial(array, array.length - n);\n  };\n\n  // Returns everything but the last entry of the array. Especially useful on\n  // the arguments object. Passing **n** will return all the values in\n  // the array, excluding the last N.\n  _.initial = function(array, n, guard) {\n    return slice.call(array, 0, Math.max(0, array.length - (n == null || guard ? 1 : n)));\n  };\n\n  // Get the last element of an array. Passing **n** will return the last N\n  // values in the array.\n  _.last = function(array, n, guard) {\n    if (array == null || array.length < 1) return n == null ? void 0 : [];\n    if (n == null || guard) return array[array.length - 1];\n    return _.rest(array, Math.max(0, array.length - n));\n  };\n\n  // Returns everything but the first entry of the array. Aliased as `tail` and `drop`.\n  // Especially useful on the arguments object. Passing an **n** will return\n  // the rest N values in the array.\n  _.rest = _.tail = _.drop = function(array, n, guard) {\n    return slice.call(array, n == null || guard ? 1 : n);\n  };\n\n  // Trim out all falsy values from an array.\n  _.compact = function(array) {\n    return _.filter(array, Boolean);\n  };\n\n  // Internal implementation of a recursive `flatten` function.\n  var flatten = function(input, shallow, strict, output) {\n    output = output || [];\n    var idx = output.length;\n    for (var i = 0, length = getLength(input); i < length; i++) {\n      var value = input[i];\n      if (isArrayLike(value) && (_.isArray(value) || _.isArguments(value))) {\n        // Flatten current level of array or arguments object.\n        if (shallow) {\n          var j = 0, len = value.length;\n          while (j < len) output[idx++] = value[j++];\n        } else {\n          flatten(value, shallow, strict, output);\n          idx = output.length;\n        }\n      } else if (!strict) {\n        output[idx++] = value;\n      }\n    }\n    return output;\n  };\n\n  // Flatten out an array, either recursively (by default), or just one level.\n  _.flatten = function(array, shallow) {\n    return flatten(array, shallow, false);\n  };\n\n  // Return a version of the array that does not contain the specified value(s).\n  _.without = restArguments(function(array, otherArrays) {\n    return _.difference(array, otherArrays);\n  });\n\n  // Produce a duplicate-free version of the array. If the array has already\n  // been sorted, you have the option of using a faster algorithm.\n  // The faster algorithm will not work with an iteratee if the iteratee\n  // is not a one-to-one function, so providing an iteratee will disable\n  // the faster algorithm.\n  // Aliased as `unique`.\n  _.uniq = _.unique = function(array, isSorted, iteratee, context) {\n    if (!_.isBoolean(isSorted)) {\n      context = iteratee;\n      iteratee = isSorted;\n      isSorted = false;\n    }\n    if (iteratee != null) iteratee = cb(iteratee, context);\n    var result = [];\n    var seen = [];\n    for (var i = 0, length = getLength(array); i < length; i++) {\n      var value = array[i],\n          computed = iteratee ? iteratee(value, i, array) : value;\n      if (isSorted && !iteratee) {\n        if (!i || seen !== computed) result.push(value);\n        seen = computed;\n      } else if (iteratee) {\n        if (!_.contains(seen, computed)) {\n          seen.push(computed);\n          result.push(value);\n        }\n      } else if (!_.contains(result, value)) {\n        result.push(value);\n      }\n    }\n    return result;\n  };\n\n  // Produce an array that contains the union: each distinct element from all of\n  // the passed-in arrays.\n  _.union = restArguments(function(arrays) {\n    return _.uniq(flatten(arrays, true, true));\n  });\n\n  // Produce an array that contains every item shared between all the\n  // passed-in arrays.\n  _.intersection = function(array) {\n    var result = [];\n    var argsLength = arguments.length;\n    for (var i = 0, length = getLength(array); i < length; i++) {\n      var item = array[i];\n      if (_.contains(result, item)) continue;\n      var j;\n      for (j = 1; j < argsLength; j++) {\n        if (!_.contains(arguments[j], item)) break;\n      }\n      if (j === argsLength) result.push(item);\n    }\n    return result;\n  };\n\n  // Take the difference between one array and a number of other arrays.\n  // Only the elements present in just the first array will remain.\n  _.difference = restArguments(function(array, rest) {\n    rest = flatten(rest, true, true);\n    return _.filter(array, function(value){\n      return !_.contains(rest, value);\n    });\n  });\n\n  // Complement of _.zip. Unzip accepts an array of arrays and groups\n  // each array's elements on shared indices.\n  _.unzip = function(array) {\n    var length = array && _.max(array, getLength).length || 0;\n    var result = Array(length);\n\n    for (var index = 0; index < length; index++) {\n      result[index] = _.pluck(array, index);\n    }\n    return result;\n  };\n\n  // Zip together multiple lists into a single array -- elements that share\n  // an index go together.\n  _.zip = restArguments(_.unzip);\n\n  // Converts lists into objects. Pass either a single array of `[key, value]`\n  // pairs, or two parallel arrays of the same length -- one of keys, and one of\n  // the corresponding values. Passing by pairs is the reverse of _.pairs.\n  _.object = function(list, values) {\n    var result = {};\n    for (var i = 0, length = getLength(list); i < length; i++) {\n      if (values) {\n        result[list[i]] = values[i];\n      } else {\n        result[list[i][0]] = list[i][1];\n      }\n    }\n    return result;\n  };\n\n  // Generator function to create the findIndex and findLastIndex functions.\n  var createPredicateIndexFinder = function(dir) {\n    return function(array, predicate, context) {\n      predicate = cb(predicate, context);\n      var length = getLength(array);\n      var index = dir > 0 ? 0 : length - 1;\n      for (; index >= 0 && index < length; index += dir) {\n        if (predicate(array[index], index, array)) return index;\n      }\n      return -1;\n    };\n  };\n\n  // Returns the first index on an array-like that passes a predicate test.\n  _.findIndex = createPredicateIndexFinder(1);\n  _.findLastIndex = createPredicateIndexFinder(-1);\n\n  // Use a comparator function to figure out the smallest index at which\n  // an object should be inserted so as to maintain order. Uses binary search.\n  _.sortedIndex = function(array, obj, iteratee, context) {\n    iteratee = cb(iteratee, context, 1);\n    var value = iteratee(obj);\n    var low = 0, high = getLength(array);\n    while (low < high) {\n      var mid = Math.floor((low + high) / 2);\n      if (iteratee(array[mid]) < value) low = mid + 1; else high = mid;\n    }\n    return low;\n  };\n\n  // Generator function to create the indexOf and lastIndexOf functions.\n  var createIndexFinder = function(dir, predicateFind, sortedIndex) {\n    return function(array, item, idx) {\n      var i = 0, length = getLength(array);\n      if (typeof idx == 'number') {\n        if (dir > 0) {\n          i = idx >= 0 ? idx : Math.max(idx + length, i);\n        } else {\n          length = idx >= 0 ? Math.min(idx + 1, length) : idx + length + 1;\n        }\n      } else if (sortedIndex && idx && length) {\n        idx = sortedIndex(array, item);\n        return array[idx] === item ? idx : -1;\n      }\n      if (item !== item) {\n        idx = predicateFind(slice.call(array, i, length), _.isNaN);\n        return idx >= 0 ? idx + i : -1;\n      }\n      for (idx = dir > 0 ? i : length - 1; idx >= 0 && idx < length; idx += dir) {\n        if (array[idx] === item) return idx;\n      }\n      return -1;\n    };\n  };\n\n  // Return the position of the first occurrence of an item in an array,\n  // or -1 if the item is not included in the array.\n  // If the array is large and already in sort order, pass `true`\n  // for **isSorted** to use binary search.\n  _.indexOf = createIndexFinder(1, _.findIndex, _.sortedIndex);\n  _.lastIndexOf = createIndexFinder(-1, _.findLastIndex);\n\n  // Generate an integer Array containing an arithmetic progression. A port of\n  // the native Python `range()` function. See\n  // [the Python documentation](http://docs.python.org/library/functions.html#range).\n  _.range = function(start, stop, step) {\n    if (stop == null) {\n      stop = start || 0;\n      start = 0;\n    }\n    if (!step) {\n      step = stop < start ? -1 : 1;\n    }\n\n    var length = Math.max(Math.ceil((stop - start) / step), 0);\n    var range = Array(length);\n\n    for (var idx = 0; idx < length; idx++, start += step) {\n      range[idx] = start;\n    }\n\n    return range;\n  };\n\n  // Chunk a single array into multiple arrays, each containing `count` or fewer\n  // items.\n  _.chunk = function(array, count) {\n    if (count == null || count < 1) return [];\n    var result = [];\n    var i = 0, length = array.length;\n    while (i < length) {\n      result.push(slice.call(array, i, i += count));\n    }\n    return result;\n  };\n\n  // Function (ahem) Functions\n  // ------------------\n\n  // Determines whether to execute a function as a constructor\n  // or a normal function with the provided arguments.\n  var executeBound = function(sourceFunc, boundFunc, context, callingContext, args) {\n    if (!(callingContext instanceof boundFunc)) return sourceFunc.apply(context, args);\n    var self = baseCreate(sourceFunc.prototype);\n    var result = sourceFunc.apply(self, args);\n    if (_.isObject(result)) return result;\n    return self;\n  };\n\n  // Create a function bound to a given object (assigning `this`, and arguments,\n  // optionally). Delegates to **ECMAScript 5**'s native `Function.bind` if\n  // available.\n  _.bind = restArguments(function(func, context, args) {\n    if (!_.isFunction(func)) throw new TypeError('Bind must be called on a function');\n    var bound = restArguments(function(callArgs) {\n      return executeBound(func, bound, context, this, args.concat(callArgs));\n    });\n    return bound;\n  });\n\n  // Partially apply a function by creating a version that has had some of its\n  // arguments pre-filled, without changing its dynamic `this` context. _ acts\n  // as a placeholder by default, allowing any combination of arguments to be\n  // pre-filled. Set `_.partial.placeholder` for a custom placeholder argument.\n  _.partial = restArguments(function(func, boundArgs) {\n    var placeholder = _.partial.placeholder;\n    var bound = function() {\n      var position = 0, length = boundArgs.length;\n      var args = Array(length);\n      for (var i = 0; i < length; i++) {\n        args[i] = boundArgs[i] === placeholder ? arguments[position++] : boundArgs[i];\n      }\n      while (position < arguments.length) args.push(arguments[position++]);\n      return executeBound(func, bound, this, this, args);\n    };\n    return bound;\n  });\n\n  _.partial.placeholder = _;\n\n  // Bind a number of an object's methods to that object. Remaining arguments\n  // are the method names to be bound. Useful for ensuring that all callbacks\n  // defined on an object belong to it.\n  _.bindAll = restArguments(function(obj, keys) {\n    keys = flatten(keys, false, false);\n    var index = keys.length;\n    if (index < 1) throw new Error('bindAll must be passed function names');\n    while (index--) {\n      var key = keys[index];\n      obj[key] = _.bind(obj[key], obj);\n    }\n  });\n\n  // Memoize an expensive function by storing its results.\n  _.memoize = function(func, hasher) {\n    var memoize = function(key) {\n      var cache = memoize.cache;\n      var address = '' + (hasher ? hasher.apply(this, arguments) : key);\n      if (!has(cache, address)) cache[address] = func.apply(this, arguments);\n      return cache[address];\n    };\n    memoize.cache = {};\n    return memoize;\n  };\n\n  // Delays a function for the given number of milliseconds, and then calls\n  // it with the arguments supplied.\n  _.delay = restArguments(function(func, wait, args) {\n    return setTimeout(function() {\n      return func.apply(null, args);\n    }, wait);\n  });\n\n  // Defers a function, scheduling it to run after the current call stack has\n  // cleared.\n  _.defer = _.partial(_.delay, _, 1);\n\n  // Returns a function, that, when invoked, will only be triggered at most once\n  // during a given window of time. Normally, the throttled function will run\n  // as much as it can, without ever going more than once per `wait` duration;\n  // but if you'd like to disable the execution on the leading edge, pass\n  // `{leading: false}`. To disable execution on the trailing edge, ditto.\n  _.throttle = function(func, wait, options) {\n    var timeout, context, args, result;\n    var previous = 0;\n    if (!options) options = {};\n\n    var later = function() {\n      previous = options.leading === false ? 0 : _.now();\n      timeout = null;\n      result = func.apply(context, args);\n      if (!timeout) context = args = null;\n    };\n\n    var throttled = function() {\n      var now = _.now();\n      if (!previous && options.leading === false) previous = now;\n      var remaining = wait - (now - previous);\n      context = this;\n      args = arguments;\n      if (remaining <= 0 || remaining > wait) {\n        if (timeout) {\n          clearTimeout(timeout);\n          timeout = null;\n        }\n        previous = now;\n        result = func.apply(context, args);\n        if (!timeout) context = args = null;\n      } else if (!timeout && options.trailing !== false) {\n        timeout = setTimeout(later, remaining);\n      }\n      return result;\n    };\n\n    throttled.cancel = function() {\n      clearTimeout(timeout);\n      previous = 0;\n      timeout = context = args = null;\n    };\n\n    return throttled;\n  };\n\n  // Returns a function, that, as long as it continues to be invoked, will not\n  // be triggered. The function will be called after it stops being called for\n  // N milliseconds. If `immediate` is passed, trigger the function on the\n  // leading edge, instead of the trailing.\n  _.debounce = function(func, wait, immediate) {\n    var timeout, result;\n\n    var later = function(context, args) {\n      timeout = null;\n      if (args) result = func.apply(context, args);\n    };\n\n    var debounced = restArguments(function(args) {\n      if (timeout) clearTimeout(timeout);\n      if (immediate) {\n        var callNow = !timeout;\n        timeout = setTimeout(later, wait);\n        if (callNow) result = func.apply(this, args);\n      } else {\n        timeout = _.delay(later, wait, this, args);\n      }\n\n      return result;\n    });\n\n    debounced.cancel = function() {\n      clearTimeout(timeout);\n      timeout = null;\n    };\n\n    return debounced;\n  };\n\n  // Returns the first function passed as an argument to the second,\n  // allowing you to adjust arguments, run code before and after, and\n  // conditionally execute the original function.\n  _.wrap = function(func, wrapper) {\n    return _.partial(wrapper, func);\n  };\n\n  // Returns a negated version of the passed-in predicate.\n  _.negate = function(predicate) {\n    return function() {\n      return !predicate.apply(this, arguments);\n    };\n  };\n\n  // Returns a function that is the composition of a list of functions, each\n  // consuming the return value of the function that follows.\n  _.compose = function() {\n    var args = arguments;\n    var start = args.length - 1;\n    return function() {\n      var i = start;\n      var result = args[start].apply(this, arguments);\n      while (i--) result = args[i].call(this, result);\n      return result;\n    };\n  };\n\n  // Returns a function that will only be executed on and after the Nth call.\n  _.after = function(times, func) {\n    return function() {\n      if (--times < 1) {\n        return func.apply(this, arguments);\n      }\n    };\n  };\n\n  // Returns a function that will only be executed up to (but not including) the Nth call.\n  _.before = function(times, func) {\n    var memo;\n    return function() {\n      if (--times > 0) {\n        memo = func.apply(this, arguments);\n      }\n      if (times <= 1) func = null;\n      return memo;\n    };\n  };\n\n  // Returns a function that will be executed at most one time, no matter how\n  // often you call it. Useful for lazy initialization.\n  _.once = _.partial(_.before, 2);\n\n  _.restArguments = restArguments;\n\n  // Object Functions\n  // ----------------\n\n  // Keys in IE < 9 that won't be iterated by `for key in ...` and thus missed.\n  var hasEnumBug = !{toString: null}.propertyIsEnumerable('toString');\n  var nonEnumerableProps = ['valueOf', 'isPrototypeOf', 'toString',\n    'propertyIsEnumerable', 'hasOwnProperty', 'toLocaleString'];\n\n  var collectNonEnumProps = function(obj, keys) {\n    var nonEnumIdx = nonEnumerableProps.length;\n    var constructor = obj.constructor;\n    var proto = _.isFunction(constructor) && constructor.prototype || ObjProto;\n\n    // Constructor is a special case.\n    var prop = 'constructor';\n    if (has(obj, prop) && !_.contains(keys, prop)) keys.push(prop);\n\n    while (nonEnumIdx--) {\n      prop = nonEnumerableProps[nonEnumIdx];\n      if (prop in obj && obj[prop] !== proto[prop] && !_.contains(keys, prop)) {\n        keys.push(prop);\n      }\n    }\n  };\n\n  // Retrieve the names of an object's own properties.\n  // Delegates to **ECMAScript 5**'s native `Object.keys`.\n  _.keys = function(obj) {\n    if (!_.isObject(obj)) return [];\n    if (nativeKeys) return nativeKeys(obj);\n    var keys = [];\n    for (var key in obj) if (has(obj, key)) keys.push(key);\n    // Ahem, IE < 9.\n    if (hasEnumBug) collectNonEnumProps(obj, keys);\n    return keys;\n  };\n\n  // Retrieve all the property names of an object.\n  _.allKeys = function(obj) {\n    if (!_.isObject(obj)) return [];\n    var keys = [];\n    for (var key in obj) keys.push(key);\n    // Ahem, IE < 9.\n    if (hasEnumBug) collectNonEnumProps(obj, keys);\n    return keys;\n  };\n\n  // Retrieve the values of an object's properties.\n  _.values = function(obj) {\n    var keys = _.keys(obj);\n    var length = keys.length;\n    var values = Array(length);\n    for (var i = 0; i < length; i++) {\n      values[i] = obj[keys[i]];\n    }\n    return values;\n  };\n\n  // Returns the results of applying the iteratee to each element of the object.\n  // In contrast to _.map it returns an object.\n  _.mapObject = function(obj, iteratee, context) {\n    iteratee = cb(iteratee, context);\n    var keys = _.keys(obj),\n        length = keys.length,\n        results = {};\n    for (var index = 0; index < length; index++) {\n      var currentKey = keys[index];\n      results[currentKey] = iteratee(obj[currentKey], currentKey, obj);\n    }\n    return results;\n  };\n\n  // Convert an object into a list of `[key, value]` pairs.\n  // The opposite of _.object.\n  _.pairs = function(obj) {\n    var keys = _.keys(obj);\n    var length = keys.length;\n    var pairs = Array(length);\n    for (var i = 0; i < length; i++) {\n      pairs[i] = [keys[i], obj[keys[i]]];\n    }\n    return pairs;\n  };\n\n  // Invert the keys and values of an object. The values must be serializable.\n  _.invert = function(obj) {\n    var result = {};\n    var keys = _.keys(obj);\n    for (var i = 0, length = keys.length; i < length; i++) {\n      result[obj[keys[i]]] = keys[i];\n    }\n    return result;\n  };\n\n  // Return a sorted list of the function names available on the object.\n  // Aliased as `methods`.\n  _.functions = _.methods = function(obj) {\n    var names = [];\n    for (var key in obj) {\n      if (_.isFunction(obj[key])) names.push(key);\n    }\n    return names.sort();\n  };\n\n  // An internal function for creating assigner functions.\n  var createAssigner = function(keysFunc, defaults) {\n    return function(obj) {\n      var length = arguments.length;\n      if (defaults) obj = Object(obj);\n      if (length < 2 || obj == null) return obj;\n      for (var index = 1; index < length; index++) {\n        var source = arguments[index],\n            keys = keysFunc(source),\n            l = keys.length;\n        for (var i = 0; i < l; i++) {\n          var key = keys[i];\n          if (!defaults || obj[key] === void 0) obj[key] = source[key];\n        }\n      }\n      return obj;\n    };\n  };\n\n  // Extend a given object with all the properties in passed-in object(s).\n  _.extend = createAssigner(_.allKeys);\n\n  // Assigns a given object with all the own properties in the passed-in object(s).\n  // (https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object/assign)\n  _.extendOwn = _.assign = createAssigner(_.keys);\n\n  // Returns the first key on an object that passes a predicate test.\n  _.findKey = function(obj, predicate, context) {\n    predicate = cb(predicate, context);\n    var keys = _.keys(obj), key;\n    for (var i = 0, length = keys.length; i < length; i++) {\n      key = keys[i];\n      if (predicate(obj[key], key, obj)) return key;\n    }\n  };\n\n  // Internal pick helper function to determine if `obj` has key `key`.\n  var keyInObj = function(value, key, obj) {\n    return key in obj;\n  };\n\n  // Return a copy of the object only containing the whitelisted properties.\n  _.pick = restArguments(function(obj, keys) {\n    var result = {}, iteratee = keys[0];\n    if (obj == null) return result;\n    if (_.isFunction(iteratee)) {\n      if (keys.length > 1) iteratee = optimizeCb(iteratee, keys[1]);\n      keys = _.allKeys(obj);\n    } else {\n      iteratee = keyInObj;\n      keys = flatten(keys, false, false);\n      obj = Object(obj);\n    }\n    for (var i = 0, length = keys.length; i < length; i++) {\n      var key = keys[i];\n      var value = obj[key];\n      if (iteratee(value, key, obj)) result[key] = value;\n    }\n    return result;\n  });\n\n  // Return a copy of the object without the blacklisted properties.\n  _.omit = restArguments(function(obj, keys) {\n    var iteratee = keys[0], context;\n    if (_.isFunction(iteratee)) {\n      iteratee = _.negate(iteratee);\n      if (keys.length > 1) context = keys[1];\n    } else {\n      keys = _.map(flatten(keys, false, false), String);\n      iteratee = function(value, key) {\n        return !_.contains(keys, key);\n      };\n    }\n    return _.pick(obj, iteratee, context);\n  });\n\n  // Fill in a given object with default properties.\n  _.defaults = createAssigner(_.allKeys, true);\n\n  // Creates an object that inherits from the given prototype object.\n  // If additional properties are provided then they will be added to the\n  // created object.\n  _.create = function(prototype, props) {\n    var result = baseCreate(prototype);\n    if (props) _.extendOwn(result, props);\n    return result;\n  };\n\n  // Create a (shallow-cloned) duplicate of an object.\n  _.clone = function(obj) {\n    if (!_.isObject(obj)) return obj;\n    return _.isArray(obj) ? obj.slice() : _.extend({}, obj);\n  };\n\n  // Invokes interceptor with the obj, and then returns obj.\n  // The primary purpose of this method is to \"tap into\" a method chain, in\n  // order to perform operations on intermediate results within the chain.\n  _.tap = function(obj, interceptor) {\n    interceptor(obj);\n    return obj;\n  };\n\n  // Returns whether an object has a given set of `key:value` pairs.\n  _.isMatch = function(object, attrs) {\n    var keys = _.keys(attrs), length = keys.length;\n    if (object == null) return !length;\n    var obj = Object(object);\n    for (var i = 0; i < length; i++) {\n      var key = keys[i];\n      if (attrs[key] !== obj[key] || !(key in obj)) return false;\n    }\n    return true;\n  };\n\n\n  // Internal recursive comparison function for `isEqual`.\n  var eq, deepEq;\n  eq = function(a, b, aStack, bStack) {\n    // Identical objects are equal. `0 === -0`, but they aren't identical.\n    // See the [Harmony `egal` proposal](http://wiki.ecmascript.org/doku.php?id=harmony:egal).\n    if (a === b) return a !== 0 || 1 / a === 1 / b;\n    // `null` or `undefined` only equal to itself (strict comparison).\n    if (a == null || b == null) return false;\n    // `NaN`s are equivalent, but non-reflexive.\n    if (a !== a) return b !== b;\n    // Exhaust primitive checks\n    var type = typeof a;\n    if (type !== 'function' && type !== 'object' && typeof b != 'object') return false;\n    return deepEq(a, b, aStack, bStack);\n  };\n\n  // Internal recursive comparison function for `isEqual`.\n  deepEq = function(a, b, aStack, bStack) {\n    // Unwrap any wrapped objects.\n    if (a instanceof _) a = a._wrapped;\n    if (b instanceof _) b = b._wrapped;\n    // Compare `[[Class]]` names.\n    var className = toString.call(a);\n    if (className !== toString.call(b)) return false;\n    switch (className) {\n      // Strings, numbers, regular expressions, dates, and booleans are compared by value.\n      case '[object RegExp]':\n      // RegExps are coerced to strings for comparison (Note: '' + /a/i === '/a/i')\n      case '[object String]':\n        // Primitives and their corresponding object wrappers are equivalent; thus, `\"5\"` is\n        // equivalent to `new String(\"5\")`.\n        return '' + a === '' + b;\n      case '[object Number]':\n        // `NaN`s are equivalent, but non-reflexive.\n        // Object(NaN) is equivalent to NaN.\n        if (+a !== +a) return +b !== +b;\n        // An `egal` comparison is performed for other numeric values.\n        return +a === 0 ? 1 / +a === 1 / b : +a === +b;\n      case '[object Date]':\n      case '[object Boolean]':\n        // Coerce dates and booleans to numeric primitive values. Dates are compared by their\n        // millisecond representations. Note that invalid dates with millisecond representations\n        // of `NaN` are not equivalent.\n        return +a === +b;\n      case '[object Symbol]':\n        return SymbolProto.valueOf.call(a) === SymbolProto.valueOf.call(b);\n    }\n\n    var areArrays = className === '[object Array]';\n    if (!areArrays) {\n      if (typeof a != 'object' || typeof b != 'object') return false;\n\n      // Objects with different constructors are not equivalent, but `Object`s or `Array`s\n      // from different frames are.\n      var aCtor = a.constructor, bCtor = b.constructor;\n      if (aCtor !== bCtor && !(_.isFunction(aCtor) && aCtor instanceof aCtor &&\n                               _.isFunction(bCtor) && bCtor instanceof bCtor)\n                          && ('constructor' in a && 'constructor' in b)) {\n        return false;\n      }\n    }\n    // Assume equality for cyclic structures. The algorithm for detecting cyclic\n    // structures is adapted from ES 5.1 section 15.12.3, abstract operation `JO`.\n\n    // Initializing stack of traversed objects.\n    // It's done here since we only need them for objects and arrays comparison.\n    aStack = aStack || [];\n    bStack = bStack || [];\n    var length = aStack.length;\n    while (length--) {\n      // Linear search. Performance is inversely proportional to the number of\n      // unique nested structures.\n      if (aStack[length] === a) return bStack[length] === b;\n    }\n\n    // Add the first object to the stack of traversed objects.\n    aStack.push(a);\n    bStack.push(b);\n\n    // Recursively compare objects and arrays.\n    if (areArrays) {\n      // Compare array lengths to determine if a deep comparison is necessary.\n      length = a.length;\n      if (length !== b.length) return false;\n      // Deep compare the contents, ignoring non-numeric properties.\n      while (length--) {\n        if (!eq(a[length], b[length], aStack, bStack)) return false;\n      }\n    } else {\n      // Deep compare objects.\n      var keys = _.keys(a), key;\n      length = keys.length;\n      // Ensure that both objects contain the same number of properties before comparing deep equality.\n      if (_.keys(b).length !== length) return false;\n      while (length--) {\n        // Deep compare each member\n        key = keys[length];\n        if (!(has(b, key) && eq(a[key], b[key], aStack, bStack))) return false;\n      }\n    }\n    // Remove the first object from the stack of traversed objects.\n    aStack.pop();\n    bStack.pop();\n    return true;\n  };\n\n  // Perform a deep comparison to check if two objects are equal.\n  _.isEqual = function(a, b) {\n    return eq(a, b);\n  };\n\n  // Is a given array, string, or object empty?\n  // An \"empty\" object has no enumerable own-properties.\n  _.isEmpty = function(obj) {\n    if (obj == null) return true;\n    if (isArrayLike(obj) && (_.isArray(obj) || _.isString(obj) || _.isArguments(obj))) return obj.length === 0;\n    return _.keys(obj).length === 0;\n  };\n\n  // Is a given value a DOM element?\n  _.isElement = function(obj) {\n    return !!(obj && obj.nodeType === 1);\n  };\n\n  // Is a given value an array?\n  // Delegates to ECMA5's native Array.isArray\n  _.isArray = nativeIsArray || function(obj) {\n    return toString.call(obj) === '[object Array]';\n  };\n\n  // Is a given variable an object?\n  _.isObject = function(obj) {\n    var type = typeof obj;\n    return type === 'function' || type === 'object' && !!obj;\n  };\n\n  // Add some isType methods: isArguments, isFunction, isString, isNumber, isDate, isRegExp, isError, isMap, isWeakMap, isSet, isWeakSet.\n  _.each(['Arguments', 'Function', 'String', 'Number', 'Date', 'RegExp', 'Error', 'Symbol', 'Map', 'WeakMap', 'Set', 'WeakSet'], function(name) {\n    _['is' + name] = function(obj) {\n      return toString.call(obj) === '[object ' + name + ']';\n    };\n  });\n\n  // Define a fallback version of the method in browsers (ahem, IE < 9), where\n  // there isn't any inspectable \"Arguments\" type.\n  if (!_.isArguments(arguments)) {\n    _.isArguments = function(obj) {\n      return has(obj, 'callee');\n    };\n  }\n\n  // Optimize `isFunction` if appropriate. Work around some typeof bugs in old v8,\n  // IE 11 (#1621), Safari 8 (#1929), and PhantomJS (#2236).\n  var nodelist = root.document && root.document.childNodes;\n  if ( true && typeof Int8Array != 'object' && typeof nodelist != 'function') {\n    _.isFunction = function(obj) {\n      return typeof obj == 'function' || false;\n    };\n  }\n\n  // Is a given object a finite number?\n  _.isFinite = function(obj) {\n    return !_.isSymbol(obj) && isFinite(obj) && !isNaN(parseFloat(obj));\n  };\n\n  // Is the given value `NaN`?\n  _.isNaN = function(obj) {\n    return _.isNumber(obj) && isNaN(obj);\n  };\n\n  // Is a given value a boolean?\n  _.isBoolean = function(obj) {\n    return obj === true || obj === false || toString.call(obj) === '[object Boolean]';\n  };\n\n  // Is a given value equal to null?\n  _.isNull = function(obj) {\n    return obj === null;\n  };\n\n  // Is a given variable undefined?\n  _.isUndefined = function(obj) {\n    return obj === void 0;\n  };\n\n  // Shortcut function for checking if an object has a given property directly\n  // on itself (in other words, not on a prototype).\n  _.has = function(obj, path) {\n    if (!_.isArray(path)) {\n      return has(obj, path);\n    }\n    var length = path.length;\n    for (var i = 0; i < length; i++) {\n      var key = path[i];\n      if (obj == null || !hasOwnProperty.call(obj, key)) {\n        return false;\n      }\n      obj = obj[key];\n    }\n    return !!length;\n  };\n\n  // Utility Functions\n  // -----------------\n\n  // Run Underscore.js in *noConflict* mode, returning the `_` variable to its\n  // previous owner. Returns a reference to the Underscore object.\n  _.noConflict = function() {\n    root._ = previousUnderscore;\n    return this;\n  };\n\n  // Keep the identity function around for default iteratees.\n  _.identity = function(value) {\n    return value;\n  };\n\n  // Predicate-generating functions. Often useful outside of Underscore.\n  _.constant = function(value) {\n    return function() {\n      return value;\n    };\n  };\n\n  _.noop = function(){};\n\n  // Creates a function that, when passed an object, will traverse that object’s\n  // properties down the given `path`, specified as an array of keys or indexes.\n  _.property = function(path) {\n    if (!_.isArray(path)) {\n      return shallowProperty(path);\n    }\n    return function(obj) {\n      return deepGet(obj, path);\n    };\n  };\n\n  // Generates a function for a given object that returns a given property.\n  _.propertyOf = function(obj) {\n    if (obj == null) {\n      return function(){};\n    }\n    return function(path) {\n      return !_.isArray(path) ? obj[path] : deepGet(obj, path);\n    };\n  };\n\n  // Returns a predicate for checking whether an object has a given set of\n  // `key:value` pairs.\n  _.matcher = _.matches = function(attrs) {\n    attrs = _.extendOwn({}, attrs);\n    return function(obj) {\n      return _.isMatch(obj, attrs);\n    };\n  };\n\n  // Run a function **n** times.\n  _.times = function(n, iteratee, context) {\n    var accum = Array(Math.max(0, n));\n    iteratee = optimizeCb(iteratee, context, 1);\n    for (var i = 0; i < n; i++) accum[i] = iteratee(i);\n    return accum;\n  };\n\n  // Return a random integer between min and max (inclusive).\n  _.random = function(min, max) {\n    if (max == null) {\n      max = min;\n      min = 0;\n    }\n    return min + Math.floor(Math.random() * (max - min + 1));\n  };\n\n  // A (possibly faster) way to get the current timestamp as an integer.\n  _.now = Date.now || function() {\n    return new Date().getTime();\n  };\n\n  // List of HTML entities for escaping.\n  var escapeMap = {\n    '&': '&amp;',\n    '<': '&lt;',\n    '>': '&gt;',\n    '\"': '&quot;',\n    \"'\": '&#x27;',\n    '`': '&#x60;'\n  };\n  var unescapeMap = _.invert(escapeMap);\n\n  // Functions for escaping and unescaping strings to/from HTML interpolation.\n  var createEscaper = function(map) {\n    var escaper = function(match) {\n      return map[match];\n    };\n    // Regexes for identifying a key that needs to be escaped.\n    var source = '(?:' + _.keys(map).join('|') + ')';\n    var testRegexp = RegExp(source);\n    var replaceRegexp = RegExp(source, 'g');\n    return function(string) {\n      string = string == null ? '' : '' + string;\n      return testRegexp.test(string) ? string.replace(replaceRegexp, escaper) : string;\n    };\n  };\n  _.escape = createEscaper(escapeMap);\n  _.unescape = createEscaper(unescapeMap);\n\n  // Traverses the children of `obj` along `path`. If a child is a function, it\n  // is invoked with its parent as context. Returns the value of the final\n  // child, or `fallback` if any child is undefined.\n  _.result = function(obj, path, fallback) {\n    if (!_.isArray(path)) path = [path];\n    var length = path.length;\n    if (!length) {\n      return _.isFunction(fallback) ? fallback.call(obj) : fallback;\n    }\n    for (var i = 0; i < length; i++) {\n      var prop = obj == null ? void 0 : obj[path[i]];\n      if (prop === void 0) {\n        prop = fallback;\n        i = length; // Ensure we don't continue iterating.\n      }\n      obj = _.isFunction(prop) ? prop.call(obj) : prop;\n    }\n    return obj;\n  };\n\n  // Generate a unique integer id (unique within the entire client session).\n  // Useful for temporary DOM ids.\n  var idCounter = 0;\n  _.uniqueId = function(prefix) {\n    var id = ++idCounter + '';\n    return prefix ? prefix + id : id;\n  };\n\n  // By default, Underscore uses ERB-style template delimiters, change the\n  // following template settings to use alternative delimiters.\n  _.templateSettings = {\n    evaluate: /<%([\\s\\S]+?)%>/g,\n    interpolate: /<%=([\\s\\S]+?)%>/g,\n    escape: /<%-([\\s\\S]+?)%>/g\n  };\n\n  // When customizing `templateSettings`, if you don't want to define an\n  // interpolation, evaluation or escaping regex, we need one that is\n  // guaranteed not to match.\n  var noMatch = /(.)^/;\n\n  // Certain characters need to be escaped so that they can be put into a\n  // string literal.\n  var escapes = {\n    \"'\": \"'\",\n    '\\\\': '\\\\',\n    '\\r': 'r',\n    '\\n': 'n',\n    '\\u2028': 'u2028',\n    '\\u2029': 'u2029'\n  };\n\n  var escapeRegExp = /\\\\|'|\\r|\\n|\\u2028|\\u2029/g;\n\n  var escapeChar = function(match) {\n    return '\\\\' + escapes[match];\n  };\n\n  // JavaScript micro-templating, similar to John Resig's implementation.\n  // Underscore templating handles arbitrary delimiters, preserves whitespace,\n  // and correctly escapes quotes within interpolated code.\n  // NB: `oldSettings` only exists for backwards compatibility.\n  _.template = function(text, settings, oldSettings) {\n    if (!settings && oldSettings) settings = oldSettings;\n    settings = _.defaults({}, settings, _.templateSettings);\n\n    // Combine delimiters into one regular expression via alternation.\n    var matcher = RegExp([\n      (settings.escape || noMatch).source,\n      (settings.interpolate || noMatch).source,\n      (settings.evaluate || noMatch).source\n    ].join('|') + '|$', 'g');\n\n    // Compile the template source, escaping string literals appropriately.\n    var index = 0;\n    var source = \"__p+='\";\n    text.replace(matcher, function(match, escape, interpolate, evaluate, offset) {\n      source += text.slice(index, offset).replace(escapeRegExp, escapeChar);\n      index = offset + match.length;\n\n      if (escape) {\n        source += \"'+\\n((__t=(\" + escape + \"))==null?'':_.escape(__t))+\\n'\";\n      } else if (interpolate) {\n        source += \"'+\\n((__t=(\" + interpolate + \"))==null?'':__t)+\\n'\";\n      } else if (evaluate) {\n        source += \"';\\n\" + evaluate + \"\\n__p+='\";\n      }\n\n      // Adobe VMs need the match returned to produce the correct offset.\n      return match;\n    });\n    source += \"';\\n\";\n\n    // If a variable is not specified, place data values in local scope.\n    if (!settings.variable) source = 'with(obj||{}){\\n' + source + '}\\n';\n\n    source = \"var __t,__p='',__j=Array.prototype.join,\" +\n      \"print=function(){__p+=__j.call(arguments,'');};\\n\" +\n      source + 'return __p;\\n';\n\n    var render;\n    try {\n      render = new Function(settings.variable || 'obj', '_', source);\n    } catch (e) {\n      e.source = source;\n      throw e;\n    }\n\n    var template = function(data) {\n      return render.call(this, data, _);\n    };\n\n    // Provide the compiled source as a convenience for precompilation.\n    var argument = settings.variable || 'obj';\n    template.source = 'function(' + argument + '){\\n' + source + '}';\n\n    return template;\n  };\n\n  // Add a \"chain\" function. Start chaining a wrapped Underscore object.\n  _.chain = function(obj) {\n    var instance = _(obj);\n    instance._chain = true;\n    return instance;\n  };\n\n  // OOP\n  // ---------------\n  // If Underscore is called as a function, it returns a wrapped object that\n  // can be used OO-style. This wrapper holds altered versions of all the\n  // underscore functions. Wrapped objects may be chained.\n\n  // Helper function to continue chaining intermediate results.\n  var chainResult = function(instance, obj) {\n    return instance._chain ? _(obj).chain() : obj;\n  };\n\n  // Add your own custom functions to the Underscore object.\n  _.mixin = function(obj) {\n    _.each(_.functions(obj), function(name) {\n      var func = _[name] = obj[name];\n      _.prototype[name] = function() {\n        var args = [this._wrapped];\n        push.apply(args, arguments);\n        return chainResult(this, func.apply(_, args));\n      };\n    });\n    return _;\n  };\n\n  // Add all of the Underscore functions to the wrapper object.\n  _.mixin(_);\n\n  // Add all mutator Array functions to the wrapper.\n  _.each(['pop', 'push', 'reverse', 'shift', 'sort', 'splice', 'unshift'], function(name) {\n    var method = ArrayProto[name];\n    _.prototype[name] = function() {\n      var obj = this._wrapped;\n      method.apply(obj, arguments);\n      if ((name === 'shift' || name === 'splice') && obj.length === 0) delete obj[0];\n      return chainResult(this, obj);\n    };\n  });\n\n  // Add all accessor Array functions to the wrapper.\n  _.each(['concat', 'join', 'slice'], function(name) {\n    var method = ArrayProto[name];\n    _.prototype[name] = function() {\n      return chainResult(this, method.apply(this._wrapped, arguments));\n    };\n  });\n\n  // Extracts the result from a wrapped and chained object.\n  _.prototype.value = function() {\n    return this._wrapped;\n  };\n\n  // Provide unwrapping proxy for some methods used in engine operations\n  // such as arithmetic and JSON stringification.\n  _.prototype.valueOf = _.prototype.toJSON = _.prototype.value;\n\n  _.prototype.toString = function() {\n    return String(this._wrapped);\n  };\n\n  // AMD registration happens at the end for compatibility with AMD loaders\n  // that may not enforce next-turn semantics on modules. Even though general\n  // practice for AMD registration is to be anonymous, underscore registers\n  // as a named module because, like jQuery, it is a base library that is\n  // popular enough to be bundled in a third party lib, but not be part of\n  // an AMD load request. Those cases could generate an error when an\n  // anonymous define() is called outside of a loader request.\n  if (true) {\n    !(__WEBPACK_AMD_DEFINE_ARRAY__ = [], __WEBPACK_AMD_DEFINE_RESULT__ = (function() {\n      return _;\n    }).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n  }\n}());\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\"), __webpack_require__(/*! ./../webpack/buildin/module.js */ \"./node_modules/webpack/buildin/module.js\")(module)))\n\n//# sourceURL=webpack:///./node_modules/underscore/underscore.js?");

/***/ }),

/***/ "./node_modules/webpack/buildin/global.js":
/*!***********************************!*\
  !*** (webpack)/buildin/global.js ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("var g;\n\n// This works in non-strict mode\ng = (function() {\n\treturn this;\n})();\n\ntry {\n\t// This works if eval is allowed (see CSP)\n\tg = g || new Function(\"return this\")();\n} catch (e) {\n\t// This works if the window reference is available\n\tif (typeof window === \"object\") g = window;\n}\n\n// g can still be undefined, but nothing to do about it...\n// We return undefined, instead of nothing here, so it's\n// easier to handle this case. if(!global) { ...}\n\nmodule.exports = g;\n\n\n//# sourceURL=webpack:///(webpack)/buildin/global.js?");

/***/ }),

/***/ "./node_modules/webpack/buildin/harmony-module.js":
/*!*******************************************!*\
  !*** (webpack)/buildin/harmony-module.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = function(originalModule) {\n\tif (!originalModule.webpackPolyfill) {\n\t\tvar module = Object.create(originalModule);\n\t\t// module.parent = undefined by default\n\t\tif (!module.children) module.children = [];\n\t\tObject.defineProperty(module, \"loaded\", {\n\t\t\tenumerable: true,\n\t\t\tget: function() {\n\t\t\t\treturn module.l;\n\t\t\t}\n\t\t});\n\t\tObject.defineProperty(module, \"id\", {\n\t\t\tenumerable: true,\n\t\t\tget: function() {\n\t\t\t\treturn module.i;\n\t\t\t}\n\t\t});\n\t\tObject.defineProperty(module, \"exports\", {\n\t\t\tenumerable: true\n\t\t});\n\t\tmodule.webpackPolyfill = 1;\n\t}\n\treturn module;\n};\n\n\n//# sourceURL=webpack:///(webpack)/buildin/harmony-module.js?");

/***/ }),

/***/ "./node_modules/webpack/buildin/module.js":
/*!***********************************!*\
  !*** (webpack)/buildin/module.js ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = function(module) {\n\tif (!module.webpackPolyfill) {\n\t\tmodule.deprecate = function() {};\n\t\tmodule.paths = [];\n\t\t// module.parent = undefined by default\n\t\tif (!module.children) module.children = [];\n\t\tObject.defineProperty(module, \"loaded\", {\n\t\t\tenumerable: true,\n\t\t\tget: function() {\n\t\t\t\treturn module.l;\n\t\t\t}\n\t\t});\n\t\tObject.defineProperty(module, \"id\", {\n\t\t\tenumerable: true,\n\t\t\tget: function() {\n\t\t\t\treturn module.i;\n\t\t\t}\n\t\t});\n\t\tmodule.webpackPolyfill = 1;\n\t}\n\treturn module;\n};\n\n\n//# sourceURL=webpack:///(webpack)/buildin/module.js?");

/***/ }),

/***/ "./src/javascript/components/CanvasComponent.js":
/*!******************************************************!*\
  !*** ./src/javascript/components/CanvasComponent.js ***!
  \******************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var underscore__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! underscore */ \"./node_modules/underscore/underscore.js\");\n/* harmony import */ var underscore__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(underscore__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var gsap_TweenMax__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! gsap/TweenMax */ \"./node_modules/gsap/TweenMax.js\");\n/* harmony import */ var _utils_Lerp_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/Lerp.js */ \"./src/javascript/utils/Lerp.js\");\n/* harmony import */ var _FaceRecognitionModule_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./FaceRecognitionModule.js */ \"./src/javascript/components/FaceRecognitionModule.js\");\n/* harmony import */ var dat_gui__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! dat.gui */ \"./node_modules/dat.gui/build/dat.gui.module.js\");\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\n\n\n\n\n //\n\nvar CanvasComponent =\n/*#__PURE__*/\nfunction () {\n  function CanvasComponent() {\n    _classCallCheck(this, CanvasComponent);\n\n    underscore__WEBPACK_IMPORTED_MODULE_0___default.a.bindAll(this, '_tickHandler', '_resizeHandler', '_mousemoveHandler');\n\n    this.ui = {\n      video: document.querySelector('video')\n    };\n    this._canvas = document.querySelector('.js-canvas-component');\n    this._canvas.style.background = 'black';\n    this._ctx = this._canvas.getContext('2d');\n    this.components = {\n      faceDetection: new _FaceRecognitionModule_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"]()\n    };\n    this._settings = {\n      limit: 200,\n      speed: 10,\n      shootInterval: 200,\n      fontSize: 20\n    };\n    var gui = new dat_gui__WEBPACK_IMPORTED_MODULE_4__[\"default\"].GUI();\n    gui.add(this._settings, 'limit', 100, 1000).step(1).onChange(this._initConfettis);\n    gui.add(this._settings, 'speed', 1, 100).step(1);\n    gui.add(this._settings, 'shootInterval', 10, 1000).step(1);\n    gui.add(this._settings, 'fontSize', 1, 500).step(1);\n    this._isMouseDetected = false;\n    this._mouseOpen = false;\n\n    this._setup();\n  }\n\n  _createClass(CanvasComponent, [{\n    key: \"_setup\",\n    value: function _setup() {\n      this._resize();\n\n      this._setupEventListener();\n    }\n  }, {\n    key: \"_resize\",\n    value: function _resize() {\n      this._width = 640;\n      this._height = 480; // this._width = window.innerWidth;\n      // this._height = window.innerHeight;\n\n      this._canvas.width = this._width;\n      this._canvas.height = this._height;\n    }\n  }, {\n    key: \"_getMouseBoudingBoxes\",\n    value: function _getMouseBoudingBoxes() {\n      if (!this._faceDescriptions) return;\n      var radius = 1.5;\n      this._mouseBoundingBoxes = [];\n\n      for (var n = 0; n < this._faceDescriptions.length; n++) {\n        var responsePositions = this._faceDescriptions[n].landmarks.positions;\n\n        for (var i = 0; i < responsePositions.length; i++) {\n          this._ctx.beginPath();\n\n          if (i == 0) {\n            this._ctx.moveTo(responsePositions[i].newX, responsePositions[i].y);\n          } else {\n            this._ctx.lineTo(responsePositions[i].newX, responsePositions[i].y);\n          }\n\n          this._ctx.closePath();\n\n          this._ctx.stroke();\n\n          this._ctx.beginPath();\n\n          this._ctx.fillStyle = '#04F802';\n\n          this._ctx.arc(responsePositions[i].newX, responsePositions[i].y, radius, 0, 2 * Math.PI);\n\n          this._ctx.closePath();\n\n          this._ctx.fill();\n        } //left: 48, right: 54, Top: 57, bottom: 50\n\n\n        var center = {\n          x: (responsePositions[54].newX - responsePositions[48].newX) / 2 + responsePositions[48].newX,\n          y: (responsePositions[57].y - responsePositions[50].y) / 2 + responsePositions[50].y\n        };\n        var top = {\n          x: responsePositions[57].newX,\n          y: responsePositions[57].y\n        };\n        var right = {\n          x: responsePositions[54].newX,\n          y: responsePositions[54].y\n        };\n        var bottom = {\n          x: responsePositions[50].newX,\n          y: responsePositions[50].y\n        };\n        var left = {\n          x: responsePositions[48].newX,\n          y: responsePositions[48].y\n        };\n\n        this._mouseBoundingBoxes.push({\n          center: center,\n          top: top,\n          right: right,\n          bottom: bottom,\n          left: left\n        });\n\n        this._ctx.beginPath();\n\n        this._ctx.fillStyle = 'red';\n\n        this._ctx.arc(center.x, center.y, 5, 0, 2 * Math.PI);\n\n        this._ctx.fill();\n\n        this._ctx.closePath();\n      }\n    }\n  }, {\n    key: \"_drawBackground\",\n    value: function _drawBackground() {\n      this._ctx.beginPath();\n\n      this._ctx.fillStyle = 'rgba(0, 0, 0, 0.1)';\n\n      this._ctx.fillRect(0, 0, this._canvas.width, this._canvas.width);\n\n      this._ctx.closePath();\n    }\n  }, {\n    key: \"_drawVideo\",\n    value: function _drawVideo() {\n      this._ctx.save();\n\n      this._ctx.setTransform(-1, 0, 0, 1, 0, 0);\n\n      this._ctx.globalAlpha = 0.8;\n\n      this._ctx.drawImage(this.ui.video, -this._width, 0);\n\n      this._ctx.setTransform(1, 0, 0, 1, 0, 0);\n\n      this._ctx.restore();\n    }\n  }, {\n    key: \"_draw\",\n    value: function _draw() {\n      this._drawBackground();\n\n      var detection = this.components.faceDetection.getFaceDescription(this._width, this._height);\n      this._faceDescriptions = this._reverseDetectionX(detection); // this._drawVideo();\n\n      this._getMouseBoudingBoxes();\n\n      this._ctx.globalAlpha = 1;\n    }\n  }, {\n    key: \"_reverseDetectionX\",\n    value: function _reverseDetectionX(detection) {\n      if (!detection) return;\n\n      for (var n = 0; n < detection.length; n++) {\n        for (var i = 0; i < detection[n].landmarks.positions.length; i++) {\n          var newPositionX = this._width / 2 + (this._width / 2 - detection[n].landmarks.positions[i].x);\n          detection[n].landmarks.positions[i].newX = newPositionX;\n        }\n      }\n\n      return detection;\n    }\n  }, {\n    key: \"_setupEventListener\",\n    value: function _setupEventListener() {\n      gsap_TweenMax__WEBPACK_IMPORTED_MODULE_1__[\"TweenLite\"].ticker.addEventListener('tick', this._tickHandler);\n      window.addEventListener('resize', this._resizeHandler);\n      window.addEventListener('mousemove', this._mousemoveHandler);\n    }\n  }, {\n    key: \"_tickHandler\",\n    value: function _tickHandler() {\n      this._draw();\n    }\n  }, {\n    key: \"_resizeHandler\",\n    value: function _resizeHandler() {\n      this._resize();\n    }\n  }, {\n    key: \"_mousemoveHandler\",\n    value: function _mousemoveHandler(e) {\n      this._mousePosition = {\n        x: e.clientX,\n        y: e.clientY\n      };\n    }\n  }]);\n\n  return CanvasComponent;\n}();\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (CanvasComponent);\n\n//# sourceURL=webpack:///./src/javascript/components/CanvasComponent.js?");

/***/ }),

/***/ "./src/javascript/components/FaceRecognitionModule.js":
/*!************************************************************!*\
  !*** ./src/javascript/components/FaceRecognitionModule.js ***!
  \************************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var face_api_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! face-api.js */ \"./node_modules/face-api.js/build/es6/index.js\");\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\n\nvar MODEL_URL = './assets/models';\nvar mtcnnForwardParams = {\n  maxNumScales: 10,\n  scaleFactor: 0.709,\n  scoreThresholds: [0.6, 0.7, 0.7],\n  minFaceSize: 200\n};\n\nvar FaceRecognitionModule =\n/*#__PURE__*/\nfunction () {\n  function FaceRecognitionModule() {\n    _classCallCheck(this, FaceRecognitionModule);\n\n    this._loadModels(); // this._draw();\n\n  }\n\n  _createClass(FaceRecognitionModule, [{\n    key: \"_loadModels\",\n    value: function _loadModels() {\n      var _this = this;\n\n      var promises = [face_api_js__WEBPACK_IMPORTED_MODULE_0__[\"nets\"].tinyFaceDetector.loadFromUri(MODEL_URL), face_api_js__WEBPACK_IMPORTED_MODULE_0__[\"nets\"].faceLandmark68Net.loadFromUri(MODEL_URL), face_api_js__WEBPACK_IMPORTED_MODULE_0__[\"nets\"].faceRecognitionNet.loadFromUri(MODEL_URL), face_api_js__WEBPACK_IMPORTED_MODULE_0__[\"nets\"].faceExpressionNet.loadFromUri(MODEL_URL)];\n      Promise.all(promises).then(function () {\n        _this._getCamera();\n      });\n    }\n  }, {\n    key: \"_getCamera\",\n    value: function _getCamera() {\n      var _this2 = this;\n\n      this._video = document.querySelector('.webcam-stream');\n      navigator.mediaDevices.getUserMedia({\n        video: true\n      }).then(function (stream) {\n        _this2._video.srcObject = stream;\n\n        _this2._detectFace();\n      });\n    }\n  }, {\n    key: \"_detectFace\",\n    value: function _detectFace() {\n      var _this3 = this;\n\n      face_api_js__WEBPACK_IMPORTED_MODULE_0__[\"detectAllFaces\"](this._video, new face_api_js__WEBPACK_IMPORTED_MODULE_0__[\"TinyFaceDetectorOptions\"]()).withFaceLandmarks().then(function (response) {\n        _this3._fullFaceDescriptions = response; // this._draw();\n      });\n      requestAnimationFrame(this._detectFace.bind(this));\n    } // _draw() {\n    //   this._canvas = document.querySelector('.js-canvas-component');\n    //   let displaySize = {\n    //     width: this._canvas.width,\n    //     height: this._canvas.height\n    //   };\n    //   const resizeDetection = FaceApi.resizeResults(\n    //     this._fullFaceDescriptions,\n    //     displaySize\n    //   );\n    //   this._canvas\n    //     .getContext('2d')\n    //     .clearRect(0, 0, displaySize.width, displaySize.height);\n    //   FaceApi.draw.drawDetections(this._canvas, resizeDetection);\n    //   FaceApi.draw.drawFaceLandmarks(this._canvas, resizeDetection);\n    // }\n\n  }, {\n    key: \"getFaceDescription\",\n    value: function getFaceDescription(width, height) {\n      if (!this._fullFaceDescriptions) return;\n      this._resizedFaceDescriptions = face_api_js__WEBPACK_IMPORTED_MODULE_0__[\"resizeResults\"](this._fullFaceDescriptions, {\n        width: width,\n        height: height\n      });\n      return this._resizedFaceDescriptions;\n    }\n  }]);\n\n  return FaceRecognitionModule;\n}();\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (FaceRecognitionModule);\n\n//# sourceURL=webpack:///./src/javascript/components/FaceRecognitionModule.js?");

/***/ }),

/***/ "./src/javascript/index.js":
/*!*********************************!*\
  !*** ./src/javascript/index.js ***!
  \*********************************/
/*! no exports provided */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _components_CanvasComponent_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./components/CanvasComponent.js */ \"./src/javascript/components/CanvasComponent.js\");\n // import FaceRecognitionModule from './components/FaceRecognitionModule';\n// import ScreenShotModule from './modules/ScreenShotModule';\n\nnew _components_CanvasComponent_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]();\n\n//# sourceURL=webpack:///./src/javascript/index.js?");

/***/ }),

/***/ "./src/javascript/utils/Lerp.js":
/*!**************************************!*\
  !*** ./src/javascript/utils/Lerp.js ***!
  \**************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"default\", function() { return Lerp; });\nfunction Lerp(start, end, value) {\n  return (1 - value) * start + value * end;\n}\n\n//# sourceURL=webpack:///./src/javascript/utils/Lerp.js?");

/***/ }),

/***/ 0:
/*!************************!*\
  !*** crypto (ignored) ***!
  \************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/* (ignored) */\n\n//# sourceURL=webpack:///crypto_(ignored)?");

/***/ }),

/***/ 1:
/*!****************************!*\
  !*** node-fetch (ignored) ***!
  \****************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/* (ignored) */\n\n//# sourceURL=webpack:///node-fetch_(ignored)?");

/***/ }),

/***/ 2:
/*!**********************!*\
  !*** util (ignored) ***!
  \**********************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/* (ignored) */\n\n//# sourceURL=webpack:///util_(ignored)?");

/***/ })

/******/ });